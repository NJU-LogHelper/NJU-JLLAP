171: Daniel Mitterdorfer, Error, CatchClause, logger.warn("Error while executing bulk request", ex);
59: javanna, debug, IfStmt, logger.debug("request [" + request.getMethod() + " " + host + getUri(request.getRequestLine()) + "] returned [" + httpResponse.getStatusLine() + "]");
65: Luca Cavanna, Warn, IfStmt, logger.warn(buildWarningMessage(request, host, warnings));
92: javanna, debug, IfStmt, logger.debug("request [" + request.getMethod() + " " + host + getUri(request.getRequestLine()) + "] failed", e);
475: javanna, trace, IfStmt, logger.trace("resurrecting host [" + deadHost + "]");
494: javanna, debug, IfStmt, logger.debug("removed host [" + host + "] from blacklist");
506: javanna, debug, IfStmt, logger.debug("added host [" + host + "] to blacklist");
511: javanna, debug, IfStmt, logger.debug("updated host [" + host + "] already in blacklist");
96: javanna, Trace, MethodDeclaration, String traceRequest = RequestLogger.buildTraceRequest(request, host);
143: javanna, Trace, MethodDeclaration, String traceResponse = RequestLogger.buildTraceResponse(httpResponse);
167: Luca Cavanna, Warn, MethodDeclaration, assertEquals(expected.toString(), RequestLogger.buildWarningMessage(request, host, warnings));
189: Luca Cavanna, error, ForeachStmt, logger.error("bulk failure", bulkFailure);
1033: olcbean, debug, MethodDeclaration, logger.debug("Executing bulk [{}] with {} requests", executionId, numberOfActions);
1043: olcbean, debug, IfStmt, logger.debug("Bulk [{}] completed in {} milliseconds", executionId, response.getTook().getMillis());
1041: Tanguy Leroux, warn, IfStmt, logger.warn("Bulk [{}] executed with failures", executionId);
1050: Tanguy Leroux, error, MethodDeclaration, logger.error("Failed to execute bulk", failure);
113: Luca Cavanna, trace, IfStmt, logger.trace("adding node [" + nodeId + "]");
150: Luca Cavanna, debug, IfStmt, logger.debug("skipping node [" + nodeId + "] with http disabled");
102: javanna, error, CatchClause, logger.error("error while scheduling next sniffer task", e);
99: javanna, debug, TryStmt, logger.debug("scheduling next sniff in " + delayMillis + " ms");
130: javanna, error, CatchClause, logger.error("error while sniffing nodes", e);
120: javanna, debug, TryStmt, logger.debug("sniffed hosts: " + sniffedHosts);
125: javanna, warn, IfStmt, logger.warn("no hosts to set, hosts will be updated at the next sniffing round");
53: Nik Everett, error, MethodDeclaration, logger.error("This failing test was generated by documentation starting at {}. It may include many snippets. " + "See docs/README.asciidoc for an explanation of test generation.", name);
61: Tim Brooks, error, MethodDeclaration, logger.error(new ParameterizedMessage("failed to register server channel: {}", context.getChannel()), exception);
81: Tim Brooks, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("exception while accepting new channel from server channel: {}", context.getChannel()), exception);
42: Tim Brooks, warn, MethodDeclaration, logger.warn(new ParameterizedMessage("io exception during select [thread={}]", Thread.currentThread().getName()), exception);
51: Tim Brooks, warn, MethodDeclaration, logger.warn(new ParameterizedMessage("io exception while closing selector [thread={}]", Thread.currentThread().getName()), exception);
86: Tim Brooks, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("exception while closing channel: {}", context.getChannel()), exception);
98: Tim Brooks, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("exception while handling event for channel: {}", channel.getChannel()), exception);
65: Tim Brooks, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("failed to register socket channel: {}", context.getChannel()), exception);
88: Tim Brooks, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("failed to connect to socket channel: {}", context.getChannel()), exception);
109: Tim Brooks, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("exception while reading from socket channel: {}", context.getChannel()), exception);
130: Tim Brooks, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("exception while writing to socket channel: {}", context.getChannel()), exception);
141: Tim Brooks, warn, MethodDeclaration, logger.warn(new ParameterizedMessage("exception while executing listener: {}", listener), exception);
202: Martijn van Groningen, info, MethodDeclaration, logger.info("Stopping");
115: Jason Tedor, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("Error running {}", template), e);
66: Nik Everett, info, MethodDeclaration, logger.info("Starting to write [index.asciidoc]");
86: Nik Everett, info, ForeachStmt, logger.info("Writing [{}.asciidoc]", type.name);
130: Nik Everett, info, MethodDeclaration, logger.info("Done writing [index.asciidoc]");
192: Yannick Welsch, info, ForeachStmt, logger.info("bucket={}", bucket.getKey());
195: Martijn van Groningen, info, ForeachStmt, logger.info("total_hits={}", topHits.getHits().getTotalHits());
197: Simon Willnauer, info, ForeachStmt, logger.info("hit= {} {} {}", searchHit.getSortValues()[0], searchHit.getType(), searchHit.getId());
261: Martijn van Groningen, info, ForStmt, logger.info("Round {}", i);
1742: Martijn van Groningen, info, ForeachStmt, logger.info("Testing with highlight type [{}]", highlightType);
373: Martijn van Groningen, info, ForeachStmt, logger.info("Test with document: {}" + document);
383: Martijn van Groningen, info, ForeachStmt, logger.info("Test with document: {}" + document);
1071: Martijn van Groningen, error, CatchClause, logger.error("topDocs.totalHits={}", topDocs.totalHits);
1072: Martijn van Groningen, error, CatchClause, logger.error("controlTopDocs.totalHits={}", controlTopDocs.totalHits);
1074: Martijn van Groningen, error, CatchClause, logger.error("topDocs.scoreDocs.length={}", topDocs.scoreDocs.length);
1075: Martijn van Groningen, error, CatchClause, logger.error("controlTopDocs.scoreDocs.length={}", controlTopDocs.scoreDocs.length);
1078: Martijn van Groningen, error, ForStmt, logger.error("topDocs.scoreDocs[{}].doc={}", i, topDocs.scoreDocs[i].doc);
1079: Martijn van Groningen, error, ForStmt, logger.error("topDocs.scoreDocs[{}].score={}", i, topDocs.scoreDocs[i].score);
1082: Martijn van Groningen, error, ForStmt, logger.error("controlTopDocs.scoreDocs[{}].doc={}", i, controlTopDocs.scoreDocs[i].doc);
1083: Martijn van Groningen, error, ForStmt, logger.error("controlTopDocs.scoreDocs[{}].score={}", i, controlTopDocs.scoreDocs[i].score);
1087: Martijn van Groningen, error, ForStmt, logger.error("controlTopDocs.scoreDocs[{}].query_to_string={}", i, queryToString);
1097: Martijn van Groningen, error, ForStmt, logger.error("controlTopDocs.scoreDocs[{}].query_terms_field={}", i, builder.toString());
1106: Martijn van Groningen, error, IfStmt, logger.error("controlTopDocs.scoreDocs[{}].minimum_should_match_field=[NO_VALUE]", i);
1103: Martijn van Groningen, error, IfStmt, logger.error("controlTopDocs.scoreDocs[{}].minimum_should_match_field={}", i, numericValues.longValue());
89: Martijn van Groningen, info, MethodDeclaration, logger.info("percolating empty doc");
97: Martijn van Groningen, info, MethodDeclaration, logger.info("percolating doc with 1 field");
109: Martijn van Groningen, info, MethodDeclaration, logger.info("percolating doc with 2 fields");
122: Martijn van Groningen, info, MethodDeclaration, logger.info("percolating doc with 2 fields");
196: Martijn van Groningen, info, MethodDeclaration, logger.info("response={}", response);
305: Martijn van Groningen, info, MethodDeclaration, logger.info("percolating empty doc");
312: Martijn van Groningen, info, MethodDeclaration, logger.info("percolating doc with 1 field");
321: Martijn van Groningen, info, MethodDeclaration, logger.info("percolating doc with 2 fields");
344: Alex Benusovich, info, MethodDeclaration, logger.info("percolating empty doc with source disabled");
487: Martijn van Groningen, info, MethodDeclaration, logger.info("searchResponse={}", searchResponse);
551: Martijn van Groningen, info, MethodDeclaration, logger.info("searchResponse={}", searchResponse);
241: Nik Everett, debug, MethodDeclaration, logger.debug("[{}]: starting", task.getId());
243: Nik Everett, debug, IfStmt, logger.debug("[{}]: finishing early because the task was cancelled", task.getId());
262: Nik Everett, debug, MethodDeclaration, logger.debug("[{}]: got scroll response with [{}] hits", task.getId(), response.getHits().size());
264: Nik Everett, debug, IfStmt, logger.debug("[{}]: finishing early because the task was cancelled", task.getId());
306: Nik Everett, debug, MethodDeclaration, logger.debug("[{}]: preparing bulk request", task.getId());
308: Nik Everett, debug, IfStmt, logger.debug("[{}]: finishing early because the task was cancelled", task.getId());
343: Nik Everett, debug, IfStmt, logger.debug("[{}]: sending [{}] entry, [{}] bulk request", task.getId(), request.requests().size(), new ByteSizeValue(request.estimatedSizeInBytes()));
347: Nik Everett, debug, IfStmt, logger.debug("[{}]: finishing early because the task was cancelled", task.getId());
397: Nik Everett, debug, IfStmt, logger.debug("[{}]: Finishing early because the task was cancelled", task.getId());
429: Nik Everett, debug, IfStmt, logger.debug("[{}]: finishing early because the task was cancelled", task.getId());
460: Nik Everett, debug, MethodDeclaration, logger.debug("[{}]: refreshing", task.getId());
480: Nik Everett, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("[{}]: finishing with a catastrophic failure", task.getId()), failure);
493: Nik Everett, debug, MethodDeclaration, logger.debug("[{}]: finishing without any catastrophic failures", task.getId());
294: Nik Everett, error, IfStmt, logger.error("Failed to properly stop client thread [{}]", thread.getName());
95: Andy Bristol, debug, IfStmt, logger.debug("children of task [{}] are already finished, nothing to rethrottle", task.getId());
86: Andy Bristol, debug, IfStmt, logger.debug("rethrottling children of task [{}] to [{}] requests per second", task.getId(), subRequest.getRequestsPerSecond());
102: Andy Bristol, debug, MethodDeclaration, logger.debug("rethrottling local task [{}] to [{}] requests per second", task.getId(), newRequestsPerSecond);
102: Nik Everett, debug, IfStmt, logger.debug("First response looks like a scan response. Jumping right to the second. scroll=[{}]", response.getScrollId());
122: Nik Everett, debug, MethodDeclaration, logger.debug("Successfully cleared [{}]", scrollId);
137: Nik Everett, debug, IfStmt, logger.debug((Supplier<?>) () -> new ParameterizedMessage("Failed to clear scroll [{}] from pre-2.0 Elasticsearch. This is normal if the request terminated " + "normally as the scroll has already been cleared automatically.", scrollId), e);
143: Nik Everett, warn, MethodDeclaration, logger.warn((Supplier<?>) () -> new ParameterizedMessage("Failed to clear scroll [{}]", scrollId), e);
158: Nik Everett, error, CatchClause, logger.error("Failed to shutdown the remote connection", e);
156: Nik Everett, debug, TryStmt, logger.debug("Shut down remote connection");
226: Simon Willnauer, trace, IfStmt, logger.trace((Supplier<?>) () -> new ParameterizedMessage("retrying rejected search after [{}]", delay), e);
96: Nik Everett, debug, MethodDeclaration, logger.debug("setting up [{}] docs", numDocs);
112: Nik Everett, debug, MethodDeclaration, logger.debug("chose to modify [{}] out of [{}] docs", numModifiedDocs, numDocs);
122: Nik Everett, debug, MethodDeclaration, logger.debug("waiting for updates to be blocked");
146: Nik Everett, debug, MethodDeclaration, logger.debug("asserting that parent is marked canceled {}", status);
154: Nik Everett, debug, IfStmt, logger.debug("finding at least one canceled child among {}", sliceList.getTasks());
164: Nik Everett, debug, MethodDeclaration, logger.debug("unblocking the blocked update");
319: Nik Everett, debug, TryStmt, log.debug("checking");
321: Nik Everett, debug, IfStmt, log.debug("passed");
152: Tanguy Leroux, info, MethodDeclaration, logger.info("--> indexing [{}] documents with routing", docs);
160: Tanguy Leroux, info, MethodDeclaration, logger.info("--> counting documents with no routing, should be equal to [{}]", docs);
165: Tanguy Leroux, info, MethodDeclaration, logger.info("--> counting documents with routing [{}]", routing);
168: Tanguy Leroux, info, MethodDeclaration, logger.info("--> delete all documents with routing [{}] with a delete-by-query", routing);
119: Nik Everett, info, CatchClause, logger.info("Triggered a reindex failure on the {} attempt: {}", attempt, e.getMessage());
108: Nik Everett, info, TryStmt, logger.info("Didn't trigger a reindex failure on the {} attempt", attempt);
79: Nik Everett, info, MethodDeclaration, logger.info("Starting test for [{}] with [{}] slices", actionName, request.request().getSlices());
196: Nik Everett, info, IfStmt, logger.info("caught unprepared task, retrying until prepared");
230: Nik Everett, info, IfStmt, logger.info("Expected [{}] total children, [{}] are running and [{}] are finished\n{}", sliceCount, taskGroup.getChildTasks().size(), finishedChildStatuses, status.getSliceStatuses());
191: Nik Everett, info, MethodDeclaration, logger.info("Blocking search");
198: Nik Everett, info, MethodDeclaration, logger.info("Starting request");
202: Nik Everett, info, TryStmt, logger.info("Waiting for search rejections on the initial search");
205: Nik Everett, info, TryStmt, logger.info("Blocking bulk and unblocking search so we start to get bulk rejections");
209: Nik Everett, info, TryStmt, logger.info("Waiting for bulk rejections");
215: Nik Everett, info, TryStmt, logger.info("Blocking search and unblocking bulk so we should get search rejections for the scroll");
219: Nik Everett, info, TryStmt, logger.info("Waiting for search rejections for the scroll");
222: Nik Everett, info, TryStmt, logger.info("Unblocking the scroll");
225: Nik Everett, info, TryStmt, logger.info("Waiting for the request to finish");
245: Nik Everett, info, MethodDeclaration, logger.info("Blocking the [{}] executor", name);
250: Nik Everett, info, TryStmt, logger.info("Blocked the [{}] executor", name);
252: Simon Willnauer, info, TryStmt, logger.info("Unblocking the [{}] executor", name);
85: Nik Everett, info, CatchClause, logger.info("Caught expected version conflict trying to perform mutation number [{}] with version [{}] " + "on attempt [{}]. Retrying.", i, get.getVersion(), attempts);
96: Nik Everett, error, IfStmt, logger.error("failed to remove old index", e);
94: Nik Everett, warn, IfStmt, logger.warn("old index not deleted because it doesn't exist");
124: Igor Motov, warn, CatchClause, logger.warn("cannot parse the specified url [{}]", url);
132: Tim Brooks, warn, IfStmt, logger.warn(logMessage, url, ALLOWED_URLS_SETTING.getKey(), environment.repoFiles());
108: Tanguy Leroux, debug, CatchClause, logger.debug("Failed to resolve inet address for allowed URL [{}], skipping", allowedUrl);
55: Tim Brooks, info, MethodDeclaration, logger.info("-->  creating repository");
66: Tim Brooks, info, MethodDeclaration, logger.info("--> indexing some data");
73: Tim Brooks, info, MethodDeclaration, logger.info("--> snapshot");
96: Tim Brooks, info, MethodDeclaration, logger.info("--> delete index");
99: Tim Brooks, info, MethodDeclaration, logger.info("--> create read-only URL repository");
104: Tim Brooks, info, MethodDeclaration, logger.info("--> restore index after deletion");
117: Tim Brooks, info, MethodDeclaration, logger.info("--> list available shapshots");
122: Tim Brooks, info, MethodDeclaration, logger.info("--> delete snapshot");
126: Tim Brooks, info, MethodDeclaration, logger.info("--> list available shapshot again, no snapshots should be returned");
238: Jason Tedor, debug, ConstructorDeclaration, logger.debug("using max_chunk_size[{}], max_header_size[{}], max_initial_line_length[{}], max_content_length[{}], " + "receive_predictor[{}], pipelining[{}], pipelining_max_events[{}]", maxChunkSize, maxHeaderSize, maxInitialLineLength, this.maxContentLength, receivePredictor, pipelining, pipeliningMaxEvents);
283: Simon Willnauer, info, IfStmt, logger.info("{}", boundAddress);
407: Jason Tedor, debug, IfStmt, logger.debug("Bound http to address {{}}", NetworkAddress.format(boundSocket.get()));
419: Jason Tedor, trace, CatchClause, logger.trace("exception while closing channels", e);
496: Jason Tedor, debug, IfStmt, logger.debug((Supplier<?>) () -> new ParameterizedMessage("caught exception while handling client http traffic, closing connection {}", ctx.channel()), cause);
490: Jason Tedor, warn, IfStmt, logger.warn((Supplier<?>) () -> new ParameterizedMessage("caught exception while handling client http traffic, closing connection {}", ctx.channel()), cause);
481: Tim Brooks, trace, IfStmt, logger.trace("Read timeout [{}]", ctx.channel().remoteAddress());
138: Tim Brooks, error, CatchClause, logger.error("unexpected error while releasing pipelined http responses", e);
53: Jason Tedor, trace, CatchClause, logger.trace("an exception occurred formatting a trace message", e);
44: Jason Tedor, trace, MethodDeclaration, logger.trace(msg);
49: Jason Tedor, trace, MethodDeclaration, logger.trace(format, arg);
54: Jason Tedor, trace, MethodDeclaration, logger.trace(format, argA, argB);
59: Jason Tedor, trace, MethodDeclaration, logger.trace(format, arguments);
64: Jason Tedor, trace, MethodDeclaration, logger.trace(msg, t);
74: Jason Tedor, debug, MethodDeclaration, logger.debug(msg);
79: Jason Tedor, debug, MethodDeclaration, logger.debug(format, arg);
84: Jason Tedor, debug, MethodDeclaration, logger.debug(format, argA, argB);
89: Jason Tedor, debug, MethodDeclaration, logger.debug(format, arguments);
94: Jason Tedor, debug, MethodDeclaration, logger.debug(msg, t);
104: Jason Tedor, info, MethodDeclaration, logger.info(msg);
109: Jason Tedor, info, MethodDeclaration, logger.info(format, arg);
114: Jason Tedor, info, MethodDeclaration, logger.info(format, argA, argB);
119: Jason Tedor, info, MethodDeclaration, logger.info(format, arguments);
124: Jason Tedor, info, MethodDeclaration, logger.info(msg, t);
134: Jason Tedor, warn, MethodDeclaration, logger.warn(msg);
139: Jason Tedor, warn, MethodDeclaration, logger.warn(format, arg);
144: Jason Tedor, warn, MethodDeclaration, logger.warn(format, arguments);
149: Jason Tedor, warn, MethodDeclaration, logger.warn(format, argA, argB);
154: Jason Tedor, warn, MethodDeclaration, logger.warn(msg, t);
164: Jason Tedor, error, MethodDeclaration, logger.error(msg);
169: Jason Tedor, error, MethodDeclaration, logger.error(format, arg);
174: Jason Tedor, error, MethodDeclaration, logger.error(format, argA, argB);
179: Jason Tedor, error, MethodDeclaration, logger.error(format, arguments);
184: Jason Tedor, error, MethodDeclaration, logger.error(msg, t);
58: Jason Tedor, trace, IfStmt, logger.trace("channel closed: {}", future.channel());
66: Jason Tedor, trace, IfStmt, logger.trace("channel opened: {}", ctx.channel());
91: Jason Tedor, trace, CatchClause, logger.trace("exception while closing channels", e);
178: Jason Tedor, debug, IfStmt, logger.debug("using profile[{}], worker_count[{}], port[{}], bind_host[{}], publish_host[{}], compress[{}], " + "connect_timeout[{}], connections_per_node[{}/{}/{}/{}/{}], receive_predictor[{}->{}]", name, workerCount, profileSettings.portOrRange, profileSettings.bindHosts, profileSettings.publishHosts, compress, defaultConnectionProfile.getConnectTimeout(), defaultConnectionProfile.getNumConnectionsPerType(TransportRequestOptions.Type.RECOVERY), defaultConnectionProfile.getNumConnectionsPerType(TransportRequestOptions.Type.BULK), defaultConnectionProfile.getNumConnectionsPerType(TransportRequestOptions.Type.REG), defaultConnectionProfile.getNumConnectionsPerType(TransportRequestOptions.Type.STATE), defaultConnectionProfile.getNumConnectionsPerType(TransportRequestOptions.Type.PING), receivePredictorMin, receivePredictorMax);
292: Jason Tedor, debug, IfStmt, logger.debug((Supplier<?>) () -> new ParameterizedMessage("Error closing server bootstrap for profile [{}]", future.v1()), future.v2().cause());
352: Tim Brooks, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("exception while closing channel: {}", channel), f.cause());
183: Jason Tedor, fatal, TryStmt, logger.error("fatal error on the network layer\n{}", formatted);
214: Jason Tedor, info, MethodDeclaration, logger.info("Caught exception", cause);
98: Jason Tedor, error, CatchClause, logger.error("Unexpected failure", e);
125: Jason Tedor, error, MethodDeclaration, logger.error("Unexpected failure", exp);
57: Jason Tedor, info, MethodDeclaration, logger.info("--> starting a node on ipv4 only");
61: Jason Tedor, info, MethodDeclaration, logger.info("--> starting a node on ipv4 and ipv6");
65: Jason Tedor, info, MethodDeclaration, logger.info("--> waiting for the cluster to declare itself stable");
68: Jason Tedor, info, MethodDeclaration, logger.info("--> checking if boundAddress matching publishAddress has same port");
59: Yannick Welsch, trace, ConstructorDeclaration, logger.trace("creating new Azure client for [{}], [{}]", subscriptionId, serviceName);
74: Tanguy Leroux, Trace, TryStmt, configuration.setProperty(Configuration.PROPERTY_LOG_HTTP_REQUESTS, logger.isTraceEnabled());
79: Tanguy Leroux, debug, TryStmt, logger.debug("creating new Azure client for [{}], [{}]", subscriptionId, serviceName);
119: David Pilato, error, CatchClause, logger.error("error while closing Azure client", e);
144: David Pilato, trace, IfStmt, logger.trace("using cache to retrieve node list");
149: David Pilato, debug, MethodDeclaration, logger.debug("start building nodes list using Azure API");
157: David Pilato, debug, CatchClause, logger.debug("Azure discovery service has been disabled. Returning empty list of nodes.");
161: David Pilato, warn, CatchClause, logger.warn("can not get list of azure nodes: [{}]. Returning empty list of nodes.", e.getMessage());
162: David Pilato, trace, CatchClause, logger.trace("AzureServiceRemoteException caught", e);
173: David Pilato, trace, CatchClause, logger.trace("exception while finding ip", e);
170: David Pilato, trace, TryStmt, logger.trace("ip of current node: [{}]", ipAddress);
179: David Pilato, debug, IfStmt, logger.debug("current deployment slot [{}] for [{}] is different from [{}]. skipping...", deployment.getDeploymentSlot(), deployment.getName(), deploymentSlot);
186: David Pilato, debug, IfStmt, logger.debug("current deployment name [{}] different from [{}]. skipping...", deployment.getName(), deploymentName);
195: David Pilato, debug, IfStmt, logger.debug("[{}] status is [{}]. skipping...", deployment.getName(), deployment.getStatus());
206: David Pilato, warn, IfStmt, logger.warn("no network address found. ignoring [{}]...", instance.getInstanceName());
219: David Pilato, warn, CatchClause, logger.warn("can not convert [{}] to transport address. skipping. [{}]", networkAddress, e.getMessage());
214: Robert Muir, trace, ForeachStmt, logger.trace("adding {}, transport_address {}", networkAddress, address);
224: David Pilato, debug, MethodDeclaration, logger.debug("{} node(s) added", cachedDiscoNodes.size());
242: Tanguy Leroux, trace, IfStmt, logger.trace("ignoring endpoint [{}] as different than [{}]", endpoint.getName(), publicEndpointName);
235: Tanguy Leroux, trace, IfStmt, logger.trace("no private ip provided. ignoring [{}]...", instance.getInstanceName());
52: David Pilato, trace, ConstructorDeclaration, logger.trace("starting azure classic discovery plugin...");
36: Tanguy Leroux, info, MethodDeclaration, logger.info("--> using azure host type " + hostType);
43: David Pilato, info, MethodDeclaration, logger.info("--> start first node");
48: David Pilato, info, MethodDeclaration, logger.info("--> start another node");
78: Ryan Ernst, debug, IfStmt, logger.debug("Using basic key/secret credentials");
75: Ryan Ernst, debug, IfStmt, logger.debug("Using either environment variables, system properties or instance profile credentials");
117: David Pilato, warn, MethodDeclaration, logger.warn("EC2 API request failed, retry again. Reason was:", exception);
133: David Pilato, debug, IfStmt, logger.debug("using explicit ec2 endpoint [{}]", endpoint);
94: javanna, debug, IfStmt, logger.debug("using host_type [{}], tags [{}], groups [{}] with any_group [{}], availability_zones [{}]", hostType, tags, groups, bindAnyGroup, availabilityZones);
117: Gianni O'Neill, info, CatchClause, logger.info("Exception while retrieving instance list from AWS API: {}", e.getMessage());
118: Gianni O'Neill, debug, CatchClause, logger.debug("Full exception:", e);
122: Shay Banon, trace, MethodDeclaration, logger.trace("building dynamic unicast discovery nodes...");
146: javanna, trace, IfStmt, logger.trace("filtering out instance {} based on groups {}, does not include all of {}", instance.getInstanceId(), instanceSecurityGroups, groups);
138: javanna, trace, IfStmt, logger.trace("filtering out instance {} based on groups {}, not part of {}", instance.getInstanceId(), instanceSecurityGroups, groups);
166: David Pilato, debug, IfStmt, logger.debug("reading hostname from [{}] instance tag", tagName);
171: David Pilato, debug, IfStmt, logger.debug("using [{}] as the instance address", address);
193: Joe Pollard, trace, IfStmt, logger.trace("not adding {}, address is null, host_type {}", instance.getInstanceId(), hostType);
188: Jason Tedor, warn, CatchClause, logger.warn((Supplier<?>) () -> new ParameterizedMessage("failed to add {}, address {}", instance.getInstanceId(), finalAddress), e);
182: Joe Pollard, trace, ForStmt, logger.trace("adding {}, address {}, transport_address {}", instance.getInstanceId(), address, addresses[i]);
198: Shay Banon, debug, MethodDeclaration, logger.debug("using dynamic discovery nodes {}", discoNodes);
90: David Pilato, debug, MethodDeclaration, logger.debug("Register _ec2_, _ec2:xxx_ network names");
148: Ryan Ernst, debug, TryStmt, logger.debug("obtaining ec2 [placement/availability-zone] from ec2 meta-data url {}", url);
167: Ryan Ernst, error, CatchClause, logger.error("failed to get metadata for [placement/availability-zone]", e);
100: Shay Banon, debug, TryStmt, logger.debug("obtaining ec2 hostname from ec2 meta-data url {}", url);
562: David Pilato, debug, MethodDeclaration, logger.debug("--> mocking describeInstances");
603: David Pilato, debug, IfStmt, logger.debug("--> expected tags: [{}]", expectedTags);
604: David Pilato, debug, IfStmt, logger.debug("--> instance tags: [{}]", instanceTags);
632: David Pilato, debug, IfStmt, logger.debug("--> instance filtered");
629: David Pilato, debug, IfStmt, logger.debug("--> instance added");
97: David Pilato, debug, MethodDeclaration, logger.debug("--> nodes found: {}", discoveryNodes);
224: Yannick Welsch, info, MethodDeclaration, logger.info("started [{}] instances with [{}] stage=prod tag", nodes, prodInstances);
255: Yannick Welsch, info, MethodDeclaration, logger.info("started [{}] instances with [{}] stage=prod tag", nodes, prodInstances);
282: David Pilato, info, MethodDeclaration, logger.info("started [{}] instances", nodes);
85: Ali Beyad, warn, CatchClause, logger.warn((Supplier<?>) () -> new ParameterizedMessage("[discovery-file] Failed to find unicast hosts file [{}]", unicastHostsFilePath), e);
89: Ali Beyad, warn, CatchClause, logger.warn((Supplier<?>) () -> new ParameterizedMessage("[discovery-file] Error reading unicast hosts file [{}]", unicastHostsFilePath), e);
108: Ali Beyad, debug, MethodDeclaration, logger.debug("[discovery-file] Using dynamic discovery nodes {}", discoNodes);
62: Simon Willnauer, debug, MethodDeclaration, logger.debug("get instances for project [{}], zones [{}]", project, zones);
75: Jason Tedor, warn, CatchClause, logger.warn((Supplier<?>) () -> new ParameterizedMessage("Problem fetching instance list for zone {}", zoneId), e);
76: Simon Willnauer, debug, CatchClause, logger.debug("Full exception:", e);
86: Simon Willnauer, warn, IfStmt, logger.warn("disabling GCE discovery. Can not get list of nodes");
127: David Pilato, trace, BlockStmt, logger.trace("using cache to retrieve client");
176: David Pilato, warn, CatchClause, logger.warn("unable to start GCE discovery service", e);
136: David Pilato, info, TryStmt, logger.info("starting GCE discovery service");
150: David Pilato, debug, TryStmt, logger.debug("token [{}] will expire in [{}] s", credential.getAccessToken(), credential.getExpiresInSeconds());
70: David Pilato, debug, MethodDeclaration, logger.debug("get metadata from [{}]", urlMetadataNetwork);
86: David Pilato, debug, TryStmt, logger.debug("metadata found [{}]", metadata);
104: David Pilato, warn, CatchClause, logger.warn("unable to shutdown GCE Http Transport", e);
44: David Pilato, debug, MethodDeclaration, logger.debug("configure GceModule (bind compute service)");
91: David Pilato, debug, IfStmt, logger.debug("using tags {}", this.tags);
111: David Pilato, trace, BlockStmt, logger.trace("using cache to retrieve node list");
116: David Pilato, debug, MethodDeclaration, logger.debug("start building nodes list using GCE API");
252: Jason Tedor, warn, CatchClause, logger.warn("exception caught during discovery", e);
135: David Pilato, trace, IfStmt, logger.trace("no instance found for project [{}], zones [{}].", this.project, this.zones);
144: David Pilato, trace, ForeachStmt, logger.trace("gce instance {} with status {} found.", name, status);
149: David Pilato, debug, IfStmt, logger.debug("node {} is TERMINATED. Ignoring", name);
156: David Pilato, trace, IfStmt, logger.trace("start filtering instance {} with tags {}.", name, tags);
164: David Pilato, trace, IfStmt, logger.trace("comparing instance tags {} with tags filter {}.", instance.getTags().getItems(), tags);
160: David Pilato, trace, IfStmt, logger.trace("no tags for this instance but we asked for tags. {} won't be part of the cluster.", name);
185: David Pilato, trace, IfStmt, logger.trace("instance {} with tags {} is added to discovery", name, tags);
181: David Pilato, trace, IfStmt, logger.trace("filtering out instance {} based tags {}, not part of {}", name, tags, instance.getTags() == null || instance.getTags().getItems() == null ? "" : instance.getTags());
247: Jason Tedor, warn, CatchClause, logger.warn((Supplier<?>) () -> new ParameterizedMessage("failed to add {}, address {}", name, finalIpPrivate), e);
224: David Pilato, trace, IfStmt, logger.trace("es_port is defined with {}", es_port);
229: David Pilato, trace, IfStmt, logger.trace("es_port is instance of {}. Ignoring...", es_port.getClass().getName());
239: Robert Muir, trace, ForeachStmt, logger.trace("adding {}, type {}, address {}, transport_address {}, status {}", name, type, ip_private, transportAddress, status);
255: David Pilato, debug, MethodDeclaration, logger.debug("{} node(s) added", cachedDiscoNodes.size());
256: David Pilato, debug, MethodDeclaration, logger.debug("using dynamic discovery nodes {}", cachedDiscoNodes);
72: David Pilato, trace, ConstructorDeclaration, logger.trace("starting gce discovery plugin...");
91: David Pilato, debug, MethodDeclaration, logger.debug("Register _gce_, _gce:xxx network names");
113: David Pilato, info, MethodDeclaration, logger.info("--> nodes found: {}", discoveryNodes);
58: David Pilato, info, IfStmt, logger.info("--> Simulate GCE API response for [{}]", url);
55: David Pilato, info, IfStmt, logger.info("--> Simulate GCE Auth/Metadata response for [{}]", url);
45: David Pilato, debug, MethodDeclaration, logger.debug("unzipping all tika sample files");
55: Alexander Reelsen, debug, ForeachStmt, logger.debug("parsing: {}", doc);
67: Alexander Reelsen, debug, TryStmt, logger.debug("extracted content: {}", parsedContent);
53: Martijn van Groningen, debug, IfStmt, LOGGER.debug("Loaded [{}] geoip database", databaseFileName);
54: David Pilato, trace, MethodDeclaration, logger.trace("blobExists({})", blobName);
58: David Pilato, warn, CatchClause, logger.warn("can not access [{}] in container {{}}: {}", blobName, blobStore, e.getMessage());
65: David Pilato, trace, MethodDeclaration, logger.trace("readBlob({})", blobName);
94: David Pilato, trace, MethodDeclaration, logger.trace("writeBlob({}, stream, {})", buildKey(blobName), blobSize);
104: David Pilato, trace, MethodDeclaration, logger.trace("deleteBlob({})", blobName);
113: David Pilato, warn, CatchClause, logger.warn("can not access [{}] in container {{}}: {}", blobName, blobStore, e.getMessage());
120: David Pilato, trace, MethodDeclaration, logger.trace("listBlobsByPrefix({})", prefix);
125: David Pilato, warn, CatchClause, logger.warn("can not access [{}] in container {{}}: {}", prefix, blobStore, e.getMessage());
132: David Pilato, trace, MethodDeclaration, logger.trace("move({}, {})", sourceBlobName, targetBlobName);
141: David Pilato, warn, CatchClause, logger.warn("can not move blob [{}] to [{}] in container {{}}: {}", sourceBlobName, targetBlobName, blobStore, e.getMessage());
137: David Pilato, debug, TryStmt, logger.debug("moving blob [{}] to [{}] in container {{}}", source, target, blobStore);
148: David Pilato, trace, MethodDeclaration, logger.trace("listBlobs()");
87: David Pilato, warn, CatchClause, logger.warn("can not remove [{}] in container {{}}: {}", keyPath, container, e.getMessage());
121: David Pilato, debug, ConstructorDeclaration, logger.debug("using container [{}], chunk_size [{}], compress [{}], base_path [{}]", container, chunkSize, compress, basePath);
68: Ryan Ernst, debug, ConstructorDeclaration, logger.debug("starting azure storage client instance");
72: David Pilato, debug, ForeachStmt, logger.debug("registering regular client for account [{}]", azureStorageSettingsEntry.getKey());
100: craigwi, error, CatchClause, logger.error("can not create azure storage client: {}", e.getMessage());
79: kel, trace, TryStmt, logger.trace("creating new Azure storage client using account [{}], key [{}], endpoint suffix [{}]", azureStorageSettings.getAccount(), azureStorageSettings.getKey(), azureStorageSettings.getEndpointSuffix());
105: David Pilato, trace, MethodDeclaration, logger.trace("selecting a client named [{}], mode [{}]", clientName, mode.name());
157: David Pilato, error, CatchClause, logger.error("can not access container [{}]", container);
166: David Pilato, trace, MethodDeclaration, logger.trace("removing container [{}]", container);
178: Jason Tedor, trace, CatchClause, logger.trace((Supplier<?>) () -> new ParameterizedMessage("fails creating container [{}]", container), e);
175: David Pilato, trace, TryStmt, logger.trace("creating container [{}]", container);
185: David Pilato, trace, MethodDeclaration, logger.trace("delete files container [{}], path [{}]", container, path);
196: Tim Brooks, trace, ForeachStmt, logger.trace("removing blob [{}] full URI was [{}]", blobName, blobItem.getUri());
239: David Pilato, trace, MethodDeclaration, logger.trace("delete blob for container [{}], blob [{}]", container, blob);
245: David Pilato, trace, IfStmt, logger.trace("container [{}]: blob [{}] found. removing.", container, blob);
255: David Pilato, trace, MethodDeclaration, logger.trace("reading container [{}], blob [{}]", container, blob);
280: Tim Brooks, trace, ForeachStmt, logger.trace("blob url [{}]", uri);
287: Tim Brooks, trace, ForeachStmt, logger.trace("blob url [{}], name [{}], size [{}]", uri, name, properties.getLength());
298: David Pilato, debug, MethodDeclaration, logger.debug("moveBlob container [{}], sourceBlob [{}], targetBlob [{}]", container, sourceBlob, targetBlob);
309: David Pilato, debug, IfStmt, logger.debug("moveBlob container [{}], sourceBlob [{}], targetBlob [{}] -> done", container, sourceBlob, targetBlob);
316: David Pilato, trace, MethodDeclaration, logger.trace("writeBlob({}, stream, {})", blobName, blobSize);
321: David Pilato, trace, MethodDeclaration, logger.trace("writeBlob({}, stream, {}) - done", blobName, blobSize);
168: David Pilato, info, MethodDeclaration, logger.info("-->  creating azure repository with path [{}]", getRepositoryPath());
187: David Pilato, info, MethodDeclaration, logger.info("--> indexing some data");
196: David Pilato, info, MethodDeclaration, logger.info("--> snapshot 1");
203: David Pilato, info, MethodDeclaration, logger.info("--> snapshot 2");
216: David Pilato, info, MethodDeclaration, logger.info("--> delete indices");
218: David Pilato, info, MethodDeclaration, logger.info("--> restore one index after deletion from snapshot 1");
228: David Pilato, info, MethodDeclaration, logger.info("--> restore other index after deletion from snapshot 2");
247: David Pilato, info, MethodDeclaration, logger.info("--> indexing some data");
256: David Pilato, info, MethodDeclaration, logger.info("-->  creating azure repository without any path");
266: David Pilato, info, MethodDeclaration, logger.info("--> snapshot");
278: David Pilato, info, MethodDeclaration, logger.info("-->  creating azure repository path [{}]", getRepositoryPath());
289: David Pilato, info, MethodDeclaration, logger.info("--> snapshot");
304: David Pilato, info, MethodDeclaration, logger.info("-->  creating azure repository without any path");
332: David Pilato, info, MethodDeclaration, logger.info("-->  creating azure repository with path [{}]", getRepositoryPath());
341: David Pilato, info, MethodDeclaration, logger.info("--> restore non existing snapshot");
360: David Pilato, info, MethodDeclaration, logger.info("-->  creating azure repository while container is being removed");
382: David Pilato, info, MethodDeclaration, logger.info("-->  creating azure primary repository");
389: David Pilato, info, MethodDeclaration, logger.info("--> start get snapshots on primary");
396: David Pilato, info, MethodDeclaration, logger.info("-->  creating azure secondary repository");
404: David Pilato, info, MethodDeclaration, logger.info("--> start get snapshots on secondary");
408: David Pilato, info, MethodDeclaration, logger.info("--> end of get snapshots on secondary. Took {} ms", endWait - startWait);
273: Tanguy Leroux, error, MethodDeclaration, logger.error("failed to delete blob [{}] in bucket [{}]: {}", delete.getObject(), delete.getBucket(), e.getMessage());
88: Tanguy Leroux, debug, ConstructorDeclaration, logger.debug("using bucket [{}], base_path [{}], chunk_size [{}], compress [{}]", bucket, basePath, chunkSize, compress);
115: James Baiera, debug, ForeachStmt, LOGGER.debug("Adding configuration to HDFS Client Configuration : {} = {}", key, confSettings.get(key));
146: James Baiera, debug, MethodDeclaration, logger.debug("Using file-system [{}] for URI [{}], path [{}]", fileContext.getDefaultFileSystem(), fileContext.getDefaultFileSystem().getUri(), path);
168: James Baiera, warn, IfStmt, LOGGER.warn("Hadoop authentication method is set to [SIMPLE], but a Kerberos principal is " + "specified. Continuing with [KERBEROS] authentication.");
181: James Baiera, debug, MethodDeclaration, LOGGER.debug("Hadoop security enabled: [{}]", UserGroupInformation.isSecurityEnabled());
182: James Baiera, debug, MethodDeclaration, LOGGER.debug("Using Hadoop authentication method: [{}]", SecurityUtil.getAuthenticationMethod(hadoopConfiguration));
189: James Baiera, debug, IfStmt, LOGGER.debug("Using kerberos principal [{}] and keytab located at [{}]", principal, keytab);
210: James Baiera, debug, IfStmt, LOGGER.debug("Found service principal. Converted original principal name [{}] to server principal [{}]", originalPrincipal, finalPrincipal);
89: James Baiera, info, IfStmt, logger.info("Keytab Length: " + Files.readAllBytes(kt).length);
266: James Baiera, info, MethodDeclaration, logger.info("Swapping active namenodes: [{}] to standby and [{}] to active", from, to);
65: Costin Leau, info, MethodDeclaration, logger.info("--> indexing some data");
76: Costin Leau, info, MethodDeclaration, logger.info("--> snapshot");
83: Costin Leau, info, MethodDeclaration, logger.info("--> delete some data");
98: Costin Leau, info, MethodDeclaration, logger.info("--> close indices");
101: Costin Leau, info, MethodDeclaration, logger.info("--> restore all indices from the snapshot");
111: Costin Leau, info, MethodDeclaration, logger.info("--> delete indices");
113: Costin Leau, info, MethodDeclaration, logger.info("--> restore one index after deletion");
73: Ryan Ernst, debug, MethodDeclaration, logger.debug("creating S3 client with client_name [{}], endpoint [{}]", clientName, clientSettings.endpoint);
137: Ryan Ernst, debug, IfStmt, logger.debug("Using basic key/secret credentials");
134: Ryan Ernst, debug, IfStmt, logger.debug("Using instance profile credentials");
177: Ryan Ernst, debug, ConstructorDeclaration, logger.debug("using bucket [{}], chunk_size [{}], server_side_encryption [{}], " + "buffer_size [{}], cannedACL [{}], storageClass [{}]", bucket, chunkSize, serverSideEncryption, bufferSize, cannedACL, storageClass);
78: David Pilato, info, MethodDeclaration, logger.info("-->  creating s3 repository with bucket[{}] and path [{}]", internalCluster().getInstance(Settings.class).get("repositories.s3.bucket"), basePath);
87: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
98: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
105: Igor Motov, info, MethodDeclaration, logger.info("--> delete some data");
120: Igor Motov, info, MethodDeclaration, logger.info("--> close indices");
123: Igor Motov, info, MethodDeclaration, logger.info("--> restore all indices from the snapshot");
133: Igor Motov, info, MethodDeclaration, logger.info("--> delete indices");
135: Igor Motov, info, MethodDeclaration, logger.info("--> restore one index after deletion");
148: Robert Muir, info, MethodDeclaration, logger.info("-->  creating s3 repository with bucket[{}] and path [{}]", internalCluster().getInstance(Settings.class).get("repositories.s3.bucket"), basePath);
163: Robert Muir, info, MethodDeclaration, logger.info("--> indexing some data");
174: Robert Muir, info, MethodDeclaration, logger.info("--> snapshot");
186: Robert Muir, info, MethodDeclaration, logger.info("--> verify encryption for bucket [{}], prefix [{}]", bucketName, basePath);
192: Robert Muir, info, MethodDeclaration, logger.info("--> delete some data");
207: Robert Muir, info, MethodDeclaration, logger.info("--> close indices");
210: Robert Muir, info, MethodDeclaration, logger.info("--> restore all indices from the snapshot");
220: Robert Muir, info, MethodDeclaration, logger.info("--> delete indices");
222: Robert Muir, info, MethodDeclaration, logger.info("--> restore one index after deletion");
239: Konrad Beiske, info, MethodDeclaration, logger.info("-->  creating s3 repository with bucket[{}] and path [{}]", bucketSettings.get("bucket"), basePath);
265: Konrad Beiske, info, MethodDeclaration, logger.info("-->  creating s3 repository with bucket[{}] and path [{}]", bucketSettings.get("bucket"), basePath);
280: Bruno ReniÃ©, info, MethodDeclaration, logger.info("--> creating s3 repostoriy with endpoint [{}], bucket[{}] and path [{}]", bucketSettings.get("endpoint"), bucketSettings.get("bucket"), basePath);
297: Konrad Beiske, info, MethodDeclaration, logger.info("-->  creating s3 repository with bucket[{}] and path [{}]", bucketSettings.get("bucket"), basePath);
316: Konrad Beiske, info, MethodDeclaration, logger.info("-->  creating s3 repository with bucket[{}] and path [{}]", bucketSettings.get("bucket"), basePath);
332: David Pilato, info, MethodDeclaration, logger.info("-->  creating s3 repository with bucket[{}] and path [{}]", internalCluster().getInstance(Settings.class).get("repositories.s3.bucket"), basePath);
339: David Pilato, info, MethodDeclaration, logger.info("--> restore non existing snapshot");
353: David Pilato, info, MethodDeclaration, logger.info("-->  creating s3 repository without any path");
379: Konrad Beiske, info, MethodDeclaration, logger.info("--> indexing some data");
386: Konrad Beiske, info, MethodDeclaration, logger.info("--> snapshot");
393: Konrad Beiske, info, MethodDeclaration, logger.info("--> delete some data");
400: Konrad Beiske, info, MethodDeclaration, logger.info("--> close indices");
403: Konrad Beiske, info, MethodDeclaration, logger.info("--> restore all indices from the snapshot");
483: Ryan Ernst, warn, CatchClause, logger.warn((Supplier<?>) () -> new ParameterizedMessage("Failed to delete S3 repository [{}]", bucketName), ex);
89: tlrx, info, IfStmt, logger.info("--> random write failure on putObject method: throwing an exception for [bucket={}, key={}]", bucketName, key);
112: tlrx, info, IfStmt, logger.info("--> random write failure on uploadPart method: throwing an exception for [bucket={}, key={}]", request.getBucketName(), request.getKey());
125: tlrx, info, IfStmt, logger.info("--> random read failure on getObject method: throwing an exception for [bucket={}, key={}]", bucketName, key);
42: Tanguy Leroux, debug, MethodDeclaration, logger.debug("wrapping MMapDirectory for SMB");
42: Tanguy Leroux, debug, MethodDeclaration, logger.debug("wrapping SimpleFSDirectory for SMB");
143: Tim Brooks, warn, CatchClause, logger.warn("unexpected exception while stopping nio group", e);
72: Jason Tedor, info, MethodDeclaration, verify(logger).info("explicitly enforcing bootstrap checks");
50: Jason Tedor, Error, MethodDeclaration, LogConfigurator.registerErrorListener();
126: Jason Tedor, Trace, MethodDeclaration, assertTrue(logger.isTraceEnabled());
69: Jason Tedor, Error, MethodDeclaration, LogConfigurator.registerErrorListener();
84: Jason Tedor, error, MethodDeclaration, testLogger.error("This is an error message");
85: Jason Tedor, warn, MethodDeclaration, testLogger.warn("This is a warning message");
86: Jason Tedor, info, MethodDeclaration, testLogger.info("This is an info message");
87: Jason Tedor, debug, MethodDeclaration, testLogger.debug("This is a debug message");
88: Jason Tedor, trace, MethodDeclaration, testLogger.trace("This is a trace message");
96: Jason Tedor, Info, MethodDeclaration, final String location = "org.elasticsearch.common.logging.EvilLoggerTests.testLocationInfoTest";
302: Jason Tedor, info, MethodDeclaration, logger.info("test");
303: Jason Tedor, info, MethodDeclaration, logger.info("{}", "test");
305: Jason Tedor, info, MethodDeclaration, logger.info(new ParameterizedMessage("{}", "test"), e);
171: Martijn van Groningen, info, MethodDeclaration, logger.info("health api response: {}", healthRsp);
220: Martijn van Groningen, debug, IfStmt, logger.debug("--> creating [{}] replicas for index [{}]", numReplicas, index);
235: Martijn van Groningen, debug, IfStmt, logger.debug("--> index [{}] is green, took [{}] ms", index, (System.currentTimeMillis() - startTime));
237: Martijn van Groningen, debug, IfStmt, logger.debug("--> recovery status:\n{}", recoverRsp);
215: Martijn van Groningen, info, IfStmt, logger.info("Refreshing [{}]", index);
302: Martijn van Groningen, error, MethodDeclaration, logger.error("clusterState=" + toMap(client().performRequest("GET", "/_cluster/state", Collections.singletonMap("metric", "metadata"))));
499: Martijn van Groningen, info, MethodDeclaration, logger.info("--> testing basic search");
503: Nik Everett, info, MethodDeclaration, logger.info("Found {} in old index", numDocs);
506: Martijn van Groningen, info, MethodDeclaration, logger.info("--> testing basic search with sort");
514: Martijn van Groningen, info, MethodDeclaration, logger.info("--> testing exists filter");
531: Martijn van Groningen, info, MethodDeclaration, logger.info("--> testing _all search");
890: Boaz Leskes, info, ForeachStmt, logger.info("evaluating: {} , {}", ObjectPath.evaluate(shard, "routing"), ObjectPath.evaluate(shard, "commit"));
1000: Nik Everett, info, MethodDeclaration, logger.info("Indexing {} random documents", count);
1002: Nik Everett, debug, ForStmt, logger.debug("Indexing document [{}]", i);
1009: Nik Everett, debug, IfStmt, logger.debug("Flushing [{}]", index);
1044: Nik Everett, debug, MethodDeclaration, logger.debug("Refreshing [{}]", index);
88: Areek Zillur, info, MethodDeclaration, logger.info("cluster discovered: {}", nodes.toString());
103: Areek Zillur, info, TryStmt, logger.info("indexing docs with [{}] concurrent updates initially", nUpdates);
105: Areek Zillur, info, TryStmt, logger.info("allowing shards on all nodes");
111: Areek Zillur, info, TryStmt, logger.info("primary resolved to: " + primary.getNode().getNodeName());
118: Areek Zillur, info, TryStmt, logger.info("indexing docs with [{}] concurrent updates after allowing shards on all nodes", nUpdates);
123: Areek Zillur, info, TryStmt, logger.info("primary resolved to: " + primary.getNode().getNodeName());
130: Areek Zillur, info, TryStmt, logger.info("moving primary to new node by excluding {}", primary.getNode().getNodeName());
134: Areek Zillur, info, TryStmt, logger.info("indexing docs with [{}] concurrent updates after moving primary", nUpdates);
143: Areek Zillur, info, TryStmt, logger.info("setting number of replicas to 0");
147: Areek Zillur, info, TryStmt, logger.info("indexing doc with [{}] concurrent updates after setting number of replicas to 0", nUpdates);
156: Areek Zillur, info, TryStmt, logger.info("setting number of replicas to 1");
160: Areek Zillur, info, TryStmt, logger.info("indexing doc with [{}] concurrent updates after setting number of replicas to 1", nUpdates);
174: Boaz Leskes, info, MethodDeclaration, logger.info("cluster discovered: {}", nodes.toString());
188: Jason Tedor, info, TryStmt, logger.info("indexing [{}] docs initially", numberOfInitialDocs);
191: Boaz Leskes, info, TryStmt, logger.info("allowing shards on all nodes");
199: Jason Tedor, info, TryStmt, logger.info("indexing [{}] docs after allowing shards on all nodes", numberOfDocsAfterAllowingShardsOnAllNodes);
203: Jason Tedor, info, TryStmt, logger.info("moving primary to new node by excluding {}", primary.getNode().getNodeName());
208: Jason Tedor, info, TryStmt, logger.info("indexing [{}] docs after moving primary", numberOfDocsAfterMovingPrimary);
216: Jason Tedor, info, TryStmt, logger.info("setting number of replicas to 0");
219: Jason Tedor, info, TryStmt, logger.info("indexing [{}] docs after setting number of replicas to 0", numberOfDocsAfterDroppingReplicas);
222: Jason Tedor, info, TryStmt, logger.info("setting number of replicas to 1");
237: Nhat Nguyen, info, MethodDeclaration, logger.info("cluster discovered: {}", nodes.toString());
309: Boaz Leskes, info, TryStmt, logger.info("primary resolved to node {}", primaryShard.getNode());
312: Ryan Ernst, info, ForeachStmt, logger.info("stats for {}, primary [{}]: [{}]", shard.getNode(), shard.isPrimary(), seqNoStats);
103: David Pilato, info, MethodDeclaration, logger.info("--> Elasticsearch Java TransportClient started");
108: David Pilato, info, TryStmt, logger.info("--> connected to [{}] cluster which is running [{}] node(s).", health.getClusterName(), health.getNumberOfNodes());
136: David Pilato, error, CatchClause, logger.error("can not start the client", e);
90: kimchy, warn, IfStmt, logger.warn("Exception cause unwrapping ran for 10 levels...", t);
159: Jason Tedor, warn, IfStmt, logger.warn("giving up looking for fatal errors", cause);
378: Ryan Ernst, debug, IfStmt, logger.debug("Using REST wrapper from plugin " + plugin.getClass().getName());
100: Ali Beyad, debug, MethodDeclaration, logger.debug("explaining the allocation for [{}], found shard [{}]", request, shardRouting);
81: Igor Motov, warn, MethodDeclaration, logger.warn("attempt to execute a cluster health operation without a task");
127: Yannick Welsch, trace, MethodDeclaration, logger.trace("stopped being master while waiting for events with priority [{}]. retrying.", request.waitForEvents());
134: Nhat Nguyen, error, MethodDeclaration, logger.error(() -> new ParameterizedMessage("unexpected failure during [{}]", source), e);
106: Nhat Nguyen, error, MethodDeclaration, logger.error(() -> new ParameterizedMessage("unexpected failure during [{}]", source), e);
311: Igor Motov, trace, IfStmt, logger.trace("Calculating health based on state version [{}]", clusterState.version());
161: Igor Motov, trace, IfStmt, logger.trace("task {} doesn't have any children that should be cancelled", cancellableTask.getId());
125: Igor Motov, trace, IfStmt, logger.trace("cancelling task {} on child nodes", cancellableTask.getId());
165: Igor Motov, trace, IfStmt, logger.trace("task {} is already cancelled", cancellableTask.getId());
183: Igor Motov, trace, ForeachStmt, logger.trace("Sending ban for tasks with the parent [{}] to the node [{}], ban [{}]", request.parentTaskId, node.key, request.ban);
194: Igor Motov, warn, MethodDeclaration, logger.warn("Cannot send ban for tasks with the parent [{}] to the node [{}]", request.parentTaskId, node.key);
203: Igor Motov, debug, ForeachStmt, logger.debug("Sending remove ban for tasks with the parent [{}] to the node [{}]", request.parentTaskId, node.key);
297: Igor Motov, debug, IfStmt, logger.debug("Removing ban for the parent [{}] on the node [{}]", request.parentTaskId, clusterService.localNode().getId());
293: Igor Motov, debug, IfStmt, logger.debug("Received ban for the parent [{}] on the node [{}], reason: [{}]", request.parentTaskId, clusterService.localNode().getId(), request.reason);
114: Nhat Nguyen, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("failed to perform [{}]", source), e);
159: Jason Tedor, warn, MethodDeclaration, logger.warn("ignoring existing unknown {} setting: [{}] with value [{}]; archiving", settingType, e.getKey(), e.getValue());
164: Jason Tedor, warn, MethodDeclaration, logger.warn((Supplier<?>) () -> new ParameterizedMessage("ignoring existing invalid {} setting: [{}] with value [{}]; archiving", settingType, e.getKey(), e.getValue()), ex);
125: Martijn van Groningen, debug, IfStmt, logger.debug("Skipping reroute after cluster update settings, because node is no longer master");
154: Boaz Leskes, debug, MethodDeclaration, logger.debug("failed to preform reroute after cluster settings were updated - current node is no longer a master");
162: Nhat Nguyen, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("failed to perform [{}]", source), e);
176: Nhat Nguyen, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("failed to perform [{}]", source), e);
116: Yannick Welsch, debug, IfStmt, logger.debug("restore of [{}] completed", snapshot);
221: Ali Beyad, debug, IfStmt, logger.debug("snapshot status request ignoring snapshot [{}], not found in repository [{}]", snapshotName, repositoryName);
77: Luca Cavanna, trace, MethodDeclaration, logger.trace("Serving cluster state request using version {}", currentState.version());
67: Boaz Leskes, trace, MethodDeclaration, logger.trace("fetching pending tasks from cluster service");
69: Boaz Leskes, trace, MethodDeclaration, logger.trace("done fetching pending tasks from cluster service");
134: Shay Banon, debug, MethodDeclaration, logger.debug("failed to perform aliases", t);
116: Nhat Nguyen, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("failed to close indices [{}]", (Object) concreteIndices), t);
104: Nhat Nguyen, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("failed to delete indices [{}]", concreteIndices), t);
56: Boaz Leskes, trace, MethodDeclaration, logger.trace("{} flush request executed on primary", primary.shardId());
63: Boaz Leskes, trace, MethodDeclaration, logger.trace("{} flush request executed on replica", replica.shardId());
73: Shay Banon, trace, MethodDeclaration, logger.trace("serving getMapping request based on version {}", state.version());
100: Nhat Nguyen, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("failed to put mappings on indices [{}], type [{}]", request.indices(), request.type()), ex);
95: Nhat Nguyen, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("failed to put mappings on indices [{}], type [{}]", concreteIndices, request.type()), t);
101: Nhat Nguyen, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("failed to open indices [{}]", (Object) concreteIndices), t);
59: Boaz Leskes, trace, MethodDeclaration, logger.trace("{} refresh request executed on primary", primary.shardId());
66: Boaz Leskes, trace, MethodDeclaration, logger.trace("{} refresh request executed on replica", replica.shardId());
96: Nhat Nguyen, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("failed to update settings on indices [{}]", (Object) concreteIndices), t);
93: Boaz Leskes, trace, MethodDeclaration, logger.trace("using cluster state version [{}] to determine shards", state.version());
77: Nhat Nguyen, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("failed to delete templates [{}]", request.name()), e);
99: Nhat Nguyen, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("failed to put template [{}]", request.name()), e);
113: Igor Motov, warn, IfStmt, logger.warn("Not updating settings for the index [{}] because upgraded of some primary shards failed - expected[{}], received[{}]", index, expectedPrimaryCount, primaryCount == null ? 0 : primaryCount);
80: Nhat Nguyen, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("failed to upgrade minimum compatibility version settings on indices [{}]", request.versions().keySet()), t);
91: Nhat Nguyen, info, CatchClause, logger.info(() -> new ParameterizedMessage("Bulk request {} has been cancelled.", executionId), e);
94: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("Failed to execute bulk request {}.", executionId), e);
140: Daniel Mitterdorfer, trace, MethodDeclaration, logger.trace("Retry of bulk request scheduled in {} ms.", next.millis());
389: Areek Zillur, trace, IfStmt, logger.trace("cluster is blocked, scheduling a retry", blockException);
496: Nhat Nguyen, debug, LambdaExpr, logger.debug(() -> new ParameterizedMessage("failed to execute pipeline [{}] for document [{}/{}/{}]", indexRequest.getPipeline(), indexRequest.index(), indexRequest.type(), indexRequest.id()), exception);
501: Ryan Ernst, error, IfStmt, logger.error("failed to execute pipeline for a bulk request", exception);
202: Nhat Nguyen, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("{} failed to execute bulk item ({}) {}", request.shardId(), docWriteRequest.opType().getLowercase(), request), failure);
199: Nhat Nguyen, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("{} failed to execute bulk item ({}) {}", request.shardId(), docWriteRequest.opType().getLowercase(), request), failure);
97: Nhat Nguyen, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("{} failed to execute multi_get for [{}]/[{}]", shardId, item.type(), item.id()), e);
168: Jason Tedor, info, ForStmt, logger.info(new ParameterizedMessage("{} primary-replica resync to replica on node [{}] failed", f.fullShardId(), f.nodeId()), f.getCause());
180: Yannick Welsch, trace, IfStmt, logger.trace("primary became unavailable during resync, ignoring", exp);
150: markharwood, trace, IfStmt, logger.trace("[{}] Moving to next phase: [{}], based on results from: {} (cluster state version: {})", currentPhase.getName(), nextPhase.getName(), resultsFrom, clusterStateVersion);
142: Jim Ferenczi, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("{} shards failed for phase: [{}]", shardSearchFailures.length, getName()), cause);
132: Nhat Nguyen, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("All shards failed for phase: [{}]", getName()), cause);
163: Nhat Nguyen, debug, IfStmt, logger.debug(new ParameterizedMessage("Failed to execute [{}] while moving to [{}] phase", request, phase.getName()), e);
230: Jason Tedor, trace, CatchClause, logger.trace("failed to release context", inner);
241: Simon Willnauer, trace, IfStmt, logger.trace("got first-phase result from {}", result != null ? result.getSearchShardTarget() : null);
135: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("Clear SC failed on node[{}]", node), e);
89: Nhat Nguyen, debug, TryStmt, context.getLogger().debug(() -> new ParameterizedMessage("[{}] Failed to execute query phase", querySearchRequest.id()), exception);
171: Nhat Nguyen, debug, TryStmt, logger.debug(() -> new ParameterizedMessage("[{}] Failed to execute fetch phase", fetchSearchRequest.id()), e);
195: Simon Willnauer, trace, CatchClause, context.getLogger().trace("failed to release context", e);
106: Nhat Nguyen, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("{}: Failed to execute [{}] lastShard [{}]", shard != null ? shard.shortSummary() : shardIt.shardId(), request, lastShard), e);
116: Nhat Nguyen, debug, IfStmt, logger.debug(new ParameterizedMessage("{}: Failed to execute [{}] lastShard [{}]", shard != null ? shard.shortSummary() : shardIt.shardId(), request, lastShard), e);
98: Nhat Nguyen, trace, IfStmt, logger.trace(new ParameterizedMessage("{}: Failed to execute [{}]", shard, request), e);
95: Nhat Nguyen, debug, IfStmt, logger.debug(new ParameterizedMessage("{}: Failed to execute [{}]", shard != null ? shard.shortSummary() : shardIt.shardId(), request), e);
262: Nhat Nguyen, debug, IfStmt, logger.debug(new ParameterizedMessage("[{}] Failed to execute {} phase", searchId, phaseName), failure);
88: Alexander Kazakov, debug, MethodDeclaration, logger.debug("[{}] cluster service closed while waiting for enough shards to be started.", Arrays.toString(indexNames));
94: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("Failed to send error response for action [{}] and request [{}]", actionName, request), e1);
122: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("failed to execute failure callback on [{}]", listener), e);
172: Jason Tedor, Error, CatchClause, logger.trace("Error during transport action execution.", e);
134: Boaz Leskes, trace, ConstructorDeclaration, logger.trace("resolving shards based on cluster state version [{}]", clusterState.version());
208: Boaz Leskes, trace, MethodDeclaration, logger.trace("received response for {}", shard);
235: Nhat Nguyen, debug, IfStmt, logger.debug(new ParameterizedMessage("{}: failed to execute [{}]", shard != null ? shard.shortSummary() : shardIt.shardId(), request), e);
225: Nhat Nguyen, trace, IfStmt, logger.trace(new ParameterizedMessage("{}: failed to execute [{}]", shard != null ? shard.shortSummary() : shardIt.shardId(), request), e);
267: Jason Tedor, trace, IfStmt, logger.trace("resolving shards for [{}] based on cluster state version [{}]", actionName, clusterState.version());
349: javanna, trace, IfStmt, logger.trace("received response for [{}] from node [{}]", actionName, node.getId());
365: Nhat Nguyen, debug, IfStmt, logger.debug(new ParameterizedMessage("failed to execute [{}] on node [{}]", actionName, nodeId), t);
383: Jason Tedor, debug, CatchClause, logger.debug("failed to combine responses from nodes", e);
402: Jason Tedor, trace, IfStmt, logger.trace("[{}] executing operation on [{}] shards", actionName, totalShards);
447: Nhat Nguyen, debug, IfStmt, logger.debug(new ParameterizedMessage("[{}] failed to execute operation for shard [{}]", actionName, shardRouting.shortSummary()), e);
442: Nhat Nguyen, trace, IfStmt, logger.trace(new ParameterizedMessage("[{}] failed to execute operation for shard [{}]", actionName, shardRouting.shortSummary()), e);
428: Jason Tedor, trace, IfStmt, logger.trace("[{}]  executing operation for shard [{}]", actionName, shardRouting.shortSummary());
433: Jason Tedor, trace, IfStmt, logger.trace("[{}]  completed operation for shard [{}]", actionName, shardRouting.shortSummary());
116: Igor Motov, warn, MethodDeclaration, logger.warn("attempt to execute a master node operation without task");
209: Yannick Welsch, debug, IfStmt, logger.debug("connection exception while trying to forward request with action name [{}] to master node [{}], scheduling a retry. Error: [{}]", actionName, nodes.getMasterNode(), exp.getDetailedMessage());
197: Yannick Welsch, debug, IfStmt, logger.debug("no known master node, scheduling a retry");
181: Yannick Welsch, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("master could not publish cluster state or stepped down before publishing action [{}], scheduling a retry", actionName), t);
158: Yannick Welsch, trace, IfStmt, logger.trace("can't execute due to a cluster block, retrying", blockException);
165: Yannick Welsch, trace, CatchClause, logger.trace("exception occurred during cluster block checking, accepting state", e);
239: Nhat Nguyen, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("timed out while retrying [{}] after failure (timeout [{}])", actionName, timeout), failure);
83: Igor Motov, warn, MethodDeclaration, logger.warn("attempt to execute a transport nodes operation without a task");
235: Nhat Nguyen, debug, IfStmt, logger.debug(new ParameterizedMessage("failed to execute on node [{}]", nodeId), t);
248: Jason Tedor, debug, CatchClause, logger.debug("failed to combine responses from nodes", e);
108: Jason Tedor, trace, IfStmt, logger.trace("[{}] op [{}] completed on primary for request [{}]", primaryId, opType, request);
157: Boaz Leskes, trace, IfStmt, logger.trace("[{}] sending op [{}] to replica {} for request [{}]", shard.shardId(), opType, shard, replicaRequest);
181: Nhat Nguyen, trace, MethodDeclaration, logger.trace(() -> new ParameterizedMessage("[{}] failure while performing [{}] on replica {}, request [{}]", shard.shardId(), opType, shard, replicaRequest), replicaException);
223: Ali Beyad, trace, IfStmt, logger.trace("[{}] not enough active copies to meet shard count of [{}] (have {}, needed {}), scheduling a retry. op [{}], " + "request [{}]", shardId, waitForActiveShards, shardRoutingTable.activeShards().size(), resolvedShards, opType, request);
88: Britta Weber, trace, MethodDeclaration, logger.trace("{}: got response from {}", actionName, shardId);
96: Britta Weber, trace, MethodDeclaration, logger.trace("{}: got failure from {}", actionName, shardId);
146: Britta Weber, trace, MethodDeclaration, logger.trace("{}: got all shard responses", actionName);
268: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("Failed to send response for {}", actionName), inner);
372: Jason Tedor, warn, CatchClause, logger.warn("failed to send response", inner);
387: Jason Tedor, info, IfStmt, logger.info(new ParameterizedMessage("{} failed to execute post-operation global checkpoint sync", shard.shardId()), e);
412: Boaz Leskes, warn, CatchClause, logger.warn("failed to send response", e);
579: Jason Tedor, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("Retrying operation on replica, action [{}], request [{}]", transportReplicaAction, request), e);
621: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to send error message back to client for action [{}]", transportReplicaAction), responseException);
650: Boaz Leskes, trace, IfStmt, logger.trace("action [{}] completed on shard [{}] for request [{}]", transportReplicaAction, request.shardId(), request);
741: Boaz Leskes, trace, IfStmt, logger.trace("send action [{}] to local primary [{}] for request [{}] with cluster state version [{}] to [{}] ", transportPrimaryAction, request.shardId(), request, state.version(), primary.currentNodeId());
750: Boaz Leskes, trace, IfStmt, logger.trace("failed to find primary [{}] for request [{}] despite sender thinking it would be here. Local cluster state " + "version [{}]] is older than on sending node (version [{}]), scheduling a retry...", request.shardId(), request, state.version(), request.routedBasedOnClusterVersion());
763: Boaz Leskes, trace, IfStmt, logger.trace("send action [{}] on primary [{}] for request [{}] with cluster state version [{}] to [{}]", actionName, request.shardId(), request, state.version(), primary.currentNodeId());
772: Boaz Leskes, trace, IfStmt, logger.trace("primary shard [{}] is not yet active, scheduling a retry: action [{}], request [{}], " + "cluster state version [{}]", request.shardId(), actionName, request, state.version());
778: Boaz Leskes, trace, IfStmt, logger.trace("primary shard [{}] is assigned to an unknown node [{}], scheduling a retry: action [{}], request [{}], " + "cluster state version [{}]", request.shardId(), primary.currentNodeId(), actionName, request, state.version());
817: Isabel Drost-Fromm, trace, IfStmt, logger.trace("cluster is blocked, scheduling a retry", blockException);
850: Nhat Nguyen, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("received an error from node [{}] for request [{}], scheduling a retry", node.getId(), requestToPerform), exp);
896: Nhat Nguyen, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("operation failed. action [{}], request [{}]", actionName, request), failure);
904: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("unexpected error during the primary phase for action [{}], request [{}]", actionName, request), failure);
919: Areek Zillur, trace, IfStmt, logger.trace("operation succeeded. action [{}],request [{}]", actionName, request);
352: Jason Tedor, warn, IfStmt, logger.warn("block until refresh ran out of slots and forced a refresh: [{}]", request);
388: Nhat Nguyen, warn, IfStmt, logger.warn(new ParameterizedMessage("[{}] {}", replica.shardId(), message), exception);
259: Jason Tedor, warn, CatchClause, logger.warn("failed to send response for get", inner);
152: Boaz Leskes, trace, IfStmt, logger.trace("executing [{}] based on cluster state version [{}]", request, clusterState.version());
208: Nhat Nguyen, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("{}: failed to execute [{}]", shardRouting, internalRequest.request()), e);
225: Nhat Nguyen, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("{}: failed to execute [{}]", null, internalRequest.request()), failure);
236: Jason Tedor, trace, IfStmt, logger.trace("sending request [{}] to shard [{}] on node [{}]", internalRequest.request(), internalRequest.request().internalShardId, node);
289: Shay Banon, warn, CatchClause, logger.warn("failed to send response for get", e1);
301: Shay Banon, trace, IfStmt, logger.trace("executing [{}] on shard [{}]", request, request.internalShardId);
98: Igor Motov, warn, MethodDeclaration, logger.warn("attempt to execute a transport tasks operation without a task");
260: Jason Tedor, debug, CatchClause, logger.debug("failed to generate empty response", e);
318: Nhat Nguyen, debug, IfStmt, logger.debug(new ParameterizedMessage("failed to execute on node [{}]", nodeId), t);
333: Jason Tedor, debug, CatchClause, logger.debug("failed to combine responses from nodes", e);
362: Nik Everett, warn, CatchClause, logger.warn("Failed to send failure", e1);
91: Nhat Nguyen, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("{} failed to execute multi term vectors for [{}]/[{}]", shardId, termVectorsRequest.type(), termVectorsRequest.id()), t);
241: Areek Zillur, trace, IfStmt, logger.trace("Retry attempt [{}] of [{}] on version conflict on [{}][{}][{}]", retryCount + 1, request.retryOnConflict(), request.index(), request.getShardId(), request.id());
115: Lee Hinman, warn, IfStmt, logger.warn("Invalid upsert operation [{}] for script [{}], doing nothing...", operation, script.getIdOrCode());
384: Lee Hinman, warn, SwitchStmt, logger.warn("Used upsert operation [{}] for script [{}], doing nothing...", operation, scriptId);
126: tlrx, info, IfStmt, logger.info("running graceful exit on windows");
371: Robert Muir, error, IfStmt, logger.error("Exception", e);
368: Jason Tedor, error, IfStmt, logger.error("node validation exception\n{}", e.getMessage());
362: Jason Tedor, error, TryStmt, logger.error("Guice Exception: {}", os.toString("UTF-8"));
136: Jason Tedor, info, IfStmt, logger.info("explicitly enforcing bootstrap checks");
134: Jason Tedor, info, IfStmt, logger.info("bound or publishing to a non-loopback address, enforcing bootstrap checks");
167: Simon Willnauer, error, MethodDeclaration, logger.warn(error);
434: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("I/O exception while trying to read [{}]", path), e);
430: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("unable to parse vm.max_map_count [{}]", rawProcSysVmMaxMapCount), e);
84: Jason Tedor, Error, MethodDeclaration, LogConfigurator.registerErrorListener();
74: Nhat Nguyen, error, MethodDeclaration, logger.error(() -> new ParameterizedMessage("fatal error in thread [{}], exiting", threadName), t);
79: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("uncaught exception in thread [{}]", threadName), t);
50: Robert Muir, warn, CatchClause, logger.warn("unable to link C library. native methods (mlockall) will be disabled.", e);
61: Robert Muir, warn, CatchClause, logger.warn("JNA not found. native methods and handlers will be disabled.");
63: Robert Muir, warn, CatchClause, logger.warn("unable to link Windows/Kernel32 library. native methods and handlers will be disabled.");
59: Robert Muir, debug, TryStmt, logger.debug("windows/Kernel32 library loaded");
120: tlrx, debug, IfStmt, logger.debug("console control handler receives event [{}@{}]", event, dwCtrlType);
84: Yannick Welsch, warn, IfStmt, logger.warn("Unable to retrieve resource limits: {}", JNACLibrary.strerror(Native.getLastError()));
93: Yannick Welsch, warn, MethodDeclaration, logger.warn("Unable to lock JVM Memory: error={}, reason={}", errno, errMsg);
94: Robert Muir, warn, MethodDeclaration, logger.warn("This can result in part of the JVM being swapped out.");
110: Robert Muir, warn, IfStmt, logger.warn("Increase RLIMIT_MEMLOCK (ulimit).");
97: Yannick Welsch, warn, IfStmt, logger.warn("Increase RLIMIT_MEMLOCK, soft limit: {}, hard limit: {}", rlimitToString(softLimit), rlimitToString(hardLimit));
101: Robert Muir, warn, IfStmt, logger.warn("These can be adjusted by modifying /etc/security/limits.conf, for example: \n" + "\t# allow user '{}' mlockall\n" + "\t{} soft memlock unlimited\n" + "\t{} hard memlock unlimited", user, user, user);
107: Robert Muir, warn, IfStmt, logger.warn("If you are logged in interactively, you will have to re-login for the new limits to take effect.");
127: Jason Tedor, warn, IfStmt, logger.warn("unable to retrieve max number of threads [" + JNACLibrary.strerror(Native.getLastError()) + "]");
138: Jason Tedor, warn, IfStmt, logger.warn("unable to retrieve max size virtual memory [" + JNACLibrary.strerror(Native.getLastError()) + "]");
149: Jason Tedor, warn, IfStmt, logger.warn("unable to retrieve max file size [" + JNACLibrary.strerror(Native.getLastError()) + "]");
186: Yannick Welsch, warn, IfStmt, logger.warn("Unable to lock JVM memory. Failed to set working set size. Error code {}", Native.getLastError());
224: Jason Tedor, warn, IfStmt, logger.warn("failed to get short path name: {}", Native.getLastError());
232: Jason Tedor, warn, IfStmt, logger.warn("failed to get short path name: {}", Native.getLastError());
248: Yannick Welsch, warn, IfStmt, logger.warn("unknown error {} when adding console ctrl handler", Native.getLastError());
246: tlrx, debug, IfStmt, logger.debug("console ctrl handler correctly set");
267: Jason Tedor, debug, IfStmt, logger.debug("unable to install syscall filter", e);
269: Jason Tedor, warn, CatchClause, logger.warn("unable to install syscall filter: ", e);
48: jaymode, warn, CatchClause, logger.warn("JNA not found. native methods will be disabled.", e);
50: jaymode, warn, CatchClause, logger.warn("unable to load JNA native support library, native methods will be disabled.", e);
57: jaymode, warn, IfStmt, logger.warn("cannot mlockall because JNA is not available");
65: jaymode, warn, IfStmt, logger.warn("cannot check if running as root because JNA is not available");
73: lzh3636, warn, IfStmt, logger.warn("cannot virtual lock because JNA is not available");
87: Jason Tedor, warn, IfStmt, logger.warn("cannot obtain short path for [{}] because JNA is not avilable", path);
95: jaymode, warn, IfStmt, logger.warn("cannot register console handler because JNA is not available");
110: Jason Tedor, warn, IfStmt, logger.warn("cannot install system call filter because JNA is not available");
118: Jason Tedor, warn, IfStmt, logger.warn("cannot getrlimit RLIMIT_NPROC because JNA is not available");
126: Jason Tedor, warn, IfStmt, logger.warn("cannot getrlimit RLIMIT_AS beacuse JNA is not available");
134: Jason Tedor, warn, IfStmt, logger.warn("cannot getrlimit RLIMIT_FSIZE because JNA is not available");
120: Robert Muir, warn, CatchClause, logger.warn("unable to link C library. native methods (seccomp) will be disabled.", e);
395: Ryan Ernst, debug, IfStmt, logger.debug("seccomp(SECCOMP_SET_MODE_FILTER): {}, falling back to prctl(PR_SET_SECCOMP)...", JNACLibrary.strerror(errno1));
411: Robert Muir, debug, MethodDeclaration, logger.debug("Linux seccomp filter installation successful, threads: [{}]", method == 1 ? "all" : "app");
439: Robert Muir, warn, CatchClause, logger.warn("unable to link C library. native methods (seatbelt) will be disabled.", e);
478: Robert Muir, debug, TryStmt, logger.debug("OS X seatbelt initialization successful");
508: Robert Muir, warn, CatchClause, logger.warn("unable to link C library. native methods (priv_set) will be disabled.", e);
538: Robert Muir, debug, MethodDeclaration, logger.debug("Solaris priv_set initialization successful");
563: Robert Muir, debug, MethodDeclaration, logger.debug("BSD RLIMIT_NPROC initialization successful");
605: Robert Muir, debug, MethodDeclaration, logger.debug("Windows ActiveProcessLimit initialization successful");
136: Yannick Welsch, debug, IfStmt, logger.debug("node_sampler_interval[{}]", nodesSamplerInterval);
179: Shay Banon, debug, IfStmt, logger.debug("address [{}] already exists with [{}], ignoring...", transportAddress, otherNode);
194: Shay Banon, debug, ForeachStmt, logger.debug("adding address [{}]", node);
213: Ryan Ernst, debug, IfStmt, logger.debug("removing address [{}] from listed nodes", otherNode);
222: Ryan Ernst, debug, IfStmt, logger.debug("disconnecting from node with address [{}]", otherNode);
376: Nhat Nguyen, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("failed to connect to discovered node [{}]", node), e);
372: Boaz Leskes, trace, TryStmt, logger.trace("connecting to node [{}]", node);
395: Shay Banon, warn, CatchClause, logger.warn("failed to sample", e);
431: Nhat Nguyen, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("failed to connect to node [{}], ignoring...", listedNode), e);
434: Nhat Nguyen, info, CatchClause, logger.info(() -> new ParameterizedMessage("failed to get node info for {}, disconnecting...", listedNode), e);
420: Boaz Leskes, warn, IfStmt, logger.warn("node {} not part of the cluster {}, ignoring...", listedNode, clusterName);
484: Nhat Nguyen, info, IfStmt, logger.info(() -> new ParameterizedMessage("failed to get local cluster state info for {}, disconnecting...", nodeToPing), e);
481: Nhat Nguyen, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("failed to connect to node [{}], ignoring...", nodeToPing), e);
500: Boaz Leskes, trace, IfStmt, logger.trace("connecting to cluster node [{}]", nodeToPing);
528: Nhat Nguyen, info, MethodDeclaration, logger.info(() -> new ParameterizedMessage("failed to get local cluster state for {}, disconnecting...", nodeToPing), e);
550: javanna, warn, IfStmt, logger.warn("node {} not part of the cluster {}, ignoring...", entry.getValue().getState().nodes().getLocalNode(), clusterName);
141: Boaz Leskes, trace, IfStmt, logger.trace("observer timed out. notifying listener. timeout setting [{}], time since start [{}]", timeOutValue, new TimeValue(timeSinceStartMS));
167: Boaz Leskes, trace, IfStmt, logger.trace("observer: sampled state rejected by predicate ({}). adding listener to ClusterService", newState);
163: Boaz Leskes, trace, IfStmt, logger.trace("observer: sampled state accepted by predicate ({})", newState);
196: Boaz Leskes, trace, IfStmt, logger.trace("observer: predicate rejected change (new cluster state version [{}])", state.version());
193: Boaz Leskes, trace, IfStmt, logger.trace("observer: predicate approved change but observing context has changed - ignoring (new cluster state version [{}])", state.version());
189: Boaz Leskes, trace, IfStmt, logger.trace("observer: accepting cluster state change ({})", state);
219: Boaz Leskes, trace, IfStmt, logger.trace("observer: postAdded - predicate rejected state ({})", newState);
216: Boaz Leskes, trace, IfStmt, logger.trace("observer: postAdded - predicate approved state but observing context has changed - ignoring ({})", newState);
211: Boaz Leskes, trace, IfStmt, logger.trace("observer: post adding listener: accepting current cluster state ({})", newState);
228: Boaz Leskes, trace, IfStmt, logger.trace("observer: cluster service closed. notifying listener.");
240: Boaz Leskes, trace, IfStmt, logger.trace("observer: timeout notification from cluster service. timeout setting [{}], time since start [{}]", timeOutValue, new TimeValue(timeSinceStartMS));
133: Lee Hinman, trace, IfStmt, logger.trace("I have been elected master, scheduling a ClusterInfoUpdateJob");
144: Simon Willnauer, debug, IfStmt, logger.debug("Couldn't schedule cluster info update task - node might be shutting down", ex);
176: Lee Hinman, debug, IfStmt, logger.debug("data node was added, retrieving new cluster info");
185: Lee Hinman, trace, IfStmt, logger.trace("Removing node from cluster info: {}", removedNode.getId());
217: Lee Hinman, trace, IfStmt, logger.trace("Submitting new rescheduling cluster info update job");
238: Simon Willnauer, debug, IfStmt, logger.debug("Couldn't re-schedule cluster info update task - node might be shutting down", ex);
226: Simon Willnauer, trace, IfStmt, logger.trace("Scheduling next run for updating cluster info in: {}", updateFrequency.toString());
231: Simon Willnauer, debug, CatchClause, logger.debug("Reschedule cluster info service was rejected", ex);
278: Simon Willnauer, trace, IfStmt, logger.trace("Skipping ClusterInfoUpdatedJob since it is disabled");
288: Simon Willnauer, trace, IfStmt, logger.trace("Performing ClusterInfoUpdateJob");
310: Simon Willnauer, warn, IfStmt, logger.warn("Failed to execute NodeStatsAction for ClusterInfoUpdateJob", e);
307: Simon Willnauer, trace, IfStmt, logger.trace("Failed to execute NodeStatsAction for ClusterInfoUpdateJob", e);
303: Isabel Drost-Fromm, error, IfStmt, logger.error("NodeStatsAction timed out for ClusterInfoUpdateJob", e);
340: Simon Willnauer, warn, IfStmt, logger.warn("Failed to execute IndicesStatsAction for ClusterInfoUpdateJob", e);
337: Simon Willnauer, trace, IfStmt, logger.trace("Failed to execute IndicesStatsAction for ClusterInfoUpdateJob", e);
333: Isabel Drost-Fromm, error, IfStmt, logger.error("IndicesStatsAction timed out for ClusterInfoUpdateJob", e);
353: Simon Willnauer, warn, CatchClause, logger.warn("Failed to update node information for ClusterInfoUpdateJob within {} timeout", fetchTimeout);
360: Simon Willnauer, warn, CatchClause, logger.warn("Failed to update shard information for ClusterInfoUpdateJob within {} timeout", fetchTimeout);
366: Simon Willnauer, info, CatchClause, logger.info("Failed executing ClusterInfoService listener", e);
378: Simon Willnauer, trace, IfStmt, logger.trace("shard: {} size: {}", sid, size);
406: Lee Hinman, trace, IfStmt, logger.trace("node: [{}], most available: total disk: {}, available disk: {} / least available: total disk: {}, available disk: {}", nodeId, mostAvailablePath.getTotal(), leastAvailablePath.getAvailable(), leastAvailablePath.getTotal(), leastAvailablePath.getAvailable());
412: Lee Hinman, trace, IfStmt, logger.trace("node: [{}] least available path has less than 0 total bytes of disk [{}], skipping", nodeId, leastAvailablePath.getTotal().getBytes());
420: Lee Hinman, trace, IfStmt, logger.trace("node: [{}] most available path has less than 0 total bytes of disk [{}], skipping", nodeId, mostAvailablePath.getTotal().getBytes());
389: javanna, warn, IfStmt, logger.warn("Unable to retrieve node FS stats for {}", nodeStats.getNode().getName());
139: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to disconnect to node [{}]", node), e);
162: Nhat Nguyen, warn, IfStmt, logger.warn(() -> new ParameterizedMessage("failed to connect to node {} (tried [{}] times)", node, finalNodeFailureCount), e);
174: Jason Tedor, warn, MethodDeclaration, logger.warn("unexpected error while checking for node reconnects", e);
61: Adrien Grand, warn, IfStmt, logger.warn("can't send mapping refresh for [{}], no master known.", request.index());
103: Nhat Nguyen, debug, IfStmt, logger.debug("sending [{}] to [{}] for shard entry [{}]", actionName, masterNode.getId(), request);
116: Nhat Nguyen, warn, IfStmt, logger.warn(new ParameterizedMessage("unexpected failure while sending request [{}] to [{}] for shard entry [{}]", actionName, masterNode, request), exp);
100: Nhat Nguyen, warn, IfStmt, logger.warn("no master known for action [{}] for shard entry [{}]", actionName, request);
175: Nhat Nguyen, trace, IfStmt, logger.trace("new cluster state [{}] after waiting for master election for shard entry [{}]", state, request);
182: Nhat Nguyen, warn, MethodDeclaration, logger.warn("node closed while execution action [{}] for shard entry [{}]", actionName, request);
207: Nhat Nguyen, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("{} received shard failed for {}", request.shardId, request), request.failure);
216: Nhat Nguyen, error, MethodDeclaration, logger.error(() -> new ParameterizedMessage("{} unexpected failure while failing shard [{}]", request.shardId, request), e);
221: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("{} failed to send failure [{}] while failing shard [{}]", request.shardId, e, request), channelException);
227: Yannick Welsch, error, MethodDeclaration, logger.error("{} no longer master while failing shard [{}]", request.shardId, request);
231: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("{} failed to send no longer master while failing shard [{}]", request.shardId, request), channelException);
240: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("{} failed to send response while failing shard [{}]", request.shardId, request), channelException);
286: Yannick Welsch, debug, IfStmt, logger.debug("{} failing shard failed task [{}] (primary term {} does not match current term {})", task.shardId, task, task.primaryTerm, indexMetaData.primaryTerm(task.shardId.id()));
312: Yannick Welsch, debug, IfStmt, logger.debug("{} failing shard {} (shard failed task: [{}])", task.shardId, matched, task);
307: Yannick Welsch, debug, IfStmt, logger.debug("{} ignoring shard failed task [{}] (shard does not exist anymore)", task.shardId, task);
302: Yannick Welsch, debug, IfStmt, logger.debug("{} marking shard {} as stale (shard failed task: [{}])", task.shardId, task.allocationId, task);
270: Yannick Welsch, debug, IfStmt, logger.debug("{} ignoring shard failed task [{}] (unknown index {})", task.shardId, task, task.shardId.getIndex());
325: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to apply failed shards {}", failedShardsToBeApplied), e);
345: Yannick Welsch, trace, IfStmt, logger.trace("{}, scheduling a reroute", reason);
440: Yannick Welsch, debug, MethodDeclaration, logger.debug("{} received shard started for [{}]", request.shardId, request);
488: Yannick Welsch, debug, IfStmt, logger.debug("{} starting shard {} (shard started task: [{}])", task.shardId, matched, task);
485: Yannick Welsch, trace, IfStmt, logger.trace("{} ignoring shard started task [{}] (already scheduled to start {})", task.shardId, task, matched);
479: Yannick Welsch, debug, IfStmt, logger.debug("{} ignoring shard started task [{}] (shard exists but is not initializing: {})", task.shardId, task, matched);
503: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to apply started shards {}", shardRoutingsToBeApplied), e);
512: Nhat Nguyen, error, MethodDeclaration, logger.error(() -> new ParameterizedMessage("unexpected failure during [{}]", source), e);
1170: Igor Motov, warn, CatchClause, logger.warn("Skipping unknown custom object with type {}", currentFieldName);
205: Ali Beyad, debug, IfStmt, logger.debug("[{}] index created, but the operation timed out while waiting for " + "enough shards to be started.", request.index());
524: Sergey Galkin, info, TryStmt, logger.info("[{}] creating index, cause [{}], templates {}, shards [{}]/[{}], mappings {}", request.index(), request.cause(), templateNames, indexMetaData.getNumberOfShards(), indexMetaData.getNumberOfReplicas(), mappings.keySet());
561: Nhat Nguyen, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("[{}] failed to create", request.index()), e);
559: Nhat Nguyen, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("[{}] failed to create", request.index()), e);
100: Jason Tedor, info, ForeachStmt, logger.info("{} deleting index", index);
108: Nik Everett, trace, MethodDeclaration, logger.trace("{} tombstones purged from the cluster state. Previous tombstone size: {}. Current tombstone size: {}.", graveyardBuilder.getNumPurged(), previousGraveyardSize, currentGraveyard.getTombstones().size());
112: Luca Cavanna, info, MethodDeclaration, logger.info("closing indices [{}]", indicesAsString);
145: Alexander Kazakov, debug, IfStmt, logger.debug("[{}] indices opened, but the operation timed out while waiting for " + "enough shards to be started.", Arrays.toString(indexNames));
182: Luca Cavanna, info, MethodDeclaration, logger.info("opening indices [{}]", indicesAsString);
120: Jason Tedor, info, ForeachStmt, logger.info("removing template [{}]", templateName);
189: Jason Tedor, info, MethodDeclaration, logger.info("adding template [{}] for index patterns {}", request.name, request.indexPatterns);
212: Jason Tedor, warn, MethodCallExpr, logger.warn("{} ignoring unknown index setting: [{}] with value [{}]; archiving", indexMetaData.getIndex(), e.getKey(), e.getValue());
213: Nhat Nguyen, warn, MethodCallExpr, logger.warn(() -> new ParameterizedMessage("{} ignoring invalid index setting: [{}] with value [{}]; archiving", indexMetaData.getIndex(), e.getKey(), e.getValue()), ex);
210: Jason Tedor, warn, MethodDeclaration, final Settings upgrade = indexScopedSettings.archiveUnknownOrInvalidSettings(settings, e -> logger.warn("{} ignoring unknown index setting: [{}] with value [{}]; archiving", indexMetaData.getIndex(), e.getKey(), e.getValue()), (e, ex) -> logger.warn(() -> new ParameterizedMessage("{} ignoring invalid index setting: [{}] with value [{}]; archiving", indexMetaData.getIndex(), e.getKey(), e.getValue()), ex));
111: Boaz Leskes, debug, IfStmt, logger.debug("ignoring a mapping task of type [{}] with a null index.", task);
123: Simon Willnauer, debug, IfStmt, logger.debug("[{}] ignoring tasks - index meta data doesn't exist", entry.getKey());
135: Simon Willnauer, debug, IfStmt, logger.debug("{} ignoring task [{}] - index meta data doesn't match task uuid", index, task);
198: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to refresh-mapping in cluster state", index), e);
189: Adrien Grand, warn, IfStmt, logger.warn("[{}] re-syncing mappings with cluster state because of types [{}]", index, updatedTypes);
212: Nhat Nguyen, warn, MethodCallExpr, logger.warn(() -> new ParameterizedMessage("failure during [{}]", source), e);
208: Boaz Leskes, warn, MethodDeclaration, clusterService.submitStateUpdateTask("refresh-mapping", refreshTask, ClusterStateTaskConfig.build(Priority.HIGH), refreshExecutor, (source, e) -> logger.warn(() -> new ParameterizedMessage("failure during [{}]", source), e));
320: Simon Willnauer, info, IfStmt, logger.info("{} create_mapping [{}]", index, mappingType);
318: Simon Willnauer, debug, IfStmt, logger.debug("{} create_mapping [{}] with source [{}]", index, mappingType, updatedSource);
311: Simon Willnauer, info, IfStmt, logger.info("{} update_mapping [{}]", index, mergedMapper.type());
309: Simon Willnauer, debug, IfStmt, logger.debug("{} update_mapping [{}] with source [{}]", index, mergedMapper.type(), updatedSource);
146: Simon Willnauer, info, ForeachStmt, logger.info("{} auto expanded replicas to [{}]", index, fNumberOfReplicas);
153: Simon Willnauer, warn, ForeachStmt, logger.warn("{} fail to auto expand replicas to [{}]", index, fNumberOfReplicas);
228: Shay Banon, info, IfStmt, logger.info("updating number_of_replicas to [{}] for indices {}", updatedNumberOfReplicas, actualIndices);
127: Igor Motov, info, IfStmt, logger.info("Starting template upgrade to version {}, {} templates will be updated and {} will be removed", Version.CURRENT, changes.get().v1().size(), changes.get().v2().size());
145: Igor Motov, info, IfStmt, logger.info("Finished upgrading templates to version {}", Version.CURRENT);
148: Igor Motov, Error, IfStmt, logger.warn("Error updating template [{}], request was not acknowledged", change.getKey());
155: Igor Motov, info, IfStmt, logger.info("Templates were upgraded to version {}", Version.CURRENT);
157: Igor Motov, warn, MethodDeclaration, logger.warn(new ParameterizedMessage("Error updating template [{}]", change.getKey()), e);
170: Igor Motov, Error, IfStmt, logger.warn("Error deleting template [{}], request was not acknowledged", template);
100: Jason Tedor, warn, MethodDeclaration, logger.warn("failed to submit schedule/execute reroute post unassigned shard", e);
125: Jason Tedor, warn, MethodDeclaration, logger.warn("failed to schedule/execute reroute post unassigned shard", e);
169: Yannick Welsch, trace, IfStmt, logger.trace("cancelling existing delayed reroute task");
196: Yannick Welsch, trace, IfStmt, logger.trace("cancelling existing delayed reroute task as delayed reroute has to happen [{}] earlier", TimeValue.timeValueNanos(existingTask.scheduledTimeToRunInNanos() - newTask.scheduledTimeToRunInNanos()));
211: Yannick Welsch, trace, IfStmt, logger.trace("no need to reschedule delayed reroute - currently scheduled delayed reroute in [{}] is enough", nextDelay);
205: Yannick Welsch, info, IfStmt, logger.info("scheduling reroute for delayed shards in [{}] ({} delayed shards)", nextDelay, UnassignedInfo.getNumberOfDelayedUnassigned(state));
185: Yannick Welsch, trace, IfStmt, logger.trace("no need to schedule reroute - no delayed unassigned shards");
473: Yannick Welsch, trace, MethodDeclaration, logger.trace("{} marked shard as started (routing: {})", initializingShard.shardId(), initializingShard);
536: Yannick Welsch, debug, MethodDeclaration, logger.debug("{} failing shard {} with unassigned info ({})", failedShard.shardId(), failedShard, unassignedInfo.shortSummary());
567: Yannick Welsch, trace, IfStmt, logger.trace("{}, relocation source failed / cancelled, mark as initializing without relocation source", targetShard);
562: Yannick Welsch, trace, IfStmt, logger.trace("{} is removed due to the failure/cancellation of the source shard", targetShard);
599: Yannick Welsch, trace, IfStmt, logger.trace("{}, resolved source to [{}]. canceling relocation ... ({})", failedShard.shardId(), sourceShard, unassignedInfo.shortSummary());
120: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to reroute routing table, current state:\n{}", state), e);
89: Shay Banon, trace, IfStmt, logger.trace("already has pending reroute, ignoring {}", reason);
92: Shay Banon, trace, TryStmt, logger.trace("rerouting {}", reason);
113: Nhat Nguyen, error, IfStmt, logger.error(() -> new ParameterizedMessage("unexpected failure during [{}], current state version [{}]", source, state.version()), e);
111: Nhat Nguyen, error, IfStmt, logger.error(() -> new ParameterizedMessage("unexpected failure during [{}], current state:\n{}", source, state), e);
195: Yannick Welsch, trace, IfStmt, logger.trace("{} shard routing failed in an earlier iteration (routing: {})", shardToFail.shardId(), shardToFail);
181: Yannick Welsch, trace, IfStmt, logger.trace("{} shard routing modified in an earlier iteration (previous: {}, current: {})", shardToFail.shardId(), shardToFail, failedShard);
192: Nhat Nguyen, warn, IfStmt, logger.warn(new ParameterizedMessage("failing shard [{}]", failedShardEntry), failedShardEntry.getFailure());
341: Daniel Mitterdorfer, info, IfStmt, logger.info("Cluster health status changed from [{}] to [{}] (reason: [{}]).", previousHealth, currentHealth, reason);
75: Ryan Ernst, info, IfStmt, logger.info("low disk watermark [{}] exceeded on {}, replicas will not be assigned to this node", diskThresholdSettings.getFreeBytesThresholdLow(), usage);
72: Ryan Ernst, warn, IfStmt, logger.warn("high disk watermark [{}] exceeded on {}, shards will be relocated away from this node", diskThresholdSettings.getFreeBytesThresholdHigh(), usage);
69: Andrew Odendaal, warn, IfStmt, logger.warn("flood stage disk watermark [{}] exceeded on {}, all indices on this node will be marked read-only", diskThresholdSettings.getFreeBytesThresholdFloodStage(), usage);
87: Ryan Ernst, info, IfStmt, logger.info("low disk watermark [{}] exceeded on {}, replicas will not be assigned to this node", Strings.format1Decimals(100.0 - diskThresholdSettings.getFreeDiskThresholdLow(), "%"), usage);
84: Ryan Ernst, warn, IfStmt, logger.warn("high disk watermark [{}] exceeded on {}, shards will be relocated away from this node", Strings.format1Decimals(100.0 - diskThresholdSettings.getFreeDiskThresholdHigh(), "%"), usage);
81: Andrew Odendaal, warn, IfStmt, logger.warn("flood stage disk watermark [{}] exceeded on {}, all indices on this node will be marked read-only", Strings.format1Decimals(100.0 - diskThresholdSettings.getFreeDiskThresholdFloodStage(), "%"), usage);
148: Ryan Ernst, debug, IfStmt, logger.debug("{} has gone below a disk threshold, but an automatic reroute has occurred " + "in the last [{}], skipping reroute", node, diskThresholdSettings.getRerouteInterval());
128: Ryan Ernst, debug, IfStmt, logger.debug("high disk watermark exceeded on {} but an automatic reroute has occurred " + "in the last [{}], skipping reroute", node, diskThresholdSettings.getRerouteInterval());
156: Ryan Ernst, info, IfStmt, logger.info("rerouting shards: [{}]", explanation);
242: Nhat Nguyen, warn, ForeachStmt, logger.warn("{} marking unavailable shards as stale: {}", shardEntry.getKey(), idsToRemove);
310: Yannick Welsch, trace, IfStmt, logger.trace("Start balancing cluster");
320: Yannick Welsch, debug, IfStmt, logger.debug("skipping rebalance due to in-flight shard/store fetches");
324: Yannick Welsch, trace, IfStmt, logger.trace("skipping rebalance as it is disabled");
328: Yannick Welsch, trace, IfStmt, logger.trace("skipping rebalance as single node only");
534: Yannick Welsch, trace, IfStmt, logger.trace("Stop balancing index [{}]  min_node [{}] weight: [{}]  max_node [{}] weight: [{}]  delta: [{}]", index, maxNode.getNodeId(), weights[highIdx], minNode.getNodeId(), weights[lowIdx], delta);
540: Yannick Welsch, trace, IfStmt, logger.trace("Balancing from node [{}] weight: [{}] to node [{}] weight: [{}]  delta: [{}]", maxNode.getNodeId(), weights[highIdx], minNode.getNodeId(), weights[lowIdx], delta);
660: Ali Beyad, trace, IfStmt, logger.trace("[{}][{}] can't move", shardRouting.index(), shardRouting.id());
657: Ali Beyad, trace, IfStmt, logger.trace("Moved shard [{}] to node [{}]", shardRouting, targetNode.getRoutingNode());
751: Yannick Welsch, trace, IfStmt, logger.trace("Assigned shard [{}] to node [{}]", shard, node.getNodeId());
767: Simon Willnauer, trace, IfStmt, logger.trace("Start allocating unassigned shards");
835: Ali Beyad, trace, IfStmt, logger.trace("No eligible node found to assign shard [{}] allocation_status [{}]", shard, allocationDecision.getAllocationStatus());
857: Ali Beyad, trace, IfStmt, logger.trace("No Node found to assign shard [{}]", shard);
849: Ali Beyad, trace, IfStmt, logger.trace("Can not allocate on node [{}] remove from round decision [{}]", node, allocationDecision.getAllocationStatus());
818: Ali Beyad, trace, IfStmt, logger.trace("Assigned shard [{}] to [{}]", shard, minNode.getNodeId());
996: Simon Willnauer, trace, IfStmt, logger.trace("Try relocating shard for index index [{}] from node [{}] to node [{}]", idx, maxNode.getNodeId(), minNode.getNodeId());
1030: Boaz Leskes, debug, IfStmt, logger.debug("Relocate shard [{}] from node [{}] to node [{}]", candidate, maxNode.getNodeId(), minNode.getNodeId());
1042: Simon Willnauer, trace, IfStmt, logger.trace("Couldn't find shard to relocate from node [{}] to node [{}] allocation decision [{}]", maxNode.getNodeId(), minNode.getNodeId(), decision == null ? "NO" : decision.type().name());
77: makeyang, trace, IfStmt, logger.trace("Can not allocate [{}] on node [{}] due to [{}]", shardRouting, node.node(), allocationDecider.getClass().getSimpleName());
99: Simon Willnauer, trace, IfStmt, logger.trace("Shard [{}] should be ignored for node [{}]", shardRouting, node.nodeId());
109: Simon Willnauer, trace, IfStmt, logger.trace("Shard [{}] can not remain on node [{}] due to [{}]", shardRouting, node.nodeId(), allocationDecider.getClass().getSimpleName());
217: Ali Beyad, trace, IfStmt, logger.trace("Shard [{}] can not be forcefully allocated to node [{}] due to [{}].", shardRouting.shardId(), node.nodeId(), decider.getClass().getSimpleName());
98: Lee Hinman, warn, CatchClause, logger.warn("[{}] has a wrong value {}, defaulting to 'indices_all_active'", CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING, CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getRaw(settings));
103: Ali Beyad, debug, ConstructorDeclaration, logger.debug("using [{}] with [{}]", CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE, type);
53: kimchy, debug, ConstructorDeclaration, logger.debug("using [cluster_concurrent_rebalance] with [{}]", clusterConcurrentRebalance);
125: uboness, trace, IfStmt, logger.trace("node [{}] has {}% used disk", node.nodeId(), usedDiskPercentage);
161: uboness, debug, IfStmt, logger.debug("less than the required {} free bytes threshold ({} bytes free) on node {}, " + "preventing allocation even though primary has never been allocated", diskThresholdSettings.getFreeBytesThresholdHigh(), freeBytes, node.nodeId());
150: uboness, debug, IfStmt, logger.debug("less than the required {} free bytes threshold ({} bytes free) on node {}, " + "but allowing allocation because primary has never been allocated", diskThresholdSettings.getFreeBytesThresholdLow(), freeBytes, node.nodeId());
137: uboness, debug, IfStmt, logger.debug("less than the required {} free bytes threshold ({} bytes free) on node {}, preventing allocation", diskThresholdSettings.getFreeBytesThresholdLow(), freeBytes, node.nodeId());
204: uboness, debug, IfStmt, logger.debug("less than the required {} free bytes threshold ({} bytes free) on node {}, " + "preventing allocation even though primary has never been allocated", Strings.format1Decimals(diskThresholdSettings.getFreeDiskThresholdHigh(), "%"), Strings.format1Decimals(freeDiskPercentage, "%"), node.nodeId());
192: uboness, debug, IfStmt, logger.debug("more than the allowed {} used disk threshold ({} used) on node [{}], " + "but allowing allocation because primary has never been allocated", Strings.format1Decimals(usedDiskThresholdLow, "%"), Strings.format1Decimals(usedDiskPercentage, "%"), node.nodeId());
179: uboness, debug, IfStmt, logger.debug("more than the allowed {} used disk threshold ({} used) on node [{}], preventing allocation", Strings.format1Decimals(usedDiskThresholdLow, "%"), Strings.format1Decimals(usedDiskPercentage, "%"), node.nodeId());
222: Lee Hinman, warn, IfStmt, logger.warn("after allocating, node [{}] would have less than the required " + "{} free bytes threshold ({} bytes free), preventing allocation", node.nodeId(), diskThresholdSettings.getFreeBytesThresholdHigh(), freeBytesAfterShard);
233: Lee Hinman, warn, IfStmt, logger.warn("after allocating, node [{}] would have more than the allowed " + "{} free disk threshold ({} free), preventing allocation", node.nodeId(), Strings.format1Decimals(diskThresholdSettings.getFreeDiskThresholdHigh(), "%"), Strings.format1Decimals(freeSpaceAfterShard, "%"));
271: Lee Hinman, trace, IfStmt, logger.trace("node [{}] has {}% free disk ({} bytes)", node.nodeId(), freeDiskPercentage, freeBytes);
279: uboness, debug, IfStmt, logger.debug("less than the required {} free bytes threshold ({} bytes free) on node {}, shard cannot remain", diskThresholdSettings.getFreeBytesThresholdHigh(), freeBytes, node.nodeId());
291: uboness, debug, IfStmt, logger.debug("less than the required {}% free disk threshold ({}% free) on node {}, shard cannot remain", diskThresholdSettings.getFreeDiskThresholdHigh(), freeDiskPercentage, node.nodeId());
314: uboness, debug, IfStmt, logger.debug("unable to determine disk usage for {}, defaulting to average across nodes [{} total] [{} free] [{}% free]", node.nodeId(), usage.getTotalBytes(), usage.getFreeBytes(), usage.getFreeDiskAsPercentage());
324: Lee Hinman, trace, IfStmt, logger.trace("usage without relocations: {}", usage);
325: Lee Hinman, trace, IfStmt, logger.trace("usage with relocations: [{} bytes] {}", relocatingShardsSize, usageIncludingRelocations);
375: xuzha, trace, IfStmt, logger.trace("only a single data node is present, allowing allocation");
384: uboness, trace, IfStmt, logger.trace("cluster info unavailable for disk threshold decider, allowing allocation.");
392: uboness, trace, IfStmt, logger.trace("unable to determine disk usages for disk-aware allocation, allowing allocation");
80: Ali Beyad, trace, IfStmt, logger.trace("Preventing snapshotted shard [{}] from being moved away from node [{}]", shardRouting.shardId(), shardSnapshotStatus.nodeId());
96: Lee Hinman, debug, ConstructorDeclaration, logger.debug("using node_concurrent_outgoing_recoveries [{}], node_concurrent_incoming_recoveries [{}], " + "node_initial_primaries_recoveries [{}]", concurrentOutgoingRecoveries, concurrentIncomingRecoveries, primariesInitialRecoveries);
173: Yannick Welsch, debug, CatchClause, logger.debug("failed to notify listeners on shutdown", ex);
390: Yannick Welsch, debug, IfStmt, logger.debug("processing [{}]: ignoring, cluster applier service not started", task.source);
394: Yannick Welsch, debug, MethodDeclaration, logger.debug("processing [{}]: execute", task.source);
404: Nhat Nguyen, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("failed to execute cluster state applier in [{}], state:\nversion [{}], source [{}]\n{}{}{}", executionTime, previousClusterState.version(), task.source, previousClusterState.nodes(), previousClusterState.routingTable(), previousClusterState.getRoutingNodes()), e);
428: Yannick Welsch, debug, IfStmt, logger.debug("cluster state updated, version [{}], source [{}]", newClusterState.version(), task.source);
426: Yannick Welsch, trace, IfStmt, logger.trace("cluster state updated, source [{}]\n{}", task.source, newClusterState);
442: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to apply updated cluster state in [{}]:\nversion [{}], uuid [{}], source [{}]\n{}", executionTime, version, stateUUID, task.source, fullState), e);
433: Yannick Welsch, debug, TryStmt, logger.debug("processing [{}]: took [{}] done applying updated cluster state (version: {}, uuid: {})", task.source, executionTime, newClusterState.version(), newClusterState.stateUUID());
422: Yannick Welsch, debug, IfStmt, logger.debug("processing [{}]: took [{}] no change in cluster state", task.source, executionTime);
462: Yannick Welsch, info, IfStmt, logger.info("{}, reason: {}", summary, task.source);
468: Yannick Welsch, debug, MethodDeclaration, logger.debug("applying cluster state version {}", newClusterState.version());
476: Yannick Welsch, warn, CatchClause, logger.warn("failed to apply cluster settings", ex);
479: Yannick Welsch, debug, MethodDeclaration, logger.debug("apply cluster state with version {}", newClusterState.version());
484: Yannick Welsch, debug, MethodDeclaration, logger.debug("set locally applied cluster state to version {}", newClusterState.version());
498: Yannick Welsch, warn, CatchClause, logger.warn("failed to notify ClusterStateApplier", ex);
495: Yannick Welsch, trace, TryStmt, logger.trace("calling [{}] with change to version [{}]", applier, clusterChangedEvent.state().version());
509: Yannick Welsch, warn, CatchClause, logger.warn("failed to notify ClusterStateListener", ex);
506: Yannick Welsch, trace, TryStmt, logger.trace("calling [{}] with change to version [{}]", listener, clusterChangedEvent.state().version());
529: Nhat Nguyen, error, CatchClause, logger.error(new ParameterizedMessage("exception thrown by listener notifying of failure from [{}]", source), inner);
539: Nhat Nguyen, error, CatchClause, logger.error(new ParameterizedMessage("exception thrown by listener while notifying of cluster state processed from [{}], old cluster state:\n" + "{}\nnew cluster state:\n{}", source, oldState, newState), e);
549: Yannick Welsch, warn, IfStmt, logger.warn("cluster state applier task [{}] took [{}] above the warn threshold of {}", source, executionTime, slowTaskLoggingThreshold);
183: Yannick Welsch, debug, IfStmt, logger.debug("processing [{}]: ignoring, master service not started", summary);
187: Yannick Welsch, debug, MethodDeclaration, logger.debug("processing [{}]: execute", summary);
191: Yannick Welsch, debug, IfStmt, logger.debug("failing [{}]: local node is no longer master", summary);
210: Yannick Welsch, debug, IfStmt, logger.debug("cluster state updated, version [{}], source [{}]", newClusterState.version(), summary);
208: Yannick Welsch, trace, IfStmt, logger.trace("cluster state updated, source [{}]\n{}", summary, newClusterState);
253: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to publish updated cluster state in [{}]:\nversion [{}], uuid [{}], source [{}]\n{}", executionTime, version, stateUUID, summary, fullState), e);
219: Yannick Welsch, info, IfStmt, logger.info("{}, reason: {}", summary, nodeSummary);
223: Yannick Welsch, debug, TryStmt, logger.debug("publishing cluster state version [{}]", newClusterState.version());
228: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failing [{}]: failed to commit cluster state version [{}]", summary, version), t);
239: Nhat Nguyen, error, CatchClause, logger.error(() -> new ParameterizedMessage("exception thrown while notifying executor of new cluster state publication [{}]", summary), e);
244: Yannick Welsch, debug, TryStmt, logger.debug("processing [{}]: took [{}] done publishing updated cluster state (version: {}, uuid: {})", summary, executionTime, newClusterState.version(), newClusterState.stateUUID());
203: Yannick Welsch, debug, IfStmt, logger.debug("processing [{}]: took [{}] no change in cluster state", summary, executionTime);
381: Yannick Welsch, debug, IfStmt, logger.debug("Couldn't schedule timeout thread - node might be shutting down", ex);
470: Nhat Nguyen, error, CatchClause, logger.error(() -> new ParameterizedMessage("exception thrown by listener notifying of failure from [{}]", source), inner);
480: Nhat Nguyen, error, CatchClause, logger.error(() -> new ParameterizedMessage("exception thrown by listener while notifying no longer master from [{}]", source), e);
490: Nhat Nguyen, error, CatchClause, logger.error(() -> new ParameterizedMessage("exception thrown by listener while notifying of cluster state processed from [{}], old cluster state:\n" + "{}\nnew cluster state:\n{}", source, oldState, newState), e);
518: Yannick Welsch, error, CatchClause, logger.error("exception thrown by listener while notifying on all nodes acked", inner);
527: Yannick Welsch, error, CatchClause, logger.error("exception thrown by listener while notifying on ack timeout", e);
539: Yannick Welsch, warn, IfStmt, logger.warn("cluster state update task [{}] took [{}] above the warn threshold of {}", source, executionTime, slowTaskLoggingThreshold);
589: Yannick Welsch, trace, ConstructorDeclaration, logger.trace("expecting {} acknowledgements for cluster_state update (version: {})", countDown, clusterStateVersion);
606: Nhat Nguyen, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("ack received from node [{}], cluster_state update (version: {})", node, clusterStateVersion), e);
603: Yannick Welsch, trace, IfStmt, logger.trace("ack received from node [{}], cluster_state update (version: {})", node, clusterStateVersion);
611: Yannick Welsch, trace, IfStmt, logger.trace("all expected nodes acknowledged cluster_state update (version: {})", clusterStateVersion);
620: Yannick Welsch, trace, IfStmt, logger.trace("timeout waiting for acknowledgement for cluster_state update (version: {})", clusterStateVersion);
639: Yannick Welsch, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("failed to execute cluster state update in [{}], state:\nversion [{}], source [{}]\n{}{}{}", executionTime, previousClusterState.version(), taskInputs.summary, previousClusterState.nodes(), previousClusterState.routingTable(), previousClusterState.getRoutingNodes()), e);
95: Yannick Welsch, debug, IfStmt, logger.debug("task [{}] timed out after [{}]", task.source, timeout);
138: Yannick Welsch, trace, IfStmt, logger.trace("skipping {}, already processed", task);
134: Yannick Welsch, trace, IfStmt, logger.trace("will process {}", task);
81: Lee Hinman, trace, IfStmt, logger.trace("creating ChildCircuitBreaker with settings {}", this.settings);
97: Yannick Welsch, debug, MethodDeclaration, logger.debug("{}", message);
143: Jason Tedor, trace, IfStmt, logger.trace("[{}] Adding [{}][{}] to used bytes [new used: [{}], limit: [-1b]]", this.name, new ByteSizeValue(bytes), label, new ByteSizeValue(newUsed));
159: Jason Tedor, trace, IfStmt, logger.trace("[{}] Adding [{}][{}] to used bytes [new used: [{}], limit: {} [{}], estimate: {} [{}]]", this.name, new ByteSizeValue(bytes), label, new ByteSizeValue(newUsed), memoryBytesLimit, new ByteSizeValue(memoryBytesLimit), newUsedWithOverhead, new ByteSizeValue(newUsedWithOverhead));
166: Jason Tedor, warn, IfStmt, logger.warn("[{}] New used memory {} [{}] for data of [{}] would be larger than configured breaker: {} [{}], breaking", this.name, newUsedWithOverhead, new ByteSizeValue(newUsedWithOverhead), label, memoryBytesLimit, new ByteSizeValue(memoryBytesLimit));
192: Lee Hinman, trace, IfStmt, logger.trace("[{}] Adjusted breaker by [{}] bytes, now [{}]", this.name, bytes, u);
71: Lee Hinman, trace, IfStmt, logger.trace("Creating MemoryCircuitBreaker with a limit of {} bytes ({}) and a overhead constant of {}", this.memoryBytesLimit, limit, this.overheadConstant);
86: Yannick Welsch, debug, MethodDeclaration, logger.debug("{}", message);
112: Lee Hinman, trace, IfStmt, logger.trace("Adding [{}][{}] to used bytes [new used: [{}], limit: [-1b]]", new ByteSizeValue(bytes), label, new ByteSizeValue(newUsed));
127: Lee Hinman, trace, IfStmt, logger.trace("Adding [{}][{}] to used bytes [new used: [{}], limit: {} [{}], estimate: {} [{}]]", new ByteSizeValue(bytes), label, new ByteSizeValue(newUsed), memoryBytesLimit, new ByteSizeValue(memoryBytesLimit), newUsedWithOverhead, new ByteSizeValue(newUsedWithOverhead));
133: Lee Hinman, warn, IfStmt, logger.warn("New used memory {} [{}] from field [{}] would be larger than configured breaker: {} [{}], breaking", newUsedWithOverhead, new ByteSizeValue(newUsedWithOverhead), label, memoryBytesLimit, new ByteSizeValue(memoryBytesLimit));
155: Lee Hinman, trace, IfStmt, logger.trace("Adjusted breaker by [{}] bytes, now [{}]", bytes, u);
348: Yannick Welsch, debug, IfStmt, LOGGER.debug("shift: [{}]", shiftOffset);
426: Yannick Welsch, debug, ForStmt, LOGGER.debug("Component [{}]:", i);
428: Yannick Welsch, debug, ForStmt, LOGGER.debug("\t{}", Arrays.toString(result[i][j]));
478: Yannick Welsch, debug, IfStmt, LOGGER.debug("Holes: {}", Arrays.toString(holes));
534: Yannick Welsch, debug, IfStmt, LOGGER.debug("\tposition ({}) of edge {}: {}", index, current, edges[index]);
535: Yannick Welsch, debug, IfStmt, LOGGER.debug("\tComponent: {}", component);
536: Yannick Welsch, debug, IfStmt, LOGGER.debug("\tHole intersections ({}): {}", current.coordinate.x, Arrays.toString(edges));
117: Simon Willnauer, debug, IfStmt, logger.debug("[{}] directory does not exist.", directory.toAbsolutePath());
121: Simon Willnauer, debug, IfStmt, logger.debug("[{}] should be a directory but is not.", directory.toAbsolutePath());
125: Simon Willnauer, debug, IfStmt, logger.debug("[{}] directory is not readable.", directory.toAbsolutePath());
322: Jason Tedor, warn, IfStmt, logger.warn(message, params);
84: Jason Tedor, ERROR, MethodDeclaration, StatusLogger.getLogger().registerListener(ERROR_LISTENER);
117: Jason Tedor, ERROR, TryStmt, StatusLogger.getLogger().removeListener(ERROR_LISTENER);
43: Michael McCandless, trace, MethodDeclaration, getLogger(component).trace("{} {}: {}", Thread.currentThread().getName(), component, message);
113: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("no version match {}, default to {}", version, defaultVersion), e);
48: Robert Muir, warn, CatchClause, logger.warn("unable to gather network information", e);
107: Yannick Welsch, debug, MethodDeclaration, logger.debug("configuration:{}{}", System.lineSeparator(), msg);
137: Nhat Nguyen, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("failed to prepareCommit settings for [{}]", settingUpdater), ex);
173: Simon Willnauer, warn, CatchClause, logger.warn("failed to apply settings", ex);
165: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to prepareCommit settings for [{}]", settingUpdater), ex);
1199: Alexander Reelsen, info, IfStmt, logger.info("updating [{}] from [{}] to [{}]", setting.key, setting.getRaw(previous), setting.getRaw(current));
1197: Alexander Reelsen, info, IfStmt, logger.info("updating [{}]", setting.key);
128: Simon Willnauer, warn, TryStmt, logger.warn(builder.toString());
74: Areek Zillur, info, IfStmt, logger.info("{} moved from [{}] to [{}]", index, source, target);
75: Areek Zillur, trace, IfStmt, logger.trace("{} syncing directory [{}]", index, target);
116: Areek Zillur, warn, IfStmt, logger.warn("[{}] no index state found - ignoring", indexFolderPath);
113: Areek Zillur, debug, IfStmt, logger.debug("[{}] no upgrade needed - already upgraded", indexFolderPath);
93: Areek Zillur, info, IfStmt, logger.info("{} upgrading [{}] to new naming convention", index, indexFolderPath);
108: Areek Zillur, info, IfStmt, logger.info("[{}] no upgrade needed - already upgraded", customLocationTarget);
63: Chris Earle, trace, IfStmt, logger.trace("lifecycle is stopping. exiting");
109: Simon Willnauer, debug, CatchClause, logger.debug("failed to write candidates", ex);
119: Simon Willnauer, warn, CatchClause, logger.warn("failed to notify callback", ex);
40: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to execute [{}]", runnable.toString()), e);
78: Jason Tedor, debug, ConstructorDeclaration, logger.debug("thread pool [{}] will adjust queue by [{}] when determining automatic queue size", getName(), QUEUE_ADJUSTMENT_AMOUNT);
200: Yannick Welsch, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to calculate optimal queue size for [{}] thread pool, " + "total frame time [{}ns], tasks [{}], task execution time [{}ns]", getName(), totalRuntime, tasksPerFrame, totalNanos), e);
176: Lee Hinman, debug, IfStmt, logger.debug("[{}]: there were [{}] tasks in [{}], avg task time [{}], EWMA task execution [{}], " + "[{} tasks/s], optimal queue is [{}], current capacity [{}]", getName(), tasksPerFrame, TimeValue.timeValueNanos(totalRuntime), TimeValue.timeValueNanos(avgTaskTime), TimeValue.timeValueNanos((long) executionEWMA.getAverage()), String.format(Locale.ROOT, "%.2f", lambda * TimeValue.timeValueSeconds(1).nanos()), desiredQueueSize, oldCapacity);
194: Jason Tedor, debug, IfStmt, logger.debug("adjusted [{}] queue size by [{}], old capacity: [{}], new capacity: [{}]", getName(), newCapacity > oldCapacity ? QUEUE_ADJUSTMENT_AMOUNT : -QUEUE_ADJUSTMENT_AMOUNT, oldCapacity, newCapacity);
72: Nhat Nguyen, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("error while processing ack for node [{}]", node), inner);
79: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("failed while applying cluster state locally [{}]", event.source()), e);
103: Shay Banon, debug, ConstructorDeclaration, logger.debug("using minimum_master_nodes [{}]", minimumMasterNodes);
165: Yannick Welsch, warn, IfStmt, logger.warn("value for setting \"{}\" is too low. This can result in data loss! Please set it to at least a quorum of master-" + "eligible nodes (current value: [{}], total number of master-eligible nodes used for publishing in this round: [{}])", ElectMasterService.DISCOVERY_ZEN_MINIMUM_MASTER_NODES_SETTING.getKey(), minimumMasterNodes(), newState.getNodes().getMasterNodes().size());
87: Boaz Leskes, debug, ConstructorDeclaration, logger.debug("[master] uses ping_interval [{}], ping_timeout [{}], ping_retries [{}]", pingInterval, pingRetryTimeout, pingRetryCount);
109: kimchy, debug, IfStmt, logger.debug("[master] restarting fault detection against master [{}], reason [{}]", masterNode, reason);
133: kimchy, debug, IfStmt, logger.debug("[master] stopping fault detection against master [{}], reason [{}]", masterNode, reason);
178: kimchy, trace, IfStmt, logger.trace("[master] [{}] transport disconnected", node);
174: kimchy, trace, CatchClause, logger.trace("[master] [{}] transport disconnected (with verified connect)", masterNode);
193: Boaz Leskes, error, CatchClause, logger.error("master failure notification was rejected, it's highly likely the node is shutting down", e);
265: Boaz Leskes, debug, IfStmt, logger.debug("[master] pinging a master {} but we do not exists on it, act as if its master failure", masterNode);
261: Shay Banon, debug, IfStmt, logger.debug("[master] pinging a master {} that is not the master", masterNode);
257: Shay Banon, debug, IfStmt, logger.debug("[master] pinging a master {} that is no longer a master", masterNode);
272: Nhat Nguyen, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("[master] failed to ping [{}], retry [{}] out of [{}]", masterNode, retryCount, pingRetryCount), exp);
276: Boaz Leskes, debug, IfStmt, logger.debug("[master] failed to ping [{}], tried [{}] times, each with maximum [{}] timeout", masterNode, pingRetryCount, pingRetryTimeout);
334: Boaz Leskes, trace, IfStmt, logger.trace("master fault detection ping request is targeted for a different [{}] cluster then us [{}]", request.clusterName, clusterName);
349: Boaz Leskes, trace, IfStmt, logger.trace("checking ping from {} under a cluster state thread", request.sourceNode);
376: Jason Tedor, error, CatchClause, logger.warn("error while sending ping response", inner);
385: Boaz Leskes, error, CatchClause, logger.warn("error while sending ping response", e);
153: Jason Tedor, warn, CatchClause, logger.warn("failed to send back failure on join request", inner);
133: Jason Tedor, error, CatchClause, logger.error("unexpected failure while waiting for incoming joins", e);
129: Boaz Leskes, trace, IfStmt, logger.trace("timed out waiting to be elected. waited [{}]. pending master node joins [{}]", timeValue, pendingNodes);
154: Boaz Leskes, trace, MethodDeclaration, logger.trace("starting an election context, will accumulate joins");
163: Boaz Leskes, trace, MethodDeclaration, logger.trace("stopping election ([{}])", reason);
201: Boaz Leskes, trace, IfStmt, logger.trace("have enough joins for election. Got [{}], required [{}]", pendingMasterJoins, electionContext.requiredMasterJoins);
196: Boaz Leskes, trace, IfStmt, logger.trace("not enough joins for election. Got [{}], required [{}]", pendingMasterJoins, electionContext.requiredMasterJoins);
366: Nhat Nguyen, error, CatchClause, logger.error(() -> new ParameterizedMessage("error handling task failure [{}]", e), inner);
377: Nhat Nguyen, error, CatchClause, logger.error(() -> new ParameterizedMessage("unexpected error during [{}]", source), e);
427: Boaz Leskes, trace, IfStmt, logger.trace("processing node joins, but we are not the master. current master: {}", currentNodes.getMasterNode());
446: Boaz Leskes, debug, IfStmt, logger.debug("received a join request for an existing node [{}]", node);
486: Yannick Welsch, debug, IfStmt, logger.debug("removing existing node [{}], which conflicts with incoming join from [{}]", nodeWithSameId, joiningNode);
491: Yannick Welsch, debug, IfStmt, logger.debug("removing existing node [{}], which conflicts with incoming join from [{}]", nodeWithSameAddress, joiningNode);
76: Boaz Leskes, debug, ConstructorDeclaration, logger.debug("[node  ] uses ping_interval [{}], ping_timeout [{}], ping_retries [{}]", pingInterval, pingRetryTimeout, pingRetryCount);
163: kimchy, trace, IfStmt, logger.trace("[node  ] [{}] transport disconnected", node);
157: kimchy, trace, CatchClause, logger.trace("[node  ] [{}] transport disconnected (with verified connect)", node);
179: Nhat Nguyen, trace, CatchClause, logger.trace(() -> new ParameterizedMessage("[node  ] [{}] ignoring node failure (reason [{}]). Local node is shutting down", node, reason), ex);
245: Nhat Nguyen, trace, MethodDeclaration, logger.trace(() -> new ParameterizedMessage("[node  ] failed to ping [{}], retry [{}] out of [{}]", node, retryCount, pingRetryCount), exp);
248: Boaz Leskes, debug, IfStmt, logger.debug("[node  ] failed to ping [{}], tried [{}] times, each with  maximum [{}] timeout", node, pingRetryCount, pingRetryTimeout);
74: Boaz Leskes, warn, IfStmt, logger.warn("dropping pending state [{}]. more than [{}] pending states.", context, maxQueueSize);
129: Boaz Leskes, debug, IfStmt, logger.debug("failing committed state {} together with state {}", pendingContext, failedContext);
179: Boaz Leskes, trace, IfStmt, logger.trace("processing pending state uuid[{}]/v[{}] together with state uuid[{}]/v[{}]", pendingState.stateUUID(), pendingState.version(), state.stateUUID(), state.version());
170: Ryan Ernst, trace, IfStmt, logger.trace("removing non-committed state with uuid[{}]/v[{}] from [{}] - a state from" + " [{}] was successfully processed", pendingState.stateUUID(), pendingState.version(), pendingMasterNode, currentMaster);
163: Ryan Ernst, warn, IfStmt, logger.warn("received a cluster state (uuid[{}]/v[{}]) from a different master than the current one," + " rejecting (received {}, current {})", pendingState.stateUUID(), pendingState.version(), pendingMasterNode, currentMaster);
206: Ryan Ernst, warn, IfStmt, logger.warn("timed out waiting for all nodes to process published state [{}] (timeout [{}], pending nodes: {})", clusterState.version(), publishTimeout, pendingNodes);
250: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to serialize cluster_state before publishing it to node {}", node), e);
304: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("error sending cluster state to {}", node), e);
286: Ryan Ernst, debug, IfStmt, logger.debug("node {} responded for cluster state [{}] (took longer than [{}])", node, clusterState.version(), publishTimeout);
298: Nhat Nguyen, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("failed to send cluster state to {}", node), exp);
295: Igor Motov, debug, IfStmt, logger.debug("resending full cluster state to node {} reason {}", node, exp.getDetailedMessage());
337: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("error sending cluster state commit (uuid [{}], version [{}]) to {}", clusterState.stateUUID(), clusterState.version(), node), t);
311: Ryan Ernst, trace, TryStmt, logger.trace("sending commit for cluster state (uuid: [{}], version [{}]) to [{}]", clusterState.stateUUID(), clusterState.version(), node);
324: Boaz Leskes, debug, IfStmt, logger.debug("node {} responded to cluster state commit [{}]", node, clusterState.version());
331: Nhat Nguyen, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("failed to commit cluster state (uuid [{}], version [{}]) to {}", clusterState.stateUUID(), clusterState.version(), node), exp);
391: Yannick Welsch, debug, IfStmt, logger.debug("received diff for but don't have any local cluster state - requesting full state");
388: Yannick Welsch, debug, IfStmt, logger.debug("received diff cluster state version [{}] with uuid [{}], diff size [{}]", incomingState.version(), incomingState.stateUUID(), request.bytes().length());
382: Yannick Welsch, debug, IfStmt, logger.debug("received full cluster state version [{}] with size [{}]", incomingState.version(), request.bytes().length());
415: Boaz Leskes, debug, CatchClause, logger.debug("failed to send response on cluster state processed", e);
426: Jason Tedor, debug, CatchClause, logger.debug("failed to send response on cluster state processed", inner);
538: Boaz Leskes, trace, IfStmt, logger.trace("ignoring ack from [{}] for cluster state version [{}]. already failed", node, clusterState.version());
557: Boaz Leskes, trace, MethodDeclaration, logger.trace("master node {} acked cluster state version [{}]. processing ... (current pending [{}], needed [{}])", masterNode, clusterState.version(), pendingMasterNodes, neededMastersToCommit);
580: Ryan Ernst, trace, IfStmt, logger.trace("master node {} failed to ack cluster state version [{}]. " + "processing ... (current pending [{}], needed [{}])", node, clusterState.version(), pendingMasterNodes, neededMastersToCommit);
597: Boaz Leskes, trace, MethodDeclaration, logger.trace("committing version [{}]", clusterState.version());
612: Nhat Nguyen, trace, MethodDeclaration, logger.trace(() -> new ParameterizedMessage("failed to commit version [{}]. {}", clusterState.version(), details), reason);
628: Boaz Leskes, trace, MethodDeclaration, logger.trace("failed to commit version [{}]. {}", clusterState.version(), reason);
157: Jason Tedor, debug, ConstructorDeclaration, logger.debug("using initial hosts {}, with concurrent_connects [{}], resolve_timeout [{}]", configuredHosts, concurrentConnects, resolveTimeout);
249: Jason Tedor, warn, IfStmt, logger.warn("timed out after [{}] resolving host [{}]", resolveTimeout, hostname);
246: Jason Tedor, warn, CatchClause, logger.warn(message, e.getCause());
229: Jason Tedor, trace, TryStmt, logger.trace("resolved host [{}] to {}", hostname, addresses);
324: Boaz Leskes, warn, IfStmt, logger.warn("unexpected error while pinging", e);
344: Boaz Leskes, warn, MethodDeclaration, logger.warn("unexpected error while finishing pinging round", e);
396: Boaz Leskes, trace, IfStmt, logger.trace("[{}] opening connection to [{}]", id(), node);
409: Boaz Leskes, trace, IfStmt, logger.trace("[{}] closing connection to [{}] due to failure", id(), node);
497: Boaz Leskes, trace, CatchClause, logger.trace("[{}] node [{}] just disconnected, will create a temp connection", pingingRound.id(), node);
505: Boaz Leskes, trace, MethodDeclaration, logger.trace("[{}] sending to {}", pingingRound.id(), node);
521: Nhat Nguyen, warn, IfStmt, logger.warn(() -> new ParameterizedMessage("[{}] failed send ping to {}", pingingRound.id(), node), e);
518: Nhat Nguyen, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("[{}] received a remote error as a response to ping {}", pingingRound.id(), node), e);
515: Nhat Nguyen, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("[{}] failed to ping {}", pingingRound.id(), node), e);
556: Boaz Leskes, trace, MethodDeclaration, logger.trace("[{}] received response from {}: {}", pingingRound.id(), node, Arrays.toString(response.pingResponses));
559: Boaz Leskes, trace, IfStmt, logger.trace("[{}] skipping received response from {}. already closed", pingingRound.id(), node);
573: Nhat Nguyen, warn, IfStmt, logger.warn(() -> new ParameterizedMessage("failed to send ping to [{}]", node), exp);
571: Nhat Nguyen, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("failed to connect to {}", node), exp);
182: Boaz Leskes, debug, ConstructorDeclaration, logger.debug("using ping_timeout [{}], join.timeout [{}], master_election.ignore_non_master [{}]", this.pingTimeout, joinTimeout, masterElectionIgnoreNonMasters);
306: Nhat Nguyen, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("failed to send leave request from master [{}] to possible master [{}]", nodes.getMasterNode(), possibleMaster), e);
294: Nhat Nguyen, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("failed to send leave request to master [{}]", nodes.getMasterNode()), e);
341: Yannick Welsch, debug, CatchClause, logger.debug("failed to publish cluster state version [{}] (not enough nodes acknowledged, min master nodes [{}])", newState.version(), electMaster.minimumMasterNodes());
370: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("failed while applying cluster state locally [{}]", clusterChangedEvent.source()), e);
384: Yannick Welsch, warn, IfStmt, logger.warn("cluster state with version [{}] that is published locally has neither been processed nor failed", newState.version());
393: Nhat Nguyen, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("interrupted while applying cluster state locally [{}]", clusterChangedEvent.source()), e);
446: Boaz Leskes, trace, IfStmt, logger.trace("thread is no longer in currentJoinThread. Stopping.");
452: Boaz Leskes, debug, IfStmt, logger.debug("elected as master, waiting for incoming joins ([{}] needed)", requiredJoins);
464: Boaz Leskes, trace, MethodDeclaration, logger.trace("failed while waiting for nodes to join, rejoining", t);
511: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to connect to master [{}], retrying...", masterNode), e);
533: Jason Tedor, info, IfStmt, logger.info("failed to send join request to master [{}], reason [{}]", masterNode, ExceptionsHelper.detailedMessage(e));
531: Nhat Nguyen, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("failed to send join request to master [{}]", masterNode), e);
527: Jason Tedor, trace, IfStmt, logger.trace("master {} failed with [{}]. retrying... (attempts done: [{}])", masterNode, ExceptionsHelper.detailedMessage(e), joinAttempt);
524: Jason Tedor, info, IfStmt, logger.info("failed to send join request to master [{}], reason [{}], tried [{}] times", masterNode, ExceptionsHelper.detailedMessage(e), joinAttempt);
517: Boaz Leskes, trace, TryStmt, logger.trace("joining master {}", masterNode);
612: Jason Tedor, debug, IfStmt, logger.debug("node [{}] does not exist in cluster state, ignoring", task);
643: Nhat Nguyen, error, MethodDeclaration, logger.error(() -> new ParameterizedMessage("unexpected failure during [{}]", source), e);
648: Jason Tedor, debug, MethodDeclaration, logger.debug("no longer master while processing node removal [{}]", source);
715: Nhat Nguyen, info, MethodDeclaration, logger.info(() -> new ParameterizedMessage("master_left [{}], reason [{}]", masterNode, reason), cause);
761: Nhat Nguyen, error, CatchClause, logger.error(() -> new ParameterizedMessage("unexpected exception while failing [{}]", reason), inner);
768: Yannick Welsch, debug, IfStmt, logger.debug("got first state from fresh master [{}]", newClusterState.nodes().getMasterNodeId());
804: Nhat Nguyen, error, MethodDeclaration, logger.error(() -> new ParameterizedMessage("unexpected failure applying [{}]", reason), e);
811: Nhat Nguyen, error, CatchClause, logger.error(() -> new ParameterizedMessage("unexpected exception while failing [{}]", reason), inner);
832: Jason Tedor, debug, IfStmt, logger.debug("received a cluster state that is not newer than the current one, ignoring (received {}, current {})", newClusterState.version(), currentState.version());
838: Martijn van Groningen, debug, IfStmt, logger.debug("received a cluster state that has a lower version than the current one, ignoring (received {}, current {})", newClusterState.version(), currentState.version());
854: javanna, warn, IfStmt, logger.warn("received a cluster state from a different master than the current one, rejecting (received {}, current {})", newClusterState.nodes().getMasterNode(), currentNodes.getMasterNode());
877: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to validate incoming join request from node [{}]", node), e);
887: Boaz Leskes, trace, MethodDeclaration, logger.trace("starting to ping");
890: Martijn van Groningen, trace, IfStmt, logger.trace("No full ping responses");
902: Yannick Welsch, trace, IfStmt, logger.trace("full ping responses:{}", sb);
940: Chris Earle, warn, IfStmt, logger.warn("not enough master nodes discovered during pinging (found [{}], but needed [{}]), pinging again", masterCandidates, electMaster.minimumMasterNodes());
936: Boaz Leskes, trace, IfStmt, logger.trace("candidate {} won election", winner);
968: Boaz Leskes, debug, IfStmt, logger.debug("filtered ping responses: (ignore_non_masters [{}]){}", masterElectionIgnoreNonMasters, sb);
977: Yannick Welsch, warn, MethodDeclaration, logger.warn("{}, current nodes: {}", reason, clusterState.nodes());
1016: Martijn van Groningen, warn, IfStmt, logger.warn("discovered [{}] which is also master but with an older cluster_state, telling [{}] to rejoin the cluster ([{}])", otherMaster, otherMaster, reason);
1030: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to send rejoin request to [{}]", otherMaster), e);
1026: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("failed to send rejoin request to [{}]", otherMaster), exp);
1047: Ryan Ernst, trace, CatchClause, logger.trace("pingAndWait interrupted");
1050: Boaz Leskes, warn, CatchClause, logger.warn("Ping execution failed", e);
1089: Yannick Welsch, warn, IfStmt, logger.warn("received cluster state from [{}] which is also master but with a different cluster name [{}]", incomingState.nodes().getMasterNode(), incomingClusterName);
1094: Yannick Welsch, warn, IfStmt, logger.warn("received a cluster state from [{}] and not part of the cluster, should not happen", incomingState.nodes().getMasterNode());
1107: Yannick Welsch, warn, IfStmt, logger.warn(message);
1144: Martijn van Groningen, trace, IfStmt, logger.trace("got a ping from another master {}. current ping count: [{}]", pingRequest.masterNode(), pingsWhileMaster.get());
1147: Martijn van Groningen, debug, MethodDeclaration, logger.debug("got a ping from another master {}. resolving who should rejoin. current ping count: [{}]", pingRequest.masterNode(), pingsWhileMaster.get());
1196: Yannick Welsch, warn, CatchClause, logger.warn("failed to send response on rejoin cluster request handling", e);
1250: Martijn van Groningen, error, CatchClause, logger.error("unexpected error while joining cluster, trying again", e);
220: Nhat Nguyen, trace, CatchClause, startupTraceLogger.trace(() -> new ParameterizedMessage("failed to obtain node lock on {}", dir.toAbsolutePath()), e);
206: Boaz Leskes, trace, TryStmt, startupTraceLogger.trace("obtaining node lock on {} ...", dir.toAbsolutePath());
212: Jason Tedor, trace, CatchClause, startupTraceLogger.trace(new ParameterizedMessage("failed to obtain node lock on {}", dir.toAbsolutePath()), ex);
253: Boaz Leskes, debug, IfStmt, logger.debug("using node location [{}], local_lock_id [{}]", nodePaths, nodeLockId);
330: Jason Tedor, info, IfStmt, logger.info("using [{}] data paths, mounts [{}], net usable_space [{}], net total_space [{}], types [{}]", nodePaths.length, allMounts, totFSPath.getAvailable(), totFSPath.getTotal(), toString(allTypes));
311: Yannick Welsch, debug, IfStmt, logger.debug("node data locations details:{}", sb);
339: Jason Tedor, info, MethodDeclaration, logger.info("heap size [{}], compressed ordinary object pointers [{}]", maxHeapSize, useCompressedOops);
390: Lee Hinman, trace, MethodDeclaration, logger.trace("deleting shard {} directory, paths: [{}]", shardId, paths);
441: Lee Hinman, trace, MethodDeclaration, logger.trace("acquiring locks for {}, paths: [{}]", shardId, paths);
446: Lee Hinman, trace, IfStmt, logger.trace("acquiring lock for {}, custom path: [{}]", shardId, customLocation);
448: Simon Willnauer, trace, IfStmt, logger.trace("deleting custom shard {} directory [{}]", shardId, customLocation);
451: Simon Willnauer, trace, MethodDeclaration, logger.trace("deleted shard {} directory, paths: [{}]", shardId, paths);
504: Simon Willnauer, trace, MethodDeclaration, logger.trace("deleting index {} directory, paths({}): [{}]", index, indexPaths.length, indexPaths);
508: Simon Willnauer, trace, IfStmt, logger.trace("deleting custom index {} directory [{}]", index, customLocation);
529: Simon Willnauer, trace, MethodDeclaration, logger.trace("locking all shards for index {} - [{}]", index, numShards);
541: Lee Hinman, trace, IfStmt, logger.trace("unable to lock all shards for index {}", index);
573: Boaz Leskes, trace, MethodDeclaration, logger.trace("acquiring node shardlock on [{}], timeout [{}]", shardId, lockTimeoutMS);
598: Boaz Leskes, trace, MethodDeclaration, logger.trace("successfully acquired shardlock for [{}]", shardId);
603: Areek Zillur, trace, MethodDeclaration, logger.trace("released shard lock for [{}]", shardId);
659: Areek Zillur, trace, SynchronizedStmt, logger.trace("shard lock wait count for {} is now [{}]", shardId, waitCount);
661: Areek Zillur, trace, IfStmt, logger.trace("last shard lock wait decremented, removing lock for {}", shardId);
900: Nhat Nguyen, trace, CatchClause, logger.trace(() -> new ParameterizedMessage("failed to release lock [{}]", lock), e);
897: Igor Motov, trace, TryStmt, logger.trace("releasing lock [{}]", lock);
913: Robert Muir, warn, CatchClause, logger.warn("lock assertion failed", e);
177: Boaz Leskes, trace, IfStmt, logger.trace("{} ignoring fetched [{}] results, already closed", shardId, type);
180: Boaz Leskes, trace, MethodDeclaration, logger.trace("{} processing fetched [{}] results", shardId, type);
195: Yannick Welsch, trace, IfStmt, logger.trace("{} marking {} as done for [{}], result is [{}]", shardId, nodeEntry.getNodeId(), type, response);
191: Yannick Welsch, trace, IfStmt, logger.trace("{} node {} has failed for [{}] (failure [{}])", shardId, nodeEntry.getNodeId(), type, nodeEntry.getFailure());
188: Yannick Welsch, trace, IfStmt, logger.trace("{} received response for [{}] from node {} for an older fetching round (expected: {} but was: {})", shardId, nodeEntry.getNodeId(), type, nodeEntry.getFetchingRound(), fetchingRound);
203: Boaz Leskes, trace, ForeachStmt, logger.trace("{} processing failure {} for [{}]", shardId, failure, type);
219: Nhat Nguyen, warn, IfStmt, logger.warn(() -> new ParameterizedMessage("{}: failed to list shard for {} on node [{}]", shardId, type, failure.nodeId()), failure);
208: Yannick Welsch, trace, IfStmt, logger.trace("{} received failure for [{}] from node {} for an older fetching round (expected: {} but was: {})", shardId, nodeEntry.getNodeId(), type, nodeEntry.getFetchingRound(), fetchingRound);
287: Boaz Leskes, trace, MethodDeclaration, logger.trace("{} fetching [{}] from {}", shardId, type, nodes);
104: Areek Zillur, debug, IfStmt, logger.debug("[{}] no longer dangling (created), removing from dangling list", index);
101: Areek Zillur, warn, IfStmt, logger.warn("[{}] can not be imported as a dangling index, as there is already another index " + "with the same name but a different uuid. local index will be ignored (but not deleted)", index);
150: Areek Zillur, warn, CatchClause, logger.warn("failed to list dangling indices", e);
143: Ali Beyad, info, IfStmt, logger.info("[{}] dangling index exists on local file system, but not in cluster metadata, " + "auto import to cluster state", indexMetaData.getIndex());
139: Ali Beyad, warn, IfStmt, logger.warn("[{}] can not be imported as a dangling index, as an index with the same name and UUID exist in the " + "index tombstones.  This situation is likely caused by copying over the data directory for an index " + "that was previously deleted.", indexMetaData.getIndex());
136: Areek Zillur, warn, IfStmt, logger.warn("[{}] can not be imported as a dangling index, as index with same name already exists in cluster metadata", indexMetaData.getIndex());
178: Shay Banon, warn, CatchClause, logger.warn("failed to send allocate dangled", e);
168: Ali Beyad, trace, MethodDeclaration, logger.trace("allocated dangled");
173: Ali Beyad, info, MethodDeclaration, logger.info("failed to send allocated dangled", e);
61: Simon Willnauer, trace, MethodDeclaration, logger.trace("performing state recovery from {}", Arrays.toString(nodesIds));
70: Simon Willnauer, warn, ForeachStmt, logger.warn("failed to fetch state from node", failedNodeException);
122: Boaz Leskes, debug, IfStmt, logger.debug("[{}] found [{}], required [{}], not adding", index, indexMetaDataCount, requiredAllocation);
131: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("recovering index {} failed - recovering as closed", electedIndex), e);
156: Jason Tedor, warn, MethodDeclaration, logger.warn("ignoring unknown {} setting: [{}] with value [{}]; archiving", settingType, e.getKey(), e.getValue());
160: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("ignoring invalid {} setting: [{}] with value [{}]; archiving", settingType, e.getKey(), e.getValue()), ex);
149: Shay Banon, trace, MethodDeclaration, logger.trace("{} scheduling reroute for {}", shardId, reason);
107: Shay Banon, error, CatchClause, logger.error("failed to read local state, exiting...", e);
105: Michael McCandless, debug, TryStmt, logger.debug("took {} to load state", TimeValue.timeValueMillis(TimeValue.nsecToMSec(System.nanoTime() - startNS)));
217: Yannick Welsch, trace, IfStmt, logger.trace("[upgrade]: processing [{}]", stateFile.getFileName());
169: Yannick Welsch, debug, IfStmt, logger.debug("not recovering from gateway, nodes_size (master) [{}] < recover_after_master_nodes [{}]", nodes.getMasterNodes().size(), recoverAfterMasterNodes);
166: Yannick Welsch, debug, IfStmt, logger.debug("not recovering from gateway, nodes_size (data) [{}] < recover_after_data_nodes [{}]", nodes.getDataNodes().size(), recoverAfterDataNodes);
163: Yannick Welsch, debug, IfStmt, logger.debug("not recovering from gateway, nodes_size (data+master) [{}] < recover_after_nodes [{}]", nodes.getMasterAndDataNodes().size(), recoverAfterNodes);
161: Boaz Leskes, debug, IfStmt, logger.debug("not recovering from gateway, no master elected yet");
215: Jason Tedor, warn, MethodDeclaration, logger.warn("Recovery failed", e);
202: Boaz Leskes, info, IfStmt, logger.info("delaying initial state recovery for [{}]. {}", recoverAfterTime, reason);
205: Boaz Leskes, info, IfStmt, logger.info("recover_after_time [{}] elapsed. performing state recovery...", recoverAfterTime);
234: Shay Banon, trace, MethodDeclaration, logger.trace("successful state recovery, importing cluster state...");
285: Nhat Nguyen, error, MethodDeclaration, logger.error(() -> new ParameterizedMessage("unexpected failure during [{}]", source), e);
291: Shay Banon, info, MethodDeclaration, logger.info("recovered [{}] indices into cluster_state", newState.metaData().indices().size());
301: Shay Banon, info, MethodDeclaration, logger.info("metadata state not restored, reason: {}", message);
136: Simon Willnauer, warn, IfStmt, logger.warn("ignoring dangled index [{}] on node [{}]" + " since it's created version [{}] is not supported by at least one node in the cluster minVersion [{}]", indexMetaData.getIndex(), request.fromNode, indexMetaData.getCreationVersion(), minIndexCompatibilityVersion);
146: Boaz Leskes, warn, IfStmt, logger.warn("ignoring dangled index [{}] on node [{}] due to an existing alias with the same name", indexMetaData.getIndex(), request.fromNode);
160: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("found dangled index [{}] on node [{}]. This index cannot be upgraded to the latest version, adding as closed", indexMetaData.getIndex(), request.fromNode), ex);
173: Shay Banon, info, MethodDeclaration, logger.info("auto importing dangled indices {} from [{}]", sb.toString(), request.fromNode);
185: Nhat Nguyen, error, MethodDeclaration, logger.error(() -> new ParameterizedMessage("unexpected failure during [{}]", source), e);
190: Jason Tedor, warn, CatchClause, logger.warn("failed send response for allocating dangled", inner);
199: Devin Chollak, warn, CatchClause, logger.warn("failed send response for allocating dangled", e);
280: Lee Hinman, trace, IfStmt, logger.trace("found state file: {}", pav);
325: Nhat Nguyen, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("{}: failed to read [{}], ignoring...", pathAndStateId.file.toAbsolutePath(), prefix), e);
320: Simon Willnauer, trace, IfStmt, logger.trace("state id [{}] read from [{}]", id, stateFile.getFileName());
308: Simon Willnauer, debug, IfStmt, logger.debug("{}: no data for [{}], ignoring...", prefix, stateFile.toAbsolutePath());
316: Simon Willnauer, debug, IfStmt, logger.debug("{}: no data for [{}], ignoring...", prefix, stateFile.toAbsolutePath());
69: Areek Zillur, debug, IfStmt, logger.debug("[{}] failed to find metadata for existing index location", indexFolderName);
102: Areek Zillur, debug, IfStmt, logger.debug("[{}] failed to find metadata for existing index location", indexFolderName);
122: Areek Zillur, trace, MethodDeclaration, logger.trace("[{}] writing state, reason [{}]", index, reason);
127: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}]: failed to write index state", index), ex);
136: Simon Willnauer, trace, MethodDeclaration, logger.trace("[_global] writing state, reason [{}]", reason);
140: Simon Willnauer, warn, CatchClause, logger.warn("[_global]: failed to write global state", ex);
114: Yannick Welsch, debug, MethodDeclaration, logger.debug("[{}][{}]: found {} allocation candidates of {} based on allocation ids: [{}]", unassignedShard.index(), unassignedShard.id(), nodeShardsResult.orderedAllocationCandidates.size(), unassignedShard, inSyncAllocationIds);
120: Ali Beyad, debug, IfStmt, logger.debug("[{}][{}]: missing local data, will restore from [{}]", unassignedShard.index(), unassignedShard.id(), unassignedShard.recoverySource());
162: Ali Beyad, debug, IfStmt, logger.debug("[{}][{}]: forced primary allocation denied [{}]", unassignedShard.index(), unassignedShard.id(), unassignedShard);
158: Ali Beyad, debug, IfStmt, logger.debug("[{}][{}]: throttling allocation [{}] to [{}] on forced primary allocation", unassignedShard.index(), unassignedShard.id(), unassignedShard, nodesToAllocate.throttleNodeShards);
153: Ali Beyad, debug, IfStmt, logger.debug("[{}][{}]: allocating [{}] to [{}] on forced primary allocation", unassignedShard.index(), unassignedShard.id(), unassignedShard, nodeShardState.getNode());
142: Ali Beyad, debug, IfStmt, logger.debug("[{}][{}]: allocating [{}] to [{}] on primary allocation", unassignedShard.index(), unassignedShard.id(), unassignedShard, decidedNode.nodeShardState.getNode());
263: Nhat Nguyen, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("[{}] on node [{}] has allocation id [{}] but the store can not be opened, treating as no allocation id", shard, nodeShardState.getNode(), finalAllocationId), nodeShardState.storeException());
261: Nhat Nguyen, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("[{}] on node [{}] has allocation id [{}] but the store can not be opened as it's locked, treating as valid shard", shard, nodeShardState.getNode(), finalAllocationId), nodeShardState.storeException());
256: Yannick Welsch, trace, IfStmt, logger.trace("[{}] on node [{}] has allocation id [{}]", shard, nodeShardState.getNode(), allocationId);
254: Yannick Welsch, trace, IfStmt, logger.trace("[{}] on node [{}] has no shard state information", shard, nodeShardState.getNode());
292: Yannick Welsch, trace, IfStmt, logger.trace("{} candidates for allocation: {}", shard, nodeShardStates.stream().map(s -> s.getNode().getName()).collect(Collectors.joining(", ")));
91: Shay Banon, trace, IfStmt, logger.trace("{}: fetching new stores for initializing shard", shard);
172: Ali Beyad, trace, IfStmt, logger.trace("{}: ignoring allocation, still fetching shard stores", unassignedShard);
215: Ali Beyad, debug, IfStmt, logger.debug("[{}][{}]: allocating [{}] to [{}] in order to reuse its unallocated persistent store", unassignedShard.index(), unassignedShard.id(), unassignedShard, nodeWithHighestMatch.node());
210: Ali Beyad, debug, IfStmt, logger.debug("[{}][{}]: throttling allocation [{}] to [{}] in order to reuse its unallocated persistent store", unassignedShard.index(), unassignedShard.id(), unassignedShard, nodeWithHighestMatch.node());
357: Ali Beyad, trace, IfStmt, logger.trace("{}: node [{}] has [{}/{}] bytes of re-usable data", shard, discoNode.getName(), new ByteSizeValue(matchingBytes), matchingBytes);
355: Ali Beyad, trace, IfStmt, logger.trace("{}: node [{}] has same sync id {} as primary", shard, discoNode.getName(), storeFilesMetaData.syncId());
118: Simon Willnauer, trace, TryStmt, logger.trace("{} loading local shard state info", shardId);
148: Nhat Nguyen, trace, CatchClause, logger.trace(() -> new ParameterizedMessage("{} can't open index for shard [{}] in path [{}]", shardId, shardStateMetaData, (finalShardPath != null) ? finalShardPath.resolveIndex() : ""), exception);
161: Boaz Leskes, debug, IfStmt, logger.debug("{} shard state info found: [{}]", shardId, shardStateMetaData);
166: Simon Willnauer, trace, TryStmt, logger.trace("{} no local shard info found", shardId);
63: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to invoke shard touring changed callback", indexShard.shardId().getId()), e);
74: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to invoke after shard created callback", indexShard.shardId().getId()), e);
86: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to invoke after shard started callback", indexShard.shardId().getId()), e);
99: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to invoke before shard closed callback", shardId.getId()), e);
112: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to invoke after shard closed callback", shardId.getId()), e);
124: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to invoke on shard inactive callback", indexShard.shardId().getId()), e);
136: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to invoke index shard state changed callback", indexShard.shardId().getId()), e);
148: Jason Tedor, warn, CatchClause, logger.warn("failed to invoke before index created callback", e);
160: Jason Tedor, warn, CatchClause, logger.warn("failed to invoke after index created callback", e);
172: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to invoke before shard created callback", shardId), e);
184: Boaz Leskes, warn, CatchClause, logger.warn("failed to invoke before index removed callback", e);
196: Boaz Leskes, warn, CatchClause, logger.warn("failed to invoke after index removed callback", e);
209: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to invoke before shard deleted callback", shardId.getId()), e);
222: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to invoke after shard deleted callback", shardId.getId()), e);
234: Jason Tedor, warn, CatchClause, logger.warn("failed to invoke before index added to cluster callback", e);
246: Jason Tedor, warn, CatchClause, logger.warn("failed to invoke on store closed", e);
157: Areek Zillur, trace, IfStmt, indexLogger.trace("{}", new SlowLogParsedDocumentPrinter(index, doc, tookInNanos, reformat, maxSourceCharsToLog));
155: Areek Zillur, debug, IfStmt, indexLogger.debug("{}", new SlowLogParsedDocumentPrinter(index, doc, tookInNanos, reformat, maxSourceCharsToLog));
153: Areek Zillur, info, IfStmt, indexLogger.info("{}", new SlowLogParsedDocumentPrinter(index, doc, tookInNanos, reformat, maxSourceCharsToLog));
151: Areek Zillur, warn, IfStmt, indexLogger.warn("{}", new SlowLogParsedDocumentPrinter(index, doc, tookInNanos, reformat, maxSourceCharsToLog));
277: Jason Tedor, warn, CatchClause, logger.warn("failed to close shard", e);
336: Alexander Reelsen, warn, CatchClause, logger.warn("{} failed to load shard path, trying to remove leftover", shardId);
365: Simon Willnauer, debug, IfStmt, logger.debug("{} creating using an existing path [{}]", shardId, path);
363: Simon Willnauer, debug, IfStmt, logger.debug("{} creating using a new path [{}]", shardId, path);
372: Simon Willnauer, debug, TryStmt, logger.debug("creating shard_id {}", shardId);
411: Simon Willnauer, debug, MethodDeclaration, logger.debug("[{}] closing... (reason: [{}])", shardId, reason);
416: Simon Willnauer, debug, MethodDeclaration, logger.debug("[{}] closed (reason: [{}])", shardId, reason);
449: Jason Tedor, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to close store on shard removal (reason: [{}])", shardId, reason), e);
446: Ali Beyad, trace, IfStmt, logger.trace("[{}] store not initialized prior to closing shard, nothing to close", shardId);
434: Nhat Nguyen, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("[{}] failed to close index shard", shardId), e);
468: Jason Tedor, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("[{}] failed to delete shard content - scheduled a retry", lock.getShardId().id()), e);
547: Simon Willnauer, debug, CatchClause, logger.debug("failed to close resource", ex);
624: Jason Tedor, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to notify shard about setting change", shard.shardId().id()), e);
638: Simon Willnauer, warn, MethodDeclaration, logger.warn("forced refresh failed after interval change", e);
706: Simon Willnauer, warn, CatchClause, logger.warn("failed to sync translog", e);
767: Jason Tedor, info, IfStmt, logger.info(new ParameterizedMessage("{} failed to execute background global checkpoint sync", shard.shardId()), e);
814: Simon Willnauer, trace, IfStmt, indexService.logger.trace("scheduled {} disabled", toString());
810: Jason Tedor, trace, IfStmt, indexService.logger.trace("scheduling {} every {}", toString(), interval);
830: Jason Tedor, warn, IfStmt, indexService.logger.warn(() -> new ParameterizedMessage("failed to run task {} - suppressing re-occurring exceptions unless the exception changes", toString()), ex);
70: Adrien Grand, trace, IfStmt, logger.trace("{} top warming [{}]", shard.shardId(), searcher.reader());
85: Adrien Grand, warn, CatchClause, logger.warn("top warming has been interrupted", e);
92: Adrien Grand, trace, IfStmt, shard.warmerService().logger().trace("top warming took [{}]", new TimeValue(took, TimeUnit.NANOSECONDS));
154: Jason Tedor, warn, CatchClause, indexShard.warmerService().logger().warn(() -> new ParameterizedMessage("failed to warm-up global ordinals for [{}]", fieldType.name()), e);
148: Jason Tedor, trace, IfStmt, indexShard.warmerService().logger().trace("warmed global ordinals for [{}], took [{}]", fieldType.name(), TimeValue.timeValueNanos(System.nanoTime() - start));
169: Simon Willnauer, warn, IfStmt, logger.warn("[{}] is set to false, this should only be used in tests and can cause serious problems in production environments", INDEX_MERGE_ENABLED);
181: Simon Willnauer, trace, IfStmt, logger.trace("using [tiered] merge mergePolicy with expunge_deletes_allowed[{}], floor_segment[{}], max_merge_at_once[{}], max_merge_at_once_explicit[{}], max_merged_segment[{}], segments_per_tier[{}], reclaim_deletes_weight[{}]", forceMergeDeletesPctAllowed, floorSegment, maxMergeAtOnce, maxMergeAtOnceExplicit, maxMergedSegment, segmentsPerTier, reclaimDeletesWeight);
226: Simon Willnauer, debug, IfStmt, logger.debug("changing max_merge_at_once from [{}] to [{}] because segments_per_tier [{}] has to be higher or equal to it", maxMergeAtOnce, newMaxMergeAtOnce, segmentsPerTier);
123: Igor Motov, trace, IfStmt, queryLogger.trace("{}", new SlowLogSearchContextPrinter(context, tookInNanos));
121: Igor Motov, debug, IfStmt, queryLogger.debug("{}", new SlowLogSearchContextPrinter(context, tookInNanos));
119: Igor Motov, info, IfStmt, queryLogger.info("{}", new SlowLogSearchContextPrinter(context, tookInNanos));
117: Igor Motov, warn, IfStmt, queryLogger.warn("{}", new SlowLogSearchContextPrinter(context, tookInNanos));
136: Igor Motov, trace, IfStmt, fetchLogger.trace("{}", new SlowLogSearchContextPrinter(context, tookInNanos));
134: Igor Motov, debug, IfStmt, fetchLogger.debug("{}", new SlowLogSearchContextPrinter(context, tookInNanos));
132: Igor Motov, info, IfStmt, fetchLogger.info("{}", new SlowLogSearchContextPrinter(context, tookInNanos));
130: Igor Motov, warn, IfStmt, fetchLogger.warn("{}", new SlowLogSearchContextPrinter(context, tookInNanos));
112: Lee Hinman, debug, MethodDeclaration, logger.debug("clearing all bitsets because [{}]", reason);
266: Nhat Nguyen, warn, CatchClause, indexShard.warmerService().logger().warn(() -> new ParameterizedMessage("failed to load bitset for [{}]", filterToWarm), e);
263: Simon Willnauer, trace, IfStmt, indexShard.warmerService().logger().trace("warmed bitset for [{}], took [{}]", filterToWarm, TimeValue.timeValueNanos(System.nanoTime() - start));
32: Adrien Grand, debug, ConstructorDeclaration, logger.debug("Using no query cache");
50: Adrien Grand, debug, MethodDeclaration, logger.debug("full cache clear, reason [{}]", reason);
59: Simon Willnauer, warn, IfStmt, logger.warn("no index mapper found for field: [{}] returning default postings format", field);
88: Nhat Nguyen, debug, MethodDeclaration, logger.debug("Delete index commit [{}]", commitDescription(commit));
95: Nhat Nguyen, debug, MethodDeclaration, logger.debug("Safe commit [{}], last commit [{}]", commitDescription(safeCommit), commitDescription(lastCommit));
95: Simon Willnauer, trace, IfStmt, logger.trace("merge [{}] starting..., merging [{}] segments, [{}] docs, [{}] size, into [{}] estimated_size", OneMergeHelper.getSegmentName(merge), merge.segments.size(), totalNumDocs, new ByteSizeValue(totalSizeInBytes), new ByteSizeValue(merge.estimatedMergeBytes));
139: Yannick Welsch, trace, IfStmt, logger.trace("{}", message);
137: Yannick Welsch, debug, IfStmt, logger.debug("{}", message);
647: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("Error when opening compound reader for Directory [{}] and SegmentCommitInfo [{}]", segmentReader.directory(), segmentCommitInfo), e);
670: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("Couldn't list Directory from SegmentReader [{}] and SegmentInfo [{}]", segmentReader, segmentReader.getSegmentInfo()), e);
663: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("Couldn't list Compound Reader Directory [{}]", finalDirectory), e);
683: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("Tried to query fileLength but file is gone [{}] [{}]", finalDirectory, file), e);
686: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("Error when trying to query fileLength [{}] [{}]", finalDirectory, file), e);
699: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("Error when closing compound reader on Directory [{}]", finalDirectory), e);
750: Nhat Nguyen, trace, CatchClause, logger.trace(() -> new ParameterizedMessage("failed to get size for [{}]", info.info.name), e);
776: Nhat Nguyen, trace, CatchClause, logger.trace(() -> new ParameterizedMessage("failed to get size for [{}]", info.info.name), e);
805: Lee Hinman, error, CatchClause, logger.error("failed to access searcher manager", e);
915: Jason Tedor, error, TryStmt, logger.error(maybeMessage, error);
967: Nhat Nguyen, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("tried to fail engine but could not acquire lock - engine should be failed by now [{}]", reason), failure);
962: Jason Tedor, warn, CatchClause, logger.warn("failEngine threw exception", inner);
934: Nhat Nguyen, warn, IfStmt, logger.warn(() -> new ParameterizedMessage("tried to fail engine but engine is already failed. ignoring. [{}]", reason), failure);
944: Nhat Nguyen, warn, TryStmt, logger.warn(() -> new ParameterizedMessage("failed engine [{}]", reason), failure);
954: Areek Zillur, warn, CatchClause, logger.warn("Couldn't mark store corrupted", e);
1400: Simon Willnauer, trace, IfStmt, logger.trace("flushAndClose now acquire writeLock");
1402: Simon Willnauer, trace, TryStmt, logger.trace("flushAndClose now acquired writeLock");
1404: Simon Willnauer, debug, TryStmt, logger.debug("flushing shard on close - this might take some time to sync files to disk");
1408: Simon Willnauer, debug, CatchClause, logger.debug("engine already closed - skipping flushAndClose");
1421: Simon Willnauer, debug, IfStmt, logger.debug("close now acquiring writeLock");
1423: Simon Willnauer, debug, TryStmt, logger.debug("close acquired writeLock");
56: Simon Willnauer, warn, IfStmt, logger.warn("Searcher was released twice", new IllegalStateException("Double release"));
225: Lee Hinman, trace, ConstructorDeclaration, logger.trace("created new InternalEngine");
236: Boaz Leskes, trace, MethodDeclaration, logger.trace("recovered maximum sequence number [{}] and local checkpoint [{}]", maxSeqNo, localCheckpoint);
408: Simon Willnauer, trace, IfStmt, logger.trace("flushing post recovery from translog. ops recovered [{}]. committed translog id [{}]. current id [{}]", opsRecovered, translogGeneration == null ? null : translogGeneration.translogFileGeneration, translog.currentFileGeneration());
1355: Boaz Leskes, trace, IfStmt, logger.trace("can't sync commit [{}]. have pending changes", syncId);
1359: Boaz Leskes, trace, IfStmt, logger.trace("can't sync commit [{}]. current commit id is not equal to expected.", syncId);
1369: Boaz Leskes, trace, IfStmt, logger.trace("can't sync commit [{}]. have pending changes", syncId);
1373: Boaz Leskes, trace, IfStmt, logger.trace("can't sync commit [{}]. current commit id is not equal to expected.", syncId);
1376: Boaz Leskes, trace, TryStmt, logger.trace("starting sync commit [{}]", syncId);
1378: Boaz Leskes, debug, TryStmt, logger.debug("successfully sync committed. sync id [{}].", syncId);
1395: Simon Willnauer, trace, IfStmt, logger.trace("start renewing sync commit [{}]", syncId);
1397: Simon Willnauer, debug, IfStmt, logger.debug("successfully sync committed. sync id [{}].", syncId);
1469: Simon Willnauer, trace, IfStmt, logger.trace("acquired flush lock immediately");
1462: Simon Willnauer, trace, IfStmt, logger.trace("waiting for in-flight flush to finish");
1464: Simon Willnauer, trace, IfStmt, logger.trace("acquired flush lock after blocking");
1478: Simon Willnauer, trace, TryStmt, logger.trace("starting commit for flush; commitTranslog=true");
1480: Michael McCandless, trace, TryStmt, logger.trace("finished commit for flush");
1522: Boaz Leskes, warn, TryStmt, logger.warn("failed to read latest segment infos on flush", e);
1630: Michael McCandless, info, IfStmt, logger.info("starting segment upgrade upgradeOnlyAncientSegments={}", upgradeOnlyAncientSegments);
1650: Simon Willnauer, info, IfStmt, logger.info("finished segment upgrade");
1684: Boaz Leskes, trace, IfStmt, logger.trace("start flush for snapshot");
1686: Boaz Leskes, trace, IfStmt, logger.trace("finish flush for snapshot");
1828: Simon Willnauer, warn, CatchClause, logger.warn("failed to rollback writer on close", e);
1832: Boaz Leskes, debug, TryStmt, logger.debug("engine closed [{}]", reason);
1811: Jason Tedor, warn, CatchClause, logger.warn("Failed to close SearcherManager", e);
1816: Jason Tedor, warn, CatchClause, logger.warn("Failed to close translog", e);
1819: Simon Willnauer, trace, TryStmt, logger.trace("rollback indexWriter");
1826: Simon Willnauer, trace, TryStmt, logger.trace("rollback indexWriter done");
1866: Nhat Nguyen, error, CatchClause, logger.error(() -> new ParameterizedMessage("failed to acquire searcher, source {}", source), ex);
1885: Jason Tedor, warn, CatchClause, logger.warn("could not lock IndexWriter", ex);
1951: Shay Banon, warn, IfStmt, logger.warn("failed to prepare/warm", e);
2008: Simon Willnauer, info, IfStmt, logger.info("now throttling indexing: numMergesInFlight={}, maxNumMerges={}", numMergesInFlight, maxNumMerges);
2019: Simon Willnauer, info, IfStmt, logger.info("stop throttling indexing: numMergesInFlight={}, maxNumMerges={}", numMergesInFlight, maxNumMerges);
2030: Simon Willnauer, warn, IfStmt, logger.warn("failed to flush after merge has finished");
2056: Jason Tedor, debug, MethodDeclaration, logger.debug("merge failure action rejected", e);
2109: Jason Tedor, trace, LambdaExpr, logger.trace("committing writer with commit data [{}]", commitData);
70: Adrien Grand, debug, IfStmt, logger.debug("global-ordinals [{}][{}] took [{}]", indexFieldData.getFieldName(), ordinalMap.getValueCount(), new TimeValue(System.nanoTime() - startTimeNS, TimeUnit.NANOSECONDS));
196: Lee Hinman, warn, CatchClause, logger.warn("Unable to estimate memory overhead", e);
189: Lee Hinman, trace, IfStmt, logger.trace("totalTermBytes: {}, terms.size(): {}, terms.getSumDocFreq(): {}", totalTermBytes, terms.size(), terms.getSumDocFreq());
221: Lee Hinman, trace, IfStmt, logger.trace("Filter exists, can't circuit break normally, using RamAccountingTermsEnum");
162: Adrien Grand, trace, IfStmt, logger.trace("default mapping source[{}]", defaultMappingSource);
210: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to apply mappings", index()), e);
226: Yannick Welsch, debug, IfStmt, logger.debug("[{}] {} mapping [{}] (source suppressed due to length, use TRACE level if needed)", index(), op, mappingType);
224: Yannick Welsch, trace, IfStmt, logger.trace("[{}] {} mapping [{}], source [{}]", index(), op, mappingType, incomingMappingSource.string());
222: Yannick Welsch, debug, IfStmt, logger.debug("[{}] {} mapping [{}], source [{}]", index(), op, mappingType, incomingMappingSource.string());
233: Yannick Welsch, debug, IfStmt, logger.debug("[{}] parsed mapping [{}], and got different sources\noriginal:\n{}\nparsed:\n{}", index(), mappingType, incomingMappingSource, documentMapper(mappingType).mappingSource());
73: Nik Everett, debug, IfStmt, logger.debug("executing initial scroll against {}{}", isEmpty(firstSearchRequest.indices()) ? "all indices" : firstSearchRequest.indices(), isEmpty(firstSearchRequest.types()) ? "" : firstSearchRequest.types());
101: Nik Everett, debug, MethodDeclaration, logger.debug("Freed [{}] contexts", response.getNumFreed());
107: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("Failed to clear scroll [{}]", scrollId), e);
165: Nik Everett, warn, IfStmt, logger.warn("giving up on search because it failed with a non-retryable exception", e);
160: Nhat Nguyen, warn, IfStmt, logger.warn(() -> new ParameterizedMessage("giving up on search because we retried [{}] times without success", retryCount), e);
156: Nhat Nguyen, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("retrying rejected search after [{}]", delay), e);
70: Nik Everett, debug, LambdaExpr, logger.debug("scroll returned [{}] documents with a scroll id of [{}]", response.getHits().size(), response.getScrollId());
190: Andy Bristol, debug, SynchronizedStmt, logger.debug("[{}]: preparing bulk request for [{}]", task.getId(), delay);
229: Andy Bristol, debug, SynchronizedStmt, logger.debug("[{}]: rethrottling to [{}] requests per second", task.getId(), newRequestsPerSecond);
235: Andy Bristol, debug, IfStmt, logger.debug("[{}]: skipping rescheduling because there is no scheduled task", task.getId());
273: Andy Bristol, debug, IfStmt, logger.debug("[{}]: skipping rescheduling because the new throttle [{}] is slower than the old one [{}]", task.getId(), newRequestsPerSecond, requestsPerSecond);
282: Andy Bristol, debug, IfStmt, logger.debug("[{}]: skipping rescheduling because we couldn't cancel the task", task.getId());
291: Andy Bristol, debug, MethodDeclaration, logger.debug("[{}]: rescheduling for [{}] in the future", task.getId(), newDelay);
95: Jason Tedor, info, IfStmt, logger.info(new ParameterizedMessage("{} global checkpoint sync failed", shardId), e);
438: Jason Tedor, trace, MethodCallExpr, logger.trace("updating global checkpoint from [{}] to [{}] due to [{}]", current, globalCheckpoint, reason);
435: Jason Tedor, trace, MethodDeclaration, updateGlobalCheckpoint(shardAllocationId, globalCheckpoint, current -> logger.trace("updating global checkpoint from [{}] to [{}] due to [{}]", current, globalCheckpoint, reason));
455: Jason Tedor, trace, MethodCallExpr, logger.trace("updating local knowledge for [{}] on the primary of the global checkpoint from [{}] to [{}]", allocationId, current, globalCheckpoint);
452: Jason Tedor, trace, MethodDeclaration, updateGlobalCheckpoint(allocationId, globalCheckpoint, current -> logger.trace("updating local knowledge for [{}] on the primary of the global checkpoint from [{}] to [{}]", allocationId, current, globalCheckpoint));
619: Yannick Welsch, trace, IfStmt, logger.trace("marked [{}] as in-sync", allocationId);
639: Yannick Welsch, trace, IfStmt, logger.trace("skipped updating local checkpoint of [{}] from [{}] to [{}], current checkpoint is higher", allocationId, cps.localCheckpoint, localCheckpoint);
635: Jason Tedor, trace, IfStmt, logger.trace("updated local checkpoint of [{}] from [{}] to [{}]", allocationId, cps.localCheckpoint, localCheckpoint);
668: Yannick Welsch, trace, IfStmt, logger.trace("marked [{}] as in-sync", allocationId);
714: Yannick Welsch, trace, IfStmt, logger.trace("global checkpoint updated to [{}]", computedGlobalCheckpoint);
105: Yannick Welsch, debug, IfStmt, logger.debug("Returning {} merges for upgrade", spec.merges.size());
112: Yannick Welsch, debug, IfStmt, logger.debug("Returning {} merges for end of upgrade", spec.merges.size());
96: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("preIndex listener [{}] failed", listener), e);
109: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("postIndex listener [{}] failed", listener), e);
122: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("postIndex listener [{}] failed", listener), inner);
134: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("preDelete listener [{}] failed", listener), e);
147: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("postDelete listener [{}] failed", listener), e);
160: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("postDelete listener [{}] failed", listener), inner);
294: kimchy, debug, ConstructorDeclaration, logger.debug("state: [CREATED]");
488: Yannick Welsch, info, MethodDeclaration, logger.info("primary-replica resync completed with {} operations", resyncTask.getResyncedOperations());
588: Yannick Welsch, warn, CatchClause, logger.warn("timed out waiting for relocation hand-off to complete");
631: Luca Cavanna, debug, MethodDeclaration, logger.debug("state: [{}]->[{}], reason [{}]", state, newState, reason);
697: Simon Willnauer, trace, IfStmt, logger.trace("index [{}][{}] (seq# [{}])", index.type(), index.id(), index.seqNo());
724: Yannick Welsch, trace, IfStmt, logger.trace("noop (seq# [{}])", noOp.seqNo());
788: Boaz Leskes, trace, IfStmt, logger.trace("delete [{}] (seq no [{}])", delete.uid().text(), delete.seqNo());
810: Simon Willnauer, trace, IfStmt, logger.trace("refresh with source [{}]", source);
857: Nhat Nguyen, trace, CatchClause, logger.trace(() -> new ParameterizedMessage("failed to get size for [{}]", info.info.name), e);
953: Boaz Leskes, trace, MethodDeclaration, logger.trace("trying to sync flush. sync id [{}]. expected commit id [{}]]", syncId, expectedCommitId);
971: Jason Tedor, trace, MethodDeclaration, logger.trace("flush with {}", request);
1012: Lee Hinman, trace, IfStmt, logger.trace("force merge with {}", forceMerge);
1025: Igor Motov, trace, IfStmt, logger.trace("upgrade with {}", upgrade);
1035: Yannick Welsch, trace, IfStmt, logger.trace("upgraded segments for {} from version {} to version {}", shardId, previousVersion, version);
1247: Yannick Welsch, info, IfStmt, logger.info("ignoring recovery of a corrupt translog entry", e);
1237: Yannick Welsch, trace, TryStmt, logger.trace("[translog] recover op {}", operation);
1485: Michael McCandless, debug, IfStmt, logger.debug("shard is now inactive");
1489: Simon Willnauer, warn, CatchClause, logger.warn("failed to notify index event listener", e);
1653: Michael McCandless, warn, IfStmt, logger.warn("Failed to perform engine refresh", e);
1648: Michael McCandless, warn, IfStmt, logger.warn("Failed to perform engine refresh", e);
1789: Jason Tedor, trace, IfStmt, logger.trace("syncing global checkpoint for [{}]", reason);
1915: Nhat Nguyen, warn, IfStmt, logger.warn("check index [failure]\n{}", os.bytes().utf8ToString());
1918: Nhat Nguyen, debug, IfStmt, logger.debug("fixing index, writing new segments file ...");
1922: Nhat Nguyen, debug, IfStmt, logger.debug("index fixed, wrote new segments file \"{}\"", status.segmentsFileName);
1903: Simon Willnauer, warn, IfStmt, logger.warn("check index [failure]\n{}", os.bytes().utf8ToString());
1932: Simon Willnauer, debug, IfStmt, logger.debug("check index [success]\n{}", os.bytes().utf8ToString());
2083: Jason Tedor, warn, CatchClause, logger.warn("exception while notifying engine failure", inner);
2141: Yannick Welsch, trace, IfStmt, logger.trace("{} skip writing shard state, has been written before", shardId);
2136: Yannick Welsch, trace, IfStmt, logger.trace("{} writing shard state, reason [{}]", shardId, writeReason);
2225: Jason Tedor, trace, LambdaExpr, logger.trace("detected new primary with primary term [{}], resetting local checkpoint from [{}] to [{}]", operationPrimaryTerm, getLocalCheckpoint(), localCheckpoint);
2305: Jason Tedor, debug, CatchClause, logger.debug("failed to sync translog", ex);
2386: Jason Tedor, debug, IfStmt, logger.debug("submitting async roll translog generation request");
2391: Jason Tedor, warn, IfStmt, logger.warn("failed to roll translog generation", e);
2363: Simon Willnauer, debug, IfStmt, logger.debug("submitting async flush request");
2368: Jason Tedor, warn, IfStmt, logger.warn("failed to flush index", e);
258: Yannick Welsch, trace, IfStmt, logger.trace("{} resync completed (total sent: [{}], skipped: [{}])", shardId, totalSentOps.get(), totalSkippedOps.get());
254: Yannick Welsch, trace, IfStmt, logger.trace("{} sending batch of [{}][{}] (total sent: [{}], skipped: [{}])", shardId, operations.size(), new ByteSizeValue(size), totalSentOps.get(), totalSkippedOps.get());
251: Jason Tedor, Error, CatchClause, logger.warn("Error firing refresh listener", e);
135: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("onPreQueryPhase listener [{}] failed", listener), e);
146: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("onFailedQueryPhase listener [{}] failed", listener), e);
157: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("onQueryPhase listener [{}] failed", listener), e);
168: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("onPreFetchPhase listener [{}] failed", listener), e);
179: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("onFailedFetchPhase listener [{}] failed", listener), e);
190: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("onFetchPhase listener [{}] failed", listener), e);
201: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("onNewContext listener [{}] failed", listener), e);
212: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("onFreeContext listener [{}] failed", listener), e);
223: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("onNewScrollContext listener [{}] failed", listener), e);
234: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("onFreeScrollContext listener [{}] failed", listener), e);
123: Simon Willnauer, warn, IfStmt, logger.warn("{} found shard on path: [{}] with a different index UUID - this shard seems to be leftover from a different index with the same name. Remove the leftover shard in order to reuse the path with the current index", shardId, path);
144: Michael McCandless, debug, IfStmt, logger.debug("{} loaded data path [{}], state path [{}]", shardId, dataPath, statePath);
161: Simon Willnauer, warn, IfStmt, logger.warn("{} deleting leftover shard on path: [{}] with a different index UUID", lock.getShardId(), path);
94: Simon Willnauer, debug, LambdaExpr, logger.debug("starting recovery from store ...");
124: Simon Willnauer, debug, LambdaExpr, logger.debug("starting recovery from local shards {}", shards);
277: Yannick Welsch, debug, LambdaExpr, logger.debug("restoring from {} ...", indexShard.recoveryState().getRecoverySource());
324: Simon Willnauer, debug, IfStmt, logger.debug("recovery completed from [shard_store], took [{}]", timeValueMillis(recoveryState.getTimer().time()));
322: Yannick Welsch, trace, IfStmt, logger.trace("recovery completed from [shard_store], took [{}]\n{}", timeValueMillis(recoveryState.getTimer().time()), sb);
407: Yannick Welsch, debug, CatchClause, logger.debug("failed to list file details", e);
443: Ali Beyad, trace, IfStmt, logger.trace("[{}] restoring shard [{}]", restoreSource.snapshot(), shardId);
172: Simon Willnauer, debug, ConstructorDeclaration, logger.debug("store stats are refreshed with refresh_interval [{}]", refreshInterval);
337: Nhat Nguyen, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("failed to delete file [{}]", origFile), ex);
436: Yannick Welsch, debug, IfStmt, logger.debug("store reference count on close: {}", refCounter.refCount());
448: Simon Willnauer, debug, CatchClause, logger.debug("failed to close directory", e);
468: Simon Willnauer, info, CatchClause, logger.info("Failed to open / find files while reading metadata snapshot");
470: Nhat Nguyen, info, CatchClause, logger.info(() -> new ParameterizedMessage("{}: failed to obtain shard lock", shardId), ex);
484: Nhat Nguyen, trace, CatchClause, logger.trace(() -> new ParameterizedMessage("Can't open index for path [{}]", indexLocation), ex);
500: Boaz Leskes, trace, TryStmt, logger.trace("{} loaded segment info [{}]", shardId, segInfo);
684: Nhat Nguyen, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("failed to delete file [{}]", existingFile), ex);
716: Simon Willnauer, debug, IfStmt, logger.debug("Files are missing on the recovery target: {} ", recoveryDiff);
711: Simon Willnauer, debug, IfStmt, logger.debug("Files are different on the recovery target: {} ", recoveryDiff);
745: Simon Willnauer, trace, MethodDeclaration, deletesLogger.trace("{}: delete file {}", msg, name);
929: Nhat Nguyen, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("Can retrieve checksum from file [{}]", file), ex);
1410: Simon Willnauer, warn, CatchClause, logger.warn("Can't mark store as corrupted", ex);
175: Boaz Leskes, warn, IfStmt, logger.warn("deleted previously created, but not yet committed, next generation [{}]. This can happen due to a tragic exception when creating a new generation", nextTranslogFile.getFileName());
271: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to delete temp file {}", tempFile), ex);
209: Simon Willnauer, debug, TryStmt, logger.debug("open uncommitted translog checkpoint {}", checkpoint);
237: Simon Willnauer, debug, ForStmt, logger.debug("recovered local translog from checkpoint {}", checkpoint);
323: Simon Willnauer, debug, TryStmt, logger.debug("translog closed");
1521: Jason Tedor, trace, TryStmt, logger.trace("current translog set to [{}]", current.getGeneration());
1556: Jason Tedor, trace, ForStmt, logger.trace("delete translog file [{}], not referenced and not current anymore", translogPath);
1584: Boaz Leskes, trace, IfStmt, logger.trace("closing files. translog is closed and there are no pending retention locks");
123: Michael McCandless, debug, ConstructorDeclaration, logger.debug("using indexing buffer size [{}] with {} [{}], {} [{}]", this.indexingBuffer, SHARD_INACTIVE_TIME_SETTING.getKey(), this.inactiveTime, SHARD_MEMORY_INTERVAL_TIME_SETTING.getKey(), this.interval);
181: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("failed to write indexing buffer for shard [{}]; ignoring", shard.shardId()), e);
313: Michael McCandless, trace, IfStmt, logger.trace("total indexing heap bytes used [{}] vs {} [{}], currently writing bytes [{}]", new ByteSizeValue(totalBytesUsed), INDEX_BUFFER_SIZE_SETTING.getKey(), indexingBuffer, new ByteSizeValue(totalBytesWriting));
346: Michael McCandless, trace, IfStmt, logger.trace("shard [{}] is using [{}] heap, not writing any bytes", shard.shardId(), shardBytesUsed);
344: Michael McCandless, trace, IfStmt, logger.trace("shard [{}] is using [{}] heap, writing [{}] heap", shard.shardId(), shardBytesUsed, shardWritingBytes);
353: Michael McCandless, debug, IfStmt, logger.debug("now write some indexing buffers: total indexing heap bytes used [{}] vs {} [{}], currently writing bytes [{}], [{}] shards with non-zero indexing buffer", new ByteSizeValue(totalBytesUsed), INDEX_BUFFER_SIZE_SETTING.getKey(), indexingBuffer, new ByteSizeValue(totalBytesWriting), queue.size());
358: Michael McCandless, debug, WhileStmt, logger.debug("write indexing buffer to disk for shard [{}] to free up its [{}] indexing buffer", largest.shard.shardId(), new ByteSizeValue(largest.bytesUsed));
362: Michael McCandless, info, IfStmt, logger.info("now throttling indexing for shard [{}]: segment writing can't keep up", largest.shard.shardId());
371: Michael McCandless, info, ForeachStmt, logger.info("stop throttling indexing for shard [{}]", shard.shardId());
386: Nhat Nguyen, trace, CatchClause, logger.trace(() -> new ParameterizedMessage("ignore exception while checking if shard {} is inactive", shard.shardId()), e);
75: Adrien Grand, debug, ConstructorDeclaration, logger.debug("using [node] query cache with size [{}] max filter count [{}]", size, count);
237: Simon Willnauer, warn, IfStmt, logger.warn("Not all shards are closed yet, waited {}sec - stopping service", shardsClosedTimeout.seconds());
314: Yannick Welsch, trace, CatchClause, logger.trace(() -> new ParameterizedMessage("{} ignoring shard stats", indexShard.shardId()), e);
439: Lee Hinman, debug, MethodDeclaration, logger.debug("creating Index [{}], shards [{}]/[{}] - reason [{}]", indexMetaData.getIndex(), idxSettings.getNumberOfShards(), idxSettings.getNumberOfReplicas(), reason);
564: Yannick Welsch, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to remove index {} ([{}][{}])", index, reason, extraInfo), e);
545: Simon Willnauer, debug, SynchronizedStmt, logger.debug("[{}] closing ... (reason [{}])", indexName, reason);
554: Boaz Leskes, debug, TryStmt, logger.debug("{} closing index service (reason [{}][{}])", index, reason, extraInfo);
556: Boaz Leskes, debug, TryStmt, logger.debug("{} closed... (reason [{}][{}])", index, reason, extraInfo);
620: Yannick Welsch, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to delete unassigned index (reason [{}])", metaData.getIndex(), reason), e);
672: Yannick Welsch, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("{} failed to delete index store - at least one shards is still locked", index), ex);
674: Yannick Welsch, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("{} failed to delete index", index), ex);
695: Simon Willnauer, trace, MethodDeclaration, logger.trace("{} deleting shard reason [{}]", shardId, reason);
721: Boaz Leskes, debug, MethodDeclaration, logger.debug("{} deleted shard reason [{}]", shardId, reason);
734: Boaz Leskes, trace, IfStmt, logger.trace("[{}] still has shard stores, leaving as is", shardId.getIndex());
777: Yannick Welsch, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to load state file from a stale deleted index, folders will be left on disk", index), e);
930: Simon Willnauer, debug, MethodDeclaration, logger.debug("{} processing pending deletes", index);
976: Simon Willnauer, warn, IfStmt, logger.warn("{} no shard lock for pending delete", delete.shardId);
973: Yannick Welsch, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("{} retry pending delete", shardLock.getShardId()), ex);
958: Simon Willnauer, debug, IfStmt, logger.debug("{} deleting index store reason [{}]", index, "pending delete");
963: Yannick Welsch, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("{} retry pending delete", index), ex);
982: Simon Willnauer, warn, IfStmt, logger.warn("{} still pending deletes present for shards {} - retrying", index, remove.toString());
985: Daniel Mitterdorfer, debug, IfStmt, logger.debug("{} schedule pending delete retry after {} ms", index, sleepTime);
1047: Simon Willnauer, trace, IfStmt, logger.trace("running periodic field data cache cleanup");
1052: Simon Willnauer, warn, CatchClause, logger.warn("Exception during periodic field data cache cleanup:", e);
1055: Simon Willnauer, trace, IfStmt, logger.trace("periodic field data cache cleanup finished in {} milliseconds", TimeValue.nsecToMSec(System.nanoTime() - startTimeNS));
1061: Simon Willnauer, warn, CatchClause, logger.warn("Exception during periodic request cache cleanup:", e);
164: Clinton Gormley, debug, IfStmt, logger.debug("Loading hunspell dictionary [{}]...", locale);
201: Nhat Nguyen, error, CatchClause, logger.error(() -> new ParameterizedMessage("Could not load hunspell dictionary [{}]", locale), e);
120: Lee Hinman, trace, IfStmt, logger.trace("parent circuit breaker with settings {}", this.parentSettings);
139: Simon Willnauer, info, MethodDeclaration, logger.info("Updated breaker settings request: {}", newRequestSettings);
147: Daniel Mitterdorfer, info, MethodDeclaration, logger.info("Updated breaker settings for in-flight requests: {}", newInFlightRequestsSettings);
157: Simon Willnauer, info, MethodDeclaration, logger.info("Updated breaker settings field data: {}", newFielddataSettings);
258: Yannick Welsch, trace, IfStmt, logger.trace("[{}] re-sending failed shard [{}], reason [{}]", matchedRouting.shardId(), matchedRouting, message);
278: Simon Willnauer, debug, IfStmt, logger.debug("[{}] cleaning index, no longer part of the metadata", index);
309: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("[{}] failed to complete pending deletion for index", index), e);
321: Yannick Welsch, warn, CatchClause, logger.warn("[{}] failed to lock all shards for index - timed out after 30 seconds", index);
323: Yannick Welsch, warn, CatchClause, logger.warn("[{}] failed to lock all shards for index - interrupted", index);
363: Boaz Leskes, debug, IfStmt, logger.debug("{} removing index, [{}]", index, reason);
414: Boaz Leskes, debug, IfStmt, logger.debug("{} removing shard (stale allocation id, stale {}, new {})", shardId, currentRoutingEntry, newShardRouting);
448: Yannick Welsch, debug, ForeachStmt, logger.debug("[{}] creating index", index);
542: Boaz Leskes, trace, IfStmt, logger.trace("ignoring initializing shard {} - no source node can be found.", shardRouting.shardId());
548: Yannick Welsch, debug, TryStmt, logger.debug("{} creating shard", shardRouting.shardId());
595: Yannick Welsch, trace, IfStmt, logger.trace("{} master marked shard as initializing, but shard has state [{}], resending shard started to {}", shardRouting.shardId(), state, nodes.getMasterNode());
627: Yannick Welsch, trace, IfStmt, logger.trace("can't find relocation source node for shard {} because it is assigned to an unknown node [{}].", shardRouting.shardId(), shardRouting.relocatingNodeId());
622: Yannick Welsch, trace, IfStmt, logger.trace("can't find replica source node because primary shard {} is not active.", primary);
619: Yannick Welsch, trace, IfStmt, logger.trace("can't find replica source node because primary shard {} is assigned to an unknown node.", primary);
671: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}][{}] failed to remove shard after failure ([{}])", shardRouting.getIndexName(), shardRouting.getId(), message), inner);
691: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}][{}] failed to mark shard as failed (because of [{}])", shardRouting.getIndexName(), shardRouting.getId(), message), inner);
685: Nhat Nguyen, warn, TryStmt, logger.warn(() -> new ParameterizedMessage("[{}] marking and sending shard failed due to [{}]", shardRouting.shardId(), message), failure);
96: Simon Willnauer, error, CatchClause, logger.error("Failed to call listener on field data cache unloading", e);
145: Simon Willnauer, error, CatchClause, logger.error("Failed to call listener on atomic field data loading", e);
171: Simon Willnauer, error, CatchClause, logger.error("Failed to call listener on global ordinals loading", e);
104: Simon Willnauer, trace, MethodDeclaration, logger.trace("{} sync flush on inactive shard returned successfully for sync_id: {}", syncedFlushResult.getShardId(), syncedFlushResult.syncId());
109: Nhat Nguyen, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("{} sync flush on inactive shard failed", indexShard.shardId()), e);
153: Boaz Leskes, debug, MethodDeclaration, logger.debug("{} unexpected error while executing synced flush", shardId);
307: Simon Willnauer, trace, IfStmt, logger.trace("{} failed to resolve node for primary shard {}, skipping sync", shardId, primaryShard);
311: Simon Willnauer, trace, TryStmt, logger.trace("{} retrieving in flight operation count", shardId);
326: Boaz Leskes, debug, MethodDeclaration, logger.debug("{} unexpected error while retrieving in flight op count", shardId);
360: Boaz Leskes, trace, IfStmt, logger.trace("{} is assigned to an unknown node. skipping for sync id [{}]. shard routing {}", shardId, syncId, shard);
367: Yannick Welsch, trace, IfStmt, logger.trace("{} can't resolve expected commit id for current node, skipping for sync id [{}]. shard routing {}", shardId, syncId, shard);
374: Nhat Nguyen, warn, IfStmt, logger.warn("{} can't to issue sync id [{}] for out of sync replica [{}] with num docs [{}]; num docs on primary [{}]", shardId, syncId, shard, preSyncedResponse.numDocs, numDocsOnPrimary);
381: Boaz Leskes, trace, ForeachStmt, logger.trace("{} sending synced flush request to {}. sync id [{}].", shardId, shard, syncId);
399: Nhat Nguyen, trace, MethodDeclaration, logger.trace(() -> new ParameterizedMessage("{} error while performing synced flush on [{}], skipping", shardId, shard), exp);
428: Boaz Leskes, trace, ForeachStmt, logger.trace("{} sending pre-synced flush request to {}", shardId, shard);
431: Boaz Leskes, trace, IfStmt, logger.trace("{} shard routing {} refers to an unknown node. skipping.", shardId, shard);
455: Nhat Nguyen, trace, MethodDeclaration, logger.trace(() -> new ParameterizedMessage("{} error while performing pre synced flush on [{}], skipping", shardId, shard), exp);
472: Boaz Leskes, trace, MethodDeclaration, logger.trace("{} performing pre sync flush", request.shardId());
476: Nhat Nguyen, trace, MethodDeclaration, logger.trace("{} pre sync flush done. commit id {}, num docs {}", request.shardId(), commitId, commitStats.getNumDocs());
483: Boaz Leskes, trace, MethodDeclaration, logger.trace("{} performing sync flush. sync id [{}], expected commit id {}", request.shardId(), request.syncId(), request.expectedCommitId());
485: Boaz Leskes, trace, MethodDeclaration, logger.trace("{} sync flush done. sync id [{}], result [{}]", request.shardId(), request.syncId(), result);
505: Boaz Leskes, trace, MethodDeclaration, logger.trace("{} in flight operations sampled at [{}]", request.shardId(), opCount);
91: Yannick Welsch, debug, IfStmt, logger.debug("delaying recovery of {} as source shard is not marked yet as relocating to {}", request.shardId(), request.targetNode());
96: Yannick Welsch, trace, MethodDeclaration, logger.trace("[{}][{}] starting recovery to {}", request.shardId().getIndex().getName(), request.shardId().id(), request.targetNode());
146: Nhat Nguyen, trace, MethodDeclaration, logger.trace(() -> new ParameterizedMessage("will retry recovery with id [{}] in [{}]", recoveryId, retryAfter), reason);
152: Yannick Welsch, trace, MethodDeclaration, logger.trace("will retry recovery with id [{}] in [{}] (reason [{}])", recoveryId, retryAfter, reason);
170: Jason Tedor, trace, IfStmt, logger.trace("not running recovery with id [{}] - can not find it (probably finished)", recoveryId);
183: Yannick Welsch, trace, CatchClause, logger.trace("unexpected error while preparing shard for peer recovery, failing recovery", e);
179: Yannick Welsch, trace, TryStmt, logger.trace("{} preparing shard for peer recovery", recoveryTarget.shardId());
227: Boaz Leskes, trace, CatchClause, logger.trace("recovery cancelled", e);
230: Nhat Nguyen, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("[{}][{}] Got exception on recovery", request.shardId().getIndex().getName(), request.shardId().id()), e);
270: Yannick Welsch, debug, IfStmt, logger.debug("delaying recovery of {} for [{}] due to networking error [{}]", request.shardId(), recoverySettings.retryDelayNetwork(), cause.getMessage());
191: Yannick Welsch, trace, TryStmt, logger.trace("{} starting recovery from {}", request.shardId(), request.sourceNode());
224: Yannick Welsch, debug, IfStmt, logger.debug("{} recovery done from [{}], took [{}]", request.shardId(), request.sourceNode(), recoveryTime);
222: Yannick Welsch, trace, IfStmt, logger.trace("{}", sb);
297: Jason Tedor, trace, CatchClause, logger.trace("{} shard folder empty, recovering all files", recoveryTarget);
300: Jason Tedor, error, CatchClause, logger.warn("error while listing local files, recovering as if there are none", e);
313: Jason Tedor, trace, MethodDeclaration, logger.trace("{} collecting local files for [{}]", recoveryTarget.shardId(), recoveryTarget.sourceNode());
316: Jason Tedor, trace, MethodDeclaration, logger.trace("{} local file count [{}]", recoveryTarget.shardId(), metadataSnapshot.size());
328: Jason Tedor, trace, IfStmt, logger.trace("{} preparing for sequence-number-based recovery starting at local checkpoint [{}] from [{}]", recoveryTarget.shardId(), startingSeqNo, recoveryTarget.sourceNode());
326: Jason Tedor, trace, IfStmt, logger.trace("{} preparing for file-based recovery from [{}]", recoveryTarget.shardId(), recoveryTarget.sourceNode());
367: Nhat Nguyen, trace, IfStmt, logger.trace("Calculate starting seqno based on global checkpoint [{}], safe commit [{}], existing commits [{}]", globalCheckpoint, CombinedDeletionPolicy.commitDescription(safeCommit), descriptionOfExistingCommits);
476: Boaz Leskes, warn, CatchClause, logger.warn("failed to send error back to recovery source", e1);
506: Yannick Welsch, trace, IfStmt, logger.trace("waiting for cluster state version {} (current: {})", clusterStateVersion, clusterState.getVersion());
529: Nhat Nguyen, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("failed waiting for cluster state with version {} (current: {})", clusterStateVersion, clusterService.state().getVersion()), e);
527: Yannick Welsch, trace, TryStmt, logger.trace("successfully waited for cluster state with version {} (current: {})", clusterStateVersion, currentVersion);
502: Yannick Welsch, trace, IfStmt, logger.trace("node has cluster state with version higher than {} (current: {})", clusterStateVersion, clusterState.getVersion());
615: Nhat Nguyen, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("unexpected error during recovery, but recovery id [{}] is finished", recoveryId), e);
609: Nhat Nguyen, error, IfStmt, logger.error(() -> new ParameterizedMessage("unexpected error during recovery [{}], failing shard", recoveryId), e);
77: Yannick Welsch, trace, MethodDeclaration, logger.trace("{} started recovery from {}, id [{}]", recoveryTarget.shardId(), recoveryTarget.sourceNode(), recoveryTarget.recoveryId());
113: Yannick Welsch, trace, IfStmt, logger.trace("{} recovery could not be reset as it is already cancelled, recovery from {}, id [{}], previous id [{}]", newRecoveryTarget.shardId(), newRecoveryTarget.sourceNode(), newRecoveryTarget.recoveryId(), oldRecoveryTarget.recoveryId());
109: Yannick Welsch, trace, IfStmt, logger.trace("{} restarted recovery from {}, id [{}], previous id [{}]", newRecoveryTarget.shardId(), newRecoveryTarget.sourceNode(), newRecoveryTarget.recoveryId(), oldRecoveryTarget.recoveryId());
160: Boaz Leskes, trace, IfStmt, logger.trace("{} canceled recovery from {}, id [{}] (reason [{}])", removed.shardId(), removed.sourceNode(), removed.recoveryId(), reason);
178: Yannick Welsch, trace, IfStmt, logger.trace("{} failing recovery from {}, id [{}]. Send shard failure: [{}]", removed.shardId(), removed.sourceNode(), removed.recoveryId(), sendShardFailure);
188: Boaz Leskes, trace, IfStmt, logger.trace("{} marking recovery from {} as done, id [{}]", removed.shardId(), removed.sourceNode(), removed.recoveryId());
218: Yannick Welsch, trace, ForeachStmt, logger.trace("{} canceled recovery from {}, id [{}] (reason [{}])", removed.shardId(), removed.sourceNode(), removed.recoveryId(), reason);
271: Nhat Nguyen, error, MethodDeclaration, logger.error(() -> new ParameterizedMessage("unexpected error while monitoring recovery [{}]", recoveryId), e);
278: Boaz Leskes, trace, IfStmt, logger.trace("[monitor] no status found for [{}], shutting down", recoveryId);
291: Yannick Welsch, trace, MethodDeclaration, logger.trace("[monitor] rescheduling check for [{}]. last access time is [{}]", recoveryId, lastSeenAccessTime);
107: Simon Willnauer, debug, ConstructorDeclaration, logger.debug("using max_bytes_per_sec[{}]", maxBytesPerSec);
140: Yannick Welsch, debug, IfStmt, logger.debug("delaying recovery of {} as it is not listed as assigned to target node {}", request.shardId(), request.targetNode());
177: Jason Tedor, warn, CatchClause, logger.warn("releasing snapshot caused exception", ex);
153: Boaz Leskes, trace, IfStmt, logger.trace("performing sequence numbers based recovery. starting at [{}]", request.startingSeqNo());
208: Boaz Leskes, trace, TryStmt, logger.trace("all operations up to [{}] completed, which will be used as an ending sequence number", endingSeqNo);
210: Nhat Nguyen, trace, TryStmt, logger.trace("snapshot translog for recovery; current size is [{}]", shard.estimateTranslogOperationsFromMinSeq(startingSeqNo));
257: Boaz Leskes, trace, MethodDeclaration, logger.trace("testing sequence numbers in range: [{}, {}]", startingSeqNo, localCheckpoint);
304: Lee Hinman, info, IfStmt, logger.info("Snapshot differs from actual index for file: {} meta: {}", name, recoverySourceMetadata.asMap());
334: Boaz Leskes, trace, IfStmt, logger.trace("recovery [phase1]: not recovering [{}], exist in local store and has checksum [{}]," + " size [{}]", md.name(), md.checksum(), md.length());
347: Boaz Leskes, trace, IfStmt, logger.trace("recovery [phase1]: recovering [{}], does not exist in remote", md.name());
344: Boaz Leskes, trace, IfStmt, logger.trace("recovery [phase1]: recovering [{}], exists in local store, but is different: remote [{}], local [{}]", md.name(), request.metadataSnapshot().asMap().get(md.name()), md);
357: Boaz Leskes, trace, IfStmt, logger.trace("recovery [phase1]: recovering_files [{}] with total_size [{}], reusing_files [{}] with total_size [{}]", response.phase1FileNames.size(), new ByteSizeValue(totalSize), response.phase1ExistingFileNames.size(), new ByteSizeValue(existingTotalSize));
392: Boaz Leskes, debug, ForeachStmt, logger.debug("checking integrity for file {} after remove corruption exception", md);
395: Boaz Leskes, warn, IfStmt, logger.warn("Corrupted file detected {} checksum mismatch", md);
407: Nhat Nguyen, warn, IfStmt, logger.warn(() -> new ParameterizedMessage("{} Remote file corruption during finalization of recovery on node {}. local checksum OK", shard.shardId(), request.targetNode()), corruptIndexException);
417: Boaz Leskes, trace, TryStmt, logger.trace("recovery [phase1]: took [{}]", stopWatch.totalTime());
428: Boaz Leskes, trace, MethodDeclaration, logger.trace("recovery [phase1]: prepare remote engine for translog");
436: Boaz Leskes, trace, MethodDeclaration, logger.trace("recovery [phase1]: remote engine start took [{}]", stopWatch.totalTime());
462: Boaz Leskes, trace, MethodDeclaration, logger.trace("recovery [phase2]: sending transaction log operations (seq# from [" + startingSeqNo + "], " + "required [" + requiredSeqNoRangeStart + ":" + endingSeqNo + "]");
469: Boaz Leskes, trace, MethodDeclaration, logger.trace("recovery [phase2]: took [{}]", stopWatch.totalTime());
484: Boaz Leskes, trace, MethodDeclaration, logger.trace("finalizing recovery");
499: Yannick Welsch, trace, IfStmt, logger.trace("performing relocation hand-off");
508: Boaz Leskes, trace, MethodDeclaration, logger.trace("finalizing recovery took [{}]", stopWatch.totalTime());
552: Boaz Leskes, trace, IfStmt, logger.trace("no translog operations to send");
580: Jason Tedor, trace, IfStmt, logger.trace("sent batch of [{}][{}] (total: [{}]) translog operations", ops, new ByteSizeValue(size), expectedTotalOps);
602: Jason Tedor, trace, MethodDeclaration, logger.trace("sent final batch of [{}][{}] (total: [{}]) translog operations", ops, new ByteSizeValue(size), expectedTotalOps);
678: Nhat Nguyen, warn, IfStmt, logger.warn(() -> new ParameterizedMessage("{} Remote file corruption on node {}, recovering {}. local checksum OK", shardId, request.targetNode(), md), corruptIndexException);
671: Simon Willnauer, warn, IfStmt, logger.warn("{} Corrupted file detected {} checksum mismatch", shardId, md);
198: Yannick Welsch, debug, TryStmt, logger.debug("reset of recovery with shard {} and id [{}]", shardId, recoveryId);
206: Yannick Welsch, trace, CatchClause, logger.trace("new recovery target cancelled for shard {} while waiting on old recovery target with id [{}] to close", shardId, recoveryId);
235: Boaz Leskes, debug, TryStmt, logger.debug("recovery canceled (reason: [{}])", reason);
328: Simon Willnauer, trace, WhileStmt, logger.trace("closing IndexOutput file [{}]", entry.getValue());
332: Nhat Nguyen, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("error while closing recovery output [{}]", entry.getValue()), e);
338: Simon Willnauer, trace, ForeachStmt, logger.trace("cleaning temporary file [{}]", file);
460: Boaz Leskes, debug, CatchClause, logger.debug("Failed to clean lucene index", e);
218: Boaz Leskes, trace, ForeachStmt, logger.trace("{} sending shard active check to {}", request.v2().shardId, request.v1());
246: Boaz Leskes, trace, MethodDeclaration, logger.trace("{} is {}active on node {}", shardId, response.shardActive ? "" : "not ", response.node);
258: Nhat Nguyen, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("shards active request failed for {}", shardId), exp);
271: Boaz Leskes, trace, IfStmt, logger.trace("not deleting shard {}, expected {} active copies, but only {} found active copies", shardId, expectedActiveCopies, activeCopies.get());
277: Igor Motov, trace, IfStmt, logger.trace("not deleting shard {}, the latest cluster state version[{}] is not equal to cluster state before shard active api call [{}]", shardId, latestClusterState.getVersion(), clusterStateVersion);
284: Igor Motov, trace, IfStmt, logger.trace("not deleting shard {}, the update task state version[{}] is not equal to cluster state before shard active api call [{}]", shardId, currentState.getVersion(), clusterStateVersion);
290: Nhat Nguyen, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("{} failed to delete unallocated shard, ignoring", shardId), ex);
293: Nhat Nguyen, error, MethodCallExpr, logger.error(() -> new ParameterizedMessage("{} unexpected error during deletion of unallocated shard", shardId), e);
342: Nhat Nguyen, error, CatchClause, logger.error(() -> new ParameterizedMessage("failed send response for shard active while trying to delete shard {} - shard will probably not be removed", request.shardId), e);
344: Nhat Nguyen, error, CatchClause, logger.error(() -> new ParameterizedMessage("failed send response for shard active while trying to delete shard {} - shard will probably not be removed", request.shardId), e);
369: Martijn van Groningen, trace, IfStmt, logger.trace("shard exists request meant for cluster[{}], but this is cluster[{}], ignoring request", request.clusterName, thisClusterName);
116: Boaz Leskes, trace, MethodDeclaration, logger.trace("listing store meta data for {}", shardId);
157: Boaz Leskes, trace, IfStmt, logger.trace("{} didn't find any store meta data to load (took [{}])", shardId, took);
155: Boaz Leskes, debug, IfStmt, logger.debug("{} loaded store meta data (took [{}])", shardId, took);
138: Boaz Leskes, trace, IfStmt, logger.trace("{} node doesn't have meta data for the requests index, responding with empty", shardId);
55: Tanguy Leroux, debug, ConstructorDeclaration, logger.debug("using refresh_interval [{}]", refreshInterval);
67: Jason Tedor, debug, CatchClause, logger.debug("unexpected exception reading filesystem info", e);
156: Jason Tedor, debug, ConstructorDeclaration, logger.debug("enabled [{}], interval [{}], gc_threshold [{}], overhead [{}, {}, {}]", this.enabled, this.interval, this.gcThresholds, this.gcOverheadThreshold.warnThreshold, this.gcOverheadThreshold.infoThreshold, this.gcOverheadThreshold.debugThreshold);
189: Jason Tedor, debug, MethodDeclaration, logger.debug("failed to monitor", e);
227: Jason Tedor, warn, IfStmt, logger.warn(SLOW_GC_LOG_MESSAGE, name, seq, totalGcCollectionCount, currentGcCollectionTime, currentGcCollectionCount, TimeValue.timeValueMillis(elapsed), currentGcCollectionTime, totalGcCollectionTime, lastJvmStats.getMem().getHeapUsed(), currentJvmStats.getMem().getHeapUsed(), maxHeapUsed, pools.apply(lastJvmStats, currentJvmStats));
245: Jason Tedor, info, IfStmt, logger.info(SLOW_GC_LOG_MESSAGE, name, seq, totalGcCollectionCount, currentGcCollectionTime, currentGcCollectionCount, TimeValue.timeValueMillis(elapsed), currentGcCollectionTime, totalGcCollectionTime, lastJvmStats.getMem().getHeapUsed(), currentJvmStats.getMem().getHeapUsed(), maxHeapUsed, pools.apply(lastJvmStats, currentJvmStats));
263: Jason Tedor, debug, IfStmt, logger.debug(SLOW_GC_LOG_MESSAGE, name, seq, totalGcCollectionCount, currentGcCollectionTime, currentGcCollectionCount, TimeValue.timeValueMillis(elapsed), currentGcCollectionTime, totalGcCollectionTime, lastJvmStats.getMem().getHeapUsed(), currentJvmStats.getMem().getHeapUsed(), maxHeapUsed, pools.apply(lastJvmStats, currentJvmStats));
316: Jason Tedor, warn, IfStmt, logger.warn(OVERHEAD_LOG_MESSAGE, seq, TimeValue.timeValueMillis(current), TimeValue.timeValueMillis(elapsed));
321: Jason Tedor, info, IfStmt, logger.info(OVERHEAD_LOG_MESSAGE, seq, TimeValue.timeValueMillis(current), TimeValue.timeValueMillis(elapsed));
326: Jason Tedor, debug, IfStmt, logger.debug(OVERHEAD_LOG_MESSAGE, seq, TimeValue.timeValueMillis(current), TimeValue.timeValueMillis(elapsed));
47: Tanguy Leroux, debug, ConstructorDeclaration, logger.debug("using refresh_interval [{}]", refreshInterval);
152: Jason Tedor, error, IfStmt, logger.debug("error reading one minute load average from operating system", e);
138: Jason Tedor, error, IfStmt, logger.debug("error reading /proc/loadavg", e);
503: Jason Tedor, error, CatchClause, logger.debug("error reading control group stats", e);
46: Tanguy Leroux, debug, ConstructorDeclaration, logger.debug("using refresh_interval [{}]", refreshInterval);
45: Tanguy Leroux, debug, ConstructorDeclaration, logger.debug("using refresh_interval [{}]", refreshInterval);
260: Boaz Leskes, info, BlockStmt, logger.info("initializing ...");
282: Jason Tedor, info, IfStmt, logger.info("node name [{}], node ID [{}]", nodeName, nodeId);
280: Tanguy Leroux, info, IfStmt, logger.info("node name derived from node ID [{}]; set [{}] to override", nodeId, NODE_NAME_SETTING.getKey());
286: Boaz Leskes, info, TryStmt, logger.info("version[{}], pid[{}], build[{}/{}/{}/{}], OS[{}/{}/{}], JVM[{}/{}/{}/{}]", Version.displayVersion(Version.CURRENT, Build.CURRENT.isSnapshot()), jvmInfo.pid(), Build.CURRENT.flavor().displayName(), Build.CURRENT.type().displayName(), Build.CURRENT.shortHash(), Build.CURRENT.date(), Constants.OS_NAME, Constants.OS_VERSION, Constants.OS_ARCH, Constants.JVM_VENDOR, Constants.JVM_NAME, Constants.JAVA_VERSION, Constants.JVM_VERSION);
301: Jason Tedor, info, TryStmt, logger.info("JVM arguments {}", Arrays.toString(jvmInfo.getInputArguments()));
305: Boaz Leskes, debug, IfStmt, logger.debug("using config [{}], data [{}], logs [{}], plugins [{}]", environment.configFile(), Arrays.toString(environment.dataFiles()), environment.logsFile(), environment.pluginsFile());
545: Nik Everett, debug, IfStmt, logger.debug("initializing HTTP handlers ...");
548: Boaz Leskes, info, TryStmt, logger.info("initialized");
562: Jason Tedor, warn, IfStmt, logger.warn("version [{}] is a pre-release version of Elasticsearch and is not suitable for production", Version.displayVersion(version, isSnapshot));
617: Simon Willnauer, info, MethodDeclaration, logger.info("starting ...");
680: Boaz Leskes, debug, IfStmt, logger.debug("waiting to join the cluster. timeout [{}]", initialStateTimeout);
693: Simon Willnauer, warn, MethodDeclaration, logger.warn("timed out while waiting for initial discovery state - timeout: {}", initialStateTimeout);
721: Simon Willnauer, info, MethodDeclaration, logger.info("started");
733: Simon Willnauer, info, MethodDeclaration, logger.info("stopping ...");
760: Simon Willnauer, info, MethodDeclaration, logger.info("stopped");
778: Simon Willnauer, info, MethodDeclaration, logger.info("closing ...");
844: Simon Willnauer, trace, IfStmt, logger.trace("Close times for each service:\n{}", stopWatch.prettyPrint());
847: Simon Willnauer, info, MethodDeclaration, logger.info("closed");
150: Nhat Nguyen, warn, IfStmt, logger.warn(() -> new ParameterizedMessage("task {} failed with an exception", getPersistentTaskId()), failure);
155: Igor Motov, trace, IfStmt, logger.trace("sending notification for completed task [{}] with id [{}]", getAction(), getPersistentTaskId());
160: Igor Motov, trace, MethodDeclaration, logger.trace("notification for task [{}] with id [{}] was successful", getAction(), getPersistentTaskId());
166: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("notification for task [{}] with id [{}] failed", getAction(), getPersistentTaskId()), e);
147: Igor Motov, warn, IfStmt, logger.warn("attempt to complete task [{}] with id [{}] in the [{}] state", getAction(), getPersistentTaskId(), prevState);
114: Igor Motov, warn, IfStmt, logger.warn("persistent task " + id + " failed", failure);
131: Igor Motov, warn, IfStmt, logger.warn("The task [{}] wasn't found, status is not updated", id);
128: Igor Motov, warn, IfStmt, logger.warn("The task [{}] with id [{}] was found but it has a different allocation id [{}], status is not updated", PersistentTasksCustomMetaData.getTaskWithId(currentState, id).getTaskName(), id, allocationId);
200: Igor Motov, warn, IfStmt, logger.warn("trying to update status on non-existing task {}", id);
198: Igor Motov, warn, IfStmt, logger.warn("trying to update status on task {} with unexpected allocation id {}", id, allocationId);
244: Tanguy Leroux, trace, IfStmt, logger.trace("checking task reassignment for cluster state {}", event.state().getVersion());
253: Tanguy Leroux, warn, MethodDeclaration, logger.warn("failed to reassign persistent tasks", e);
302: Igor Motov, trace, IfStmt, logger.trace("reassigning {} persistent tasks", tasks.tasks().size());
317: Igor Motov, trace, IfStmt, logger.trace("ignoring task {} because it is still running", task.getId());
314: Igor Motov, trace, IfStmt, logger.trace("ignoring task {} because assignment is the same {}", task.getId(), assignment);
310: Igor Motov, trace, IfStmt, logger.trace("reassigning task {} from node {} to node {}", task.getId(), task.getAssignment().getExecutorNode(), assignment.getExecutorNode());
128: Igor Motov, trace, IfStmt, logger.trace("Found completed persistent task [{}] with id [{}] and allocation id [{}] - removing", task.getAction(), task.getPersistentTaskId(), task.getAllocationId());
184: Igor Motov, warn, IfStmt, logger.warn("Persistent task [{}] with id [{}] and allocation id [{}] failed to create", task.getAction(), task.getPersistentTaskId(), task.getAllocationId());
171: Igor Motov, trace, TryStmt, logger.trace("Persistent task [{}] with id [{}] and allocation id [{}] was created", task.getAction(), task.getPersistentTaskId(), task.getAllocationId());
202: Igor Motov, trace, MethodDeclaration, logger.trace("Persistent task [{}] with id [{}] and allocation id [{}] was cancelled", task.getAction(), task.getPersistentTaskId(), task.getAllocationId());
209: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("failed to cancel task [{}] with id [{}] and allocation id [{}]", task.getAction(), task.getPersistentTaskId(), task.getAllocationId()), e);
115: Ryan Ernst, trace, IfStmt, logger.trace("plugin loaded from classpath [{}]", pluginInfo);
187: Jason Tedor, Info, ConstructorDeclaration, logPluginInfo(info.getPluginInfos(), "plugin", logger);
196: Jason Tedor, info, ForeachStmt, logger.info("loaded " + type + " [" + name + "]");
193: Jason Tedor, info, IfStmt, logger.info("no " + type + "s loaded");
134: Igor Motov, info, IfStmt, logger.info("update repository [{}]", request.name);
131: Igor Motov, info, IfStmt, logger.info("put repository [{}]", request.name);
116: Igor Motov, info, IfStmt, logger.info("put repository [{}]", request.name);
144: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("failed to create repository [{}]", request.name), e);
181: Igor Motov, info, IfStmt, logger.info("delete repository [{}]", repositoryMetaData.name());
236: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to finish repository verification", repositoryName), inner);
219: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to finish repository verification", repositoryName), e);
316: Igor Motov, warn, CatchClause, logger.warn("failure updating cluster state ", ex);
266: Igor Motov, trace, TryStmt, logger.trace("processing new index repositories for state version [{}]", event.state().version());
272: Igor Motov, debug, IfStmt, logger.debug("unregistering repository [{}]", entry.getKey());
305: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to create repository [{}]", repositoryMetaData.name()), ex);
290: Igor Motov, debug, IfStmt, logger.debug("updating repository [{}]", repositoryMetaData.name());
309: Igor Motov, debug, IfStmt, logger.debug("registering repository [{}]", repositoryMetaData.name());
368: Ryan Ernst, debug, MethodDeclaration, logger.debug("closing repository [{}][{}]", repository.getMetadata().type(), repository.getMetadata().name());
376: Igor Motov, debug, MethodDeclaration, logger.debug("creating repository [{}][{}]", repositoryMetaData.type(), repositoryMetaData.name());
387: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to create repository [{}][{}]", repositoryMetaData.type(), repositoryMetaData.name()), e);
83: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to verify repository", repository), e);
154: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to verify repository", request.repository), ex);
269: Igor Motov, warn, CatchClause, logger.warn("cannot close blob store", t);
352: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("cannot read snapshot file [{}]", snapshotId), ex);
375: Tanguy Leroux, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] [{}] failed to read metadata for index", snapshotId, index), ex);
387: Tanguy Leroux, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to delete shard data for shard [{}][{}]", snapshotId, index, finalShardId), ex);
411: Nhat Nguyen, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("[{}] index [{}] no longer part of any snapshots in the repository, but failed to clean up " + "its index folder.", metadata.name(), indexId), ioe);
428: Nhat Nguyen, warn, IfStmt, logger.warn(() -> new ParameterizedMessage("Unable to delete snapshot file [{}]", blobId), e);
425: Nhat Nguyen, warn, IfStmt, logger.warn(() -> new ParameterizedMessage("[{}] Unable to delete snapshot file [{}]", snapshotInfo.snapshotId(), blobId), e);
441: Nhat Nguyen, warn, IfStmt, logger.warn(() -> new ParameterizedMessage("Unable to delete global metadata file [{}]", blobId), e);
438: Nhat Nguyen, warn, IfStmt, logger.warn(() -> new ParameterizedMessage("[{}] Unable to delete global metadata file [{}]", snapshotInfo.snapshotId(), blobId), e);
452: Tanguy Leroux, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to delete metadata for index [{}]", snapshotId, indexId.getName()), ex);
595: Ali Beyad, warn, CatchClause, logger.warn("[{}] index blob is not valid x-content [{} bytes]", snapshotsIndexBlobName, out.bytes().length());
610: Ali Beyad, debug, IfStmt, logger.debug("[{}] Incompatible snapshots blob [{}] does not exist, the likely " + "reason is that there are no incompatible snapshots in the repository", metadata.name(), INCOMPATIBLE_SNAPSHOTS_BLOB);
666: Ali Beyad, debug, MethodDeclaration, logger.debug("Repository [{}] writing new index generational blob [{}]", metadata.name(), indexBlob);
685: Ali Beyad, debug, MethodDeclaration, logger.debug("Repository [{}] updating index.latest with generation [{}]", metadata.name(), newGen);
907: Ryan Ernst, debug, CatchClause, logger.debug("[{}] [{}] failed to delete shard snapshot file", shardId, snapshotId);
968: Nhat Nguyen, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("[{}] [{}] error deleting blob [{}] during cleanup", snapshotId, shardId, blobName), e);
1013: Ryan Ernst, warn, CatchClause, logger.warn("file [{}] does not conform to the '{}' schema", name, DATA_BLOB_PREFIX);
1036: Ryan Ernst, warn, CatchClause, logger.warn("failed to parse index file name [{}]", name);
1050: Ali Beyad, debug, IfStmt, logger.debug("Could not find a readable index-N file in a non-empty shard snapshot directory [{}]", blobContainer.path());
1047: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to read index file [{}]", file), e);
1065: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to read commit point [{}]", name), e);
1102: Ryan Ernst, debug, MethodDeclaration, logger.debug("[{}] [{}] snapshot to [{}] ...", shardId, snapshotId, metadata.name());
1139: Ryan Ernst, debug, IfStmt, logger.debug("[{}] [{}] Aborted on the file [{}], exiting", shardId, snapshotId, fileName);
1143: Ryan Ernst, trace, ForeachStmt, logger.trace("[{}] [{}] Processing [{}]", shardId, snapshotId, fileName);
1156: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("{} Can't calculate hash from blob for file [{}] [{}]", shardId, fileInfo.physicalName(), fileInfo.metadata()), e);
1205: Tanguy Leroux, trace, MethodDeclaration, logger.trace("[{}] [{}] writing shard snapshot file", shardId, snapshotId);
1263: Ryan Ernst, warn, CatchClause, logger.warn("store cannot be marked as corrupted", inner);
1318: Ryan Ernst, debug, IfStmt, logger.debug("[{}] [{}] Aborted on the file [{}], exiting", shardId, snapshotId, fileName);
1398: Ryan Ernst, debug, TryStmt, logger.debug("[{}] [{}] restoring to [{}] ...", snapshotId, metadata.name(), shardId);
1428: Boaz Leskes, trace, CatchClause, logger.trace("[{}] [{}] restoring from to an empty shard", shardId, snapshotId);
1431: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("{} Can't read metadata from store, will not reuse any local file while restoring", shardId), e);
1447: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("{} Can't calculate hash from blog for file [{}] [{}]", shardId, fileInfo.physicalName(), fileInfo.metadata()), e);
1465: Ryan Ernst, trace, IfStmt, logger.trace("[{}] [{}] not_recovering [{}] from [{}], exists in local store and is same", shardId, snapshotId, fileInfo.physicalName(), fileInfo.name());
1477: Ryan Ernst, trace, IfStmt, logger.trace("[{}] [{}] recovering [{}] from [{}], exists in local store but is different", shardId, snapshotId, fileInfo.physicalName(), fileInfo.name());
1475: Ryan Ernst, trace, IfStmt, logger.trace("[{}] [{}] recovering [{}] from [{}], does not exists in local store", shardId, snapshotId, fileInfo.physicalName(), fileInfo.name());
1483: Ryan Ernst, trace, IfStmt, logger.trace("no files to recover, all exists within the local store");
1500: Tanguy Leroux, trace, IfStmt, logger.trace("[{}] [{}] deleting pre-existing file [{}]", shardId, snapshotId, physicalName);
1504: Ryan Ernst, trace, ForeachStmt, logger.trace("[{}] [{}] restoring file [{}]", shardId, snapshotId, fileToRecover.name());
1534: Ryan Ernst, warn, CatchClause, logger.warn("[{}] failed to list directory - some of files might not be deleted", snapshotId);
1530: Ryan Ernst, warn, CatchClause, logger.warn("[{}] failed to delete file [{}] during snapshot cleanup", snapshotId, storeFile);
1574: Ryan Ernst, warn, CatchClause, logger.warn("store cannot be marked as corrupted", e);
81: Igor Motov, warn, IfStmt, logger.warn("the repository location is missing, it should point to a shared file system location that is available on all master and data nodes");
90: Igor Motov, warn, IfStmt, logger.warn("The specified location [{}] should start with a repository path specified by the path.repo setting, but the path.repo setting was not set on this node", location);
87: Igor Motov, warn, IfStmt, logger.warn("The specified location [{}] doesn't start with any repository paths specified by the path.repo setting: [{}] ", location, environment.repoFiles());
133: Tanguy Leroux, warn, IfStmt, SUPPRESSED_ERROR_LOGGER.warn(messageSupplier, e);
131: Tanguy Leroux, debug, IfStmt, SUPPRESSED_ERROR_LOGGER.debug(messageSupplier, e);
179: Yannick Welsch, error, CatchClause, logger.error(() -> new ParameterizedMessage("failed to send failure response for uri [{}]", request.uri()), inner);
202: Jason Tedor, warn, CatchClause, logger.warn("failed to send bad request response", e);
373: Lee Hinman, warn, CatchClause, logger.warn("failed to send bad request response", e);
61: Jason Tedor, error, CatchClause, logger.error("failed to send failure response", inner);
221: Jason Tedor, debug, ConstructorDeclaration, logger.debug("using script cache with max_size [{}], expire [{}]", cacheMaxSize, cacheExpire);
309: Jack Conradson, trace, IfStmt, logger.trace("compiling lang: [{}] type: [{}] script: {}", lang, type, idOrCode);
331: Jack Conradson, trace, IfStmt, logger.trace("compiling script, type: [{}], lang: [{}], options: [{}]", type, lang, options);
524: Tanguy Leroux, debug, IfStmt, logger.debug("removed {} from cache, reason: {}", notification.getValue(), notification.getRemovalReason());
306: kimchy, trace, CatchClause, logger.trace("Dfs phase failed", e);
379: kimchy, trace, CatchClause, logger.trace("Query phase failed", e);
422: kimchy, trace, CatchClause, logger.trace("Query phase failed", e);
453: kimchy, trace, CatchClause, logger.trace("Query phase failed", e);
494: kimchy, trace, CatchClause, logger.trace("Fetch phase failed", e);
525: kimchy, trace, CatchClause, logger.trace("Fetch phase failed", e);
709: Jason Tedor, warn, CatchClause, logger.warn("failed to process shard failure to (potentially) send back shard failure on corruption", inner);
953: javanna, debug, IfStmt, logger.debug("freeing search context [{}], time [{}], lastAccessTime [{}], keepAlive [{}]", context.id(), time, lastAccessTime, context.keepAlive());
489: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to restore snapshot", request.repositoryName + ":" + request.snapshotName), e);
472: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("[{}] failed to restore snapshot", snapshotId), e);
696: Nhat Nguyen, error, MethodDeclaration, logger.error(() -> new ParameterizedMessage("unexpected failure during [{}]", source), e);
701: Yannick Welsch, debug, MethodDeclaration, logger.debug("no longer master while processing restore state update [{}]", source);
839: Igor Motov, warn, CatchClause, logger.warn("Failed to update restore state ", t);
177: Jason Tedor, warn, CatchClause, logger.warn("Failed to update snapshot state ", e);
188: Ali Beyad, debug, IfStmt, logger.debug("[{}] shard closing, abort snapshotting for snapshot [{}]", shardId, snapshotShards.getKey().getSnapshotId());
294: Tanguy Leroux, debug, IfStmt, logger.debug("[{}] trying to cancel snapshot on the shard [{}] that has already failed, " + "updating status on the master", entry.snapshot(), shard.key);
289: Tanguy Leroux, debug, IfStmt, logger.debug("[{}] trying to cancel snapshot on the shard [{}] that is already done, " + "updating status on the master", entry.snapshot(), shard.key);
285: Tanguy Leroux, debug, IfStmt, logger.debug("[{}] trying to cancel snapshot on shard [{}] that is finalizing, " + "letting it finish", entry.snapshot(), shard.key);
253: Nik Everett, trace, IfStmt, logger.trace("[{}] - Adding shard to the queue", shard.key);
342: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("[{}][{}] failed to snapshot shard", shardId, snapshot), e);
395: Tanguy Leroux, debug, IfStmt, logger.debug("snapshot ({}) completed to {} with {}", snapshot, repository, lastSnapshotStatus);
435: Tanguy Leroux, debug, IfStmt, logger.debug("[{}] new master thinks the shard [{}] is not completed but the shard failed locally, " + "updating status on master", snapshot.snapshot(), shardId);
429: Tanguy Leroux, debug, IfStmt, logger.debug("[{}] new master thinks the shard [{}] is not completed but the shard is done locally, " + "updating status on the master", snapshot.snapshot(), shardId);
532: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] [{}] failed to update snapshot state", snapshot, status), e);
542: Igor Motov, trace, MethodDeclaration, logger.trace("received updated snapshot restore state [{}]", request);
575: Yannick Welsch, trace, IfStmt, logger.trace("[{}] Updating shard [{}] with status [{}]", updateSnapshotState.snapshot(), updateSnapshotState.shardId(), updateSnapshotState.status().state());
601: Yannick Welsch, trace, IfStmt, logger.trace("changed cluster state triggered by {} snapshot state updates", changedCount);
194: Nhat Nguyen, warn, IfStmt, logger.warn(() -> new ParameterizedMessage("failed to get snapshot [{}]", snapshotId), ex);
253: Ali Beyad, trace, IfStmt, logger.trace("[{}][{}] creating snapshot for indices [{}]", repositoryName, snapshotName, indices);
272: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("[{}][{}] failed to create snapshot", repositoryName, snapshotName), e);
465: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to create snapshot [{}]", snapshot.snapshot().getSnapshotId()), e);
366: Tanguy Leroux, info, TryStmt, logger.info("snapshot [{}] started", snapshot.snapshot());
434: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("[{}] failed to create snapshot", snapshot.snapshot().getSnapshotId()), e);
513: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to close snapshot in repository", snapshot.snapshot()), inner);
659: Jason Tedor, warn, CatchClause, logger.warn("Failed to update snapshot state ", e);
763: Ali Beyad, debug, MethodDeclaration, logger.debug("cleaned up abandoned snapshot {} in INIT state", snapshot.snapshot());
768: Ali Beyad, warn, MethodDeclaration, logger.warn("failed to clean up abandoned snapshot {} in INIT state", snapshot.snapshot());
737: Nik Everett, warn, IfStmt, logger.warn("failing snapshot of shard [{}] on closed node [{}]", shardEntry.key, shardStatus.nodeId());
782: Igor Motov, warn, MethodDeclaration, logger.warn("failed to update snapshot state after node removal");
824: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("failed to update snapshot state after shards started from [{}] ", source), e);
845: Nik Everett, trace, IfStmt, logger.trace("starting shard that we were waiting for [{}] on node [{}]", shardId, shardStatus.nodeId());
857: Nik Everett, warn, IfStmt, logger.warn("failing snapshot of shard [{}] on unassigned shard [{}]", shardId, shardStatus.nodeId());
983: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to finalize snapshot", snapshot), e);
962: Tanguy Leroux, trace, TryStmt, logger.trace("[{}] finalizing snapshot in repository, state: [{}], failure[{}]", snapshot, entry.state(), failure);
981: Tanguy Leroux, info, TryStmt, logger.info("snapshot [{}] completed with state [{}]", snapshot, snapshotInfo.state());
1032: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("[{}] failed to remove snapshot metadata", snapshot), e);
1055: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to notify listener [{}]", listener), t);
1186: Igor Motov, debug, IfStmt, logger.debug("trying to delete completed snapshot - should wait for shards to finalize on all nodes");
1256: Ali Beyad, debug, IfStmt, logger.debug("deleted snapshot is not running - deleting files");
1211: Igor Motov, trace, IfStmt, logger.trace("adding snapshot completion listener to wait for deleted snapshot to finish");
1216: Ali Beyad, debug, IfStmt, logger.debug("deleted snapshot completed - deleting files");
1224: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("[{}] failed to delete snapshot", snapshot), ex);
1234: Ali Beyad, warn, IfStmt, logger.warn("deleted snapshot failed - deleting files", e);
1243: Nhat Nguyen, info, CatchClause, logger.info(() -> new ParameterizedMessage("Tried deleting in-progress snapshot [{}], but it " + "could not be found after failing to abort.", smex.getSnapshotName()), e);
1303: Tanguy Leroux, info, TryStmt, logger.info("snapshot [{}] deleted", snapshot);
1338: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("[{}] failed to remove snapshot deletion metadata", snapshot), e);
48: Nik Everett, info, MethodDeclaration, logger.info("{} finished with response {}", task.getId(), response);
53: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("{} failed with exception", task.getId()), e);
118: Nik Everett, trace, IfStmt, logger.trace("register {} [{}] [{}] [{}]", task.getId(), type, action, task.getDescription());
161: Igor Motov, trace, IfStmt, logger.trace("cancelling task with id {}", task.getId());
171: Igor Motov, trace, MethodDeclaration, logger.trace("unregister task for id: {}", task.getId());
199: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("couldn't store error {}", ExceptionsHelper.detailedMessage(error)), ex);
211: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("couldn't store error {}", ExceptionsHelper.detailedMessage(error)), e);
224: Igor Motov, warn, IfStmt, logger.warn("couldn't store response {}, the node didn't join the cluster yet", response);
232: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("couldn't store response {}", response), ex);
245: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("couldn't store response {}", response), e);
313: Igor Motov, trace, MethodDeclaration, logger.trace("setting ban for the parent task {} {}", parentTaskId, reason);
338: Igor Motov, trace, MethodDeclaration, logger.trace("removing ban for the parent task {}", parentTaskId);
353: Igor Motov, debug, IfStmt, logger.debug("Removing ban for the parent [{}] on the node [{}], reason: the parent node is gone", taskId, event.state().getNodes().getLocalNode());
186: Nhat Nguyen, error, CatchClause, logger.error(() -> new ParameterizedMessage("failed to create tasks results index template [{}]", TASK_RESULT_INDEX_MAPPING_FILE), e);
206: Yannick Welsch, debug, ForeachStmt, logger.debug("created thread pool: {}", entry.getValue().formatInfo(executorHolder.info));
353: Nhat Nguyen, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("scheduled task [{}] was rejected on thread pool [{}]", command, executor), e);
357: Nhat Nguyen, warn, ObjectCreationExpr, logger.warn(() -> new ParameterizedMessage("failed to run scheduled task [{}] on thread pool [{}]", command, executor), e);
445: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to run {}", runnable.toString()), e);
479: Nhat Nguyen, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("fetching nodes from external cluster {} failed", clusterAlias), ex);
437: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("seed node {} cluster name mismatch expected " + "cluster name {}", connection.getNode(), remoteClusterName.get()), ex);
564: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("fetching nodes from external cluster {} failed", clusterAlias), ex);
572: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("fetching nodes from external cluster {} failed", clusterAlias), exp);
138: Simon Willnauer, warn, CatchClause, logger.warn("failed to close remote cluster connections for cluster: " + entry.getKey(), e);
163: Simon Willnauer, warn, IfStmt, logger.warn("failed to update seed list for cluster: " + entry.getKey(), exception);
339: Simon Willnauer, warn, CatchClause, logger.warn("failed to connect to remote clusters within {}", timeValue.toString());
359: Nhat Nguyen, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("[{}] failed to send ping transport message (channel closed)", node), e);
356: Nhat Nguyen, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("[{}] failed to send ping transport message", node), e);
383: Simon Willnauer, debug, IfStmt, logger.debug("couldn't schedule new ping execution, executor is shutting down", ex);
395: Jason Tedor, warn, IfStmt, logger.warn("failed to send ping transport message", e);
393: Jason Tedor, trace, IfStmt, logger.trace("failed to send ping transport message", e);
458: Tim Brooks, warn, CatchClause, logger.warn(new ParameterizedMessage("unexpected exception when setting SO_LINGER on channel {}", c), e);
546: Nhat Nguyen, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("failed to connect to [{}], cleaning dangling connections", node));
519: Simon Willnauer, debug, IfStmt, logger.debug("connected to node [{}]", node);
604: Tim Brooks, trace, TryStmt, logger.trace(() -> new ParameterizedMessage("Tcp transport client channel opened: {}", channel));
751: Tim Brooks, debug, IfStmt, logger.debug("binding server bootstrap to: {}", (Object) addresses);
797: Simon Willnauer, debug, IfStmt, logger.debug("Bound profile [{}] to address {{}}", name, NetworkAddress.format(boundSocket.get()));
945: Tim Brooks, warn, MethodCallExpr, logger.warn(() -> new ParameterizedMessage("Error closing serverChannel for profile [{}]", profile), e);
1027: Nhat Nguyen, warn, IfStmt, logger.warn(() -> new ParameterizedMessage("exception caught on transport layer [{}], closing connection", channel), e);
1020: Tim Brooks, debug, MethodDeclaration, logger.debug("failed to send message to httpOnTransport channel", e);
1004: Nhat Nguyen, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("cancelled key exception caught on transport layer [{}], disconnecting from relevant node", channel), e);
1000: Nhat Nguyen, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("bind exception caught on transport layer [{}]", channel), e);
996: Nhat Nguyen, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("connect exception caught on transport layer [{}]", channel), e);
991: Nhat Nguyen, trace, IfStmt, logger.trace(() -> new ParameterizedMessage("close connection exception caught on transport layer [{}], disconnecting from relevant node", channel), e);
1037: Tim Brooks, trace, MethodDeclaration, logger.trace(() -> new ParameterizedMessage("Tcp transport channel accepted: {}", channel));
1530: Nhat Nguyen, error, CatchClause, logger.error(() -> new ParameterizedMessage("failed to handle exception response [{}]", handler), e);
1573: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("Failed to send error message back to client for action [{}]", action), inner);
1619: Nhat Nguyen, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("Failed to send error message back to client for action [{}]", reg.getAction()), inner);
1774: Tim Brooks, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("send message failed [channel: {}]", channel), e);
66: Nhat Nguyen, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("failed to send failure {}", extraInfoOnError == null ? "" : "(" + extraInfoOnError + ")"), e);
216: kimchy, info, IfStmt, logger.info("{}", transport.boundAddress());
218: jaymode, info, ForeachStmt, logger.info("profile [{}]: {}", entry.getKey(), entry.getValue());
251: Jason Tedor, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("failed to notify response handler on rejection, action: {}", holderToNotify.action()), e);
259: Jason Tedor, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("failed to notify response handler on exception, action: {}", holderToNotify.action()), e);
633: Ryan Ernst, debug, IfStmt, logger.debug("Exception while sending request, handler likely already notified due to timeout", e);
613: Jason Tedor, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("failed to notify response handler on rejection, action: {}", holderToNotify.action()), e);
621: Jason Tedor, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("failed to notify response handler on exception, action: {}", holderToNotify.action()), e);
682: Jason Tedor, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to notify channel of error message for action [{}]", action), inner);
670: Yannick Welsch, warn, CatchClause, logger.warn(() -> new ParameterizedMessage("failed to notify channel of error message for action [{}]", action), inner);
815: Nhat Nguyen, trace, MethodDeclaration, tracerLog.trace(() -> new ParameterizedMessage("[{}][{}] sent error response", requestId, action), e);
826: Tim Brooks, trace, CatchClause, logger.trace("interrupted while waiting for incoming requests block to be removed");
870: Tim Brooks, warn, IfStmt, logger.warn("Transport response handler not found of id [{}]", requestId);
864: Tim Brooks, warn, IfStmt, logger.warn("Received response for a request that has timed out, sent [{}ms] ago, timed out [{}ms] ago, " + "action [{}], node [{}], id [{}]", time - timeoutInfoHolder.sentTime(), time - timeoutInfoHolder.timeoutTime(), timeoutInfoHolder.action(), timeoutInfoHolder.node(), requestId);
910: Tim Brooks, debug, CatchClause, logger.debug("Rejected execution on NodeDisconnected", ex);
929: Tim Brooks, debug, CatchClause, logger.debug("Rejected execution on onConnectionClosed", ex);
934: Tim Brooks, trace, MethodDeclaration, tracerLog.trace("[{}][{}] received request", requestId, action);
938: Tim Brooks, trace, MethodDeclaration, tracerLog.trace("[{}][{}] sent response", requestId, action);
942: Tim Brooks, trace, MethodDeclaration, tracerLog.trace("[{}][{}] received response from [{}]", requestId, action, sourceNode);
946: Tim Brooks, trace, MethodDeclaration, tracerLog.trace("[{}] received response but can't resolve it to a request", requestId);
950: Tim Brooks, trace, MethodDeclaration, tracerLog.trace("[{}][{}] sent to [{}] (timeout: [{}])", requestId, action, node, options.timeout());
1190: Jason Tedor, error, CatchClause, logger.error(() -> new ParameterizedMessage("failed to handle exception for action [{}], handler [{}]", action, handler), e);
261: Jason Tedor, warn, CatchClause, logger.warn("cannot notify file changes listener", e);
271: Jason Tedor, warn, CatchClause, logger.warn("cannot notify file changes listener", e);
281: Jason Tedor, warn, CatchClause, logger.warn("cannot notify file changes listener", e);
296: Jason Tedor, warn, CatchClause, logger.warn("cannot notify file changes listener", e);
311: Jason Tedor, warn, CatchClause, logger.warn("cannot notify file changes listener", e);
199: Simon Willnauer, trace, CatchClause, logger.trace("failed to check resource watcher", e);
274: Simon Willnauer, debug, IfStmt, logger.debug("Checking {}", v);
104: Simon Willnauer, error, MethodDeclaration, logger.error("FAILED", e);
70: Ali Beyad, info, MethodDeclaration, logger.info("--> starting 2 nodes");
73: Ali Beyad, info, MethodDeclaration, logger.info("--> creating an index with 1 primary, 0 replicas");
76: Ali Beyad, info, MethodDeclaration, logger.info("--> stopping the node with the primary");
149: Lee Hinman, info, MethodDeclaration, logger.info("--> starting 3 nodes");
152: Ali Beyad, info, MethodDeclaration, logger.info("--> creating an index with 1 primary, 1 replica");
154: Ali Beyad, info, MethodDeclaration, logger.info("--> stopping the node with the replica");
164: Ali Beyad, info, MethodDeclaration, logger.info("--> observing delayed allocation...");
268: Ali Beyad, info, MethodDeclaration, logger.info("--> starting 3 nodes");
271: Ali Beyad, info, MethodDeclaration, logger.info("--> creating an index with 1 primary and 1 replica");
276: Ali Beyad, info, MethodDeclaration, logger.info("--> shutting down all nodes except the one that holds the primary");
281: Ali Beyad, info, MethodDeclaration, logger.info("--> setting allocation filtering to only allow allocation on the currently running node");
285: Ali Beyad, info, MethodDeclaration, logger.info("--> restarting the stopped nodes");
389: Ali Beyad, info, MethodDeclaration, logger.info("--> starting 2 nodes");
392: Ali Beyad, info, MethodDeclaration, logger.info("--> creating an index with 1 primary, 0 replicas, with allocation filtering so the primary can't be assigned");
481: Ali Beyad, info, MethodDeclaration, logger.info("--> starting 2 nodes");
484: Ali Beyad, info, MethodDeclaration, logger.info("--> creating an index with 1 primary and 0 replicas");
487: Ali Beyad, info, MethodDeclaration, logger.info("--> setting up allocation filtering to prevent allocation to both nodes");
590: Ali Beyad, info, MethodDeclaration, logger.info("--> starting a single node");
594: Ali Beyad, info, MethodDeclaration, logger.info("--> creating an index with 5 shards, all allocated to the single node");
597: Ali Beyad, info, MethodDeclaration, logger.info("--> disabling rebalancing on the index");
601: Ali Beyad, info, MethodDeclaration, logger.info("--> starting another node, with rebalancing disabled, it should get no shards");
703: Ali Beyad, info, MethodDeclaration, logger.info("--> starting a single node");
707: Ali Beyad, info, MethodDeclaration, logger.info("--> creating an index with 5 shards, all allocated to the single node");
710: Ali Beyad, info, MethodDeclaration, logger.info("--> setting balancing threshold really high, so it won't be met");
714: Ali Beyad, info, MethodDeclaration, logger.info("--> starting another node, with the rebalance threshold so high, it should not get any shards");
807: Ali Beyad, info, MethodDeclaration, logger.info("--> starting a single node");
811: Ali Beyad, info, MethodDeclaration, logger.info("--> creating an index with 5 shards, all allocated to the single node");
814: Ali Beyad, info, MethodDeclaration, logger.info("--> setting up allocation filtering to only allow allocation to the current node");
818: Ali Beyad, info, MethodDeclaration, logger.info("--> starting another node, with filtering not allowing allocation to the new node, it should not get any shards");
918: Lee Hinman, info, MethodDeclaration, logger.info("--> starting 3 nodes");
921: Ali Beyad, info, MethodDeclaration, logger.info("--> creating an index with 1 primary and 2 replicas");
1015: Ali Beyad, info, MethodDeclaration, logger.info("--> starting 3 nodes");
1022: Ali Beyad, info, MethodDeclaration, logger.info("--> creating an index with 1 primary and 1 replica");
1037: Ali Beyad, info, MethodDeclaration, logger.info("--> stop node with the replica shard");
1040: Ali Beyad, info, MethodDeclaration, logger.info("--> index more data, now the replica is stale");
1043: Ali Beyad, info, MethodDeclaration, logger.info("--> stop the node with the primary");
1046: Ali Beyad, info, MethodDeclaration, logger.info("--> restart the node with the stale replica");
1145: Lee Hinman, debug, IfStmt, logger.debug("--> explain json output: \n{}", Strings.toString(explanation.toXContent(builder, ToXContent.EMPTY_PARAMS)));
216: Boaz Leskes, info, ForStmt, logger.info("The action in the node [{}] should block: [{}]", testNodes[i].getNodeId(), shouldBlock);
222: Igor Motov, info, IfStmt, logger.info("Awaiting for all actions to start");
224: Igor Motov, info, IfStmt, logger.info("Done waiting for all actions to start");
234: Igor Motov, info, MethodDeclaration, logger.info("waitForActionToStart is set to {}", waitForActionToStart);
397: Igor Motov, info, IfStmt, logger.info("--> Simulate issuing cancel request on the node that is about to leave the cluster");
404: Igor Motov, info, IfStmt, logger.info("--> Done simulating issuing cancel request on the node that is about to leave the cluster");
407: Igor Motov, error, IfStmt, logger.error("!!!!");
232: Igor Motov, debug, MethodDeclaration, logger.debug("number of shards, total: [{}], primaries: [{}] ", numberOfShards.totalNumShards, numberOfShards.numPrimaries);
233: Igor Motov, debug, MethodDeclaration, logger.debug("main events {}", numberOfEvents(RefreshAction.NAME, Tuple::v1));
234: Nik Everett, debug, MethodDeclaration, logger.debug("main event node {}", findEvents(RefreshAction.NAME, Tuple::v1).get(0).getTaskId().getNodeId());
235: Igor Motov, debug, MethodDeclaration, logger.debug("[s] events {}", numberOfEvents(RefreshAction.NAME + "[s]", Tuple::v1));
236: Igor Motov, debug, MethodDeclaration, logger.debug("[s][*] events {}", numberOfEvents(RefreshAction.NAME + "[s][*]", Tuple::v1));
237: Igor Motov, debug, MethodDeclaration, logger.debug("nodes with the index {}", internalCluster().nodesInclude("test"));
440: Nik Everett, debug, IfStmt, logger.debug("Blocking [{}] starting", task);
500: Igor Motov, info, MethodDeclaration, logger.info("--> started test tasks");
506: Igor Motov, info, MethodDeclaration, logger.info("--> cancelling the main test task");
513: Igor Motov, info, MethodDeclaration, logger.info("--> checking that test tasks are not running");
727: Igor Motov, info, IfStmt, logger.info("creating an empty results index with custom settings");
302: Igor Motov, info, MethodDeclaration, logger.info("Test task started on the node {}", clusterService.localNode());
315: Igor Motov, info, MethodDeclaration, logger.info("Test task finished on the node {}", clusterService.localNode());
303: Yannick Welsch, info, MethodDeclaration, logger.info("Action on node {}", node);
310: Yannick Welsch, info, MethodDeclaration, logger.info("Action on node {} finished", node);
320: Igor Motov, info, MethodDeclaration, logger.info("Awaiting for all actions to start");
322: Igor Motov, info, MethodDeclaration, logger.info("Done waiting for all actions to start");
341: Igor Motov, warn, MethodDeclaration, logger.warn("Couldn't get list of tasks", e);
365: Igor Motov, info, MethodDeclaration, logger.info("Listing currently running tasks using node [{}]", testNodeNum);
367: Igor Motov, info, MethodDeclaration, logger.info("Checking currently running tasks");
588: Yannick Welsch, info, MethodDeclaration, logger.info("Action on node {}", node);
628: Yannick Welsch, info, MethodDeclaration, logger.info("Task action on node {}", node);
630: Yannick Welsch, info, IfStmt, logger.info("Failing on node {}", node);
634: Nik Everett, info, LambdaExpr, logger.info("Throwing exception from taskOperation");
638: Nik Everett, info, LambdaExpr, logger.info("Calling listener synchronously with exception from taskOperation");
642: Nik Everett, info, LambdaExpr, logger.info("Calling listener asynchronously with exception from taskOperation");
696: Igor Motov, info, MethodDeclaration, logger.info("Filtering out nodes {} size: {}", filterNodes, filterNodesSize);
801: Lee Hinman, info, MethodDeclaration, logger.info(Strings.toString(builder));
42: tlrx, info, MethodDeclaration, logger.info("-->  registering a repository is blocked when the cluster is read only");
53: tlrx, info, MethodDeclaration, logger.info("-->  registering a repository is allowed when the cluster is not read only");
82: tlrx, info, MethodDeclaration, logger.info("-->  deleting a repository is blocked when the cluster is read only");
90: tlrx, info, MethodDeclaration, logger.info("-->  deleting a repository is allowed when the cluster is not read only");
108: Simon Willnauer, info, CatchClause, logger.info("", ex);
69: tlrx, info, MethodDeclaration, logger.info("--> register a repository");
74: tlrx, info, MethodDeclaration, logger.info("--> verify the repository");
78: tlrx, info, MethodDeclaration, logger.info("--> create a snapshot");
88: Igor Motov, info, MethodDeclaration, logger.info("-->  creating a snapshot is allowed when the cluster is read only");
96: tlrx, info, MethodDeclaration, logger.info("-->  creating a snapshot is allowed when the cluster is not read only");
104: Igor Motov, info, MethodDeclaration, logger.info("-->  creating a snapshot is not blocked when an index is read only");
112: Igor Motov, info, MethodDeclaration, logger.info("-->  creating a snapshot is blocked when an index is blocked for reads");
116: Igor Motov, info, TryStmt, logger.info("-->  creating a snapshot is not blocked when an read-blocked index is not part of the snapshot");
124: Igor Motov, info, MethodDeclaration, logger.info("-->  deleting a snapshot is allowed when the cluster is read only");
137: tlrx, info, MethodDeclaration, logger.info("-->  restoring a snapshot is blocked when the cluster is read only");
145: tlrx, info, MethodDeclaration, logger.info("-->  creating a snapshot is allowed when the cluster is not read only");
264: Simon Willnauer, info, MethodDeclaration, logger.info("total: {}", expected.getHits().getTotalHits());
280: Boaz Leskes, info, MethodDeclaration, logger.info("merge node {}", mergeNode);
134: Simon Willnauer, info, MethodDeclaration, logger.info("use routing {} use mixed routing {} use nested {}", useRouting, useMixedRouting, useNested);
405: Simon Willnauer, info, TryStmt, logger.info("split node {}", mergeNode);
107: Areek Zillur, info, MethodDeclaration, logger.info("--> disable allocation");
109: Areek Zillur, info, MethodDeclaration, logger.info("--> stop random node");
123: Areek Zillur, info, MethodDeclaration, logger.info("--> enable allocation");
166: Areek Zillur, info, MethodDeclaration, logger.info("--> disable allocation");
169: Areek Zillur, info, MethodDeclaration, logger.info("--> corrupt random shard copies");
178: David Turner, debug, IfStmt, logger.debug("--> failing shard [{}] on node [{}]", shardId, node);
180: David Turner, debug, IfStmt, logger.debug("--> failed shard [{}] on node [{}]", shardId, node);
209: Areek Zillur, info, MethodDeclaration, logger.info("--> enable allocation");
129: Nik Everett, info, MethodDeclaration, logger.info("starting to wait");
140: Nik Everett, info, IfStmt, logger.info("timed out");
126: Daniel Mitterdorfer, debug, IfStmt, logger.debug("We maxed out the number of bulk retries and got rejected (this is ok).");
440: Boaz Leskes, info, ForStmt, logger.info("bulk indexing {}-{}", i - bulk, i - 1);
609: Lee Hinman, info, MethodDeclaration, logger.info("--> metadata.getIndex(): {}", metaData.getIndex());
629: Lee Hinman, info, MethodDeclaration, logger.info("--> verifying mappings noop");
642: Lee Hinman, info, MethodDeclaration, logger.info("--> mapperService.index(): {}", mapperService.index());
847: Lee Hinman, info, MethodDeclaration, logger.info("--> preparing update for {} - {}", s, u);
865: Lee Hinman, info, MethodDeclaration, logger.info("--> preparing failing update for {} - {}", s, u);
83: jaymode, error, MethodDeclaration, logger.error("unexpected error", e);
73: Simon Willnauer, warn, MethodDeclaration, logger.warn("test failed", e);
172: Simon Willnauer, warn, MethodDeclaration, logger.warn("test failed", e);
272: Simon Willnauer, warn, MethodDeclaration, logger.warn("test failed", e);
232: Simon Willnauer, warn, CatchClause, logger.warn(e);
142: Ali Beyad, info, MethodDeclaration, logger.info("--> start the index creation process");
149: Ali Beyad, info, MethodDeclaration, logger.info("--> wait until the cluster state contains the new index");
152: Ali Beyad, info, MethodDeclaration, logger.info("--> delete the index");
155: Ali Beyad, info, MethodDeclaration, logger.info("--> ensure the create index request completes");
70: Yannick Welsch, info, MethodDeclaration, logger.info("Done Cluster Health, status {}", clusterHealth.getStatus());
92: Yannick Welsch, info, MethodDeclaration, logger.info("Done Cluster Health, status {}", clusterHealth.getStatus());
70: Yannick Welsch, info, MethodDeclaration, logger.info("--> start 4 nodes, 3 master, 1 data");
84: Yannick Welsch, info, MethodDeclaration, logger.info("--> wait for all nodes to join the cluster");
101: Yannick Welsch, warn, CatchClause, logger.warn("Barrier interrupted", e);
104: Yannick Welsch, warn, CatchClause, logger.warn("Broken barrier", e);
129: Yannick Welsch, info, MethodDeclaration, logger.info("--> disrupting network");
132: Yannick Welsch, info, MethodDeclaration, logger.info("--> waiting for new master to be elected");
136: Yannick Welsch, info, MethodDeclaration, logger.info("--> waiting to heal");
122: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> using initial state:\n{}", clusterService.state());
132: Britta Weber, info, MethodDeclaration, logger.info("total shards: {}, ", response.get().getTotalShards());
141: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> using initial state:\n{}", clusterService.state());
148: Britta Weber, info, MethodDeclaration, logger.info("total shards: {}, ", response.get().getTotalShards());
156: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> using initial state:\n{}", clusterService.state());
186: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> using initial state:\n{}", clusterService.state());
196: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> using initial state:\n{}", clusterService.state());
108: Boaz Leskes, debug, IfStmt, logger.debug("--> simulating failure on {} with [{}]", replica, t.getClass().getSimpleName());
267: Yannick Welsch, debug, MethodDeclaration, logger.debug("--> using initial replicationGroup:\n{}", replicationGroup.get());
275: Yannick Welsch, debug, MethodDeclaration, logger.debug("--> state after primary operation:\n{}", replicationGroup.get());
311: Ali Beyad, debug, MethodDeclaration, logger.debug("using active shard count of [{}], assigned shards [{}], total shards [{}]." + " expecting op to [{}]. using state: \n{}", request.waitForActiveShards(), 1 + assignedReplicas, 1 + assignedReplicas + unassignedReplicas, passesActiveShardCheck ? "succeed" : "retry", state);
264: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> using initial state:\n{}", clusterService.state());
283: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> primary assigned state:\n{}", clusterService.state());
312: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> relocation ongoing state:\n{}", clusterService.state());
335: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> relocation complete state:\n{}", clusterService.state());
352: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> using initial state:\n{}", clusterService.state());
376: Yannick Welsch, debug, MethodDeclaration, logger.debug("--> using initial state:\n{}", clusterService.state());
405: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> using initial state:\n{}", clusterService.state());
462: Boaz Leskes, debug, MethodDeclaration, logger.debug("using state: \n{}", clusterService.state());
472: Areek Zillur, info, MethodDeclaration, logger.info("--> primary is assigned to [{}], checking request forwarded", primaryNodeId);
617: Boaz Leskes, info, MethodDeclaration, logger.info("using state: {}", state);
676: Jason Tedor, debug, MethodDeclaration, logger.debug("--> using initial state:\n{}", clusterService.state());
731: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> using initial state:\n{}", clusterService.state());
873: Boaz Leskes, debug, CatchClause, logger.debug("got exception:", throwable);
268: Lee Hinman, info, MethodDeclaration, logger.info("using state: {}", state);
189: Jason Tedor, info, IfStmt, logger.info("expected ClusterBlockException  but got ", e);
226: Britta Weber, info, IfStmt, logger.info("expected TransportException  but got ", t);
292: Britta Weber, info, IfStmt, logger.info("expected ConnectTransportException  but got ", t);
322: Jason Tedor, info, IfStmt, logger.info("expected IllegalStateException  but got ", e);
780: Alex Ksikes, info, MethodDeclaration, logger.info("--> index doc 1");
826: Alex Ksikes, info, MethodDeclaration, logger.info("--> index doc 1 again, so increasing the version");
876: Alex Ksikes, info, MethodDeclaration, logger.info("Setting up the index ...");
885: Alex Ksikes, info, MethodDeclaration, logger.info("Indexing one document with tags of increasing length ...");
896: Alex Ksikes, info, MethodDeclaration, logger.info("Checking best tags by longest to shortest size ...");
913: Alex Ksikes, info, MethodDeclaration, logger.info("Setting up the index ...");
921: Alex Ksikes, info, MethodDeclaration, logger.info("Indexing one document with tags of increasing frequencies ...");
936: Alex Ksikes, info, MethodDeclaration, logger.info("Checking best tags by highest to lowest term freq ...");
952: Alex Ksikes, info, MethodDeclaration, logger.info("Setting up the index ...");
962: Alex Ksikes, info, MethodDeclaration, logger.info("Indexing {} documents with tags of increasing dfs ...", numDocs);
971: Alex Ksikes, info, MethodDeclaration, logger.info("Checking best terms by highest to lowest idf ...");
83: kimchy, info, MethodDeclaration, logger.info("--> creating index [test]");
88: kimchy, info, MethodDeclaration, logger.info("--> aliasing index [test] with [alias1]");
91: kimchy, info, MethodDeclaration, logger.info("--> indexing against [alias1], should work now");
96: Luca Cavanna, info, MethodDeclaration, logger.info("--> creating index [test_x]");
101: kimchy, info, MethodDeclaration, logger.info("--> remove [alias1], Aliasing index [test_x] with [alias1]");
104: kimchy, info, MethodDeclaration, logger.info("--> indexing against [alias1], should work against [test_x]");
111: kimchy, info, MethodDeclaration, logger.info("--> creating index [test]");
126: Igor Motov, info, MethodDeclaration, logger.info("--> creating index [test]");
131: Igor Motov, info, MethodDeclaration, logger.info("--> aliasing index [test] with [alias1] and filter [user:kimchy]");
136: Igor Motov, info, MethodDeclaration, logger.info("--> making sure that filter was stored with alias [alias1] and filter [user:kimchy]");
144: Luca Cavanna, info, MethodDeclaration, logger.info("--> creating index [test]");
148: Luca Cavanna, info, MethodDeclaration, logger.info("--> aliasing index [test] with [alias1] and empty filter");
155: Igor Motov, info, MethodDeclaration, logger.info("--> creating index [test]");
160: Igor Motov, info, MethodDeclaration, logger.info("--> adding filtering aliases to index [test]");
167: Igor Motov, info, MethodDeclaration, logger.info("--> indexing against [test]");
177: Igor Motov, info, MethodDeclaration, logger.info("--> checking single filtering alias search");
181: Shay Banon, info, MethodDeclaration, logger.info("--> checking single filtering alias wildcard search");
188: Igor Motov, info, MethodDeclaration, logger.info("--> checking single filtering alias search with sort");
192: Igor Motov, info, MethodDeclaration, logger.info("--> checking single filtering alias search with global facets");
201: Igor Motov, info, MethodDeclaration, logger.info("--> checking single filtering alias search with global facets and sort");
210: Igor Motov, info, MethodDeclaration, logger.info("--> checking single filtering alias search with non-global facets");
221: Igor Motov, info, MethodDeclaration, logger.info("--> checking single non-filtering alias search");
225: Igor Motov, info, MethodDeclaration, logger.info("--> checking non-filtering alias and filtering alias search");
229: Igor Motov, info, MethodDeclaration, logger.info("--> checking index and filtering alias search");
233: Shay Banon, info, MethodDeclaration, logger.info("--> checking index and alias wildcard search");
239: Igor Motov, info, MethodDeclaration, logger.info("--> creating index [test1]");
241: Igor Motov, info, MethodDeclaration, logger.info("--> creating index [test2]");
245: Igor Motov, info, MethodDeclaration, logger.info("--> adding filtering aliases to index [test1]");
251: Igor Motov, info, MethodDeclaration, logger.info("--> adding filtering aliases to index [test2]");
256: Igor Motov, info, MethodDeclaration, logger.info("--> indexing against [test1]");
262: Igor Motov, info, MethodDeclaration, logger.info("--> indexing against [test2]");
270: Igor Motov, info, MethodDeclaration, logger.info("--> checking filtering alias for two indices");
275: Igor Motov, info, MethodDeclaration, logger.info("--> checking filtering alias for one index");
280: Igor Motov, info, MethodDeclaration, logger.info("--> checking filtering alias for two indices and one complete index");
285: Igor Motov, info, MethodDeclaration, logger.info("--> checking filtering alias for two indices and non-filtering alias for one index");
290: Igor Motov, info, MethodDeclaration, logger.info("--> checking filtering alias for two indices and non-filtering alias for both indices");
295: Igor Motov, info, MethodDeclaration, logger.info("--> checking filtering alias for two indices and non-filtering alias for both indices");
302: Igor Motov, info, MethodDeclaration, logger.info("--> creating indices");
311: Igor Motov, info, MethodDeclaration, logger.info("--> adding aliases to indices");
315: Igor Motov, info, MethodDeclaration, logger.info("--> adding filtering aliases to indices");
324: Igor Motov, info, MethodDeclaration, logger.info("--> indexing against [test1]");
339: Igor Motov, info, MethodDeclaration, logger.info("--> checking filtering alias for multiple indices");
366: Luca Cavanna, info, MethodDeclaration, logger.info("--> creating index [test1] and [test2");
371: Igor Motov, info, MethodDeclaration, logger.info("--> adding filtering aliases to index [test1]");
378: Igor Motov, info, MethodDeclaration, logger.info("--> adding filtering aliases to index [test2]");
384: Igor Motov, info, MethodDeclaration, logger.info("--> indexing against [test1]");
390: Igor Motov, info, MethodDeclaration, logger.info("--> indexing against [test2]");
398: Igor Motov, info, MethodDeclaration, logger.info("--> checking counts before delete");
403: Luca Cavanna, info, MethodDeclaration, logger.info("--> creating index [test1] and [test2]");
408: Britta Weber, info, MethodDeclaration, logger.info("--> adding filtering aliases to index [test1]");
415: Britta Weber, info, MethodDeclaration, logger.info("--> adding filtering aliases to index [test2]");
429: olcbean, info, MethodDeclaration, logger.info("--> creating index [foo_foo] and [bar_bar]");
434: olcbean, info, MethodDeclaration, logger.info("--> adding [foo] alias to [foo_foo] and [bar_bar]");
450: Igor Motov, info, MethodDeclaration, logger.info("--> creating index [test]");
462: Igor Motov, info, MethodDeclaration, logger.info("--> creating index [test]");
476: Igor Motov, info, MethodDeclaration, logger.info("--> creating index [test]");
502: Igor Motov, info, MethodDeclaration, logger.info("--> creating index [test]");
506: Igor Motov, info, MethodDeclaration, logger.info("--> creating alias1 ");
509: Igor Motov, info, MethodDeclaration, logger.info("--> recreating alias1 ");
515: Igor Motov, info, MethodDeclaration, logger.info("--> modifying alias1 to have a filter");
520: Igor Motov, info, MethodDeclaration, logger.info("--> recreating alias1 with the same filter");
525: Igor Motov, info, MethodDeclaration, logger.info("--> recreating alias1 with a different filter");
530: Igor Motov, info, MethodDeclaration, logger.info("--> verify that filter was updated");
534: Igor Motov, info, MethodDeclaration, logger.info("--> deleting alias1");
543: Britta Weber, info, MethodDeclaration, logger.info("--> creating index [test]");
546: Britta Weber, info, MethodDeclaration, logger.info("--> deleting alias1 which does not exist");
556: Martijn van Groningen, info, MethodDeclaration, logger.info("--> creating indices [foobar, test, test123, foobarbaz, bazbar]");
567: Martijn van Groningen, info, MethodDeclaration, logger.info("--> creating aliases [alias1, alias2]");
570: Martijn van Groningen, info, MethodDeclaration, logger.info("--> getting alias1");
587: Martijn van Groningen, info, MethodDeclaration, logger.info("--> getting all aliases that start with alias*");
610: Martijn van Groningen, info, MethodDeclaration, logger.info("--> creating aliases [bar, baz, foo]");
619: Martijn van Groningen, info, MethodDeclaration, logger.info("--> getting bar and baz for index bazbar");
640: Martijn van Groningen, info, MethodDeclaration, logger.info("--> getting *b* for index baz*");
661: Martijn van Groningen, info, MethodDeclaration, logger.info("--> getting *b* for index *bar");
687: Martijn van Groningen, info, MethodDeclaration, logger.info("--> getting f* for index *bar");
702: Martijn van Groningen, info, MethodDeclaration, logger.info("--> getting f* for index *bac");
717: Martijn van Groningen, info, MethodDeclaration, logger.info("--> getting foo for index foobar");
731: Martijn van Groningen, info, MethodDeclaration, logger.info("--> getting * for index *bac");
820: olcbean, info, MethodDeclaration, logger.info("--> creating index [2017-05-20]");
824: olcbean, info, MethodDeclaration, logger.info("--> adding [week_20] alias to [2017-05-20]");
81: Jason Tedor, info, MethodDeclaration, verify(logger).info("bound or publishing to a non-loopback address, enforcing bootstrap checks");
46: kimchy, info, MethodDeclaration, logger.info("Running Cluster Health");
52: kimchy, info, MethodDeclaration, logger.info("Count");
87: Yannick Welsch, info, MethodDeclaration, logger.info("Checking static index {}", indexName);
98: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository [{}] for version [{}]", repo, version);
105: Igor Motov, info, MethodDeclaration, logger.info("--> restoring unsupported snapshot");
46: kimchy, info, MethodDeclaration, logger.info("--> running cluster health on an index that does not exists");
52: Martijn van Groningen, info, MethodDeclaration, logger.info("--> running cluster wide health");
58: Martijn van Groningen, info, MethodDeclaration, logger.info("--> Creating index test1 with zero replicas");
61: Martijn van Groningen, info, MethodDeclaration, logger.info("--> running cluster health on an index that does exists");
67: Martijn van Groningen, info, MethodDeclaration, logger.info("--> running cluster health on an index that does exists and an index that doesn't exists");
152: Nik Everett, info, ForeachStmt, logger.info("--> usage: {}", usage.value);
156: Nik Everett, info, ForeachStmt, logger.info("--> usage: {}", usage.value);
160: Nik Everett, info, ForeachStmt, logger.info("--> shard size: {}", size.value);
205: Boaz Leskes, info, IfStmt, logger.info("dropping [{}] to [{}]", action, node);
184: Igor Motov, error, CatchClause, logger.error("Cluster state:\n{}\nCluster state from diffs:\n{}", clusterState.toString(), clusterStateFromDiffs.toString());
189: Igor Motov, info, MethodDeclaration, logger.info("Final cluster state:[{}]", clusterState.toString());
88: kimchy, info, MethodDeclaration, logger.info("--> start first node");
91: kimchy, info, MethodDeclaration, logger.info("--> should be blocked, no master...");
96: kimchy, info, MethodDeclaration, logger.info("--> start second node, cluster should be formed");
113: kimchy, info, MethodDeclaration, logger.info("--> indexing some data");
122: kimchy, info, MethodDeclaration, logger.info("--> verify we the data back");
138: kimchy, info, MethodDeclaration, logger.info("--> starting the previous master node again...");
155: Shay Banon, info, MethodDeclaration, logger.info("--> verify we the data back after cluster reform");
166: kimchy, info, MethodDeclaration, logger.info("--> starting the previous master node again...");
182: kimchy, info, MethodDeclaration, logger.info("Running Cluster Health");
185: kimchy, info, MethodDeclaration, logger.info("--> verify we the data back");
198: kimchy, info, MethodDeclaration, logger.info("--> start first 2 nodes");
210: kimchy, info, MethodDeclaration, logger.info("--> start two more nodes");
222: kimchy, info, MethodDeclaration, logger.info("--> indexing some data");
233: kimchy, info, MethodDeclaration, logger.info("--> verify we the data back");
241: kimchy, info, MethodDeclaration, logger.info("--> verify that there is no master anymore on remaining nodes");
245: Simon Willnauer, info, MethodDeclaration, logger.info("--> start back the 2 nodes ");
256: kimchy, info, MethodDeclaration, logger.info("--> verify we the data back");
272: Yannick Welsch, info, MethodDeclaration, logger.info("--> start two nodes and wait for them to form a cluster");
276: Boaz Leskes, info, MethodDeclaration, logger.info("--> setting minimum master node to 2");
285: Boaz Leskes, info, MethodDeclaration, logger.info("--> stopping a node");
287: Boaz Leskes, info, MethodDeclaration, logger.info("--> verifying min master node has effect");
290: Boaz Leskes, info, MethodDeclaration, logger.info("--> bringing another node up");
306: Jason Tedor, debug, IfStmt, logger.debug("Checking for NO_MASTER_BLOCK on client: {} NO_MASTER_BLOCK: [{}]", client, clientHasNoMasterBlock);
329: Boaz Leskes, info, MethodDeclaration, logger.info("--> starting [{}] nodes. min_master_nodes set to [{}]", nodeCount, initialMinMasterNodes);
332: Boaz Leskes, info, MethodDeclaration, logger.info("--> waiting for nodes to join");
337: Simon Willnauer, info, MethodDeclaration, logger.info("--> updating [{}] to [{}]", ElectMasterService.DISCOVERY_ZEN_MINIMUM_MASTER_NODES_SETTING.getKey(), updateCount);
341: Boaz Leskes, info, MethodDeclaration, logger.info("--> verifying no node left and master is up");
345: Simon Willnauer, info, MethodDeclaration, logger.info("--> trying to updating [{}] to [{}]", ElectMasterService.DISCOVERY_ZEN_MINIMUM_MASTER_NODES_SETTING.getKey(), updateCount);
353: Boaz Leskes, info, MethodDeclaration, logger.info("--> verifying no node left and master is up");
376: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> submitting for cluster state to be rejected");
386: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> starting the disruption, preventing cluster state publishing");
401: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> waiting for cluster state to be processed/rejected");
409: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> waiting for cluster to heal");
189: Boaz Leskes, info, MethodDeclaration, logger.info("Cluster state:\n{}", clusterState.getState());
207: Shay Banon, info, MethodDeclaration, logger.info("number of fields [{}], estimated bytes [{}]", numberOfFields, estimatedBytesSize);
54: kimchy, info, MethodDeclaration, logger.info("--> start data node / non master node");
63: kimchy, info, MethodDeclaration, logger.info("--> start master node");
68: kimchy, info, MethodDeclaration, logger.info("--> stop master node");
78: kimchy, info, MethodDeclaration, logger.info("--> start master node");
85: kimchy, info, MethodDeclaration, logger.info("--> start data node / non master node");
93: kimchy, info, MethodDeclaration, logger.info("--> start master node (1)");
98: kimchy, info, MethodDeclaration, logger.info("--> start master node (2)");
104: kimchy, info, MethodDeclaration, logger.info("--> closing master node (1)");
111: Shay Banon, info, MethodDeclaration, logger.info("--> start master node / non data");
114: Shay Banon, info, MethodDeclaration, logger.info("--> start data node / non master node");
57: Igor Motov, Error, CatchClause, logger.info("Error message: [{}]", ex.getMessage());
209: Luca Cavanna, info, MethodDeclaration, logger.info("==> going to move shard [{}] from [{}] to [{}]", shardToBeMoved, fromNodeId, toNodeId);
59: Shay Banon, info, MethodDeclaration, logger.info("--> starting 2 nodes on the same rack");
72: Shay Banon, info, MethodDeclaration, logger.info("--> starting 1 node on a different rack");
78: Jason Tedor, info, LambdaExpr, logger.info("--> waiting for no relocation");
84: Jason Tedor, info, LambdaExpr, logger.info("--> checking current state");
109: Shay Banon, info, MethodDeclaration, logger.info("--> starting 4 nodes on different zones");
121: Tanguy Leroux, info, MethodDeclaration, logger.info("--> waiting for nodes to form a cluster");
129: Tanguy Leroux, info, MethodDeclaration, logger.info("--> waiting for shards to be allocated");
155: Simon Willnauer, info, MethodDeclaration, logger.info("--> starting 2 nodes on zones 'a' & 'b'");
179: Simon Willnauer, info, MethodDeclaration, logger.info("--> starting another node in zone 'b'");
99: Shay Banon, info, MethodDeclaration, logger.info("--> create an index with 1 shard, 1 replica, nothing should allocate");
107: Shay Banon, info, MethodDeclaration, logger.info("--> explicitly allocate shard 1, *under dry_run*");
116: Shay Banon, info, MethodDeclaration, logger.info("--> get the state, verify nothing changed because of the dry run");
120: Shay Banon, info, MethodDeclaration, logger.info("--> explicitly allocate shard 1, actually allocating, no dry run");
131: Shay Banon, info, MethodDeclaration, logger.info("--> get the state, verify shard 1 primary allocated");
136: Shay Banon, info, MethodDeclaration, logger.info("--> move shard 1 primary from node1 to node2");
149: Shay Banon, info, MethodDeclaration, logger.info("--> get the state, verify shard 1 primary moved from node1 to node2");
175: Lee Hinman, info, MethodDeclaration, logger.info("--> starting 4 nodes");
185: Lee Hinman, info, MethodDeclaration, logger.info("--> create indices");
196: Lee Hinman, info, MethodDeclaration, logger.info("--> stopping node1");
204: Shay Banon, info, MethodDeclaration, logger.info("--> starting 2 nodes");
211: Shay Banon, info, MethodDeclaration, logger.info("--> create an index with 1 shard, 1 replica, nothing should allocate");
219: Shay Banon, info, MethodDeclaration, logger.info("--> explicitly allocate shard 1, actually allocating, no dry run");
230: Shay Banon, info, MethodDeclaration, logger.info("--> get the state, verify shard 1 primary allocated");
238: Shay Banon, info, MethodDeclaration, logger.info("--> closing all nodes");
243: Simon Willnauer, info, MethodDeclaration, logger.info("--> deleting the shard data [{}] ", Arrays.toString(shardLocation));
247: Igor Motov, info, MethodDeclaration, logger.info("--> starting nodes back, will not allocate the shard since it has no data, but the index will be there");
254: Shay Banon, info, MethodDeclaration, logger.info("--> explicitly allocate primary");
262: Shay Banon, info, MethodDeclaration, logger.info("--> get the state, verify shard 1 primary allocated");
274: Lee Hinman, info, MethodDeclaration, logger.info("--> starting a node");
281: Lee Hinman, info, MethodDeclaration, logger.info("--> create an index with 1 shard");
288: Lee Hinman, info, MethodDeclaration, logger.info("--> disable allocation");
294: Lee Hinman, info, MethodDeclaration, logger.info("--> starting a second node");
300: Lee Hinman, info, MethodDeclaration, logger.info("--> try to move the shard from node1 to node2");
394: tlrx, info, MethodDeclaration, logger.info("--> create an index with 1 shard and 0 replicas");
398: tlrx, info, MethodDeclaration, logger.info("--> check that the index has 1 shard");
403: tlrx, info, MethodDeclaration, logger.info("--> check that the shard is allocated");
407: tlrx, info, MethodDeclaration, logger.info("--> retrieve the node where the shard is allocated");
52: Shay Banon, info, MethodDeclaration, logger.info("--> starting 2 nodes");
58: Shay Banon, info, MethodDeclaration, logger.info("--> creating an index with no replicas");
63: Shay Banon, info, MethodDeclaration, logger.info("--> index some data");
70: Shay Banon, info, MethodDeclaration, logger.info("--> decommission the second node");
76: Shay Banon, info, MethodDeclaration, logger.info("--> verify all are allocated on node1 now");
91: Igor Motov, info, MethodDeclaration, logger.info("--> starting 2 nodes");
97: Igor Motov, info, MethodDeclaration, logger.info("--> creating an index with no replicas");
104: Igor Motov, info, MethodDeclaration, logger.info("--> index some data");
127: Igor Motov, info, MethodDeclaration, logger.info("--> remove index from the first node");
134: Simon Willnauer, info, MethodDeclaration, logger.info("--> verify all shards are allocated on node_1 now");
143: Igor Motov, info, MethodDeclaration, logger.info("--> disable allocation filtering ");
150: Igor Motov, info, MethodDeclaration, logger.info("--> verify that there are shards allocated on both nodes now");
169: Lee Hinman, info, MethodDeclaration, logger.info("--> exclude: [{}], include: [{}]", Strings.collectionToCommaDelimitedString(excludeNodes), Strings.collectionToCommaDelimitedString(includeNodes));
179: Lee Hinman, info, MethodDeclaration, logger.info("--> updating settings");
182: Lee Hinman, info, MethodDeclaration, logger.info("--> waiting for relocation");
189: Lee Hinman, info, ForeachStmt, logger.info("--> shard on {} - {}", node, shard);
197: Lee Hinman, info, MethodDeclaration, logger.info("--> updating settings with random persistent setting");
201: Lee Hinman, info, MethodDeclaration, logger.info("--> waiting for relocation");
211: Lee Hinman, info, ForeachStmt, logger.info("--> shard on {} - {}", node, shard);
39: Daniel Mitterdorfer, info, MethodDeclaration, logger.info("index status: {}, expected {}", indexHealth.getStatus(), counter.status());
128: Boaz Leskes, debug, CatchClause, logger.debug("interrupted", e);
132: Boaz Leskes, info, MethodDeclaration, logger.info("--> submit task to restore master");
139: Boaz Leskes, info, MethodDeclaration, logger.info("--> waiting for listener to be called and cluster state being blocked");
149: Boaz Leskes, info, MethodDeclaration, logger.info("--> realising task to restore master");
180: Daniel Mitterdorfer, info, MethodDeclaration, logger.info("cluster status: {}, expected {}", clusterStateHealth.getStatus(), counter.status());
148: Martijn van Groningen, info, MethodDeclaration, logger.info("timezone: [{}], now [{}], name: [{}]", timeZone, now, results.get(0));
175: Martijn van Groningen, info, MethodDeclaration, logger.info("timezone: [{}], now [{}], name: [{}]", timeZone, now, results.get(0));
76: Igor Motov, debug, LambdaExpr, logger.debug("the template dummy setting was updated to {}", integer);
178: Boaz Leskes, info, MethodDeclaration, logger.info("nodes A: {}", discoNodesA);
179: Boaz Leskes, info, MethodDeclaration, logger.info("nodes B: {}", discoNodesB);
39: Shay Banon, info, MethodDeclaration, logger.info("-- create unassigned shard");
43: Shay Banon, info, MethodDeclaration, logger.info("-- initialize the shard");
50: Shay Banon, info, MethodDeclaration, logger.info("-- start the shard");
59: Shay Banon, info, MethodDeclaration, logger.info("-- build started shard");
65: Shay Banon, info, MethodDeclaration, logger.info("-- relocate the shard");
75: Shay Banon, info, MethodDeclaration, logger.info("-- finalize the relocation");
82: Shay Banon, info, MethodDeclaration, logger.info("-- build started shard");
88: Shay Banon, info, MethodDeclaration, logger.info("-- relocate the shard");
95: Shay Banon, info, MethodDeclaration, logger.info("-- cancel relocation");
102: Shay Banon, info, MethodDeclaration, logger.info("-- build started shard");
107: Shay Banon, info, MethodDeclaration, logger.info("-- move to unassigned");
86: Yannick Welsch, info, MethodDeclaration, logger.info("--> starting 3 nodes, 1 master, 2 data");
93: Yannick Welsch, info, MethodDeclaration, logger.info("--> indexing...");
115: Yannick Welsch, info, MethodDeclaration, logger.info("--> partitioning node with primary shard from rest of cluster");
120: Yannick Welsch, info, MethodDeclaration, logger.info("--> index a document into previous replica shard (that is now primary)");
123: Yannick Welsch, info, MethodDeclaration, logger.info("--> shut down node that has new acknowledged document");
130: Yannick Welsch, info, MethodDeclaration, logger.info("--> waiting for node with old primary shard to rejoin the cluster");
133: Yannick Welsch, info, MethodDeclaration, logger.info("--> check that old primary shard does not get promoted to primary again");
144: Yannick Welsch, info, MethodDeclaration, logger.info("--> starting node that reuses data folder with the up-to-date primary shard");
147: Yannick Welsch, info, MethodDeclaration, logger.info("--> check that the up-to-date primary shard gets promoted and that documents are available");
155: Yannick Welsch, info, MethodDeclaration, logger.info("--> create single shard index");
167: Yannick Welsch, info, MethodDeclaration, logger.info("--> force allocation of stale copy to node that does not have shard copy");
170: Yannick Welsch, info, MethodDeclaration, logger.info("--> wait until shard is failed and becomes unassigned again");
181: Yannick Welsch, info, MethodDeclaration, logger.info("--> explicitly promote old primary shard");
188: Yannick Welsch, info, ForeachStmt, logger.info("--> adding allocation command for shard {}", shardId);
198: Yannick Welsch, info, MethodDeclaration, logger.info("--> check that the stale primary shard gets allocated and that documents are available");
245: Yannick Welsch, info, MethodDeclaration, logger.info("--> wait until shard is failed and becomes unassigned again");
249: Yannick Welsch, info, MethodDeclaration, logger.info("--> starting node that reuses data folder with the up-to-date shard");
264: Yannick Welsch, info, MethodDeclaration, logger.info("--> indexing...");
273: Yannick Welsch, info, MethodDeclaration, logger.info("--> wait until shard is failed and becomes unassigned again");
277: Yannick Welsch, info, MethodDeclaration, logger.info("--> starting node that reuses data folder with the up-to-date shard");
283: Yannick Welsch, info, MethodDeclaration, logger.info("--> starting 3 nodes");
285: Yannick Welsch, info, MethodDeclaration, logger.info("--> creating index with 1 primary and 2 replicas");
290: Yannick Welsch, info, MethodDeclaration, logger.info("--> removing 2 nodes from cluster");
294: Yannick Welsch, info, MethodDeclaration, logger.info("--> checking that index still gets allocated with only 1 shard copy being available");
305: Ali Beyad, info, MethodDeclaration, logger.info("--> starting 1 node");
307: Ali Beyad, info, MethodDeclaration, logger.info("--> creating index with 1 primary and 0 replicas");
314: Ali Beyad, info, MethodDeclaration, logger.info("--> update the settings to prevent allocation to the data node");
319: Ali Beyad, info, MethodDeclaration, logger.info("--> full cluster restart");
321: Ali Beyad, info, MethodDeclaration, logger.info("--> checking that the primary shard is force allocated to the data node despite being blocked by the exclude filter");
346: Nhat Nguyen, info, MethodDeclaration, logger.info("--> Indexing with gap in seqno to ensure that some operations will be replayed in resync");
363: Nhat Nguyen, info, MethodDeclaration, logger.info("--> isolating some replicas during primary-replica resync");
384: Nhat Nguyen, info, MethodDeclaration, logger.info("--> stop disrupting network and re-enable allocation");
67: Yannick Welsch, info, MethodDeclaration, logger.info("Setup test with {} shards and {} replicas.", this.numberOfShards, this.numberOfReplicas);
89: Yannick Welsch, info, MethodDeclaration, logger.info("adding {} nodes and performing rerouting", this.numberOfReplicas + 1);
114: Boaz Leskes, info, MethodDeclaration, logger.info("start primary shards for index [{}]: {} ", index, startedShards);
133: Boaz Leskes, info, MethodDeclaration, logger.info("applied reroute. active shards: p [{}], t [{}], init shards: [{}], relocating: [{}]", clusterHealth.getActivePrimaryShards(), clusterHealth.getActiveShards(), clusterHealth.getInitializingShards(), clusterHealth.getRelocatingShards());
144: Boaz Leskes, info, MethodDeclaration, logger.info("failing primary shards {} for index [{}]", shardIdsToFail, index);
156: Boaz Leskes, info, MethodDeclaration, logger.info("adding [{}] nodes", newNodes);
59: Lee Hinman, info, MethodDeclaration, logger.info("--> performing fake reroute [{}]", reason);
71: Yannick Welsch, info, MethodDeclaration, logger.info("Setup test with {} shards and {} replicas.", this.numberOfShards, this.numberOfReplicas);
89: Yannick Welsch, info, MethodDeclaration, logger.info("adding {} nodes and performing rerouting", this.numberOfReplicas + 1);
101: Yannick Welsch, info, MethodDeclaration, logger.info("start primary shards for index {}", index);
197: Yannick Welsch, debug, IfStmt, logger.debug("comparing\nthis  {} to\nother {}", routing, otherRouting);
92: Boaz Leskes, debug, MethodDeclaration, logger.debug("ClusterState: {}", clusterState.getRoutingNodes());
111: Simon Willnauer, info, MethodDeclaration, logger.info("now, start one more node, check that rebalancing will happen because we set it to always");
153: Boaz Leskes, debug, MethodDeclaration, logger.debug("ClusterState: {}", clusterState.getRoutingNodes());
173: Simon Willnauer, info, MethodDeclaration, logger.info("now, start one more node, check that rebalancing will happen because we set it to always");
215: Boaz Leskes, debug, MethodDeclaration, logger.debug("ClusterState: {}", clusterState.getRoutingNodes());
243: Simon Willnauer, info, MethodDeclaration, logger.info("now, start [{}] more node, check that rebalancing will happen because we set it to always", numNodes);
276: Yannick Welsch, info, MethodDeclaration, logger.info("start {} nodes", numberOfNodes);
284: Simon Willnauer, info, MethodDeclaration, logger.info("restart all the primary shards, replicas will start initializing");
288: Simon Willnauer, info, MethodDeclaration, logger.info("start the replica shards");
293: Simon Willnauer, info, MethodDeclaration, logger.info("complete rebalancing");
312: Simon Willnauer, info, MethodDeclaration, logger.info("restart all the primary shards, replicas will start initializing");
316: Simon Willnauer, info, MethodDeclaration, logger.info("start the replica shards");
320: Simon Willnauer, info, MethodDeclaration, logger.info("complete rebalancing");
325: Simon Willnauer, info, MethodDeclaration, logger.info("Removing [{}] nodes", numNodes);
340: Simon Willnauer, info, MethodDeclaration, logger.info("start all the primary shards, replicas will start initializing");
344: Simon Willnauer, info, MethodDeclaration, logger.info("start the replica shards");
348: Simon Willnauer, info, MethodDeclaration, logger.info("rebalancing");
351: Simon Willnauer, info, MethodDeclaration, logger.info("complete rebalancing");
79: Shay Banon, info, MethodDeclaration, logger.info("creating an index with 1 shard, no replica");
88: Shay Banon, info, MethodDeclaration, logger.info("adding two nodes and performing rerouting");
92: Shay Banon, info, MethodDeclaration, logger.info("start primary shard");
95: Shay Banon, info, MethodDeclaration, logger.info("move the shard");
110: Shay Banon, info, MethodDeclaration, logger.info("finish moving the shard");
132: Shay Banon, info, MethodDeclaration, logger.info("--> building initial routing table");
145: Shay Banon, info, MethodDeclaration, logger.info("--> adding 3 nodes on same rack and do rerouting");
155: Yannick Welsch, info, MethodDeclaration, logger.info("--> allocating to non-existent node, should fail");
163: Adrien Grand, info, MethodDeclaration, logger.info("--> allocating to non-data node, should fail");
171: Yannick Welsch, info, MethodDeclaration, logger.info("--> allocating non-existing shard, should fail");
179: Yannick Welsch, info, MethodDeclaration, logger.info("--> allocating non-existing index, should fail");
187: Yannick Welsch, info, MethodDeclaration, logger.info("--> allocating empty primary with acceptDataLoss flag set to false");
195: Yannick Welsch, info, MethodDeclaration, logger.info("--> allocating stale primary with acceptDataLoss flag set to false");
203: Yannick Welsch, info, MethodDeclaration, logger.info("--> allocating empty primary with acceptDataLoss flag set to true");
212: Shay Banon, info, MethodDeclaration, logger.info("--> start the primary shard");
218: Shay Banon, info, MethodDeclaration, logger.info("--> allocate the replica shard on the primary shard node, should fail");
225: Shay Banon, info, MethodDeclaration, logger.info("--> allocate the replica shard on on the second node");
236: Shay Banon, info, MethodDeclaration, logger.info("--> start the replica shard");
243: Shay Banon, info, MethodDeclaration, logger.info("--> verify that we fail when there are no unassigned shards");
257: Shay Banon, info, MethodDeclaration, logger.info("--> building initial routing table");
266: Shay Banon, info, MethodDeclaration, logger.info("--> adding 3 nodes");
275: Yannick Welsch, info, MethodDeclaration, logger.info("--> allocating empty primary shard with accept_data_loss flag set to true");
284: Shay Banon, info, MethodDeclaration, logger.info("--> cancel primary allocation, make sure it fails...");
291: Shay Banon, info, MethodDeclaration, logger.info("--> start the primary shard");
297: Shay Banon, info, MethodDeclaration, logger.info("--> cancel primary allocation, make sure it fails...");
304: Shay Banon, info, MethodDeclaration, logger.info("--> allocate the replica shard on on the second node");
314: Shay Banon, info, MethodDeclaration, logger.info("--> cancel the relocation allocation");
324: Shay Banon, info, MethodDeclaration, logger.info("--> allocate the replica shard on on the second node");
334: Shay Banon, info, MethodDeclaration, logger.info("--> cancel the primary being replicated, make sure it fails");
341: Shay Banon, info, MethodDeclaration, logger.info("--> start the replica shard");
348: Shay Banon, info, MethodDeclaration, logger.info("--> cancel allocation of the replica shard");
358: Shay Banon, info, MethodDeclaration, logger.info("--> allocate the replica shard on on the second node");
367: Shay Banon, info, MethodDeclaration, logger.info("--> start the replica shard");
374: Simon Willnauer, info, MethodDeclaration, logger.info("--> move the replica shard");
394: Yannick Welsch, info, IfStmt, logger.info("--> cancel the move of the replica shard");
402: Yannick Welsch, info, IfStmt, logger.info("--> move the replica shard again");
412: Yannick Welsch, info, IfStmt, logger.info("--> cancel the source replica shard");
422: Yannick Welsch, info, IfStmt, logger.info("--> start the former target replica shard");
429: Yannick Welsch, info, IfStmt, logger.info("--> cancel the primary allocation (with allow_primary set to true)");
385: Yannick Welsch, info, IfStmt, logger.info("--> cancel the primary allocation (with allow_primary set to true)");
535: Mikaâ , info, MethodDeclaration, logger.info("creating an index with 1 shard, no replica");
544: Mikaâ , info, MethodDeclaration, logger.info("--> adding two nodes");
556: Mikaâ , info, MethodDeclaration, logger.info("start primary shard");
563: Mikaâ , info, MethodDeclaration, logger.info("--> executing move allocation command to non-data node");
571: Mikaâ , info, MethodDeclaration, logger.info("creating an index with 1 shard, no replica");
580: Mikaâ , info, MethodDeclaration, logger.info("--> adding two nodes");
591: Mikaâ , info, MethodDeclaration, logger.info("start primary shard");
598: Mikaâ , info, MethodDeclaration, logger.info("--> executing move allocation command from non-data node");
63: Simon Willnauer, info, MethodDeclaration, logger.info("Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded1'");
73: Shay Banon, info, MethodDeclaration, logger.info("--> adding two nodes on same rack and do rerouting");
81: Shay Banon, info, MethodDeclaration, logger.info("--> start the shards (primaries)");
84: Shay Banon, info, MethodDeclaration, logger.info("--> start the shards (replicas)");
89: Shay Banon, info, MethodDeclaration, logger.info("--> add a new node with a new rack and reroute");
99: Shay Banon, info, MethodDeclaration, logger.info("--> complete relocation");
104: Shay Banon, info, MethodDeclaration, logger.info("--> do another reroute, make sure nothing moves");
107: Shay Banon, info, MethodDeclaration, logger.info("--> add another node with a new rack, make sure nothing moves");
123: Simon Willnauer, info, MethodDeclaration, logger.info("Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded2'");
133: Shay Banon, info, MethodDeclaration, logger.info("--> adding two nodes on same rack and do rerouting");
142: Shay Banon, info, MethodDeclaration, logger.info("--> start the shards (primaries)");
145: Shay Banon, info, MethodDeclaration, logger.info("--> start the shards (replicas)");
150: Shay Banon, info, MethodDeclaration, logger.info("--> add a new node with a new rack and reroute");
160: Shay Banon, info, MethodDeclaration, logger.info("--> complete relocation");
165: Shay Banon, info, MethodDeclaration, logger.info("--> do another reroute, make sure nothing moves");
168: Shay Banon, info, MethodDeclaration, logger.info("--> add another node with a new rack, make sure nothing moves");
189: Simon Willnauer, info, MethodDeclaration, logger.info("Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded3'");
201: Shay Banon, info, MethodDeclaration, logger.info("--> adding two nodes on same rack and do rerouting");
208: Yannick Welsch, info, MethodDeclaration, logger.info("Initializing shards: {}", clusterState.getRoutingNodes().shardsWithState(INITIALIZING));
209: Yannick Welsch, info, MethodDeclaration, logger.info("Started shards: {}", clusterState.getRoutingNodes().shardsWithState(STARTED));
210: Yannick Welsch, info, MethodDeclaration, logger.info("Relocating shards: {}", clusterState.getRoutingNodes().shardsWithState(RELOCATING));
211: Yannick Welsch, info, MethodDeclaration, logger.info("Unassigned shards: {}", clusterState.getRoutingNodes().shardsWithState(UNASSIGNED));
215: Shay Banon, info, MethodDeclaration, logger.info("--> start the shards (primaries)");
218: Shay Banon, info, MethodDeclaration, logger.info("--> start the shards (replicas)");
223: Shay Banon, info, MethodDeclaration, logger.info("--> add a new node with a new rack and reroute");
234: Shay Banon, info, MethodDeclaration, logger.info("--> complete initializing");
237: Shay Banon, info, MethodDeclaration, logger.info("--> run it again, since we still might have relocation");
242: Shay Banon, info, MethodDeclaration, logger.info("--> do another reroute, make sure nothing moves");
245: Shay Banon, info, MethodDeclaration, logger.info("--> add another node with a new rack, some more relocation should happen");
252: Shay Banon, info, MethodDeclaration, logger.info("--> complete relocation");
257: Shay Banon, info, MethodDeclaration, logger.info("--> do another reroute, make sure nothing moves");
270: Simon Willnauer, info, MethodDeclaration, logger.info("Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded4'");
284: Shay Banon, info, MethodDeclaration, logger.info("--> adding two nodes on same rack and do rerouting");
292: Shay Banon, info, MethodDeclaration, logger.info("--> start the shards (primaries)");
295: Shay Banon, info, MethodDeclaration, logger.info("--> start the shards (replicas)");
300: Shay Banon, info, MethodDeclaration, logger.info("--> add a new node with a new rack and reroute");
311: Shay Banon, info, MethodDeclaration, logger.info("--> complete initializing");
313: Simon Willnauer, info, ForStmt, logger.info("--> complete initializing round: [{}]", i);
323: Shay Banon, info, MethodDeclaration, logger.info("--> do another reroute, make sure nothing moves");
326: Shay Banon, info, MethodDeclaration, logger.info("--> add another node with a new rack, some more relocation should happen");
333: Shay Banon, info, MethodDeclaration, logger.info("--> complete relocation");
335: Simon Willnauer, info, ForStmt, logger.info("--> complete initializing round: [{}]", i);
344: Shay Banon, info, MethodDeclaration, logger.info("--> do another reroute, make sure nothing moves");
355: Simon Willnauer, info, MethodDeclaration, logger.info("Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded5'");
367: Shay Banon, info, MethodDeclaration, logger.info("--> adding two nodes on same rack and do rerouting");
375: Shay Banon, info, MethodDeclaration, logger.info("--> start the shards (primaries)");
378: Shay Banon, info, MethodDeclaration, logger.info("--> start the shards (replicas)");
383: Shay Banon, info, MethodDeclaration, logger.info("--> add a new node with a new rack and reroute");
393: Shay Banon, info, MethodDeclaration, logger.info("--> complete relocation");
398: Shay Banon, info, MethodDeclaration, logger.info("--> do another reroute, make sure nothing moves");
401: Shay Banon, info, MethodDeclaration, logger.info("--> add another node with a new rack, we will have another relocation");
410: Shay Banon, info, MethodDeclaration, logger.info("--> complete relocation");
415: Shay Banon, info, MethodDeclaration, logger.info("--> make sure another reroute does not move things");
426: Simon Willnauer, info, MethodDeclaration, logger.info("Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded6'");
438: Shay Banon, info, MethodDeclaration, logger.info("--> adding two nodes on same rack and do rerouting");
448: Shay Banon, info, MethodDeclaration, logger.info("--> start the shards (primaries)");
451: Shay Banon, info, MethodDeclaration, logger.info("--> start the shards (replicas)");
456: Shay Banon, info, MethodDeclaration, logger.info("--> add a new node with a new rack and reroute");
466: Shay Banon, info, MethodDeclaration, logger.info("--> complete relocation");
471: Shay Banon, info, MethodDeclaration, logger.info("--> do another reroute, make sure nothing moves");
474: Shay Banon, info, MethodDeclaration, logger.info("--> add another node with a new rack, we will have another relocation");
483: Shay Banon, info, MethodDeclaration, logger.info("--> complete relocation");
488: Shay Banon, info, MethodDeclaration, logger.info("--> make sure another reroute does not move things");
500: Simon Willnauer, info, MethodDeclaration, logger.info("Building initial routing table for 'fullAwareness1'");
512: Shay Banon, info, MethodDeclaration, logger.info("--> adding two nodes on same rack and do rerouting");
520: Shay Banon, info, MethodDeclaration, logger.info("--> start the shards (primaries)");
523: Shay Banon, info, MethodDeclaration, logger.info("--> replica will not start because we have only one rack value");
527: Shay Banon, info, MethodDeclaration, logger.info("--> add a new node with a new rack and reroute");
537: Shay Banon, info, MethodDeclaration, logger.info("--> complete relocation");
542: Shay Banon, info, MethodDeclaration, logger.info("--> do another reroute, make sure nothing moves");
545: Shay Banon, info, MethodDeclaration, logger.info("--> add another node with a new rack, make sure nothing moves");
562: Simon Willnauer, info, MethodDeclaration, logger.info("Building initial routing table for 'fullAwareness2'");
574: Shay Banon, info, MethodDeclaration, logger.info("--> adding two nodes on same rack and do rerouting");
583: Shay Banon, info, MethodDeclaration, logger.info("--> start the shards (primaries)");
586: Shay Banon, info, MethodDeclaration, logger.info("--> replica will not start because we have only one rack value");
590: Shay Banon, info, MethodDeclaration, logger.info("--> add a new node with a new rack and reroute");
600: Shay Banon, info, MethodDeclaration, logger.info("--> complete relocation");
605: Shay Banon, info, MethodDeclaration, logger.info("--> do another reroute, make sure nothing moves");
608: Shay Banon, info, MethodDeclaration, logger.info("--> add another node with a new rack, make sure nothing moves");
630: Simon Willnauer, info, MethodDeclaration, logger.info("Building initial routing table for 'fullAwareness3'");
644: Shay Banon, info, MethodDeclaration, logger.info("--> adding two nodes on same rack and do rerouting");
652: Shay Banon, info, MethodDeclaration, logger.info("--> start the shards (primaries)");
657: Shay Banon, info, MethodDeclaration, logger.info("--> add a new node with a new rack and reroute");
667: Shay Banon, info, MethodDeclaration, logger.info("--> complete initializing");
670: Shay Banon, info, MethodDeclaration, logger.info("--> run it again, since we still might have relocation");
675: Shay Banon, info, MethodDeclaration, logger.info("--> do another reroute, make sure nothing moves");
678: Shay Banon, info, MethodDeclaration, logger.info("--> add another node with a new rack, some more relocation should happen");
685: Shay Banon, info, MethodDeclaration, logger.info("--> complete relocation");
690: Shay Banon, info, MethodDeclaration, logger.info("--> do another reroute, make sure nothing moves");
704: Simon Willnauer, info, MethodDeclaration, logger.info("Building initial routing table for 'testUnbalancedZones'");
716: Masaru Hasegawa, info, MethodDeclaration, logger.info("--> adding two nodes in different zones and do rerouting");
725: Simon Willnauer, info, MethodDeclaration, logger.info("--> start the shards (primaries)");
731: Simon Willnauer, info, MethodDeclaration, logger.info("--> all replicas are allocated and started since we have on node in each zone");
735: Simon Willnauer, info, MethodDeclaration, logger.info("--> add a new node in zone 'a' and reroute");
743: Shay Banon, info, MethodDeclaration, logger.info("--> starting initializing shards on the new node");
760: Masaru Hasegawa, info, MethodDeclaration, logger.info("Building initial routing table for 'testUnassignedShardsWithUnbalancedZones'");
772: Masaru Hasegawa, info, MethodDeclaration, logger.info("--> adding 5 nodes in different zones and do rerouting");
785: Masaru Hasegawa, info, MethodDeclaration, logger.info("--> start the shard (primary)");
819: Ali Beyad, info, MethodDeclaration, logger.info("Building initial routing table for 'testUnbalancedZones'");
831: Ali Beyad, info, MethodDeclaration, logger.info("--> adding two nodes in different zones and do rerouting");
846: Ali Beyad, info, MethodDeclaration, logger.info("--> start the shards (primaries)");
852: Ali Beyad, info, MethodDeclaration, logger.info("--> all replicas are allocated and started since we have one node in each zone and rack");
129: Shay Banon, info, MethodDeclaration, logger.info("start " + numberOfNodes + " nodes");
137: Simon Willnauer, info, MethodDeclaration, logger.info("restart all the primary shards, replicas will start initializing");
141: Simon Willnauer, info, MethodDeclaration, logger.info("start the replica shards");
145: Simon Willnauer, info, MethodDeclaration, logger.info("complete rebalancing");
150: Simon Willnauer, info, MethodDeclaration, logger.info("now, start 1 more node, check that rebalancing will happen because we set it to always");
163: Shay Banon, info, MethodDeclaration, logger.info("Removing half the nodes (" + (numberOfNodes + 1) / 2 + ")");
177: Simon Willnauer, info, MethodDeclaration, logger.info("start all the primary shards, replicas will start initializing");
181: Simon Willnauer, info, MethodDeclaration, logger.info("start the replica shards");
185: Simon Willnauer, info, MethodDeclaration, logger.info("rebalancing");
188: Simon Willnauer, info, MethodDeclaration, logger.info("complete rebalancing");
357: Simon Willnauer, info, MethodDeclaration, logger.info("use the new allocator and check if it moves shards");
368: Simon Willnauer, info, MethodDeclaration, logger.info("start the replica shards");
379: Simon Willnauer, info, MethodDeclaration, logger.info("rebalancing");
87: Simon Willnauer, debug, IfStmt, logger.debug("Add routing {}", routing);
95: Simon Willnauer, info, MethodDeclaration, logger.info("Building initial routing table");
161: Yannick Welsch, debug, WhileStmt, logger.debug("Initializing shards: {}", initializing);
165: Yannick Welsch, debug, MethodDeclaration, logger.debug("--> num relocations to get balance: {}", numRelocations);
67: kimchy, info, MethodDeclaration, logger.info("start two nodes");
83: kimchy, info, MethodDeclaration, logger.info("start all the primary shards for test1, replicas will start initializing");
99: kimchy, info, MethodDeclaration, logger.info("start the test1 replica shards");
116: kimchy, info, MethodDeclaration, logger.info("now, start 1 more node, check that rebalancing will happen (for test1) because we set it to always");
144: kimchy, info, MethodDeclaration, logger.info("start two nodes");
159: kimchy, info, MethodDeclaration, logger.info("start all the primary shards for test1, replicas will start initializing");
176: kimchy, info, MethodDeclaration, logger.info("start the test1 replica shards");
193: kimchy, info, MethodDeclaration, logger.info("start all the primary shards for test2, replicas will start initializing");
210: kimchy, info, MethodDeclaration, logger.info("now, start 1 more node, check that rebalancing happen (for test1) because we set it to primaries_active");
237: kimchy, info, MethodDeclaration, logger.info("start two nodes");
253: kimchy, info, MethodDeclaration, logger.info("start all the primary shards for test1, replicas will start initializing");
270: kimchy, info, MethodDeclaration, logger.info("start the test1 replica shards");
287: kimchy, info, MethodDeclaration, logger.info("now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to primaries_active");
313: kimchy, info, MethodDeclaration, logger.info("start two nodes");
329: kimchy, info, MethodDeclaration, logger.info("start all the primary shards for test1, replicas will start initializing");
346: kimchy, info, MethodDeclaration, logger.info("start the test1 replica shards");
363: kimchy, info, MethodDeclaration, logger.info("start all the primary shards for test2, replicas will start initializing");
380: kimchy, info, MethodDeclaration, logger.info("start the test2 replica shards");
397: kimchy, info, MethodDeclaration, logger.info("now, start 1 more node, check that rebalancing happen (for test1) because we set it to all_active");
424: kimchy, info, MethodDeclaration, logger.info("start two nodes");
440: kimchy, info, MethodDeclaration, logger.info("start all the primary shards for test1, replicas will start initializing");
457: kimchy, info, MethodDeclaration, logger.info("start the test1 replica shards");
474: kimchy, info, MethodDeclaration, logger.info("now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to all_active");
500: kimchy, info, MethodDeclaration, logger.info("start two nodes");
516: kimchy, info, MethodDeclaration, logger.info("start all the primary shards for test1, replicas will start initializing");
533: kimchy, info, MethodDeclaration, logger.info("start the test1 replica shards");
550: kimchy, info, MethodDeclaration, logger.info("start all the primary shards for test2, replicas will start initializing");
567: kimchy, info, MethodDeclaration, logger.info("now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to all_active");
610: Simon Willnauer, info, MethodDeclaration, logger.info("start two nodes");
619: Simon Willnauer, debug, MethodDeclaration, logger.debug("start all the primary shards for test");
627: Simon Willnauer, debug, MethodDeclaration, logger.debug("now, start 1 more node, check that rebalancing will not happen since we unassigned shards");
631: Simon Willnauer, debug, MethodDeclaration, logger.debug("reroute and check that nothing has changed");
643: Simon Willnauer, debug, MethodDeclaration, logger.debug("now set allocateTest1 to true and reroute we should see the [test1] index initializing");
653: Dongjoon Hyun, debug, MethodDeclaration, logger.debug("now start initializing shards and expect exactly one rebalance from node1 to node 2 since index [test] is all on node1");
703: Simon Willnauer, info, MethodDeclaration, logger.info("start two nodes");
712: Simon Willnauer, debug, MethodDeclaration, logger.debug("start all the primary shards for test");
720: Simon Willnauer, debug, MethodDeclaration, logger.debug("now, start 1 more node, check that rebalancing will not happen since we have shard sync going on");
724: Simon Willnauer, debug, MethodDeclaration, logger.debug("reroute and check that nothing has changed");
736: Simon Willnauer, debug, MethodDeclaration, logger.debug("now set hasFetches to true and reroute we should now see exactly one relocating shard");
50: kimchy, info, MethodDeclaration, logger.info("Building initial routing table");
71: kimchy, info, MethodDeclaration, logger.info("start two nodes and fully start the shards");
81: kimchy, info, MethodDeclaration, logger.info("start all the primary shards, replicas will start initializing");
91: kimchy, info, MethodDeclaration, logger.info("now, start 8 more nodes, and check that no rebalancing/relocation have happened");
103: kimchy, info, MethodDeclaration, logger.info("start the replica shards, rebalancing should start, but, only 3 should be rebalancing");
111: kimchy, info, MethodDeclaration, logger.info("finalize this session relocation, 3 more should relocate now");
119: kimchy, info, MethodDeclaration, logger.info("finalize this session relocation, 2 more should relocate now");
127: kimchy, info, MethodDeclaration, logger.info("finalize this session relocation, no more relocation");
51: Shay Banon, info, MethodDeclaration, logger.info("--> building initial routing table");
60: Shay Banon, info, MethodDeclaration, logger.info("--> adding 2 nodes on same rack and do rerouting");
73: Shay Banon, info, MethodDeclaration, logger.info("--> verifying all is allocated");
79: Shay Banon, info, MethodDeclaration, logger.info("--> fail node with primary");
98: Shay Banon, info, MethodDeclaration, logger.info("--> building initial routing table");
107: Shay Banon, info, MethodDeclaration, logger.info("--> adding 2 nodes on same rack and do rerouting");
120: Shay Banon, info, MethodDeclaration, logger.info("--> verifying all is allocated");
126: Shay Banon, info, MethodDeclaration, logger.info("--> adding additional node");
141: Shay Banon, info, MethodDeclaration, logger.info("--> moving primary shard to node3");
150: Shay Banon, info, MethodDeclaration, logger.info("--> fail primary shard recovering instance on node3 being initialized by killing node3");
167: Shay Banon, info, MethodDeclaration, logger.info("--> building initial routing table");
176: Shay Banon, info, MethodDeclaration, logger.info("--> adding 2 nodes on same rack and do rerouting");
189: Shay Banon, info, MethodDeclaration, logger.info("--> verifying all is allocated");
195: Shay Banon, info, MethodDeclaration, logger.info("--> adding additional node");
210: Shay Banon, info, MethodDeclaration, logger.info("--> moving primary shard to node3");
219: Shay Banon, info, MethodDeclaration, logger.info("--> fail primary shard recovering instance on 'origPrimaryNodeId' being relocated");
122: Ali Beyad, info, MethodDeclaration, logger.info("Building initial routing table");
140: Ali Beyad, info, MethodDeclaration, logger.info("--> adding nodes");
150: Ali Beyad, info, MethodDeclaration, logger.info("--> do the reroute");
154: Ali Beyad, info, MethodDeclaration, logger.info("--> assert cluster health");
69: Simon Willnauer, info, MethodDeclaration, logger.info("adding two nodes and performing rerouting");
73: Simon Willnauer, info, MethodDeclaration, logger.info("start primary shard");
46: kimchy, info, MethodDeclaration, logger.info("Building initial routing table");
58: kimchy, info, MethodDeclaration, logger.info("Adding two nodes and performing rerouting");
62: kimchy, info, MethodDeclaration, logger.info("Start the primary shards");
66: kimchy, info, MethodDeclaration, logger.info("Start the replica shards");
77: kimchy, info, MethodDeclaration, logger.info("Start another node and perform rerouting");
81: kimchy, info, MethodDeclaration, logger.info("find the replica shard that gets relocated");
91: Shay Banon, info, IfStmt, logger.info("kill the node [{}] of the primary shard for the relocating replica", indexShardRoutingTable.primaryShard().currentNodeId());
95: Shay Banon, info, IfStmt, logger.info("make sure all the primary shards are active");
58: Simon Willnauer, info, MethodDeclaration, logger.info("Building initial routing table");
71: Simon Willnauer, info, MethodDeclaration, logger.info("Adding one node and performing rerouting");
77: Simon Willnauer, info, MethodDeclaration, logger.info("Start the primary shard");
84: Simon Willnauer, info, MethodDeclaration, logger.info("Add another one node and reroute");
103: Simon Willnauer, info, MethodDeclaration, logger.info("creating an index with 1 shard, no replica");
112: Simon Willnauer, info, MethodDeclaration, logger.info("adding two nodes and performing rerouting");
116: Simon Willnauer, info, MethodDeclaration, logger.info("start primary shard");
119: Simon Willnauer, info, MethodDeclaration, logger.info("move the shard");
137: Simon Willnauer, info, MethodDeclaration, logger.info("finish moving the shard");
83: kimchy, info, MethodDeclaration, logger.info("start 4 nodes");
87: kimchy, info, MethodDeclaration, logger.info("start all the primary shards, replicas will start initializing");
92: kimchy, info, MethodDeclaration, logger.info("start the replica shards");
103: kimchy, info, MethodDeclaration, logger.info("remove 2 nodes where primaries are allocated, reroute");
126: Lee Hinman, info, MethodDeclaration, logger.info("--> adding random nodes");
137: Lee Hinman, info, ForeachStmt, logger.info("--> node [{}] has version [{}]", cursor.value.getId(), nodeVer);
141: Lee Hinman, info, MethodDeclaration, logger.info("--> creating some indices");
154: Lee Hinman, info, MethodDeclaration, logger.info("--> starting shards");
156: Lee Hinman, info, MethodDeclaration, logger.info("--> starting replicas a random number of times");
173: Lee Hinman, info, WhileStmt, logger.info("--> state before failing shards: {}", state);
178: Lee Hinman, info, LambdaExpr, logger.info("--> verifying version for {}", shardRouting);
184: Lee Hinman, info, LambdaExpr, logger.info("--> new primary is on version {}: {}", newPrimaryVersion, newPrimary);
190: Lee Hinman, info, IfStmt, logger.info("--> candidate on {} node; shard routing: {}", candidateVer, sr);
67: Shay Banon, info, MethodDeclaration, logger.info("--> building initial routing table");
76: Shay Banon, info, MethodDeclaration, logger.info("--> adding 2 nodes on same rack and do rerouting");
89: Shay Banon, info, MethodDeclaration, logger.info("--> verifying all is allocated");
95: Shay Banon, info, MethodDeclaration, logger.info("--> adding additional node");
110: Shay Banon, info, MethodDeclaration, logger.info("--> moving primary shard to node3");
119: Shay Banon, info, MethodDeclaration, logger.info("--> fail primary shard recovering instance on node3 being initialized");
125: Shay Banon, info, MethodDeclaration, logger.info("--> moving primary shard to node3");
134: Shay Banon, info, MethodDeclaration, logger.info("--> fail primary shard recovering instance on node1 being relocated");
149: kimchy, info, MethodDeclaration, logger.info("Building initial routing table");
161: kimchy, info, MethodDeclaration, logger.info("Adding two nodes and performing rerouting");
165: kimchy, info, MethodDeclaration, logger.info("Start the shards (primaries)");
184: kimchy, info, MethodDeclaration, logger.info("Start the shards (backups)");
201: kimchy, info, MethodDeclaration, logger.info("fail the primary shard, will have no place to be rerouted to (single node), so stays unassigned");
222: kimchy, info, MethodDeclaration, logger.info("Building initial routing table");
234: kimchy, info, MethodDeclaration, logger.info("Adding single node and performing rerouting");
250: kimchy, info, MethodDeclaration, logger.info("fail the first shard, will have no place to be rerouted to (single node), so stays unassigned");
273: Boaz Leskes, info, MethodDeclaration, logger.info("Building initial routing table");
285: Boaz Leskes, info, MethodDeclaration, logger.info("Adding {} nodes and performing rerouting", numberOfReplicas + 1);
305: Yannick Welsch, info, ForStmt, logger.info("failing shard on node [{}]", failedNode);
336: kimchy, info, MethodDeclaration, logger.info("Building initial routing table");
348: kimchy, info, MethodDeclaration, logger.info("Adding two nodes and performing rerouting");
365: kimchy, info, MethodDeclaration, logger.info("fail the first shard, will start INITIALIZING on the second node");
391: kimchy, info, MethodDeclaration, logger.info("Building initial routing table");
403: kimchy, info, MethodDeclaration, logger.info("Adding two nodes and performing rerouting");
407: kimchy, info, MethodDeclaration, logger.info("Start the shards (primaries)");
424: kimchy, info, MethodDeclaration, logger.info("Start the shards (backups)");
441: kimchy, info, MethodDeclaration, logger.info("Adding third node and reroute");
456: kimchy, info, MethodDeclaration, logger.info("Fail the shards on node 3");
619: Lee Hinman, info, MethodDeclaration, logger.info("--> all shards allocated, replica that should be promoted: {}", startedReplica);
635: Lee Hinman, info, MethodDeclaration, logger.info("--> shard {} got assigned to node with version {}", startedReplica, replicaNodeVersion);
648: Lee Hinman, info, MethodDeclaration, logger.info("--> failing primary shard a second time, should select: {}", startedReplica);
664: Lee Hinman, info, MethodDeclaration, logger.info("--> shard {} got assigned to node with version {}", startedReplica, replicaNodeVersion);
53: Shay Banon, info, MethodDeclaration, logger.info("Building initial routing table");
65: Shay Banon, info, MethodDeclaration, logger.info("--> adding four nodes and performing rerouting");
75: Shay Banon, info, MethodDeclaration, logger.info("--> start the shards (primaries)");
78: Shay Banon, info, MethodDeclaration, logger.info("--> start the shards (replicas)");
81: Shay Banon, info, MethodDeclaration, logger.info("--> make sure shards are only allocated on tag1 with value1 and value2");
93: Shay Banon, info, MethodDeclaration, logger.info("Building initial routing table");
110: Shay Banon, info, MethodDeclaration, logger.info("--> adding two nodes and performing rerouting");
120: Shay Banon, info, MethodDeclaration, logger.info("--> start the shards (primaries)");
123: Shay Banon, info, MethodDeclaration, logger.info("--> start the shards (replicas)");
126: Shay Banon, info, MethodDeclaration, logger.info("--> make sure shards are only allocated on tag1 with value1 and value2");
133: Shay Banon, info, MethodDeclaration, logger.info("--> switch between value2 and value4, shards should be relocating");
148: Shay Banon, info, MethodDeclaration, logger.info("--> finish relocation");
161: Yannick Welsch, info, MethodDeclaration, logger.info("Building initial routing table");
174: Yannick Welsch, info, MethodDeclaration, logger.info("--> adding two nodes and performing rerouting");
182: Yannick Welsch, info, MethodDeclaration, logger.info("--> start the shards (only primaries)");
185: Yannick Welsch, info, MethodDeclaration, logger.info("--> make sure all shards are started");
188: Yannick Welsch, info, MethodDeclaration, logger.info("--> disable allocation for node1 and reroute");
194: Yannick Welsch, info, MethodDeclaration, logger.info("--> move shards from node1 to node2");
196: Boaz Leskes, info, MethodDeclaration, logger.info("--> check that concurrent recoveries only allows 1 shard to move");
201: Yannick Welsch, info, MethodDeclaration, logger.info("--> start the shards (only primaries)");
204: Yannick Welsch, info, MethodDeclaration, logger.info("--> move second shard from node1 to node2");
209: Yannick Welsch, info, MethodDeclaration, logger.info("--> start the shards (only primaries)");
52: Simon Willnauer, info, MethodDeclaration, logger.info("Building initial routing table");
81: Simon Willnauer, info, MethodDeclaration, logger.info("Adding three node and performing rerouting");
99: Simon Willnauer, info, MethodDeclaration, logger.info("Another round of rebalancing");
120: Simon Willnauer, info, MethodDeclaration, logger.info("Reroute, nothing should change");
124: Simon Willnauer, info, MethodDeclaration, logger.info("Start the more shards");
168: Simon Willnauer, info, MethodDeclaration, logger.info("Building initial routing table");
197: Simon Willnauer, info, MethodDeclaration, logger.info("Adding one node and performing rerouting");
213: Simon Willnauer, info, MethodDeclaration, logger.info("Add another node and perform rerouting, nothing will happen since primary not started");
220: Simon Willnauer, info, MethodDeclaration, logger.info("Start the primary shard");
237: Simon Willnauer, info, MethodDeclaration, logger.info("Reroute, nothing should change");
241: Simon Willnauer, info, MethodDeclaration, logger.info("Start the backup shard");
265: Simon Willnauer, info, MethodDeclaration, logger.info("Add another node and perform rerouting, nothing will happen since primary not started");
272: Simon Willnauer, info, MethodDeclaration, logger.info("Reroute, nothing should change");
276: Simon Willnauer, info, MethodDeclaration, logger.info("Start the backup shard");
312: Simon Willnauer, info, MethodDeclaration, logger.info("Building initial routing table");
330: Simon Willnauer, info, MethodDeclaration, logger.info("Adding three node and performing rerouting");
347: Simon Willnauer, info, MethodDeclaration, logger.info("Another round of rebalancing");
369: Simon Willnauer, info, MethodDeclaration, logger.info("Reroute, nothing should change");
373: Simon Willnauer, info, MethodDeclaration, logger.info("Start the more shards");
394: Simon Willnauer, info, MethodDeclaration, logger.info("Add new index 3 shards 1 replica");
423: Simon Willnauer, info, MethodDeclaration, logger.info("Another round of rebalancing");
445: Simon Willnauer, info, MethodDeclaration, logger.info("Reroute, nothing should change");
449: Simon Willnauer, info, MethodDeclaration, logger.info("Start the more shards");
65: Yannick Welsch, info, MethodDeclaration, logger.info("creating an index with 1 shard, 2 replicas");
78: Yannick Welsch, info, MethodDeclaration, logger.info("adding three nodes and performing rerouting");
86: Yannick Welsch, info, MethodDeclaration, logger.info("start primary shard");
95: Yannick Welsch, info, MethodDeclaration, logger.info("start replica shards");
100: Yannick Welsch, info, MethodDeclaration, logger.info("remove a node");
109: Yannick Welsch, info, MethodDeclaration, logger.info("remove all remaining nodes");
130: Yannick Welsch, info, MethodDeclaration, logger.info("start primary shard");
136: Yannick Welsch, info, MethodDeclaration, logger.info("fail primary shard");
155: Yannick Welsch, info, MethodDeclaration, logger.info("remove replica node");
164: Yannick Welsch, info, MethodDeclaration, logger.info("fail replica (for which there is no shard routing in the CS anymore)");
198: Yannick Welsch, info, MethodDeclaration, logger.info("Failing {}", failureEntries);
227: Yannick Welsch, info, MethodDeclaration, logger.info("remove a node");
238: Yannick Welsch, info, ForStmt, logger.info("add back node");
244: Yannick Welsch, info, ForStmt, logger.info("start replica shards");
247: Yannick Welsch, info, ForStmt, logger.info("remove the node");
275: Yannick Welsch, info, MethodDeclaration, logger.info("remove replica node");
284: Yannick Welsch, info, MethodDeclaration, logger.info("remove primary node");
293: Yannick Welsch, info, MethodDeclaration, logger.info("decrease number of replicas to 0");
298: Yannick Welsch, info, MethodDeclaration, logger.info("add back node 1");
307: Yannick Welsch, info, MethodDeclaration, logger.info("start primary shard");
326: Yannick Welsch, info, MethodDeclaration, logger.info("remove replica node");
335: Yannick Welsch, info, MethodDeclaration, logger.info("fail primary shard");
345: Yannick Welsch, info, MethodDeclaration, logger.info("creating an index with 1 shard, 1 replica");
355: Yannick Welsch, info, MethodDeclaration, logger.info("adding two nodes and performing rerouting");
362: Yannick Welsch, info, MethodDeclaration, logger.info("start primary shard");
370: Yannick Welsch, info, MethodDeclaration, logger.info("start replica shard");
88: Simon Willnauer, info, MethodDeclaration, logger.info("Building initial routing table");
115: Simon Willnauer, info, MethodDeclaration, logger.info("start two nodes and fully start the shards");
126: Simon Willnauer, info, MethodDeclaration, logger.info("start all the primary shards, replicas will start initializing");
189: Simon Willnauer, info, MethodDeclaration, logger.info("Building initial routing table");
238: Simon Willnauer, info, MethodDeclaration, logger.info("Building initial routing table");
379: Boaz Leskes, trace, MethodDeclaration, logger.trace("RoutingNodes: {}", clusterState.getRoutingNodes());
385: Simon Willnauer, info, MethodDeclaration, logger.info("complete rebalancing");
388: Boaz Leskes, trace, DoStmt, logger.trace("RoutingNodes: {}", clusterState.getRoutingNodes());
399: Boaz Leskes, trace, MethodDeclaration, logger.trace("RoutingNodes: {}", routingNodes);
416: javanna, trace, IfStmt, logger.trace("From: {} with Version: {} to: {} with Version: {}", fromId, routingNodes.node(fromId).node().getVersion(), toId, routingNodes.node(toId).node().getVersion());
408: javanna, trace, IfStmt, logger.trace("From: {} with Version: {} to: {} with Version: {}", fromId, routingNodes.node(fromId).node().getVersion(), toId, routingNodes.node(toId).node().getVersion());
429: javanna, trace, IfStmt, logger.trace("From: {} with Version: {} to: {} with Version: {}", fromId, routingNodes.node(fromId).node().getVersion(), toId, routingNodes.node(toId).node().getVersion());
46: Igor Motov, info, MethodDeclaration, logger.info("create an allocation with [{}] initial primary recoveries and [{}] concurrent recoveries", primaryRecoveries, concurrentRecoveries);
52: Igor Motov, info, MethodDeclaration, logger.info("create 2 indices with [{}] no replicas, and wait till all are allocated", numberOfShards);
66: Igor Motov, info, MethodDeclaration, logger.info("adding two nodes and performing rerouting till all are allocated");
77: Igor Motov, info, MethodDeclaration, logger.info("remove one of the nodes and apply filter to move everything from another node");
94: Igor Motov, info, MethodDeclaration, logger.info("[{}] primaries should be still started but [{}] other primaries should be unassigned", numberOfShards, numberOfShards);
99: Igor Motov, info, MethodDeclaration, logger.info("start node back up");
115: Igor Motov, info, WhileStmt, logger.info("local initializations: [{}], relocating: [{}], need to initialize: {}", localInitializations, relocatingInitializations, needToInitialize);
41: Shay Banon, info, MethodDeclaration, logger.info("create an allocation with 1 initial recoveries");
48: Shay Banon, info, MethodDeclaration, logger.info("create several indices with no replicas, and wait till all are allocated");
62: Shay Banon, info, MethodDeclaration, logger.info("adding two nodes and performing rerouting till all are allocated");
70: Shay Banon, info, MethodDeclaration, logger.info("increasing the number of replicas to 1, and perform a reroute (to get the replicas allocation going)");
77: Shay Banon, info, MethodDeclaration, logger.info("2 replicas should be initializing now for the existing indices (we throttle to 1)");
80: Shay Banon, info, MethodDeclaration, logger.info("create a new index");
91: Shay Banon, info, MethodDeclaration, logger.info("reroute, verify that primaries for the new index primary shards are allocated");
46: kimchy, info, MethodDeclaration, logger.info("Building initial routing table");
58: kimchy, info, MethodDeclaration, logger.info("Adding two nodes and performing rerouting");
65: kimchy, info, MethodDeclaration, logger.info("Start the primary shard (on node1)");
69: kimchy, info, MethodDeclaration, logger.info("Start the backup shard (on node2)");
73: kimchy, info, MethodDeclaration, logger.info("Adding third node and reroute and kill first node");
94: Shay Banon, info, MethodDeclaration, logger.info("Building initial routing table");
106: Shay Banon, info, MethodDeclaration, logger.info("Adding two nodes and performing rerouting");
110: Shay Banon, info, MethodDeclaration, logger.info("Start the primary shards");
121: Shay Banon, info, MethodDeclaration, logger.info("--> fail node with primary");
48: kimchy, info, MethodDeclaration, logger.info("Building initial routing table");
60: kimchy, info, MethodDeclaration, logger.info("Adding two nodes and performing rerouting");
64: kimchy, info, MethodDeclaration, logger.info("Start the primary shard (on node1)");
70: kimchy, info, MethodDeclaration, logger.info("start another node, replica will start recovering form primary");
77: kimchy, info, MethodDeclaration, logger.info("start another node, make sure the primary is not relocated");
91: Simon Willnauer, info, ForStmt, logger.info("Start iteration [{}]", i);
99: Simon Willnauer, info, ForStmt, logger.info("adding node [{}]", nodeIdCounter);
124: Boaz Leskes, debug, IfStmt, logger.debug("not removing node [{}] as it holds a primary with no replacement", nodeId);
120: Boaz Leskes, info, IfStmt, logger.info("removing node [{}]", nodeId);
139: Simon Willnauer, info, MethodDeclaration, logger.info("Fill up nodes such that every shard can be allocated");
144: Simon Willnauer, info, ForStmt, logger.info("adding node [{}]", nodeIdCounter);
153: Simon Willnauer, info, MethodDeclaration, logger.info("now say YES to everything");
164: Boaz Leskes, info, MethodDeclaration, logger.info("Done Balancing after [{}] iterations. State:\n{}", iterations, clusterState);
68: kimchy, info, MethodDeclaration, logger.info("Building initial routing table");
89: kimchy, info, MethodDeclaration, logger.info("start two nodes and fully start the shards");
99: kimchy, info, MethodDeclaration, logger.info("start all the primary shards, replicas will start initializing");
111: kimchy, info, MethodDeclaration, logger.info("now, start 8 more nodes, and check that no rebalancing/relocation have happened");
126: kimchy, info, MethodDeclaration, logger.info("start the replica shards, rebalancing should start");
145: kimchy, info, MethodDeclaration, logger.info("complete relocation, other half of relocation should happen");
162: Dongjoon Hyun, info, MethodDeclaration, logger.info("complete relocation, that's it!");
47: kimchy, info, MethodDeclaration, logger.info("Building initial routing table");
67: kimchy, info, MethodDeclaration, logger.info("Adding one node and performing rerouting");
86: kimchy, info, MethodDeclaration, logger.info("Start all the primary shards");
52: Sebastian Geidies, info, MethodDeclaration, logger.info("Building initial routing table");
61: Sebastian Geidies, info, MethodDeclaration, logger.info("Adding three node and performing rerouting");
80: Sebastian Geidies, info, MethodDeclaration, logger.info("Another round of rebalancing");
87: Sebastian Geidies, info, MethodDeclaration, logger.info("Reroute, nothing should change");
91: Sebastian Geidies, info, MethodDeclaration, logger.info("Start the more shards");
112: Sebastian Geidies, info, MethodDeclaration, logger.info("Building initial routing table");
121: Sebastian Geidies, info, MethodDeclaration, logger.info("Adding one node and performing rerouting");
126: Sebastian Geidies, info, MethodDeclaration, logger.info("Add another node and perform rerouting, nothing will happen since primary not started");
131: Sebastian Geidies, info, MethodDeclaration, logger.info("Start the primary shard");
135: Sebastian Geidies, info, MethodDeclaration, logger.info("Reroute, nothing should change");
138: Sebastian Geidies, info, MethodDeclaration, logger.info("Start the backup shard");
146: Sebastian Geidies, info, MethodDeclaration, logger.info("Add another node and perform rerouting, nothing will happen since primary not started");
151: Sebastian Geidies, info, MethodDeclaration, logger.info("Reroute, nothing should change");
155: Sebastian Geidies, info, MethodDeclaration, logger.info("Start the backup shard");
192: Sebastian Geidies, info, MethodDeclaration, logger.info("Building initial routing table");
200: Sebastian Geidies, info, MethodDeclaration, logger.info("Adding three node and performing rerouting");
218: Sebastian Geidies, info, MethodDeclaration, logger.info("Another round of rebalancing");
239: Sebastian Geidies, info, MethodDeclaration, logger.info("Reroute, nothing should change");
243: Sebastian Geidies, info, MethodDeclaration, logger.info("Start the more shards");
261: Sebastian Geidies, info, MethodDeclaration, logger.info("Add new index 3 shards 1 replica");
284: Sebastian Geidies, info, MethodDeclaration, logger.info("Reroute, assign");
296: Sebastian Geidies, info, MethodDeclaration, logger.info("Reroute, start the primaries");
306: Sebastian Geidies, info, MethodDeclaration, logger.info("Reroute, start the replicas");
325: Sebastian Geidies, info, MethodDeclaration, logger.info("kill one node");
337: Sebastian Geidies, info, MethodDeclaration, logger.info("Start Recovering shards round 1");
347: Sebastian Geidies, info, MethodDeclaration, logger.info("Start Recovering shards round 2");
71: Shay Banon, info, MethodDeclaration, logger.info("--> adding two nodes with the same host");
82: Shay Banon, info, MethodDeclaration, logger.info("--> start all primary shards, no replica will be started since its on the same host");
88: Shay Banon, info, MethodDeclaration, logger.info("--> add another node, with a different host, replicas will be allocating");
49: Shay Banon, info, MethodDeclaration, logger.info("Building initial routing table");
63: Shay Banon, info, MethodDeclaration, logger.info("Adding two nodes and performing rerouting");
70: Shay Banon, info, MethodDeclaration, logger.info("Start the primary shards");
80: Shay Banon, info, MethodDeclaration, logger.info("Do another reroute, make sure its still not allocated");
91: Lee Hinman, info, MethodDeclaration, logger.info("Building initial routing table");
104: Lee Hinman, info, MethodDeclaration, logger.info("Adding two nodes and performing rerouting");
111: Lee Hinman, info, MethodDeclaration, logger.info("Start the primary shards");
125: Lee Hinman, info, MethodDeclaration, logger.info("Do another reroute, make sure shards are now allocated");
149: Shay Banon, info, MethodDeclaration, logger.info("Building initial routing table");
163: Shay Banon, info, MethodDeclaration, logger.info("Adding one node and reroute");
167: Shay Banon, info, MethodDeclaration, logger.info("Start the primary shards");
173: Shay Banon, info, MethodDeclaration, logger.info("add another index with 5 shards");
186: Shay Banon, info, MethodDeclaration, logger.info("Add another one node and reroute");
202: Yannick Welsch, info, MethodDeclaration, logger.info("update {} for test, see that things move", ShardsLimitAllocationDecider.INDEX_TOTAL_SHARDS_PER_NODE_SETTING.getKey());
214: Shay Banon, info, MethodDeclaration, logger.info("reroute after setting");
41: Boaz Leskes, info, MethodDeclaration, logger.info("--> disabling allocation to capture shard failure");
48: Boaz Leskes, info, MethodDeclaration, logger.info("--> failing primary of [{}] on node [{}]", shard, node);
52: Boaz Leskes, info, MethodDeclaration, logger.info("--> waiting for a yellow index");
61: Boaz Leskes, info, MethodDeclaration, logger.info("--> enabling allocation");
69: Boaz Leskes, debug, ForeachStmt, logger.debug("--> asserting primary terms terms on [{}]", node);
59: kimchy, info, MethodDeclaration, logger.info("start two nodes");
76: kimchy, info, MethodDeclaration, logger.info("start all the primary shards for test1, replicas will start initializing");
61: kimchy, info, MethodDeclaration, logger.info("Building initial routing table");
77: kimchy, info, MethodDeclaration, logger.info("Adding one node and performing rerouting");
87: kimchy, info, MethodDeclaration, logger.info("Rerouting again, nothing should change");
93: kimchy, info, MethodDeclaration, logger.info("Marking the shard as started");
105: kimchy, info, MethodDeclaration, logger.info("Starting another node and making sure nothing changed");
117: Boaz Leskes, info, MethodDeclaration, logger.info("Killing node1 where the shard is, checking the shard is unassigned");
130: Boaz Leskes, info, MethodDeclaration, logger.info("Bring node1 back, and see it's assinged");
144: kimchy, info, MethodDeclaration, logger.info("Start another node, make sure that things remain the same (shard is in node2 and initializing)");
149: Boaz Leskes, info, MethodDeclaration, logger.info("Start the shard on node 1");
165: kimchy, info, MethodDeclaration, logger.info("Building initial routing table");
182: kimchy, info, MethodDeclaration, logger.info("Adding one node and rerouting");
195: kimchy, info, MethodDeclaration, logger.info("Marking the shard as failed");
216: kimchy, info, MethodDeclaration, logger.info("Building initial routing table with " + numberOfIndices + " indices");
239: kimchy, info, MethodDeclaration, logger.info("Adding " + (numberOfIndices / 2) + " nodes");
277: kimchy, info, MethodDeclaration, logger.info("Adding additional " + (numberOfIndices / 2) + " nodes, nothing should change");
286: kimchy, info, MethodDeclaration, logger.info("Marking the shard as started");
322: kimchy, info, MethodDeclaration, logger.info("Building initial routing table with " + numberOfIndices + " indices");
339: kimchy, info, MethodDeclaration, logger.info("Starting 3 nodes and rerouting");
359: kimchy, info, MethodDeclaration, logger.info("Start two more nodes, things should remain the same");
382: kimchy, info, MethodDeclaration, logger.info("Now, mark the relocated as started");
47: kimchy, info, MethodDeclaration, logger.info("Building initial routing table");
67: kimchy, info, MethodDeclaration, logger.info("Adding one node and performing rerouting");
83: kimchy, info, MethodDeclaration, logger.info("Add another node and perform rerouting, nothing will happen since primary shards not started");
88: kimchy, info, MethodDeclaration, logger.info("Start the primary shard (on node1)");
105: kimchy, info, MethodDeclaration, logger.info("Reroute, nothing should change");
109: kimchy, info, MethodDeclaration, logger.info("Start the backup shard");
124: kimchy, info, MethodDeclaration, logger.info("Kill node1, backup shard should become primary");
141: kimchy, info, MethodDeclaration, logger.info("Start another node, backup shard should start initializing");
53: Boaz Leskes, info, MethodDeclaration, logger.info("--> building initial cluster state");
73: Boaz Leskes, info, MethodDeclaration, logger.info("--> test starting of shard");
81: Boaz Leskes, info, MethodDeclaration, logger.info("--> testing starting of relocating shards");
94: Yannick Welsch, info, MethodDeclaration, logger.info("--> building initial cluster state");
129: Yannick Welsch, info, MethodDeclaration, logger.info("--> test starting of relocating primary shard with initializing / relocating replica");
146: Yannick Welsch, info, MethodDeclaration, logger.info("--> test starting of relocating primary shard together with initializing / relocating replica");
58: kimchy, info, MethodDeclaration, logger.info("Building initial routing table");
80: kimchy, info, MethodDeclaration, logger.info("Adding one node and performing rerouting");
98: kimchy, info, MethodDeclaration, logger.info("Add another node and perform rerouting, nothing will happen since primary not started");
103: kimchy, info, MethodDeclaration, logger.info("Start the primary shard (on node1)");
121: kimchy, info, MethodDeclaration, logger.info("Reroute, nothing should change");
125: kimchy, info, MethodDeclaration, logger.info("Start the backup shard");
145: kimchy, info, MethodDeclaration, logger.info("Add another node and perform rerouting");
159: kimchy, info, MethodDeclaration, logger.info("Start the shards on node 3");
75: kimchy, info, MethodDeclaration, logger.info("Building initial routing table");
83: kimchy, info, MethodDeclaration, logger.info("start one node, do reroute, only 3 should initialize");
91: kimchy, info, MethodDeclaration, logger.info("start initializing, another 3 should initialize");
98: kimchy, info, MethodDeclaration, logger.info("start initializing, another 3 should initialize");
105: kimchy, info, MethodDeclaration, logger.info("start initializing, another 1 should initialize");
112: kimchy, info, MethodDeclaration, logger.info("start initializing, all primaries should be started");
129: kimchy, info, MethodDeclaration, logger.info("Building initial routing table");
137: Boaz Leskes, info, MethodDeclaration, logger.info("with one node, do reroute, only 3 should initialize");
144: kimchy, info, MethodDeclaration, logger.info("start initializing, another 2 should initialize");
151: kimchy, info, MethodDeclaration, logger.info("start initializing, all primaries should be started");
158: kimchy, info, MethodDeclaration, logger.info("start another node, replicas should start being allocated");
166: kimchy, info, MethodDeclaration, logger.info("start initializing replicas");
173: kimchy, info, MethodDeclaration, logger.info("start initializing replicas, all should be started");
189: Simon Willnauer, info, MethodDeclaration, logger.info("Building initial routing table");
197: Boaz Leskes, info, MethodDeclaration, logger.info("with one node, do reroute, only 5 should initialize");
204: Simon Willnauer, info, MethodDeclaration, logger.info("start initializing, all primaries should be started");
213: Simon Willnauer, info, MethodDeclaration, logger.info("start another 2 nodes, 5 shards should be relocating - at most 5 are allowed per node");
228: Simon Willnauer, info, MethodDeclaration, logger.info("start the relocating shards, one more shard should relocate away from node1");
245: Yannick Welsch, info, MethodDeclaration, logger.info("Building initial routing table");
253: Boaz Leskes, info, MethodDeclaration, logger.info("with one node, do reroute, only 1 should initialize");
260: Yannick Welsch, info, MethodDeclaration, logger.info("start initializing");
267: Yannick Welsch, info, MethodDeclaration, logger.info("start one more node, first non-primary should start being allocated");
276: Yannick Welsch, info, MethodDeclaration, logger.info("start initializing non-primary");
283: Yannick Welsch, info, MethodDeclaration, logger.info("start one more node, initializing second non-primary");
292: Yannick Welsch, info, MethodDeclaration, logger.info("start one more node");
298: Yannick Welsch, info, MethodDeclaration, logger.info("move started non-primary to new node");
48: kimchy, info, MethodDeclaration, logger.info("Building initial routing table");
69: kimchy, info, MethodDeclaration, logger.info("Adding two nodes and performing rerouting");
74: kimchy, info, MethodDeclaration, logger.info("Start all the primary shards");
78: kimchy, info, MethodDeclaration, logger.info("Start all the replica shards");
97: kimchy, info, MethodDeclaration, logger.info("add another replica");
114: kimchy, info, MethodDeclaration, logger.info("Add another node and start the added replica");
144: kimchy, info, MethodDeclaration, logger.info("now remove a replica");
160: kimchy, info, MethodDeclaration, logger.info("do a reroute, should remain the same");
105: Lee Hinman, info, MethodDeclaration, logger.info("--> calling fake getClusterInfo");
126: Lee Hinman, info, MethodDeclaration, logger.info("--> adding two nodes");
137: Lee Hinman, info, MethodDeclaration, logger.info("--> start the shards (primaries)");
146: Lee Hinman, info, MethodDeclaration, logger.info("--> start the shards (replicas)");
153: Lee Hinman, info, MethodDeclaration, logger.info("--> adding node3");
165: Lee Hinman, info, MethodDeclaration, logger.info("--> start the shards (replicas)");
175: Lee Hinman, info, MethodDeclaration, logger.info("--> changing decider settings");
206: Lee Hinman, info, MethodDeclaration, logger.info("--> changing settings again");
238: Lee Hinman, info, MethodDeclaration, logger.info("--> adding node4");
250: Lee Hinman, info, MethodDeclaration, logger.info("--> apply INITIALIZING shards");
292: Lee Hinman, info, MethodDeclaration, logger.info("--> calling fake getClusterInfo");
314: Lee Hinman, info, MethodDeclaration, logger.info("--> adding node1 and node2 node");
334: Lee Hinman, info, MethodDeclaration, logger.info("--> nodeWithPrimary: {}", nodeWithPrimary);
335: Lee Hinman, info, MethodDeclaration, logger.info("--> nodeWithoutPrimary: {}", nodeWithoutPrimary);
345: Lee Hinman, info, MethodDeclaration, logger.info("--> calling fake getClusterInfo");
361: Lee Hinman, info, MethodDeclaration, logger.info("--> start the shards (primaries)");
387: Lee Hinman, info, MethodDeclaration, logger.info("--> start the shards (replicas)");
397: Lee Hinman, info, MethodDeclaration, logger.info("--> changing decider settings");
429: Lee Hinman, info, MethodDeclaration, logger.info("--> changing settings again");
462: Lee Hinman, info, MethodDeclaration, logger.info("--> adding node4");
476: Lee Hinman, info, MethodDeclaration, logger.info("--> apply INITIALIZING shards");
487: Lee Hinman, info, MethodDeclaration, logger.info("--> adding node5");
502: Lee Hinman, info, MethodDeclaration, logger.info("--> apply INITIALIZING shards");
505: Lee Hinman, info, MethodDeclaration, logger.info("--> final cluster state:");
542: Lee Hinman, info, MethodDeclaration, logger.info("--> calling fake getClusterInfo");
563: Lee Hinman, info, MethodDeclaration, logger.info("--> adding node1");
570: Lee Hinman, info, MethodDeclaration, logger.info("--> start the shards (primaries)");
609: Lee Hinman, info, MethodDeclaration, logger.info("--> calling fake getClusterInfo");
630: Lee Hinman, info, MethodDeclaration, logger.info("--> adding node1");
642: Lee Hinman, info, MethodDeclaration, logger.info("--> start the shards (primaries)");
710: Lee Hinman, info, MethodDeclaration, logger.info("--> calling fake getClusterInfo");
734: Lee Hinman, info, MethodDeclaration, logger.info("--> adding two nodes");
745: Lee Hinman, info, MethodDeclaration, logger.info("--> start the shards");
752: Lee Hinman, info, MethodDeclaration, logger.info("--> adding node3");
892: Martijn van Groningen, info, MethodDeclaration, logger.info("--> calling fake getClusterInfo");
947: xuzha, info, MethodDeclaration, logger.info("--> adding one master node, one data node");
988: xuzha, info, MethodDeclaration, logger.info("--> calling fake getClusterInfo");
1016: xuzha, info, MethodDeclaration, logger.info("--> adding node3");
1056: Lee Hinman, info, MethodDeclaration, logger.info("--> counts: total: {}, unassigned: {}, initializing: {}, relocating: {}, started: {}", rn.shards(shard -> true).size(), rn.shardsWithState(UNASSIGNED).size(), rn.shardsWithState(INITIALIZING).size(), rn.shardsWithState(RELOCATING).size(), rn.shardsWithState(STARTED).size());
1062: Lee Hinman, info, MethodDeclaration, logger.info("--> unassigned: {}, initializing: {}, relocating: {}, started: {}", rn.shardsWithState(UNASSIGNED), rn.shardsWithState(INITIALIZING), rn.shardsWithState(RELOCATING), rn.shardsWithState(STARTED));
154: Simon Willnauer, info, MethodDeclaration, logger.info("--> adding two nodes");
59: Martijn van Groningen, info, MethodDeclaration, logger.info("Building initial routing table");
71: Martijn van Groningen, info, MethodDeclaration, logger.info("--> adding two nodes and do rerouting");
87: Martijn van Groningen, info, MethodDeclaration, logger.info("Building initial routing table");
99: Martijn van Groningen, info, MethodDeclaration, logger.info("--> adding two nodes do rerouting");
108: Martijn van Groningen, info, MethodDeclaration, logger.info("--> start the shards (primaries)");
133: Martijn van Groningen, info, MethodDeclaration, logger.info("--> adding two nodes and do rerouting");
140: Martijn van Groningen, info, MethodDeclaration, logger.info("--> start the shards (primaries)");
142: Martijn van Groningen, info, MethodDeclaration, logger.info("--> start the shards (replicas)");
145: Martijn van Groningen, info, MethodDeclaration, logger.info("--> verify only enabled index has been routed");
162: Simon Willnauer, info, MethodDeclaration, logger.info("Building initial routing table");
175: Simon Willnauer, info, MethodDeclaration, logger.info("--> adding one nodes and do rerouting");
182: Simon Willnauer, info, MethodDeclaration, logger.info("--> start the shards (primaries)");
191: Simon Willnauer, info, MethodDeclaration, logger.info("--> adding one nodes and do rerouting");
255: Simon Willnauer, info, MethodDeclaration, logger.info("Building initial routing table");
266: Simon Willnauer, info, MethodDeclaration, logger.info("--> adding one nodes and do rerouting");
273: Simon Willnauer, info, MethodDeclaration, logger.info("--> start the shards (primaries)");
278: Simon Willnauer, info, MethodDeclaration, logger.info("--> adding one nodes and do rerouting");
92: Boaz Leskes, info, LambdaExpr, logger.info("--> got: {} nodes", info.getNodeLeastAvailableDiskUsages().size());
102: Lee Hinman, info, WhileStmt, logger.info("--> node {} has {} shards", node.nodeId(), resp.getState().getRoutingNodes().node(node.nodeId()).numberOfOwningShards());
119: Boaz Leskes, info, WhileStmt, logger.info("--> node {} has {} shards", node.nodeId(), resp12.getState().getRoutingNodes().node(node.nodeId()).numberOfOwningShards());
141: Boaz Leskes, info, WhileStmt, logger.info("--> node {} has {} shards", node.nodeId(), resp1.getState().getRoutingNodes().node(node.nodeId()).numberOfOwningShards());
74: Simon Willnauer, info, MethodDeclaration, logger.info("--> balance index [test]");
86: Simon Willnauer, info, MethodDeclaration, logger.info("--> balance index [test_1]");
261: Yannick Welsch, debug, MethodDeclaration, logger.debug("Keys in 'before' map: {}", keys);
262: Yannick Welsch, debug, MethodDeclaration, logger.debug("Keys to remove: {}", keysToRemove);
263: Yannick Welsch, debug, MethodDeclaration, logger.debug("Keys to override: {}", keysToOverride);
264: Yannick Welsch, debug, MethodDeclaration, logger.debug("Keys to add: {}", keysToAdd);
266: Yannick Welsch, debug, MethodDeclaration, logger.debug("--> creating 'before' map");
273: Yannick Welsch, debug, MethodDeclaration, logger.debug("--> creating 'after' map");
310: Yannick Welsch, debug, IfStmt, logger.debug("--> serializing diff");
314: Yannick Welsch, debug, IfStmt, logger.debug("--> reading diff back");
106: Nhat Nguyen, error, MethodDeclaration, logger.error(() -> new ParameterizedMessage("failed to execute callback in test {}", source), e);
174: Nhat Nguyen, error, MethodDeclaration, logger.error(() -> new ParameterizedMessage("failed to execute callback in test {}", source), e);
245: Nhat Nguyen, error, MethodDeclaration, logger.error(() -> new ParameterizedMessage("failed to execute callback in test {}", source), e);
316: Nhat Nguyen, error, MethodDeclaration, logger.error(() -> new ParameterizedMessage("failed to execute callback in test {}", source), e);
211: Nhat Nguyen, error, MethodDeclaration, logger.error(() -> new ParameterizedMessage("unexpected failure: [{}]", source), e);
136: Yannick Welsch, trace, MethodDeclaration, logger.trace("will process {}", source);
148: Yannick Welsch, debug, LambdaExpr, logger.debug("task [{}] timed out after [{}]", task, timeout);
173: Adrien Grand, info, MethodDeclaration, logger.info(numDocs + " docs indexed at " + numDocsPerSecond + " docs/s required " + new ByteSizeValue(size) + " bytes of disk space, or " + bytesPerDoc + " bytes per document. Took: " + new TimeValue(time) + ".");
164: Lee Hinman, info, IfStmt, logger.info("--> parent tripped");
191: Lee Hinman, info, MethodDeclaration, logger.info("--> NUM_THREADS: [{}], BYTES_PER_THREAD: [{}], TOTAL_BYTES: [{}], PARENT_LIMIT: [{}], CHILD_LIMIT: [{}]", NUM_THREADS, BYTES_PER_THREAD, (BYTES_PER_THREAD * NUM_THREADS), parentLimit, childLimit);
194: Lee Hinman, info, MethodDeclaration, logger.info("--> starting threads...");
203: Lee Hinman, info, MethodDeclaration, logger.info("--> child breaker: used: {}, limit: {}", breaker.getUsed(), breaker.getLimit());
204: Lee Hinman, info, MethodDeclaration, logger.info("--> parent tripped: {}, total trip count: {} (expecting 1-2 for each)", parentTripped.get(), tripped.get());
59: Yannick Welsch, debug, MethodDeclaration, logger.debug("numberOfEntries: {}", numberOfEntries);
222: Jason Tedor, Warn, MethodDeclaration, final String first = DeprecationLogger.formatWarning(s);
223: Jason Tedor, Warn, MethodDeclaration, assertThat(DeprecationLogger.extractWarningValueFromWarningHeader(first), equalTo(s));
65: Nhat Nguyen, error, MethodDeclaration, testLogger.error(() -> new ParameterizedMessage("an error message"), ex);
71: Nhat Nguyen, warn, MethodDeclaration, testLogger.warn(() -> new ParameterizedMessage("a warn message: [{}]", "long gc"), ex);
77: Nhat Nguyen, info, MethodDeclaration, testLogger.info(() -> new ParameterizedMessage("an info message a=[{}], b=[{}], c=[{}]", 1, 2, 3));
84: Nhat Nguyen, debug, MethodDeclaration, testLogger.debug(() -> new ParameterizedMessage("a debug message options = {}", Arrays.asList("yes", "no")), ex);
91: Nhat Nguyen, trace, MethodDeclaration, testLogger.trace(() -> new ParameterizedMessage("a trace message; element = [{}]", new Object[] { null }), ex);
345: Christoph BÃ¼scher, error, CatchClause, logger.error("Rounding error at {}, timezone {}, interval: {},", new DateTime(date, tz), tz, interval);
313: Lee Hinman, info, LambdaExpr, logger.info("--> consuming settings {}", map);
94: Chris Earle, trace, MethodDeclaration, inOrder.verify(logger).trace(anyString());
46: Lee Hinman, info, MethodDeclaration, logger.info("--> auto-queue with a measurement window of {} tasks", measureWindow);
54: Lee Hinman, info, MethodDeclaration, logger.info("--> executor: {}", executor);
78: Lee Hinman, info, MethodDeclaration, logger.info("--> auto-queue with a measurement window of {} tasks", measureWindow);
86: Lee Hinman, info, MethodDeclaration, logger.info("--> executor: {}", executor);
107: Lee Hinman, info, MethodDeclaration, logger.info("--> auto-queue with a measurement window of {} tasks", measureWindow);
114: Lee Hinman, info, MethodDeclaration, logger.info("--> executor: {}", executor);
136: Lee Hinman, info, MethodDeclaration, logger.info("--> auto-queue with a measurement window of {} tasks", measureWindow);
143: Lee Hinman, info, MethodDeclaration, logger.info("--> executor: {}", executor);
166: Lee Hinman, info, MethodDeclaration, logger.info("--> auto-queue with a measurement window of {} tasks", measureWindow);
173: Lee Hinman, info, MethodDeclaration, logger.info("--> executor: {}", executor);
199: Lee Hinman, info, MethodDeclaration, logger.info("--> executor: {}", executor);
248: Lee Hinman, info, MethodDeclaration, logger.info("--> executing a task [{}] times", times);
181: Jason Tedor, Warn, MethodDeclaration, final String value = DeprecationLogger.formatWarning("qux");
185: Jason Tedor, Warn, IfStmt, final String duplicateValue = DeprecationLogger.formatWarning("qux");
170: Jason Tedor, info, MethodDeclaration, logger.info("---> configured unicast");
220: Boaz Leskes, trace, LambdaExpr, logger.trace("[{}] master is [{}]", node, state.nodes().getMasterNode());
61: Jason Tedor, error, MethodDeclaration, logger.error("unexpected error", e);
102: Jason Tedor, info, MethodDeclaration, logger.info("disruption scheme [{}] added", disruptionScheme);
113: Jason Tedor, info, MethodDeclaration, logger.info("starting indexers");
222: Jason Tedor, debug, IfStmt, logger.debug("Indexing exceptions during disruption: {}", sb);
224: Jason Tedor, info, TryStmt, logger.info("shutting down indexers");
152: Nhat Nguyen, info, CatchClause, logger.info(() -> new ParameterizedMessage("unexpected exception in background thread of [{}]", node), e);
128: Jason Tedor, info, TryStmt, logger.info("[{}] Acquired semaphore and it has {} permits left", name, semaphore.availablePermits());
144: Nhat Nguyen, trace, CatchClause, logger.trace(() -> new ParameterizedMessage("[{}] failed id [{}] through node [{}]", name, docId, node), e);
147: Jason Tedor, trace, TryStmt, logger.trace("[{}] decreased counter : {}", name, countDownLatchRef.get().getCount());
132: Jason Tedor, trace, TryStmt, logger.trace("[{}] indexing id [{}] through node [{}] targeting shard [{}]", name, id, node, shard);
140: Nhat Nguyen, trace, TryStmt, logger.trace("[{}] indexed id [{}] through node [{}], response [{}]", name, id, node, response);
163: Jason Tedor, info, TryStmt, logger.info("indexing {} docs per indexer before partition", docsPerIndexer);
171: Jason Tedor, info, ForStmt, logger.info("starting disruptions & indexing (iteration [{}])", iter);
175: Jason Tedor, info, ForStmt, logger.info("indexing {} docs per indexer during partition", docsPerIndexer);
182: Jason Tedor, info, ForStmt, logger.info("waiting for indexing requests to complete");
185: Jason Tedor, info, ForStmt, logger.info("stopping disruption");
199: Jason Tedor, info, ForStmt, logger.info("validating successful docs");
203: Jason Tedor, debug, TryStmt, logger.debug("validating through node [{}] ([{}] acked docs)", node, ackedDocs.size());
214: Jason Tedor, info, ForStmt, logger.info("done validating (iteration [{}])", iter);
264: Jason Tedor, info, MethodDeclaration, logger.info("Verifying if document exists via node[{}]", notIsolatedNode);
278: Jason Tedor, info, ForeachStmt, logger.info("Verifying if document exists after isolating node[{}] via node[{}]", isolatedNode, node);
368: Jason Tedor, info, MethodDeclaration, logger.info("--> creating index [test] with one shard and on replica");
109: Jason Tedor, info, MethodDeclaration, logger.info("---> legit elected master node={}", masterNode);
159: Jason Tedor, info, MethodDeclaration, logger.info("blocking requests from non master [{}] to master [{}]", nonMasterNode, masterNode);
166: Jason Tedor, info, MethodDeclaration, logger.info("blocking cluster state publishing from master [{}] to non master [{}]", masterNode, nonMasterNode);
177: Jason Tedor, info, MethodDeclaration, logger.info("allowing requests from non master [{}] to master [{}], waiting for two join request", nonMasterNode, masterNode);
199: Jason Tedor, info, MethodDeclaration, logger.info("waiting for cluster to reform");
218: Jason Tedor, info, MethodDeclaration, logger.info("applying disruption while cluster is forming ...");
234: Jason Tedor, info, MethodDeclaration, logger.info("--> forcing a complete election to make sure \"preferred\" master is elected");
248: Jason Tedor, info, MethodDeclaration, logger.info("--> preferred master is {}", preferredMaster);
265: Jason Tedor, info, MethodDeclaration, logger.info("--> forcing a complete election again");
297: Jason Tedor, info, MethodDeclaration, logger.info("blocking request from master [{}] to [{}]", masterNode, nonMasterNode);
306: Jason Tedor, info, MethodDeclaration, logger.info("waiting for [{}] to be removed from cluster", nonMasterNode);
309: Jason Tedor, info, MethodDeclaration, logger.info("waiting for [{}] to have no master", nonMasterNode);
312: Jason Tedor, info, MethodDeclaration, logger.info("healing partition and checking cluster reforms");
75: Jason Tedor, info, MethodDeclaration, logger.info("---> legit elected master node={}", masterNode);
115: Jason Tedor, info, MethodDeclaration, logger.info("--> stopping current master");
120: Jason Tedor, info, MethodDeclaration, logger.info("--> reducing min master nodes to 2");
133: Jason Tedor, info, MethodDeclaration, logger.info("--> isolating [{}]", nonMaster);
138: Jason Tedor, info, MethodDeclaration, logger.info("--> waiting for master to remove it");
175: Jason Tedor, info, IfStmt, logger.info("node {} received new cluster state: {} \n and had previous cluster state: {}", node, event.state(), event.previousState());
192: Jason Tedor, info, MethodDeclaration, logger.info("freezing node [{}]", oldMasterNode);
207: Jason Tedor, error, IfStmt, logger.error("discovery failed to complete, probably caused by a blocked thread: {}", new HotThreads().busiestThreads(Integer.MAX_VALUE).ignoreIdleThreads(false).detect());
225: Nhat Nguyen, warn, MethodDeclaration, logger.warn(() -> new ParameterizedMessage("failure [{}]", source), e);
231: Jason Tedor, info, MethodDeclaration, logger.info("new detected master node [{}]", newMasterNode);
234: Jason Tedor, info, MethodDeclaration, logger.info("Unfreeze node [{}]", oldMasterNode);
276: Jason Tedor, info, MethodDeclaration, logger.info("waiting for nodes to de-elect master [{}]", oldMasterNode);
281: Jason Tedor, info, MethodDeclaration, logger.info("waiting for nodes to elect a new master");
284: Jason Tedor, info, MethodDeclaration, logger.info("waiting for any pinging to stop");
338: Jason Tedor, info, MethodDeclaration, logger.info("issue a reroute");
407: Jason Tedor, info, MethodDeclaration, logger.info("wait until elected master has been removed and a new 2 node cluster was from (via [{}])", isolatedNode);
431: Jason Tedor, info, MethodDeclaration, logger.info("Verify no master block with {} set to {}", DiscoverySettings.NO_MASTER_BLOCK_SETTING.getKey(), "all");
69: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
103: Igor Motov, info, IfStmt, logger.info("--> starting disruption");
112: Igor Motov, info, MethodDeclaration, logger.info("--> starting snapshot");
116: Igor Motov, info, MethodDeclaration, logger.info("--> waiting for disruption to start");
119: Igor Motov, info, MethodDeclaration, logger.info("--> wait until the snapshot is done");
127: Igor Motov, info, IfStmt, logger.info("Snapshot is no longer in the cluster state");
124: Igor Motov, info, IfStmt, logger.info("Current snapshot state [{}]", snapshots.entries().get(0).state());
131: Igor Motov, info, MethodDeclaration, logger.info("--> verify that snapshot was successful or no longer exist");
142: Igor Motov, info, CatchClause, logger.info("--> snapshot doesn't exist");
140: Igor Motov, info, TryStmt, logger.info("--> done verifying");
146: Igor Motov, info, MethodDeclaration, logger.info("--> stopping disrupting");
149: Igor Motov, info, MethodDeclaration, logger.info("--> done");
154: Igor Motov, info, CatchClause, logger.info("--> got exception from hanged master", ex);
165: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
194: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> testing joins fail post accumulation");
218: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> using requiredJoins [{}]", requiredJoins);
234: Jason Tedor, error, MethodDeclaration, logger.error("unexpected error from waitToBeElectedAsMaster", e);
251: Boaz Leskes, error, MethodDeclaration, logger.error("unexpected error while waiting to be elected as master", t);
259: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> requiredJoins is set to 0. verifying election finished");
267: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> using requiredJoins [{}]", requiredJoins);
283: Jason Tedor, error, MethodDeclaration, logger.error("unexpected error from waitToBeElectedAsMaster", e);
300: Boaz Leskes, error, MethodDeclaration, logger.error("unexpected error while waiting to be elected as master", t);
330: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> joining [{}] unique master nodes. Total of [{}] join requests", initialJoins, nodesToJoin.size());
335: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> asserting master election didn't finish yet");
356: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> joining [{}] nodes, with repetition a total of [{}]", finalJoins, nodesToJoin.size());
360: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> waiting for master election to with no exception");
363: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> waiting on all joins to be processed");
365: Boaz Leskes, debug, ForeachStmt, logger.debug("waiting on {}", future);
369: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> testing accumulation stopped");
379: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> using requiredJoins [{}]", requiredJoins);
401: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> joining [{}] nodes, with repetition a total of [{}]", initialJoins, nodesToJoin.size());
423: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> verifying election timed out");
426: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> verifying all joins are failed");
428: Boaz Leskes, debug, ForeachStmt, logger.debug("waiting on {}", future);
465: Jason Tedor, error, MethodDeclaration, logger.error("unexpected error in join thread", e);
473: Boaz Leskes, debug, ForStmt, logger.debug("{} joining", node);
481: Boaz Leskes, info, MethodDeclaration, logger.info("--> waiting for joins to complete");
507: Jason Tedor, error, MethodDeclaration, logger.error("unexpected error in join thread", e);
515: Boaz Leskes, debug, ForStmt, logger.debug("{} joining", node);
524: Boaz Leskes, info, MethodDeclaration, logger.info("--> waiting to be elected as master (required joins [{}])", requiredJoins);
537: Boaz Leskes, error, MethodDeclaration, logger.error("unexpected error while waiting to be elected as master", t);
546: Boaz Leskes, info, MethodDeclaration, logger.info("--> waiting for joins to complete");
757: Boaz Leskes, error, MethodDeclaration, logger.error("failed to be elected as master", t);
792: Boaz Leskes, info, MethodDeclaration, logger.info("assert for [{}] in:\n{}", expectedNodes, state);
825: Boaz Leskes, debug, MethodDeclaration, logger.debug("starting {}", future);
831: Boaz Leskes, debug, MethodDeclaration, logger.debug("{} completed", future);
837: Nhat Nguyen, error, MethodDeclaration, logger.error(() -> new ParameterizedMessage("unexpected error for {}", future), e);
151: Yannick Welsch, debug, IfStmt, logger.debug("[{}] received version [{}], uuid [{}]", discoveryNode.getName(), newClusterState.version(), newClusterState.stateUUID());
538: Boaz Leskes, debug, CatchClause, logger.debug("failed to publish as expected", expected);
604: Boaz Leskes, info, MethodDeclaration, logger.info("--> expecting commit to {}. good nodes [{}], errors [{}], timeouts [{}]. min_master_nodes [{}]", expectedBehavior, goodNodes + 1, errorNodes, timeOutNodes, minMasterNodes);
618: Boaz Leskes, debug, CatchClause, logger.debug("failed to publish as expected", exception);
638: Jason Tedor, info, MethodDeclaration, logger.info("--> publishing states");
649: Boaz Leskes, info, MethodDeclaration, logger.info("--> committing states");
690: Boaz Leskes, debug, ForStmt, logger.debug("--> publishing version [{}], UUID [{}]", state.version(), state.stateUUID());
698: Boaz Leskes, debug, ForStmt, logger.debug("--> publishing [{}], verifying...", success ? "succeeded" : "failed");
124: Boaz Leskes, info, TryStmt, logger.info("shutting down...");
176: Boaz Leskes, info, MethodDeclaration, logger.info("UZP_D version set to [{}]", versionD);
229: Jason Tedor, info, MethodDeclaration, logger.info("ping from UZP_A");
240: Jason Tedor, info, MethodDeclaration, logger.info("ping from UZP_B");
250: Jason Tedor, info, MethodDeclaration, logger.info("ping from UZP_C");
257: Jason Tedor, info, MethodDeclaration, logger.info("ping from UZP_D");
266: Yannick Welsch, info, MethodDeclaration, logger.info("ping from UZP_D after closing UZP_C");
517: Jason Tedor, warn, MethodDeclaration, verify(logger).warn("failed to resolve host [" + hostname + "]", unknownHostException);
576: Jason Tedor, trace, TryStmt, verify(logger).trace("resolved host [{}] to {}", "hostname1", new TransportAddress[] { new TransportAddress(TransportAddress.META_ADDRESS, 9300) });
579: Jason Tedor, warn, TryStmt, verify(logger).warn("timed out after [{}] resolving host [{}]", resolveTimeout, "hostname2");
691: Boaz Leskes, info, BlockStmt, logger.info("pinging from UZP_A so UZP_B will learn about it");
699: Boaz Leskes, info, BlockStmt, logger.info("pinging from UZP_B");
744: Jason Tedor, warn, MethodDeclaration, verify(logger).warn(eq("failed to resolve host [127.0.0.1:9300:9300]"), Matchers.any(ExecutionException.class));
892: Boaz Leskes, trace, MethodDeclaration, logger.trace("task [{}] started. count [{}]", task, pendingTasks.incrementAndGet());
897: Boaz Leskes, trace, MethodDeclaration, logger.trace("task [{}] completed. count [{}]", task, left);
270: xuzha, info, MethodDeclaration, logger.info("--> request node discovery stats");
419: Yannick Welsch, info, MethodDeclaration, logger.info("--> testing acceptances of any master when having no master");
428: Yannick Welsch, info, MethodDeclaration, logger.info("--> testing rejection of another master");
436: Yannick Welsch, info, MethodDeclaration, logger.info("--> test state from the current master is accepted");
442: Yannick Welsch, info, MethodDeclaration, logger.info("--> testing rejection of another cluster name");
451: Yannick Welsch, info, MethodDeclaration, logger.info("--> testing rejection of a cluster state with wrong local node");
474: Yannick Welsch, info, MethodDeclaration, logger.info("--> testing acceptance of an old cluster state");
30: kimchy, info, MethodDeclaration, logger.info("Creating index [test1] with alias [test]");
36: kimchy, info, MethodDeclaration, logger.info("--> creating index test");
67: kimchy, info, MethodDeclaration, logger.info("Running Cluster Health");
69: kimchy, info, MethodDeclaration, logger.info("Indexing [type1/1]");
75: kimchy, info, MethodDeclaration, logger.info("Refreshing");
79: kimchy, info, MethodDeclaration, logger.info("--> index exists?");
81: kimchy, info, MethodDeclaration, logger.info("--> index exists?, fake index");
84: kimchy, info, MethodDeclaration, logger.info("Clearing cache");
90: Lee Hinman, info, MethodDeclaration, logger.info("Force Merging");
97: kimchy, info, MethodDeclaration, logger.info("Get [type1/1]");
108: kimchy, info, MethodDeclaration, logger.info("Get [type1/1] with script");
117: kimchy, info, MethodDeclaration, logger.info("Get [type1/2] (should be empty)");
123: kimchy, info, MethodDeclaration, logger.info("Delete [type1/1]");
128: kimchy, info, MethodDeclaration, logger.info("Refreshing");
131: kimchy, info, MethodDeclaration, logger.info("Get [type1/1] (should be empty)");
137: kimchy, info, MethodDeclaration, logger.info("Index [type1/1]");
139: kimchy, info, MethodDeclaration, logger.info("Index [type1/2]");
142: kimchy, info, MethodDeclaration, logger.info("Flushing");
146: kimchy, info, MethodDeclaration, logger.info("Refreshing");
149: kimchy, info, MethodDeclaration, logger.info("Get [type1/1] and [type1/2]");
161: kimchy, info, MethodDeclaration, logger.info("Count");
185: kimchy, info, MethodDeclaration, logger.info("-> running Cluster Health");
105: Martijn van Groningen, info, MethodDeclaration, logger.info("Number of nodes: {}", numNodes);
108: Martijn van Groningen, info, MethodDeclaration, logger.info("Number of copies: {}", numCopies);
266: Jason Tedor, error, MethodDeclaration, logger.error("unexpected error", e);
341: Shay Banon, error, CatchClause, logger.error("unexpected failure", e);
70: kimchy, info, MethodDeclaration, logger.info("--> starting 1 nodes");
73: kimchy, info, MethodDeclaration, logger.info("--> creating test index, with meta routing");
79: kimchy, info, MethodDeclaration, logger.info("--> verify meta _routing required exists");
84: Simon Willnauer, info, MethodDeclaration, logger.info("--> restarting nodes...");
87: kimchy, info, MethodDeclaration, logger.info("--> waiting for yellow status");
90: kimchy, info, MethodDeclaration, logger.info("--> verify meta _routing required exists");
96: kimchy, info, MethodDeclaration, logger.info("--> starting 2 nodes");
99: kimchy, info, MethodDeclaration, logger.info("--> creating test index");
104: kimchy, info, MethodDeclaration, logger.info("--> waiting for green status");
113: kimchy, info, MethodDeclaration, logger.info("--> indexing a simple document");
116: kimchy, info, MethodDeclaration, logger.info("--> closing test index...");
123: kimchy, info, MethodDeclaration, logger.info("--> verifying that the state is green");
126: kimchy, info, MethodDeclaration, logger.info("--> trying to index into a closed index ...");
134: kimchy, info, MethodDeclaration, logger.info("--> creating another index (test2) by indexing into it");
136: kimchy, info, MethodDeclaration, logger.info("--> verifying that the state is green");
139: kimchy, info, MethodDeclaration, logger.info("--> opening the first index again...");
142: kimchy, info, MethodDeclaration, logger.info("--> verifying that the state is green");
151: kimchy, info, MethodDeclaration, logger.info("--> trying to get the indexed document on the first index");
155: kimchy, info, MethodDeclaration, logger.info("--> closing test index...");
161: Simon Willnauer, info, MethodDeclaration, logger.info("--> restarting nodes...");
163: kimchy, info, MethodDeclaration, logger.info("--> waiting for two nodes and green status");
170: kimchy, info, MethodDeclaration, logger.info("--> trying to index into a closed index ...");
178: kimchy, info, MethodDeclaration, logger.info("--> opening index...");
181: kimchy, info, MethodDeclaration, logger.info("--> waiting for green status");
190: kimchy, info, MethodDeclaration, logger.info("--> trying to get the indexed document on the first round (before close and shutdown)");
194: kimchy, info, MethodDeclaration, logger.info("--> indexing a simple document");
199: kimchy, info, MethodDeclaration, logger.info("--> cleaning nodes");
201: kimchy, info, MethodDeclaration, logger.info("--> starting 1 master node non data");
204: kimchy, info, MethodDeclaration, logger.info("--> create an index");
207: kimchy, info, MethodDeclaration, logger.info("--> closing master node");
210: kimchy, info, MethodDeclaration, logger.info("--> starting 1 master node non data again");
213: kimchy, info, MethodDeclaration, logger.info("--> waiting for test index to be created");
218: kimchy, info, MethodDeclaration, logger.info("--> verify we have an index");
224: kimchy, info, MethodDeclaration, logger.info("--> cleaning nodes");
226: kimchy, info, MethodDeclaration, logger.info("--> starting 1 master node non data");
230: kimchy, info, MethodDeclaration, logger.info("--> create an index");
237: kimchy, info, MethodDeclaration, logger.info("--> cleaning nodes");
239: kimchy, info, MethodDeclaration, logger.info("--> starting 2 nodes");
242: kimchy, info, MethodDeclaration, logger.info("--> indexing a simple document");
245: kimchy, info, MethodDeclaration, logger.info("--> waiting for green status");
250: kimchy, info, MethodDeclaration, logger.info("--> verify 1 doc in the index");
255: kimchy, info, MethodDeclaration, logger.info("--> closing test index...");
262: kimchy, info, MethodDeclaration, logger.info("--> opening the index...");
265: kimchy, info, MethodDeclaration, logger.info("--> waiting for green status");
270: kimchy, info, MethodDeclaration, logger.info("--> verify 1 doc in the index");
278: Shay Banon, info, MethodDeclaration, logger.info("--> starting two nodes");
282: Shay Banon, info, MethodDeclaration, logger.info("--> indexing a simple document");
285: Shay Banon, info, MethodDeclaration, logger.info("--> waiting for green status");
288: Shay Banon, info, MethodDeclaration, logger.info("--> verify 1 doc in the index");
294: Simon Willnauer, info, MethodDeclaration, logger.info("--> restarting the nodes");
302: Shay Banon, info, MethodDeclaration, logger.info("--> waiting for green status");
313: Shay Banon, info, MethodDeclaration, logger.info("--> verify that the dangling index exists");
315: Shay Banon, info, MethodDeclaration, logger.info("--> waiting for green status");
318: Shay Banon, info, MethodDeclaration, logger.info("--> verify the doc is there");
331: Lee Hinman, info, MethodDeclaration, logger.info("--> starting a cluster with " + numNodes + " nodes");
334: Lee Hinman, info, MethodDeclaration, logger.info("--> create an index");
337: Ali Beyad, info, MethodDeclaration, logger.info("--> waiting for green status");
341: Ali Beyad, info, MethodDeclaration, logger.info("--> restart a random date node, deleting the index in between stopping and restarting");
346: Ali Beyad, info, MethodDeclaration, logger.info("--> stopped node[{}], remaining nodes {}", nodeName, nodes);
349: Ali Beyad, info, MethodDeclaration, logger.info("--> delete index and verify it is deleted");
357: Ali Beyad, info, MethodDeclaration, logger.info("--> wait until all nodes are back online");
361: Ali Beyad, info, MethodDeclaration, logger.info("--> waiting for green status");
364: Ali Beyad, info, MethodDeclaration, logger.info("--> verify that the deleted index is removed from the cluster and not reimported as dangling by the restarted node");
371: Ali Beyad, error, CatchClause, logger.error("Unable to retrieve available index folders from the node", e);
383: Simon Willnauer, info, MethodDeclaration, logger.info("--> starting one node");
385: Simon Willnauer, info, MethodDeclaration, logger.info("--> indexing a simple document");
387: Simon Willnauer, info, MethodDeclaration, logger.info("--> waiting for green status");
432: Simon Willnauer, info, MethodDeclaration, logger.info("--> starting one node");
447: Simon Willnauer, info, MethodDeclaration, logger.info("--> indexing a simple document");
449: Simon Willnauer, info, MethodDeclaration, logger.info("--> waiting for green status");
483: Simon Willnauer, info, MethodDeclaration, logger.info("--> starting one node");
486: Simon Willnauer, info, MethodDeclaration, logger.info("--> waiting for green status");
216: Robert Muir, debug, TryStmt, logger.debug("Corrupting file {} --  flipping at position {} from {} to {} ", fileToCorrupt.getFileName().toString(), filePointer, Integer.toHexString(oldValue), Integer.toHexString(newValue));
231: Yannick Welsch, debug, TryStmt, logger.debug("{}", msg.toString());
74: Britta Weber, debug, MethodDeclaration, logger.debug("relocating index...");
89: Britta Weber, info, MethodDeclaration, logger.info("--> wait for green index");
91: Britta Weber, info, MethodDeclaration, logger.info("--> wait for meta state written for index");
95: Britta Weber, info, MethodDeclaration, logger.info("--> close index");
153: Britta Weber, info, LambdaExpr, logger.info("checking if index directory exists...");
161: Jason Tedor, info, LambdaExpr, logger.info("checking if meta state exists...");
165: Jason Tedor, info, CatchClause, logger.info("failed to load meta state", e);
47: kimchy, info, MethodDeclaration, logger.info("--> starting 3 nodes");
55: kimchy, info, MethodDeclaration, logger.info("--> indexing...");
66: Simon Willnauer, info, MethodDeclaration, logger.info("--> restart all nodes");
77: Jason Tedor, info, LambdaExpr, logger.info("--> running cluster_health (wait for the shards to startup)");
79: Yannick Welsch, info, LambdaExpr, logger.info("--> done cluster_health, status {}", clusterHealth.getStatus());
82: Simon Willnauer, info, IfStmt, logger.info("--> one node is closed -- index 1 document into the remaining nodes");
92: Simon Willnauer, info, MethodDeclaration, logger.info("--> all nodes are started back, verifying we got the latest version");
93: kimchy, info, MethodDeclaration, logger.info("--> running cluster_health (wait for the shards to startup)");
61: kimchy, info, MethodDeclaration, logger.info("--> start node (1)");
67: kimchy, info, MethodDeclaration, logger.info("--> start node (2)");
77: kimchy, info, MethodDeclaration, logger.info("--> start node (3)");
86: kimchy, info, MethodDeclaration, logger.info("--> start master_node (1)");
94: kimchy, info, MethodDeclaration, logger.info("--> start data_node (1)");
105: kimchy, info, MethodDeclaration, logger.info("--> start data_node (2)");
119: kimchy, info, MethodDeclaration, logger.info("--> start master_node (2)");
131: kimchy, info, MethodDeclaration, logger.info("--> start master_node (1)");
140: kimchy, info, MethodDeclaration, logger.info("--> start data_node (1)");
152: kimchy, info, MethodDeclaration, logger.info("--> start master_node (2)");
167: kimchy, info, MethodDeclaration, logger.info("--> start data_node (2)");
113: kimchy, info, MethodDeclaration, logger.info("Running Cluster Health (wait for the shards to startup)");
122: kimchy, info, MethodDeclaration, logger.info("Running Cluster Health (wait for the shards to startup)");
208: Boaz Leskes, info, IfStmt, logger.info("Ensure all primaries have been started");
216: kimchy, info, MethodDeclaration, logger.info("Running Cluster Health (wait for the shards to startup)");
230: kimchy, info, MethodDeclaration, logger.info("Running Cluster Health (wait for the shards to startup)");
258: kimchy, info, MethodDeclaration, logger.info("Running Cluster Health (wait for the shards to startup)");
268: kimchy, info, MethodDeclaration, logger.info("Running Cluster Health (wait for the shards to startup)");
286: kimchy, info, MethodDeclaration, logger.info("Running Cluster Health (wait for the shards to startup)");
308: kimchy, info, MethodDeclaration, logger.info("Running Cluster Health (wait for the shards to startup)");
327: kimchy, info, MethodDeclaration, logger.info("--> running cluster_health (wait for the shards to startup)");
337: kimchy, info, MethodDeclaration, logger.info("--> closing first node, and indexing more data to the second node");
340: Boaz Leskes, info, MethodDeclaration, logger.info("--> one node is closed - start indexing data into the second one");
348: Lee Hinman, info, MethodDeclaration, logger.info("--> checking if documents exist, there should be 3");
353: Simon Willnauer, info, MethodDeclaration, logger.info("--> add some metadata and additional template");
364: Boaz Leskes, info, MethodDeclaration, logger.info("--> stopping the second node");
367: Boaz Leskes, info, MethodDeclaration, logger.info("--> starting the two nodes back");
371: kimchy, info, MethodDeclaration, logger.info("--> running cluster_health (wait for the shards to startup)");
398: Shay Banon, info, MethodDeclaration, logger.info("--> indexing docs");
420: Jason Tedor, info, MethodDeclaration, logger.info("--> restart replica node");
463: Lee Hinman, info, IfStmt, logger.info("--> replica shard {} recovered from {} to {}, recovered {}, reuse {}", recoveryState.getShardId().getId(), recoveryState.getSourceNode().getName(), recoveryState.getTargetNode().getName(), recoveryState.getIndex().recoveredBytes(), recoveryState.getIndex().reusedBytes());
542: Boaz Leskes, debug, IfStmt, logger.debug("--> deleting [{}]", item);
69: Britta Weber, info, MethodDeclaration, logger.info("--> indexing docs");
79: Britta Weber, info, MethodDeclaration, logger.info("--> running cluster health");
97: Britta Weber, info, IfStmt, logger.info("--> trying to sync flush");
86: Britta Weber, info, IfStmt, logger.info("--> disabling allocation while the cluster is shut down");
91: Britta Weber, info, IfStmt, logger.info("--> full cluster restart");
94: Britta Weber, info, IfStmt, logger.info("--> waiting for cluster to return to green after first shutdown");
102: Yannick Welsch, info, MethodDeclaration, logger.info("--> disabling allocation while the cluster is shut down{}", useSyncIds ? "" : " a second time");
107: Britta Weber, info, MethodDeclaration, logger.info("--> full cluster restart");
110: Britta Weber, info, MethodDeclaration, logger.info("--> waiting for cluster to return to green after {}shutdown", useSyncIds ? "" : "second ");
140: Britta Weber, info, IfStmt, logger.info("--> replica shard {} recovered from {} to {} using sync id, recovered {}, reuse {}", recoveryState.getShardId().getId(), recoveryState.getSourceNode().getName(), recoveryState.getTargetNode().getName(), recoveryState.getIndex().recoveredBytes(), recoveryState.getIndex().reusedBytes());
125: Britta Weber, info, IfStmt, logger.info("--> replica shard {} recovered from {} to {}, recovered {}, reuse {}", recoveryState.getShardId().getId(), recoveryState.getSourceNode().getName(), recoveryState.getTargetNode().getName(), recoveryState.getIndex().recoveredBytes(), recoveryState.getIndex().reusedBytes());
79: kimchy, info, MethodDeclaration, logger.info("--> index doc 1");
82: Simon Willnauer, info, MethodDeclaration, logger.info("--> non realtime get 1");
86: kimchy, info, MethodDeclaration, logger.info("--> realtime get 1");
93: Boaz Leskes, info, MethodDeclaration, logger.info("--> realtime get 1 (no source, implicit)");
101: Boaz Leskes, info, MethodDeclaration, logger.info("--> realtime get 1 (no source, explicit)");
109: kimchy, info, MethodDeclaration, logger.info("--> realtime get 1 (no type)");
116: Adrien Grand, info, MethodDeclaration, logger.info("--> realtime fetch of field");
124: Adrien Grand, info, MethodDeclaration, logger.info("--> realtime fetch of field & source");
135: Simon Willnauer, info, MethodDeclaration, logger.info("--> realtime get 1");
142: Simon Willnauer, info, MethodDeclaration, logger.info("--> refresh the index, so we load it from it");
145: kimchy, info, MethodDeclaration, logger.info("--> non realtime get 1 (loaded from index)");
152: kimchy, info, MethodDeclaration, logger.info("--> realtime fetch of field (loaded from index)");
160: Boaz Leskes, info, MethodDeclaration, logger.info("--> realtime fetch of field & source (loaded from index)");
169: kimchy, info, MethodDeclaration, logger.info("--> update doc 1");
172: kimchy, info, MethodDeclaration, logger.info("--> realtime get 1");
179: kimchy, info, MethodDeclaration, logger.info("--> update doc 1 again");
299: Martijn van Groningen, info, MethodDeclaration, logger.info("--> index doc 1");
343: Martijn van Groningen, info, MethodDeclaration, logger.info("--> index doc 1 again, so increasing the version");
604: Boaz Leskes, info, MethodDeclaration, logger.info("indexing documents");
608: Boaz Leskes, info, MethodDeclaration, logger.info("checking real time retrieval");
625: Boaz Leskes, info, MethodDeclaration, logger.info("waiting for recoveries to complete");
630: Boaz Leskes, info, MethodDeclaration, logger.info("flushing");
641: Boaz Leskes, info, MethodDeclaration, logger.info("checking post-flush retrieval");
144: Simon Willnauer, TRACE, MethodDeclaration, assertEquals(SlowLogLevel.TRACE, log.getLevel());
163: Simon Willnauer, TRACE, MethodDeclaration, assertEquals(SlowLogLevel.TRACE, log.getLevel());
167: Adrien Grand, TRACE, MethodDeclaration, IndexMetaData metaData = newIndexMeta("index", Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, Version.CURRENT).put(IndexingSlowLog.INDEX_INDEXING_SLOWLOG_THRESHOLD_INDEX_TRACE_SETTING.getKey(), "100ms").put(IndexingSlowLog.INDEX_INDEXING_SLOWLOG_THRESHOLD_INDEX_DEBUG_SETTING.getKey(), "200ms").put(IndexingSlowLog.INDEX_INDEXING_SLOWLOG_THRESHOLD_INDEX_INFO_SETTING.getKey(), "300ms").put(IndexingSlowLog.INDEX_INDEXING_SLOWLOG_THRESHOLD_INDEX_WARN_SETTING.getKey(), "400ms").build());
176: Simon Willnauer, Trace, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(100).nanos(), log.getIndexTraceThreshold());
177: Simon Willnauer, Debug, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(200).nanos(), log.getIndexDebugThreshold());
178: Simon Willnauer, Info, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(300).nanos(), log.getIndexInfoThreshold());
179: Simon Willnauer, Warn, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(400).nanos(), log.getIndexWarnThreshold());
181: Simon Willnauer, TRACE, MethodDeclaration, settings.updateIndexMetaData(newIndexMeta("index", Settings.builder().put(IndexingSlowLog.INDEX_INDEXING_SLOWLOG_THRESHOLD_INDEX_TRACE_SETTING.getKey(), "120ms").put(IndexingSlowLog.INDEX_INDEXING_SLOWLOG_THRESHOLD_INDEX_DEBUG_SETTING.getKey(), "220ms").put(IndexingSlowLog.INDEX_INDEXING_SLOWLOG_THRESHOLD_INDEX_INFO_SETTING.getKey(), "320ms").put(IndexingSlowLog.INDEX_INDEXING_SLOWLOG_THRESHOLD_INDEX_WARN_SETTING.getKey(), "420ms").build()));
187: Simon Willnauer, Trace, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(120).nanos(), log.getIndexTraceThreshold());
188: Simon Willnauer, Debug, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(220).nanos(), log.getIndexDebugThreshold());
189: Simon Willnauer, Info, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(320).nanos(), log.getIndexInfoThreshold());
190: Simon Willnauer, Warn, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(420).nanos(), log.getIndexWarnThreshold());
196: Simon Willnauer, Trace, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getIndexTraceThreshold());
197: Simon Willnauer, Debug, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getIndexDebugThreshold());
198: Simon Willnauer, Info, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getIndexInfoThreshold());
199: Simon Willnauer, Warn, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getIndexWarnThreshold());
204: Simon Willnauer, Trace, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getIndexTraceThreshold());
205: Simon Willnauer, Debug, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getIndexDebugThreshold());
206: Simon Willnauer, Info, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getIndexInfoThreshold());
207: Simon Willnauer, Warn, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getIndexWarnThreshold());
209: Simon Willnauer, TRACE, TryStmt, settings.updateIndexMetaData(newIndexMeta("index", Settings.builder().put(IndexingSlowLog.INDEX_INDEXING_SLOWLOG_THRESHOLD_INDEX_TRACE_SETTING.getKey(), "NOT A TIME VALUE").build()));
216: Simon Willnauer, DEBUG, TryStmt, settings.updateIndexMetaData(newIndexMeta("index", Settings.builder().put(IndexingSlowLog.INDEX_INDEXING_SLOWLOG_THRESHOLD_INDEX_DEBUG_SETTING.getKey(), "NOT A TIME VALUE").build()));
223: Simon Willnauer, INFO, TryStmt, settings.updateIndexMetaData(newIndexMeta("index", Settings.builder().put(IndexingSlowLog.INDEX_INDEXING_SLOWLOG_THRESHOLD_INDEX_INFO_SETTING.getKey(), "NOT A TIME VALUE").build()));
230: Simon Willnauer, WARN, TryStmt, settings.updateIndexMetaData(newIndexMeta("index", Settings.builder().put(IndexingSlowLog.INDEX_INDEXING_SLOWLOG_THRESHOLD_INDEX_WARN_SETTING.getKey(), "NOT A TIME VALUE").build()));
199: Simon Willnauer, TRACE, MethodDeclaration, assertEquals(SlowLogLevel.TRACE, log.getLevel());
217: Simon Willnauer, TRACE, MethodDeclaration, assertEquals(SlowLogLevel.TRACE, log.getLevel());
221: Adrien Grand, TRACE, MethodDeclaration, IndexMetaData metaData = newIndexMeta("index", Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, Version.CURRENT).put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_QUERY_TRACE_SETTING.getKey(), "100ms").put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_QUERY_DEBUG_SETTING.getKey(), "200ms").put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_QUERY_INFO_SETTING.getKey(), "300ms").put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_QUERY_WARN_SETTING.getKey(), "400ms").build());
230: Simon Willnauer, Trace, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(100).nanos(), log.getQueryTraceThreshold());
231: Simon Willnauer, Debug, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(200).nanos(), log.getQueryDebugThreshold());
232: Simon Willnauer, Info, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(300).nanos(), log.getQueryInfoThreshold());
233: Simon Willnauer, Warn, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(400).nanos(), log.getQueryWarnThreshold());
235: Simon Willnauer, TRACE, MethodDeclaration, settings.updateIndexMetaData(newIndexMeta("index", Settings.builder().put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_QUERY_TRACE_SETTING.getKey(), "120ms").put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_QUERY_DEBUG_SETTING.getKey(), "220ms").put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_QUERY_INFO_SETTING.getKey(), "320ms").put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_QUERY_WARN_SETTING.getKey(), "420ms").build()));
241: Simon Willnauer, Trace, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(120).nanos(), log.getQueryTraceThreshold());
242: Simon Willnauer, Debug, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(220).nanos(), log.getQueryDebugThreshold());
243: Simon Willnauer, Info, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(320).nanos(), log.getQueryInfoThreshold());
244: Simon Willnauer, Warn, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(420).nanos(), log.getQueryWarnThreshold());
250: Simon Willnauer, Trace, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getQueryTraceThreshold());
251: Simon Willnauer, Debug, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getQueryDebugThreshold());
252: Simon Willnauer, Info, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getQueryInfoThreshold());
253: Simon Willnauer, Warn, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getQueryWarnThreshold());
258: Simon Willnauer, Trace, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getQueryTraceThreshold());
259: Simon Willnauer, Debug, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getQueryDebugThreshold());
260: Simon Willnauer, Info, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getQueryInfoThreshold());
261: Simon Willnauer, Warn, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getQueryWarnThreshold());
263: Simon Willnauer, TRACE, TryStmt, settings.updateIndexMetaData(newIndexMeta("index", Settings.builder().put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_QUERY_TRACE_SETTING.getKey(), "NOT A TIME VALUE").build()));
270: Simon Willnauer, DEBUG, TryStmt, settings.updateIndexMetaData(newIndexMeta("index", Settings.builder().put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_QUERY_DEBUG_SETTING.getKey(), "NOT A TIME VALUE").build()));
277: Simon Willnauer, INFO, TryStmt, settings.updateIndexMetaData(newIndexMeta("index", Settings.builder().put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_QUERY_INFO_SETTING.getKey(), "NOT A TIME VALUE").build()));
284: Simon Willnauer, WARN, TryStmt, settings.updateIndexMetaData(newIndexMeta("index", Settings.builder().put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_QUERY_WARN_SETTING.getKey(), "NOT A TIME VALUE").build()));
292: Adrien Grand, TRACE, MethodDeclaration, IndexMetaData metaData = newIndexMeta("index", Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, Version.CURRENT).put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_FETCH_TRACE_SETTING.getKey(), "100ms").put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_FETCH_DEBUG_SETTING.getKey(), "200ms").put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_FETCH_INFO_SETTING.getKey(), "300ms").put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_FETCH_WARN_SETTING.getKey(), "400ms").build());
301: Simon Willnauer, Trace, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(100).nanos(), log.getFetchTraceThreshold());
302: Simon Willnauer, Debug, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(200).nanos(), log.getFetchDebugThreshold());
303: Simon Willnauer, Info, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(300).nanos(), log.getFetchInfoThreshold());
304: Simon Willnauer, Warn, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(400).nanos(), log.getFetchWarnThreshold());
306: Simon Willnauer, TRACE, MethodDeclaration, settings.updateIndexMetaData(newIndexMeta("index", Settings.builder().put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_FETCH_TRACE_SETTING.getKey(), "120ms").put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_FETCH_DEBUG_SETTING.getKey(), "220ms").put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_FETCH_INFO_SETTING.getKey(), "320ms").put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_FETCH_WARN_SETTING.getKey(), "420ms").build()));
312: Simon Willnauer, Trace, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(120).nanos(), log.getFetchTraceThreshold());
313: Simon Willnauer, Debug, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(220).nanos(), log.getFetchDebugThreshold());
314: Simon Willnauer, Info, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(320).nanos(), log.getFetchInfoThreshold());
315: Simon Willnauer, Warn, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(420).nanos(), log.getFetchWarnThreshold());
321: Simon Willnauer, Trace, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getFetchTraceThreshold());
322: Simon Willnauer, Debug, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getFetchDebugThreshold());
323: Simon Willnauer, Info, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getFetchInfoThreshold());
324: Simon Willnauer, Warn, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getFetchWarnThreshold());
329: Simon Willnauer, Trace, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getFetchTraceThreshold());
330: Simon Willnauer, Debug, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getFetchDebugThreshold());
331: Simon Willnauer, Info, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getFetchInfoThreshold());
332: Simon Willnauer, Warn, MethodDeclaration, assertEquals(TimeValue.timeValueMillis(-1).nanos(), log.getFetchWarnThreshold());
334: Simon Willnauer, TRACE, TryStmt, settings.updateIndexMetaData(newIndexMeta("index", Settings.builder().put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_FETCH_TRACE_SETTING.getKey(), "NOT A TIME VALUE").build()));
341: Simon Willnauer, DEBUG, TryStmt, settings.updateIndexMetaData(newIndexMeta("index", Settings.builder().put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_FETCH_DEBUG_SETTING.getKey(), "NOT A TIME VALUE").build()));
348: Simon Willnauer, INFO, TryStmt, settings.updateIndexMetaData(newIndexMeta("index", Settings.builder().put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_FETCH_INFO_SETTING.getKey(), "NOT A TIME VALUE").build()));
355: Simon Willnauer, WARN, TryStmt, settings.updateIndexMetaData(newIndexMeta("index", Settings.builder().put(SearchSlowLog.INDEX_SEARCH_SLOWLOG_THRESHOLD_FETCH_WARN_SETTING.getKey(), "NOT A TIME VALUE").build()));
53: Simon Willnauer, info, MethodDeclaration, logger.info("Starting rounds [{}] ", rounds);
64: Simon Willnauer, info, ForStmt, logger.info("index round [{}] - segments {}, total merges {}, current merge {}", i, stats.getPrimaries().getSegments().getCount(), stats.getPrimaries().getMerge().getTotal(), stats.getPrimaries().getMerge().getCurrent());
69: Jason Tedor, info, LambdaExpr, logger.info("numshards {}, segments {}, total merges {}, current merge {}", numOfShards, stats.getPrimaries().getSegments().getCount(), stats.getPrimaries().getMerge().getTotal(), stats.getPrimaries().getMerge().getCurrent());
75: Simon Willnauer, info, MethodDeclaration, logger.info("numshards {}, segments {}, total merges {}, current merge {}", numOfShards, stats.getPrimaries().getSegments().getCount(), stats.getPrimaries().getMerge().getTotal(), stats.getPrimaries().getMerge().getCurrent());
1470: Boaz Leskes, info, ForeachStmt, logger.info("performing [{}], v [{}], seq# [{}], term [{}]", op.operationType().name().charAt(0), op.version(), op.seqNo(), op.primaryTerm());
1613: Boaz Leskes, info, ForeachStmt, logger.info("performing [{}]{}{}", op.operationType().name().charAt(0), versionConflict ? " (conflict " + conflictingVersion + ")" : "", versionedOp ? " (versioned " + correctVersion + ")" : "");
1718: Boaz Leskes, info, ForeachStmt, logger.info("performing [{}], v [{}], seq# [{}], term [{}]", op.operationType().name().charAt(0), op.version(), op.seqNo(), op.primaryTerm());
1768: Boaz Leskes, info, IfStmt, logger.info("searching for [{}]", lastFieldValue);
2052: Boaz Leskes, info, TryStmt, logger.info("localcheckpoint {}, global {}", replicaLocalCheckpoint, primarySeqNo);
2512: Boaz Leskes, trace, CatchClause, logger.trace("exception on open", e);
2742: Britta Weber, info, MethodDeclaration, logger.info("try with {}", operation);
2769: Jason Tedor, info, MethodDeclaration, logger.info("exception caught: ", exception.get());
3497: Lee Hinman, info, MethodDeclaration, logger.info("--> got seqID: {}", seqID);
3509: Lee Hinman, info, MethodDeclaration, logger.info("--> got seqID: {}", seqID);
3523: Lee Hinman, info, MethodDeclaration, logger.info("--> got seqID: {}", seqID);
114: Yannick Welsch, info, MethodDeclaration, logger.info("Keys: {}", aField.keySet());
176: Nik Everett, info, MethodDeclaration, logger.info("top: {} bottom: {}", top, bottom);
184: Nik Everett, info, TryStmt, logger.info("Rethrottled [{}] times", rethrottles);
217: Yannick Welsch, info, TryStmt, logger.info("--> isolated replica " + replica1.routingEntry());
223: Boaz Leskes, info, TryStmt, logger.info("--> promoting replica to primary " + replica1.routingEntry());
326: Nhat Nguyen, info, TryStmt, logger.info("--> Isolate replica1");
346: Nhat Nguyen, info, TryStmt, logger.info("--> Promote replica1 as the primary");
361: Nhat Nguyen, info, TryStmt, logger.info("--> Promote replica2 as the primary");
363: Nhat Nguyen, info, TryStmt, logger.info("--> Recover replica3 from replica2");
234: Boaz Leskes, info, IfStmt, logger.info("--> indexing {} rollback docs", rollbackDocs);
324: Nhat Nguyen, info, TryStmt, logger.info("--> indexing {} stale docs", staleDocs);
372: Yannick Welsch, info, TryStmt, logger.info("--> indexing {} extra docs", extraDocs);
379: Yannick Welsch, info, TryStmt, logger.info("--> resyncing replicas");
516: Jason Tedor, info, TryStmt, logger.info("indexed [{}] docs", docs);
627: Boaz Leskes, info, IfStmt, logger.info("--> blocking recovery on stage [{}]", currentStage);
631: Boaz Leskes, info, TryStmt, logger.info("--> recovery continues from stage [{}]", currentStage);
121: Boaz Leskes, info, MethodDeclaration, logger.info("--> will run [{}] threads, maxOps [{}], unfinished seq no [{}]", threads.length, maxOps, unFinishedSeq);
136: Boaz Leskes, info, ForStmt, logger.info("[t{}] started   [{}]", threadId, seqNo);
139: Boaz Leskes, info, IfStmt, logger.info("[t{}] completed [{}]", threadId, seqNo);
173: Boaz Leskes, info, MethodDeclaration, logger.info("--> will run [{}] threads, maxOps [{}], unfinished seq no [{}]", threads.length, maxOps, unFinishedSeq);
190: Boaz Leskes, info, IfStmt, logger.info("[t{}] completed [{}]", threadId, seqNo);
122: Jason Tedor, info, MethodDeclaration, logger.info("--> using allocations");
132: Jason Tedor, info, LambdaExpr, logger.info("  - [{}], local checkpoint [{}], [{}]", aId, allocations.get(aId), type);
207: Yannick Welsch, info, MethodDeclaration, logger.info("active: {}, initializing: {}", active, initializing);
127: Boaz Leskes, info, MethodDeclaration, logger.info("--> paths: [{}]", (Object) shardPaths);
229: Boaz Leskes, info, MethodDeclaration, logger.info("--> idxPath: [{}]", idxPath);
265: Boaz Leskes, info, MethodDeclaration, logger.info("--> start dir: [{}]", startDir.toAbsolutePath().toString());
266: Boaz Leskes, info, MethodDeclaration, logger.info("-->   end dir: [{}]", endDir.toAbsolutePath().toString());
280: Boaz Leskes, info, MethodDeclaration, logger.info("--> creating an index with data_path [{}]", startDir.toAbsolutePath().toString());
288: Boaz Leskes, info, MethodDeclaration, logger.info("--> closing the index [{}]", INDEX);
290: Boaz Leskes, info, MethodDeclaration, logger.info("--> index closed, re-opening...");
292: Boaz Leskes, info, MethodDeclaration, logger.info("--> index re-opened");
303: Boaz Leskes, info, MethodDeclaration, logger.info("--> moving data on disk [{}] to [{}]", startDir.getFileName(), endDir.getFileName());
307: Boaz Leskes, info, MethodDeclaration, logger.info("--> updating settings...");
315: Boaz Leskes, info, MethodDeclaration, logger.info("--> settings updated and files moved, re-opening index");
317: Boaz Leskes, info, MethodDeclaration, logger.info("--> index re-opened");
358: Nhat Nguyen, info, MethodDeclaration, logger.info("--> current translog size: [{}] num_ops [{}] generation [{}]", translog.stats().getUncommittedSizeInBytes(), translog.stats().getUncommittedOperations(), translog.getGeneration());
364: Nhat Nguyen, info, MethodDeclaration, logger.info("--> translog size after delete: [{}] num_ops [{}] generation [{}]", translog.stats().getUncommittedSizeInBytes(), translog.stats().getUncommittedOperations(), translog.getGeneration());
367: Nhat Nguyen, info, LambdaExpr, logger.info("--> translog size on iter  : [{}] num_ops [{}] generation [{}]", translog.stats().getUncommittedSizeInBytes(), translog.stats().getUncommittedOperations(), translog.getGeneration());
581: Lee Hinman, info, MethodDeclaration, logger.info("--> force merging to a single segment");
592: Lee Hinman, info, MethodDeclaration, logger.info("--> got: {}", ExceptionsHelper.detailedMessage(e));
601: Lee Hinman, info, MethodDeclaration, logger.info("--> deleting index");
660: Boaz Leskes, info, MethodDeclaration, logger.info("shard routing to {}", shardRouting);
1512: Boaz Leskes, debug, IfStmt, logger.debug("shard relocation was cancelled");
1507: Boaz Leskes, debug, IfStmt, logger.debug("shard was relocated successfully");
1552: Boaz Leskes, info, IfStmt, logger.info("--> flushing shard");
2917: Lee Hinman, info, MethodDeclaration, logger.info("--> running with {} threads and {} iterations each", threadCount, iterations);
2959: Lee Hinman, warn, CatchClause, logger.warn("--> got exception: ", e);
2925: Lee Hinman, debug, IfStmt, logger.debug("--> {} indexing {}", threadName, id);
2931: Lee Hinman, debug, IfStmt, logger.debug("--> {}, deleting {}", threadName, id);
2936: Lee Hinman, debug, IfStmt, logger.debug("--> {} refreshing", threadName);
2942: Lee Hinman, debug, IfStmt, logger.debug("--> {} acquiring new searcher {}", threadName, searcherName);
2953: Lee Hinman, debug, IfStmt, logger.debug("--> {} closing searcher {}", threadName, searcher.source());
2984: Lee Hinman, info, MethodDeclaration, logger.info("--> comparing segmentMem: {} - breaker: {} => {}", segmentMem, breakerMem, segmentMem == breakerMem);
58: Jason Tedor, info, LambdaExpr, logger.info("Sending off {} operations", request.getOperations().length);
83: Yannick Welsch, info, MethodDeclaration, logger.info("Total ops: {}, global checkpoint: {}", numDocs, globalCheckPoint);
111: Jason Tedor, info, LambdaExpr, logger.info("Sending off {} operations", request.getOperations().length);
139: Boaz Leskes, info, IfStmt, logger.info("--> cluster has [3] data nodes, corrupted primary will be overwritten");
166: Boaz Leskes, info, MethodDeclaration, logger.info("--> {} corrupted", corruptedShardRouting);
178: Boaz Leskes, info, IfStmt, logger.info("cluster state:\n{}\n{}", client().admin().cluster().prepareState().get().getState(), client().admin().cluster().preparePendingClusterTasks().get());
212: Nhat Nguyen, warn, IfStmt, logger.warn("check index [failure]\n{}", os.bytes().utf8ToString());
281: Simon Willnauer, info, IfStmt, logger.info("Cluster turned red in busy loop: {}", didClusterTurnRed);
282: Boaz Leskes, info, IfStmt, logger.info("cluster state:\n{}\n{}", client().admin().cluster().prepareState().get().getState(), client().admin().cluster().preparePendingClusterTasks().get());
444: Boaz Leskes, info, IfStmt, logger.info("ensureGreen timed out, cluster state:\n{}\n{}", client().admin().cluster().prepareState().get().getState(), client().admin().cluster().preparePendingClusterTasks().get());
506: Simon Willnauer, info, MethodDeclaration, logger.info("--> snapshot");
509: Igor Motov, info, MethodDeclaration, logger.info("failed during snapshot -- maybe SI file got corrupted");
574: Boaz Leskes, info, ForeachStmt, logger.info("corrupting file {} on node {}", path, store.getNode().getName());
93: Simon Willnauer, info, MethodDeclaration, logger.info("unlucky node: {}", unluckyNode.getNode());
105: Britta Weber, debug, IfStmt, logger.debug("Throw ConnectTransportException");
140: Britta Weber, info, IfStmt, logger.info("found a duplicate id:");
142: Britta Weber, info, ForeachStmt, logger.info("Doc {} was found on shard {}", hit.getId(), hit.getShard().getShardId());
144: Britta Weber, info, IfStmt, logger.info("will not print anymore in case more duplicates are found.");
113: Boaz Leskes, info, MethodDeclaration, logger.info("iter {}, iter1 {}, iter2 {}, {}", suggestAllIdx, suggestIdx1, suggestIdx2, endTime - startTime);
124: Boaz Leskes, info, ForeachStmt, logger.info("evaluating {}", stat.getNode());
66: Nhat Nguyen, info, IfStmt, logger.info("--> Translog dir [{}], minUsedTranslogGen [{}]", translogDir, minUsedTranslogGen);
111: Nhat Nguyen, info, TryStmt, logger.info("--> corrupting file {} --  flipping at position {} from {} to {} file: {}", fileToCorrupt, filePointer, Integer.toHexString(oldValue), Integer.toHexString(newValue), fileToCorrupt);
680: Boaz Leskes, info, MethodDeclaration, logger.info("testing with [{}] threads, each doing [{}] ops", threadCount, opsPerThread);
809: Lee Hinman, info, TryStmt, logger.info("--> truncating {}, prev: {}, now: {}", file, prevSize, newSize);
822: Robert Muir, info, ForeachStmt, logger.info("--> corrupting {}...", file);
880: Boaz Leskes, info, MethodDeclaration, logger.info("using [{}] readers. [{}] writers. flushing every ~[{}] ops.", readers.length, writers.length, flushEveryOps);
938: Boaz Leskes, info, MethodDeclaration, logger.info("--> [{}] done. wrote [{}] ops.", threadName, counter);
943: Nhat Nguyen, error, MethodDeclaration, logger.error(() -> new ParameterizedMessage("--> writer [{}] had an error", threadName), e);
958: Nhat Nguyen, error, MethodDeclaration, logger.error(() -> new ParameterizedMessage("--> reader [{}] had an error", threadId), e);
964: Jason Tedor, error, CatchClause, logger.error("unexpected error while closing view, after failure", inner);
980: Boaz Leskes, info, MethodDeclaration, logger.info("--> [{}] min gen after acquiring lock [{}]", threadId, translog.getMinFileGeneration());
1023: Boaz Leskes, info, MethodDeclaration, logger.info("--> [{}] done. tested [{}] snapshots", threadId, iter);
1030: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> waiting for threads to stop");
1034: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> waiting for readers to stop");
1050: Boaz Leskes, info, MethodDeclaration, logger.info("--> test done. total ops written [{}]", writtenOps.size());
1589: Simon Willnauer, info, MethodDeclaration, logger.info("testing with [{}] threads, each doing [{}] ops", threadCount, opsPerThread);
1893: Yannick Welsch, info, IfStmt, logger.info("Translog exception", threadExceptions[i]);
111: Boaz Leskes, info, MethodDeclaration, logger.info("--> indexing [{}] docs to be kept", numDocsToKeep);
121: Boaz Leskes, info, MethodDeclaration, logger.info("--> indexing [{}] more doc to be truncated", numDocsToTruncate);
137: Lee Hinman, info, TryStmt, logger.info("--> running truncate while index is open on [{}]", translogDir.toAbsolutePath());
150: Boaz Leskes, info, IfStmt, logger.info("--> performed extra flushing on replica");
157: Lee Hinman, info, MethodDeclaration, logger.info("--> corrupting translog");
161: Lee Hinman, info, MethodDeclaration, logger.info("--> restarting node");
177: Lee Hinman, info, MethodDeclaration, logger.info("--> closing 'test' index");
183: Lee Hinman, info, LambdaExpr, logger.info("--> checking that lock has been released for {}", idxLocation);
188: Lee Hinman, info, CatchClause, logger.info("--> failed acquiring lock for {}", idxLocation);
196: Lee Hinman, info, ForeachStmt, logger.info("--> running truncate translog command for [{}]", translogDir.toAbsolutePath());
198: Lee Hinman, info, ForeachStmt, logger.info("--> output:\n{}", t.getOutput());
202: Lee Hinman, info, MethodDeclaration, logger.info("--> opening 'test' index");
209: Boaz Leskes, info, MethodDeclaration, logger.info("--> starting the replica node to test recovery");
248: Boaz Leskes, info, MethodDeclaration, logger.info("--> indexing [{}] docs to be kept", numDocsToKeep);
258: Boaz Leskes, info, MethodDeclaration, logger.info("--> indexing [{}] more docs to be truncated", numDocsToTruncate);
277: Boaz Leskes, info, MethodDeclaration, logger.info("--> corrupting translog");
281: Boaz Leskes, info, MethodDeclaration, logger.info("--> starting node");
296: Boaz Leskes, info, LambdaExpr, logger.info("--> checking that lock has been released for {}", idxLocation);
301: Boaz Leskes, info, CatchClause, logger.info("--> failed acquiring lock for {}", idxLocation);
309: Boaz Leskes, info, ForeachStmt, logger.info("--> running truncate translog command for [{}]", translogDir.toAbsolutePath());
311: Boaz Leskes, info, ForeachStmt, logger.info("--> output:\n{}", t.getOutput());
314: Boaz Leskes, info, MethodDeclaration, logger.info("--> starting the replica node to test recovery");
61: Boaz Leskes, info, ForStmt, logger.info("indexing [{}] docs", numOfDocs);
67: Boaz Leskes, info, ForStmt, logger.info("verifying indexed content");
80: Jason Tedor, error, CatchClause, logger.error("search for all docs types failed", e);
71: Boaz Leskes, debug, TryStmt, logger.debug("running search with all types");
76: Boaz Leskes, error, IfStmt, logger.error("{}. search response: \n{}", message, response);
95: Jason Tedor, error, CatchClause, logger.error("search for all docs of a specific type failed", e);
86: Boaz Leskes, debug, TryStmt, logger.debug("running search with a specific type");
91: Boaz Leskes, error, IfStmt, logger.error("{}. search response: \n{}", message, response);
66: kimchy, info, MethodDeclaration, logger.info("Starting sever1");
70: kimchy, info, MethodDeclaration, logger.info("Creating index [test]");
78: kimchy, info, MethodDeclaration, logger.info("Starting server2");
83: Ali Beyad, info, MethodDeclaration, logger.info("Waiting for replicas to be assigned");
86: Yannick Welsch, info, MethodDeclaration, logger.info("Done Cluster Health, status {}", clusterHealth.getStatus());
114: kimchy, info, MethodDeclaration, logger.info("Starting server3");
119: Ali Beyad, info, MethodDeclaration, logger.info("Waiting for replicas to be assigned");
160: kimchy, info, MethodDeclaration, logger.info("Closing server1");
164: kimchy, info, MethodDeclaration, logger.info("Running Cluster Health");
166: Yannick Welsch, info, MethodDeclaration, logger.info("Done Cluster Health, status {}", clusterHealth.getStatus());
193: kimchy, info, MethodDeclaration, logger.info("Deleting index [test]");
325: Yannick Welsch, info, MethodDeclaration, logger.info("--> Indexing more data");
264: Yannick Welsch, info, MethodDeclaration, logger.info("Memory size: {}", requestCacheStats.stats().getMemorySize());
305: Yannick Welsch, info, MethodDeclaration, logger.info("Memory size: {}", requestCacheStats.stats().getMemorySize());
104: Yannick Welsch, info, ForStmt, logger.info("Iteration {}", i);
113: Nhat Nguyen, error, CatchClause, logger.error(() -> new ParameterizedMessage("failed to random change state. last good state: \n{}", finalState), error);
127: Nhat Nguyen, error, CatchClause, logger.error(new ParameterizedMessage("failed to apply change on [{}].\n ***  Previous state ***\n{}\n ***  New state ***\n{}", node, event.previousState(), event.state()), error);
139: Boaz Leskes, info, MethodDeclaration, logger.info("Final cluster state: {}", state);
122: Boaz Leskes, info, IfStmt, logger.info("--> sync flushing index [test]");
119: Boaz Leskes, info, IfStmt, logger.info("--> sync flushing shard 0");
193: Britta Weber, info, MethodDeclaration, logger.info("--> trying sync flush");
195: Britta Weber, info, MethodDeclaration, logger.info("--> sync flush done");
202: Simon Willnauer, info, MethodDeclaration, logger.info("indexed {} docs", client().prepareSearch().setSize(0).get().getHits().getTotalHits());
220: Boaz Leskes, info, IfStmt, logger.info("{} sync flush failed for on node {}", singleResponse.getKey().shardId(), singleResponse.getKey().currentNodeId());
217: Boaz Leskes, info, IfStmt, logger.info("{} sync flushed on node {}", singleResponse.getKey().shardId(), singleResponse.getKey().currentNodeId());
279: Nhat Nguyen, info, MethodDeclaration, logger.info("Partial seal: {}", syncedFlushDescription(partialResult));
312: Nhat Nguyen, info, MethodDeclaration, logger.info("First seal: {}", syncedFlushDescription(firstSeal));
316: Nhat Nguyen, info, MethodDeclaration, logger.info("Second seal: {}", syncedFlushDescription(secondSeal));
325: Nhat Nguyen, info, MethodDeclaration, logger.info("Third seal: {}", syncedFlushDescription(thirdSeal));
341: Nhat Nguyen, info, MethodDeclaration, logger.info("Forth seal: {}", syncedFlushDescription(forthSeal));
93: Shay Banon, info, MethodDeclaration, logger.info("checking all the documents are there");
99: Shay Banon, info, MethodDeclaration, logger.info("checking all the fields are in the mappings");
205: Boaz Leskes, info, MethodDeclaration, logger.info("Creating index with _default_ mappings");
219: Boaz Leskes, info, MethodDeclaration, logger.info("Emptying _default_ mappings");
226: Boaz Leskes, info, MethodDeclaration, logger.info("Done Emptying _default_ mappings");
233: Boaz Leskes, info, MethodDeclaration, logger.info("Creating _default_ mappings with an analyzed field");
242: Boaz Leskes, info, MethodDeclaration, logger.info("Changing _default_ mappings field from analyzed to non-analyzed");
249: Boaz Leskes, info, MethodDeclaration, logger.info("Done changing _default_ mappings field from analyzed to non-analyzed");
257: Boaz Leskes, info, MethodDeclaration, logger.info("Confirming _default_ mappings validation");
82: Lee Hinman, info, MethodDeclaration, logger.info("--> resetting breaker settings");
127: Lee Hinman, info, IfStmt, logger.info("--> noop breakers used, skipping test");
172: Lee Hinman, info, IfStmt, logger.info("--> noop breakers used, skipping test");
224: Lee Hinman, info, IfStmt, logger.info("--> noop breakers used, skipping test");
258: Lee Hinman, info, IfStmt, logger.info("--> noop breakers used, skipping test");
341: Boaz Leskes, info, IfStmt, logger.info("--> noop breakers used, skipping test");
362: Daniel Mitterdorfer, info, IfStmt, logger.info("--> noop breakers used, skipping test");
127: Simon Willnauer, info, MethodDeclaration, logger.info("creating index: [test] using settings: [{}]", settings.build());
140: Ali Beyad, info, IfStmt, logger.info("Index creation failed - only index one doc and expect searches to fail");
138: Ali Beyad, info, IfStmt, logger.info("Index creation timed out waiting for primaries to start - only index one doc and expect searches to fail");
153: Lee Hinman, info, MethodDeclaration, logger.info("Start Refresh");
156: Lee Hinman, info, MethodDeclaration, logger.info("Refresh failed: [{}] numShardsFailed: [{}], shardFailuresLength: [{}], successfulShards: [{}], totalShards: [{}] ", refreshFailed, refreshResponse.getFailedShards(), refreshResponse.getShardFailures().length, refreshResponse.getSuccessfulShards(), refreshResponse.getTotalShards());
178: Lee Hinman, info, CatchClause, logger.info("expected SearchPhaseException: [{}]", ex.getMessage());
80: Yannick Welsch, info, ForStmt, logger.info("--> [iteration {}] relocating from {} to {} ", i, relocationSource.getName(), relocationTarget.getName());
86: Yannick Welsch, info, ForStmt, logger.info("--> [iteration {}] relocation complete", i);
92: Boaz Leskes, info, IfStmt, logger.info("--> [iteration {}] flushing index", i);
163: Andrew Selden, info, MethodDeclaration, logger.info("--> start nodes");
168: Andrew Selden, info, MethodDeclaration, logger.info("--> restarting cluster");
172: Andrew Selden, info, MethodDeclaration, logger.info("--> request recoveries");
188: Andrew Selden, info, MethodDeclaration, logger.info("--> start nodes");
193: Andrew Selden, info, MethodDeclaration, logger.info("--> restarting cluster");
197: Andrew Selden, info, MethodDeclaration, logger.info("--> request recoveries");
205: Andrew Selden, info, MethodDeclaration, logger.info("--> start node A");
208: Andrew Selden, info, MethodDeclaration, logger.info("--> create index on node: {}", nodeA);
211: Andrew Selden, info, MethodDeclaration, logger.info("--> start node B");
216: Andrew Selden, info, MethodDeclaration, logger.info("--> bump replica count");
221: Andrew Selden, info, MethodDeclaration, logger.info("--> request recoveries");
251: Andrew Selden, info, MethodDeclaration, logger.info("--> start node A");
254: Andrew Selden, info, MethodDeclaration, logger.info("--> create index on node: {}", nodeA);
257: Andrew Selden, info, MethodDeclaration, logger.info("--> start node B");
262: Boaz Leskes, info, MethodDeclaration, logger.info("--> slowing down recoveries");
265: Andrew Selden, info, MethodDeclaration, logger.info("--> move shard from: {} to: {}", nodeA, nodeB);
270: Boaz Leskes, info, MethodDeclaration, logger.info("--> waiting for recovery to start both on source and target");
281: Andrew Selden, info, MethodDeclaration, logger.info("--> request recoveries");
296: Boaz Leskes, info, MethodDeclaration, logger.info("--> request node recovery stats");
314: Boaz Leskes, info, MethodDeclaration, logger.info("--> checking throttling increases");
332: Boaz Leskes, info, MethodDeclaration, logger.info("--> speeding up recoveries");
360: Boaz Leskes, info, MethodDeclaration, logger.info("--> bump replica count");
368: Boaz Leskes, info, MethodDeclaration, logger.info("--> start node C");
372: Boaz Leskes, info, MethodDeclaration, logger.info("--> slowing down recoveries");
375: Boaz Leskes, info, MethodDeclaration, logger.info("--> move replica shard from: {} to: {}", nodeA, nodeC);
422: Boaz Leskes, info, MethodDeclaration, logger.info("--> speeding up recoveries");
445: Andrew Selden, info, MethodDeclaration, logger.info("--> start node A");
448: Andrew Selden, info, MethodDeclaration, logger.info("--> create repository");
457: Andrew Selden, info, MethodDeclaration, logger.info("--> create index on node: {}", nodeA);
460: Andrew Selden, info, MethodDeclaration, logger.info("--> snapshot");
471: Andrew Selden, info, MethodDeclaration, logger.info("--> restore");
479: Andrew Selden, info, MethodDeclaration, logger.info("--> request recoveries");
511: Andrew Selden, info, MethodDeclaration, logger.info("--> creating test index: {}", name);
516: Andrew Selden, info, MethodDeclaration, logger.info("--> indexing sample data");
593: Boaz Leskes, info, MethodDeclaration, logger.info("--> will {} between blue & red on [{}]", dropRequests ? "drop requests" : "break connection", recoveryActionToBlock);
604: Boaz Leskes, info, MethodDeclaration, logger.info("--> starting recovery from blue to red");
613: Boaz Leskes, info, MethodDeclaration, logger.info("--> stopping to block recovery");
639: Boaz Leskes, info, IfStmt, logger.info("--> preventing {} request", action);
695: Yannick Welsch, info, MethodDeclaration, logger.info("--> sending request {} on {}", action, connection.getNode());
722: Yannick Welsch, info, MethodDeclaration, logger.info("--> sending request {} on {}", action, connection.getNode());
735: Yannick Welsch, info, MethodDeclaration, logger.info("--> sending request {} on {}", action, connection.getNode());
759: Yannick Welsch, info, IfStmt, logger.info("--> starting replica recovery from blue to red");
745: Yannick Welsch, info, IfStmt, logger.info("--> starting primary relocation recovery from blue to red");
236: Boaz Leskes, info, MethodDeclaration, logger.info("testing initial information");
253: Boaz Leskes, info, IfStmt, logger.info("performing partial recovery ([{}] bytes of [{}])", bytesToRecover, totalFileBytes - totalReusedBytes);
301: Boaz Leskes, info, MethodDeclaration, logger.info("testing serialized information");
316: Boaz Leskes, info, MethodDeclaration, logger.info("testing post recovery");
155: Boaz Leskes, info, IfStmt, logger.info("--> flushing shard (translog will be retained)");
146: Boaz Leskes, info, IfStmt, logger.info("--> flushing shard (translog will be trimmed)");
46: kimchy, info, MethodDeclaration, logger.info("Creating index test");
48: kimchy, info, MethodDeclaration, logger.info("Running Cluster Health");
50: Yannick Welsch, info, MethodDeclaration, logger.info("Done Cluster Health, status {}", clusterHealth.getStatus());
73: kimchy, info, MethodDeclaration, logger.info("Increasing the number of replicas from 1 to 2");
75: kimchy, info, MethodDeclaration, logger.info("Running Cluster Health");
77: Yannick Welsch, info, MethodDeclaration, logger.info("Done Cluster Health, status {}", clusterHealth.getStatus());
85: kimchy, info, MethodDeclaration, logger.info("starting another node to new replicas will be allocated to it");
88: kimchy, info, MethodDeclaration, logger.info("Running Cluster Health");
90: Yannick Welsch, info, MethodDeclaration, logger.info("Done Cluster Health, status {}", clusterHealth.getStatus());
103: kimchy, info, MethodDeclaration, logger.info("Decreasing number of replicas from 2 to 0");
106: kimchy, info, MethodDeclaration, logger.info("Running Cluster Health");
108: Yannick Welsch, info, MethodDeclaration, logger.info("Done Cluster Health, status {}", clusterHealth.getStatus());
123: kimchy, info, MethodDeclaration, logger.info("--> creating index test with auto expand replicas");
128: kimchy, info, MethodDeclaration, logger.info("--> running cluster health");
130: Yannick Welsch, info, MethodDeclaration, logger.info("--> done cluster health, status {}", clusterHealth.getStatus());
137: kimchy, info, MethodDeclaration, logger.info("--> add another node, should increase the number of replicas");
140: kimchy, info, MethodDeclaration, logger.info("--> running cluster health");
142: Yannick Welsch, info, MethodDeclaration, logger.info("--> done cluster health, status {}", clusterHealth.getStatus());
149: kimchy, info, MethodDeclaration, logger.info("--> closing one node");
153: kimchy, info, MethodDeclaration, logger.info("--> running cluster health");
155: Yannick Welsch, info, MethodDeclaration, logger.info("--> done cluster health, status {}", clusterHealth.getStatus());
162: kimchy, info, MethodDeclaration, logger.info("--> closing another node");
166: kimchy, info, MethodDeclaration, logger.info("--> running cluster health");
168: Yannick Welsch, info, MethodDeclaration, logger.info("--> done cluster health, status {}", clusterHealth.getStatus());
177: kimchy, info, MethodDeclaration, logger.info("--> creating index test with auto expand replicas");
183: kimchy, info, MethodDeclaration, logger.info("--> running cluster health");
185: Yannick Welsch, info, MethodDeclaration, logger.info("--> done cluster health, status {}", clusterHealth.getStatus());
192: kimchy, info, MethodDeclaration, logger.info("--> add another node, should increase the number of replicas");
195: kimchy, info, MethodDeclaration, logger.info("--> running cluster health");
197: Yannick Welsch, info, MethodDeclaration, logger.info("--> done cluster health, status {}", clusterHealth.getStatus());
204: kimchy, info, MethodDeclaration, logger.info("--> closing one node");
208: kimchy, info, MethodDeclaration, logger.info("--> running cluster health");
210: Yannick Welsch, info, MethodDeclaration, logger.info("--> done cluster health, status {}", clusterHealth.getStatus());
217: kimchy, info, MethodDeclaration, logger.info("--> closing another node");
221: kimchy, info, MethodDeclaration, logger.info("--> running cluster health");
223: Yannick Welsch, info, MethodDeclaration, logger.info("--> done cluster health, status {}", clusterHealth.getStatus());
232: Shay Banon, info, MethodDeclaration, logger.info("--> creating index test with auto expand replicas set to 0-2");
237: Shay Banon, info, MethodDeclaration, logger.info("--> running cluster health");
239: Yannick Welsch, info, MethodDeclaration, logger.info("--> done cluster health, status {}", clusterHealth.getStatus());
246: Shay Banon, info, MethodDeclaration, logger.info("--> add two more nodes");
250: Shay Banon, info, MethodDeclaration, logger.info("--> update the auto expand replicas to 0-3");
253: Shay Banon, info, MethodDeclaration, logger.info("--> running cluster health");
255: Yannick Welsch, info, MethodDeclaration, logger.info("--> done cluster health, status {}", clusterHealth.getStatus());
173: Boaz Leskes, info, MethodDeclaration, logger.info("--> indexing a doc");
177: Boaz Leskes, info, MethodDeclaration, logger.info("--> delete index and recreate it");
181: Boaz Leskes, info, MethodDeclaration, logger.info("--> letting cluster proceed");
46: kimchy, info, MethodDeclaration, logger.info("--> creating test index");
49: kimchy, info, MethodDeclaration, logger.info("--> waiting for green status");
60: kimchy, info, MethodDeclaration, logger.info("--> indexing a simple document");
63: kimchy, info, MethodDeclaration, logger.info("--> closing test index...");
71: kimchy, info, MethodDeclaration, logger.info("--> trying to index into a closed index ...");
79: kimchy, info, MethodDeclaration, logger.info("--> opening index...");
83: kimchy, info, MethodDeclaration, logger.info("--> waiting for green status");
93: kimchy, info, MethodDeclaration, logger.info("--> indexing a simple document");
98: Nik Everett, info, MethodDeclaration, logger.info("--> creating test index that cannot be allocated");
108: Nik Everett, info, MethodDeclaration, logger.info("--> updating test index settings to allow allocation");
114: Nik Everett, info, MethodDeclaration, logger.info("--> waiting for green status");
125: Nik Everett, info, MethodDeclaration, logger.info("--> indexing a simple document");
130: Igor Motov, info, MethodDeclaration, logger.info("--> deleting test index....");
137: Igor Motov, info, MethodDeclaration, logger.info("--> creating test index with invalid settings ");
146: Igor Motov, info, MethodDeclaration, logger.info("--> creating test index with valid settings ");
389: Michael McCandless, info, MethodDeclaration, logger.info("test: test done");
102: Britta Weber, info, MethodDeclaration, logger.info("--> creating index [test] with one shard and on replica");
112: Britta Weber, info, MethodDeclaration, logger.info("--> making sure that shard and its replica are allocated on node_1 and node_2");
118: Britta Weber, info, MethodDeclaration, logger.info("--> starting node server3");
120: Britta Weber, info, MethodDeclaration, logger.info("--> running cluster_health");
134: Britta Weber, info, MethodDeclaration, logger.info("--> move shard from node_1 to node_3, and wait for relocation to finish");
140: Lee Hinman, info, IfStmt, logger.info("--> stopping disruption");
184: Yannick Welsch, info, IfStmt, logger.info("received: {}, waiting on cluster state", action);
182: Yannick Welsch, info, IfStmt, logger.info("received: {}, relocation done", action);
175: Yannick Welsch, info, IfStmt, logger.info("received: {}, relocation starts", action);
199: Yannick Welsch, info, MethodDeclaration, logger.info("--> waiting for relocation to start");
201: Yannick Welsch, info, MethodDeclaration, logger.info("--> starting disruption");
203: Yannick Welsch, info, MethodDeclaration, logger.info("--> waiting for relocation to finish");
205: Yannick Welsch, info, MethodDeclaration, logger.info("--> relocation completed (but cluster state processing block still in place)");
212: Britta Weber, info, MethodDeclaration, logger.info("--> creating index [test] with one shard and on replica");
242: Britta Weber, info, IfStmt, logger.info("prevent shard active request from being sent");
249: Britta Weber, info, MethodDeclaration, logger.info("--> move shard from {} to {}, and wait for relocation to finish", node_1, node_2);
274: Martijn van Groningen, info, MethodDeclaration, logger.info("--> creating index [test] with one shard and on replica");
284: Martijn van Groningen, info, MethodDeclaration, logger.info("--> making sure that shard and its replica are allocated on node_1 and node_2");
288: Martijn van Groningen, info, MethodDeclaration, logger.info("--> starting node server3");
290: Martijn van Groningen, info, MethodDeclaration, logger.info("--> running cluster_health");
297: Martijn van Groningen, info, MethodDeclaration, logger.info("--> making sure that shard is not allocated on server3");
301: Yannick Welsch, info, MethodDeclaration, logger.info("--> stopping node {}", node_2);
304: Martijn van Groningen, info, MethodDeclaration, logger.info("--> running cluster_health");
311: Yannick Welsch, info, MethodDeclaration, logger.info("--> done cluster_health, status {}", clusterHealth.getStatus());
315: Martijn van Groningen, info, MethodDeclaration, logger.info("--> making sure that shard and its replica exist on server1, server2 and server3");
320: Martijn van Groningen, info, MethodDeclaration, logger.info("--> starting node node_4");
323: Martijn van Groningen, info, MethodDeclaration, logger.info("--> running cluster_health");
326: Martijn van Groningen, info, MethodDeclaration, logger.info("--> making sure that shard and its replica are allocated on server1 and server3 but not on server2");
354: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> shutting down two random nodes");
358: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> verifying index is red");
365: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> allowing index to be assigned to node [{}]", node4);
373: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> waiting for shards to recover on [{}]", node4);
387: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> starting the two old nodes back");
397: Boaz Leskes, debug, MethodDeclaration, logger.debug("--> waiting for the lost shard to be recovered");
428: Boaz Leskes, info, MethodDeclaration, logger.info("Node [{}] has shards: {}", nonMasterNode, Arrays.toString(node2Shards));
463: Martijn van Groningen, info, MethodDeclaration, logger.info("Checking if shards aren't removed");
155: Yannick Welsch, warn, IfStmt, logger.warn("failed search {}", Arrays.toString(searchResponse.getShardFailures()));
164: Shay Banon, info, MethodDeclaration, logger.info("--> put template_1 and template_2");
201: Shay Banon, info, MethodDeclaration, logger.info("--> explicitly delete template_1");
211: Shay Banon, info, MethodDeclaration, logger.info("--> put template_1 back");
221: Shay Banon, info, MethodDeclaration, logger.info("--> delete template*");
226: Shay Banon, info, MethodDeclaration, logger.info("--> delete * with no templates, make sure we don't get a failure");
233: Alexander Reelsen, info, MethodDeclaration, logger.info("--> put template_1");
244: Alexander Reelsen, info, MethodDeclaration, logger.info("--> get template template_1");
252: Alexander Reelsen, info, MethodDeclaration, logger.info("--> get non-existing-template");
259: Alexander Reelsen, info, MethodDeclaration, logger.info("--> put template_1");
269: Alexander Reelsen, info, MethodDeclaration, logger.info("--> put template_2");
279: Alexander Reelsen, info, MethodDeclaration, logger.info("--> put template3");
289: Alexander Reelsen, info, MethodDeclaration, logger.info("--> get template template_*");
298: David Pilato, info, MethodDeclaration, logger.info("--> get all templates");
308: David Pilato, info, MethodDeclaration, logger.info("--> get templates template_1 and template_2");
319: David Pilato, info, MethodDeclaration, logger.info("--> get template null");
322: David Pilato, info, MethodDeclaration, logger.info("--> get template empty");
325: David Pilato, info, MethodDeclaration, logger.info("--> get template 'a', '', 'c'");
328: David Pilato, info, MethodDeclaration, logger.info("--> get template 'a', null, 'c'");
138: Jason Tedor, info, WhileStmt, logger.info("--> adding {} bytes to {}, {} will be: {}", getter.apply(pathToAdd), getter.apply(pathStats), field, getter.apply(pathStats) + getter.apply(pathToAdd));
148: Jason Tedor, info, MethodDeclaration, logger.info("--> adding {} bytes to {}, {} will be: {}", getter.apply(pathToAdd), getter.apply(pathStats), field, getter.apply(pathStats) + getter.apply(pathToAdd));
36: Jason Tedor, Warn, MethodDeclaration, when(logger.isWarnEnabled()).thenReturn(true);
37: Jason Tedor, Info, MethodDeclaration, when(logger.isInfoEnabled()).thenReturn(true);
38: Jason Tedor, Debug, MethodDeclaration, when(logger.isDebugEnabled()).thenReturn(true);
82: Jason Tedor, Warn, SwitchStmt, verify(logger).isWarnEnabled();
83: Jason Tedor, warn, SwitchStmt, verify(logger).warn("[gc][{}][{}][{}] duration [{}], collections [{}]/[{}], total [{}]/[{}], memory [{}]->[{}]/[{}], all_pools {}", name, seq, totalCollectionCount, currentCollectionTime, currentCollectionCount, TimeValue.timeValueMillis(elapsedValue), currentCollectionTime, totalCollectionTime, lastHeapUsed, currentHeapUsed, maxHeapUsed, "last, current");
99: Jason Tedor, Info, SwitchStmt, verify(logger).isInfoEnabled();
100: Jason Tedor, info, SwitchStmt, verify(logger).info("[gc][{}][{}][{}] duration [{}], collections [{}]/[{}], total [{}]/[{}], memory [{}]->[{}]/[{}], all_pools {}", name, seq, totalCollectionCount, currentCollectionTime, currentCollectionCount, TimeValue.timeValueMillis(elapsedValue), currentCollectionTime, totalCollectionTime, lastHeapUsed, currentHeapUsed, maxHeapUsed, "last, current");
116: Jason Tedor, Debug, SwitchStmt, verify(logger).isDebugEnabled();
117: Jason Tedor, debug, SwitchStmt, verify(logger).debug("[gc][{}][{}][{}] duration [{}], collections [{}]/[{}], total [{}]/[{}], memory [{}]->[{}]/[{}], all_pools {}", name, seq, totalCollectionCount, currentCollectionTime, currentCollectionCount, TimeValue.timeValueMillis(elapsedValue), currentCollectionTime, totalCollectionTime, lastHeapUsed, currentHeapUsed, maxHeapUsed, "last, current");
142: Jason Tedor, Warn, MethodDeclaration, when(logger.isWarnEnabled()).thenReturn(true);
143: Jason Tedor, Info, MethodDeclaration, when(logger.isInfoEnabled()).thenReturn(true);
144: Jason Tedor, Debug, MethodDeclaration, when(logger.isDebugEnabled()).thenReturn(true);
148: Jason Tedor, Warn, SwitchStmt, verify(logger).isWarnEnabled();
149: Jason Tedor, warn, SwitchStmt, verify(logger).warn("[gc][{}] overhead, spent [{}] collecting in the last [{}]", seq, TimeValue.timeValueMillis(current), TimeValue.timeValueMillis(elapsed));
156: Jason Tedor, Info, SwitchStmt, verify(logger).isInfoEnabled();
157: Jason Tedor, info, SwitchStmt, verify(logger).info("[gc][{}] overhead, spent [{}] collecting in the last [{}]", seq, TimeValue.timeValueMillis(current), TimeValue.timeValueMillis(elapsed));
164: Jason Tedor, Debug, SwitchStmt, verify(logger).isDebugEnabled();
165: Jason Tedor, debug, SwitchStmt, verify(logger).debug("[gc][{}] overhead, spent [{}] collecting in the last [{}]", seq, TimeValue.timeValueMillis(current), TimeValue.timeValueMillis(elapsed));
113: Jason Tedor, warn, MethodDeclaration, verify(logger).warn("version [{}] is a pre-release version of Elasticsearch and is not suitable for production", releaseVersion + "-SNAPSHOT");
119: Jason Tedor, warn, MethodDeclaration, verify(logger).warn("version [{}] is a pre-release version of Elasticsearch and is not suitable for production", preReleaseVersion + (isSnapshot ? "-SNAPSHOT" : ""));
113: Lee Hinman, info, MethodDeclaration, logger.info("--> got stats: {}", nodeStats);
48: Yannick Welsch, info, MethodDeclaration, logger.info("--> done cluster_health, status {}", clusterHealth.getStatus());
52: Yannick Welsch, info, MethodDeclaration, logger.info("--> started nodes: {} and {}", server1NodeId, server2NodeId);
87: Mike McCandless, info, MethodDeclaration, logger.info("--> done cluster_health, status {}", clusterHealth.getStatus());
91: Mike McCandless, info, MethodDeclaration, logger.info("--> started nodes: {} and {}", server1NodeId, server2NodeId);
125: Yannick Welsch, info, MethodDeclaration, logger.info("--> done cluster_health, status {}", clusterHealth.getStatus());
129: Yannick Welsch, info, MethodDeclaration, logger.info("--> started nodes: {} and {}", server1NodeId, server2NodeId);
107: Igor Motov, info, ForStmt, logger.info("inter {} significant: {}", i, significant);
236: Igor Motov, info, IfStmt, logger.info(clusterState.metaData().custom(PersistentTasksCustomMetaData.TYPE).toString());
442: Igor Motov, info, IfStmt, logger.info("removed node {}", task.getExecutorNode());
458: Igor Motov, info, IfStmt, logger.info("added unassignable task with custom assignment message");
454: Igor Motov, info, IfStmt, logger.info("added random task");
466: Igor Motov, info, IfStmt, logger.info("added random node");
473: Igor Motov, info, IfStmt, logger.info("changed routing table");
490: Igor Motov, info, IfStmt, logger.info("removed task with changing assignment {}", task.getId());
512: Igor Motov, info, IfStmt, logger.info("added random node");
516: Igor Motov, info, IfStmt, logger.info("added random unassignable task");
520: Igor Motov, info, IfStmt, logger.info("changed routing table");
533: Igor Motov, info, IfStmt, logger.info("removed unassigned node {}", node.getId());
547: Igor Motov, info, IfStmt, logger.info("set task custom to null");
542: Igor Motov, info, IfStmt, logger.info("removed all tasks");
552: Igor Motov, info, MethodDeclaration, logger.info("removed all unassigned tasks and changed routing table");
68: Tanguy Leroux, debug, MethodDeclaration, logger.debug("Executing task {}", task);
99: Igor Motov, info, MethodDeclaration, logger.info("Waiting for {} tasks to start", numberOfTasks);
106: Igor Motov, info, MethodDeclaration, logger.info("Complete all tasks");
89: Igor Motov, info, MethodDeclaration, logger.info("Found running task with id {} and parent {}", firstRunningTask.getId(), firstRunningTask.getParentTaskId());
94: Igor Motov, info, MethodDeclaration, logger.info("Failing the running task");
99: Igor Motov, info, MethodDeclaration, logger.info("Waiting for persistent task with id {} to disappear", firstRunningTask.getId());
120: Igor Motov, info, MethodDeclaration, logger.info("Found running task with id {} and parent {}", firstRunningTask.getId(), firstRunningTask.getParentTaskId());
127: Igor Motov, info, IfStmt, logger.info("Simulating errant completion notification");
197: Igor Motov, info, ForStmt, logger.info("Updating the task status");
226: Igor Motov, info, MethodDeclaration, logger.info("Completing the running task");
254: Igor Motov, info, MethodDeclaration, logger.info("Completing the running task");
259: Igor Motov, info, MethodDeclaration, logger.info("Waiting for persistent task with id {} to disappear", firstRunningTask.getId());
275: Igor Motov, info, IfStmt, logger.info("Cancelling the running task");
269: Igor Motov, info, IfStmt, logger.info("Completing the running task");
289: Igor Motov, info, LambdaExpr, logger.info("Found {} tasks", tasks.size());
133: Igor Motov, info, IfStmt, logger.info("No local node action was added");
306: Igor Motov, info, MethodDeclaration, logger.info("started node operation for the task {}", task);
329: Martijn van Groningen, info, IfStmt, logger.info("updating the task status to {}", newStatus);
333: Igor Motov, info, MethodDeclaration, logger.info("updating was successful");
339: Igor Motov, info, MethodDeclaration, logger.info("updating failed", e);
69: Tanguy Leroux, trace, MethodDeclaration, logger.trace("creating {} persistent tasks", numberOfTasks);
93: Tanguy Leroux, trace, MethodDeclaration, logger.trace("waiting for the tasks to be running");
102: Tanguy Leroux, trace, TryStmt, logger.trace("disable persistent tasks assignment");
105: Tanguy Leroux, trace, TryStmt, logger.trace("restart the cluster");
109: Tanguy Leroux, trace, TryStmt, logger.trace("persistent tasks assignment is still disabled");
112: Tanguy Leroux, trace, TryStmt, logger.trace("persistent tasks are not assigned");
124: Tanguy Leroux, trace, TryStmt, logger.trace("enable persistent tasks assignment");
47: Boaz Leskes, info, IfStmt, logger.info("cluster health request timed out:\n{}", clusterHealth);
74: Boaz Leskes, info, MethodDeclaration, logger.info("--> now start adding nodes");
81: Boaz Leskes, info, MethodDeclaration, logger.info("--> add two more nodes");
88: Boaz Leskes, info, MethodDeclaration, logger.info("--> refreshing and checking data");
103: Boaz Leskes, info, MethodDeclaration, logger.info("--> stopped two nodes, verifying data");
119: Boaz Leskes, info, MethodDeclaration, logger.info("--> one node left, verifying data");
61: kimchy, info, MethodDeclaration, logger.info("--> creating test index ...");
69: Simon Willnauer, info, TryStmt, logger.info("--> waiting for {} docs to be indexed ...", waitFor);
72: Boaz Leskes, info, TryStmt, logger.info("--> {} docs indexed", waitFor);
77: Boaz Leskes, info, TryStmt, logger.info("--> flushing the index ....");
81: Simon Willnauer, info, TryStmt, logger.info("--> waiting for {} docs to be indexed ...", waitFor);
84: Boaz Leskes, info, TryStmt, logger.info("--> {} docs indexed", waitFor);
89: Boaz Leskes, info, TryStmt, logger.info("--> allow 2 nodes for index [test] ...");
93: Boaz Leskes, info, TryStmt, logger.info("--> waiting for GREEN health status ...");
97: Simon Willnauer, info, TryStmt, logger.info("--> waiting for {} docs to be indexed ...", totalNumDocs);
100: Simon Willnauer, info, TryStmt, logger.info("--> {} docs indexed", totalNumDocs);
102: Boaz Leskes, info, TryStmt, logger.info("--> marking and waiting for indexing threads to stop ...");
104: Boaz Leskes, info, TryStmt, logger.info("--> indexing threads stopped");
106: Boaz Leskes, info, TryStmt, logger.info("--> refreshing the index");
108: Boaz Leskes, info, TryStmt, logger.info("--> verifying indexed content");
114: kimchy, info, MethodDeclaration, logger.info("--> creating test index ...");
122: Simon Willnauer, info, TryStmt, logger.info("--> waiting for {} docs to be indexed ...", waitFor);
125: Boaz Leskes, info, TryStmt, logger.info("--> {} docs indexed", waitFor);
130: Boaz Leskes, info, TryStmt, logger.info("--> flushing the index ....");
134: Simon Willnauer, info, TryStmt, logger.info("--> waiting for {} docs to be indexed ...", waitFor);
137: Boaz Leskes, info, TryStmt, logger.info("--> {} docs indexed", waitFor);
141: Boaz Leskes, info, TryStmt, logger.info("--> allow 4 nodes for index [test] ...");
144: Boaz Leskes, info, TryStmt, logger.info("--> waiting for GREEN health status ...");
148: Simon Willnauer, info, TryStmt, logger.info("--> waiting for {} docs to be indexed ...", totalNumDocs);
151: Simon Willnauer, info, TryStmt, logger.info("--> {} docs indexed", totalNumDocs);
153: Boaz Leskes, info, TryStmt, logger.info("--> marking and waiting for indexing threads to stop ...");
155: Boaz Leskes, info, TryStmt, logger.info("--> indexing threads stopped");
157: Boaz Leskes, info, TryStmt, logger.info("--> refreshing the index");
159: Boaz Leskes, info, TryStmt, logger.info("--> verifying indexed content");
165: kimchy, info, MethodDeclaration, logger.info("--> creating test index ...");
173: Simon Willnauer, info, TryStmt, logger.info("--> waiting for {} docs to be indexed ...", waitFor);
176: Boaz Leskes, info, TryStmt, logger.info("--> {} docs indexed", waitFor);
181: Boaz Leskes, info, TryStmt, logger.info("--> flushing the index ....");
185: Simon Willnauer, info, TryStmt, logger.info("--> waiting for {} docs to be indexed ...", waitFor);
188: Boaz Leskes, info, TryStmt, logger.info("--> {} docs indexed", waitFor);
193: Boaz Leskes, info, TryStmt, logger.info("--> allow 4 nodes for index [test] ...");
196: Boaz Leskes, info, TryStmt, logger.info("--> waiting for GREEN health status ...");
199: Simon Willnauer, info, TryStmt, logger.info("--> waiting for {} docs to be indexed ...", totalNumDocs);
203: Boaz Leskes, info, TryStmt, logger.info("--> {} docs indexed", totalNumDocs);
205: Boaz Leskes, info, TryStmt, logger.info("--> allow 3 nodes for index [test] ...");
207: Boaz Leskes, info, TryStmt, logger.info("--> waiting for relocations ...");
210: Boaz Leskes, info, TryStmt, logger.info("--> allow 2 nodes for index [test] ...");
212: Boaz Leskes, info, TryStmt, logger.info("--> waiting for relocations ...");
215: Boaz Leskes, info, TryStmt, logger.info("--> allow 1 nodes for index [test] ...");
217: Boaz Leskes, info, TryStmt, logger.info("--> waiting for relocations ...");
220: Boaz Leskes, info, TryStmt, logger.info("--> marking and waiting for indexing threads to stop ...");
222: Boaz Leskes, info, TryStmt, logger.info("--> indexing threads stopped");
226: Boaz Leskes, info, TryStmt, logger.info("--> refreshing the index");
228: Boaz Leskes, info, TryStmt, logger.info("--> verifying indexed content");
236: Igor Motov, info, MethodDeclaration, logger.info("--> creating test index ...");
246: Boaz Leskes, info, ForStmt, logger.info("--> waiting for {} docs to be indexed ...", i);
248: Boaz Leskes, info, ForStmt, logger.info("--> {} docs indexed", i);
251: Boaz Leskes, info, ForStmt, logger.info("--> waiting for GREEN health status ...");
255: Boaz Leskes, info, TryStmt, logger.info("--> marking and waiting for indexing threads to stop ...");
258: Boaz Leskes, info, TryStmt, logger.info("--> indexing threads stopped");
259: Boaz Leskes, info, TryStmt, logger.info("--> bump up number of replicas to 1 and allow all nodes to hold the index");
264: Boaz Leskes, info, TryStmt, logger.info("--> refreshing the index");
266: Boaz Leskes, info, TryStmt, logger.info("--> verifying indexed content");
289: Jason Tedor, info, ForeachStmt, logger.info("shard [{}] - count {}, primary {}", shardStats.getShardRouting().id(), docsStats.getCount(), shardStats.getShardRouting().primary());
302: Boaz Leskes, info, IfStmt, logger.info("missing id [{}] on shard {}", id, shardRouting);
310: Luca Cavanna, info, IfStmt, logger.info("--> trying to wait");
335: Luca Cavanna, info, MethodDeclaration, logger.info("iteration [{}] - successful shards: {} (expected {})", iteration, searchResponse.getSuccessfulShards(), numberOfShards);
336: Luca Cavanna, info, MethodDeclaration, logger.info("iteration [{}] - failed shards: {} (expected 0)", iteration, searchResponse.getFailedShards());
338: Luca Cavanna, info, IfStmt, logger.info("iteration [{}] - shard failures: {}", iteration, Arrays.toString(searchResponse.getShardFailures()));
340: Simon Willnauer, info, MethodDeclaration, logger.info("iteration [{}] - returned documents: {} (expected {})", iteration, searchResponse.getHits().getTotalHits(), numberOfDocs);
108: Shay Banon, info, MethodDeclaration, logger.info("--> starting [node1] ...");
111: Shay Banon, info, MethodDeclaration, logger.info("--> creating test index ...");
117: Shay Banon, info, MethodDeclaration, logger.info("--> index 10 docs");
121: Shay Banon, info, MethodDeclaration, logger.info("--> flush so we have an actual index");
123: Shay Banon, info, MethodDeclaration, logger.info("--> index more docs so we have something in the translog");
128: Shay Banon, info, MethodDeclaration, logger.info("--> verifying count");
132: Shay Banon, info, MethodDeclaration, logger.info("--> start another node");
137: Shay Banon, info, MethodDeclaration, logger.info("--> relocate the shard from node1 to node2");
145: Shay Banon, info, MethodDeclaration, logger.info("--> verifying count again...");
156: Boaz Leskes, info, MethodDeclaration, logger.info("testRelocationWhileIndexingRandom(numRelocations={}, numberOfReplicas={}, numberOfNodes={})", numberOfRelocations, numberOfReplicas, numberOfNodes);
159: Shay Banon, info, MethodDeclaration, logger.info("--> starting [node1] ...");
162: Shay Banon, info, MethodDeclaration, logger.info("--> creating test index ...");
170: Jason Tedor, info, ForStmt, logger.info("--> starting [node{}] ...", i);
181: Boaz Leskes, info, TryStmt, logger.info("--> waiting for {} docs to be indexed ...", numDocs);
183: Boaz Leskes, info, TryStmt, logger.info("--> {} docs indexed", numDocs);
185: Boaz Leskes, info, TryStmt, logger.info("--> starting relocations...");
193: Boaz Leskes, debug, ForStmt, logger.debug("--> Allow indexer to index [{}] documents", numDocs);
195: Boaz Leskes, info, ForStmt, logger.info("--> START relocate the shard from {} to {}", nodes[fromNode], nodes[toNode]);
200: Boaz Leskes, debug, IfStmt, logger.debug("--> flushing");
206: Boaz Leskes, info, ForStmt, logger.info("--> DONE relocate the shard from {} to {}", fromNode, toNode);
208: Boaz Leskes, info, TryStmt, logger.info("--> done relocations");
209: Boaz Leskes, info, TryStmt, logger.info("--> waiting for indexing threads to stop ...");
211: Boaz Leskes, info, TryStmt, logger.info("--> indexing threads stopped");
213: Boaz Leskes, info, TryStmt, logger.info("--> refreshing the index");
215: Boaz Leskes, info, TryStmt, logger.info("--> searching the index");
218: Boaz Leskes, info, ForStmt, logger.info("--> START search test round {}", i + 1);
230: Boaz Leskes, error, IfStmt, logger.error("Extra id [{}]", id);
234: Simon Willnauer, error, LambdaExpr, logger.error("Missing id [{}]", value);
238: Boaz Leskes, info, ForStmt, logger.info("--> DONE search test round {}", i + 1);
253: Boaz Leskes, info, MethodDeclaration, logger.info("testRelocationWhileIndexingRandom(numRelocations={}, numberOfReplicas={}, numberOfNodes={})", numberOfRelocations, numberOfReplicas, numberOfNodes);
256: Boaz Leskes, info, MethodDeclaration, logger.info("--> starting [node_0] ...");
259: Boaz Leskes, info, MethodDeclaration, logger.info("--> creating test index ...");
270: Boaz Leskes, info, ForStmt, logger.info("--> starting [node_{}] ...", i);
293: Boaz Leskes, info, MethodDeclaration, logger.info("--> starting relocations...");
311: Boaz Leskes, info, ForStmt, logger.info("--> START relocate the shard from {} to {}", nodes[fromNode], nodes[toNode]);
319: Boaz Leskes, debug, ForStmt, logger.debug("--> index [{}] documents", builders1.size());
324: Boaz Leskes, debug, ForStmt, logger.debug("--> index [{}] documents", builders2.size());
329: Boaz Leskes, info, ForStmt, logger.info("--> DONE relocate the shard from {} to {}", fromNode, toNode);
331: Boaz Leskes, debug, ForStmt, logger.debug("--> verifying all searches return the same number of docs");
369: Boaz Leskes, info, MethodDeclaration, logger.info("--> blocking recoveries from primary (allowed failures: [{}])", allowedFailures);
383: Boaz Leskes, info, MethodDeclaration, logger.info("--> stopping replica assignment");
387: Boaz Leskes, info, MethodDeclaration, logger.info("--> wait for all replica shards to be removed, on all nodes");
399: Boaz Leskes, info, MethodDeclaration, logger.info("--> verifying no temporary recoveries are left");
436: Boaz Leskes, info, MethodDeclaration, logger.info("blue nodes: {}", (Object) blueNodes);
437: Boaz Leskes, info, MethodDeclaration, logger.info("red nodes: {}", (Object) redNodes);
449: Britta Weber, info, MethodDeclaration, logger.info(" --> indexing [{}] docs", numDocs);
460: Britta Weber, info, MethodDeclaration, logger.info(" --> moving index to new nodes");
466: Britta Weber, info, MethodDeclaration, logger.info(" --> indexing [{}] more docs", numDocs);
475: Yannick Welsch, info, MethodDeclaration, logger.info(" --> waiting for relocation to complete");
480: Yannick Welsch, info, ForStmt, logger.info(" --> checking iteration {}", i);
503: Simon Willnauer, debug, IfStmt, logger.debug("corrupting [{}] to {}. file name: [{}]", action, connection.getNode(), chunkRequest.name());
69: kimchy, info, MethodDeclaration, logger.info("Running Cluster Health");
88: kimchy, info, MethodDeclaration, logger.info("Running Cluster Health");
130: Yannick Welsch, debug, IfStmt, logger.debug("file chunk [{}] lastChunk: {}", req, req.lastChunk());
141: Boaz Leskes, info, MethodDeclaration, logger.info("--> bumping replicas to 1");
57: Ali Beyad, info, MethodDeclaration, logger.info("-->  creating repository");
65: Ali Beyad, info, MethodDeclaration, logger.info("--> creating an index and indexing documents");
76: Ali Beyad, info, MethodDeclaration, logger.info("--> create first snapshot");
85: Ali Beyad, info, MethodDeclaration, logger.info("--> create second snapshot");
94: Ali Beyad, info, MethodDeclaration, logger.info("--> make sure the node's repository can resolve the snapshots");
51: Igor Motov, info, MethodDeclaration, logger.info("--> indexing with id [1], and routing [0] using alias");
53: Igor Motov, info, MethodDeclaration, logger.info("--> verifying get with no routing, should not find anything");
57: Igor Motov, info, MethodDeclaration, logger.info("--> verifying get with routing, should find");
62: Igor Motov, info, MethodDeclaration, logger.info("--> verifying get with routing alias, should find");
67: Shay Banon, info, MethodDeclaration, logger.info("--> updating with id [1] and routing through alias");
78: Igor Motov, info, MethodDeclaration, logger.info("--> deleting with no routing, should not delete anything");
86: Igor Motov, info, MethodDeclaration, logger.info("--> deleting with routing alias, should delete");
94: Igor Motov, info, MethodDeclaration, logger.info("--> indexing with id [1], and routing [0] using alias");
96: Igor Motov, info, MethodDeclaration, logger.info("--> verifying get with no routing, should not find anything");
100: Igor Motov, info, MethodDeclaration, logger.info("--> verifying get with routing, should find");
116: Igor Motov, info, MethodDeclaration, logger.info("--> indexing with id [1], and routing [0] using alias");
118: Igor Motov, info, MethodDeclaration, logger.info("--> verifying get with no routing, should not find anything");
122: Igor Motov, info, MethodDeclaration, logger.info("--> verifying get with routing, should find");
127: Igor Motov, info, MethodDeclaration, logger.info("--> search with no routing, should fine one");
132: Igor Motov, info, MethodDeclaration, logger.info("--> search with wrong routing, should not find");
140: Igor Motov, info, MethodDeclaration, logger.info("--> search with correct routing, should find");
148: Igor Motov, info, MethodDeclaration, logger.info("--> indexing with id [2], and routing [1] using alias");
151: Igor Motov, info, MethodDeclaration, logger.info("--> search with no routing, should fine two");
157: Igor Motov, info, MethodDeclaration, logger.info("--> search with 0 routing, should find one");
165: Igor Motov, info, MethodDeclaration, logger.info("--> search with 1 routing, should find one");
173: Jim Ferenczi, info, MethodDeclaration, logger.info("--> search with 0,1 indexRoutings , should find two");
181: Igor Motov, info, MethodDeclaration, logger.info("--> search with two routing aliases , should find two");
187: Igor Motov, info, MethodDeclaration, logger.info("--> search with alias0, alias1 and alias01, should find two");
193: Igor Motov, info, MethodDeclaration, logger.info("--> search with test, alias0 and alias1, should find two");
220: Igor Motov, info, MethodDeclaration, logger.info("--> indexing with id [1], and routing [0] using alias to test-a");
222: Igor Motov, info, MethodDeclaration, logger.info("--> verifying get with no routing, should not find anything");
226: Igor Motov, info, MethodDeclaration, logger.info("--> verifying get with routing, should find");
231: Igor Motov, info, MethodDeclaration, logger.info("--> indexing with id [0], and routing [1] using alias to test-b");
233: Igor Motov, info, MethodDeclaration, logger.info("--> verifying get with no routing, should not find anything");
237: Igor Motov, info, MethodDeclaration, logger.info("--> verifying get with routing, should find");
243: Igor Motov, info, MethodDeclaration, logger.info("--> search with alias-a1,alias-b0, should not find");
249: Igor Motov, info, MethodDeclaration, logger.info("--> search with alias-ab, should find two");
255: Igor Motov, info, MethodDeclaration, logger.info("--> search with alias-a0,alias-b1 should find two");
274: Benjamin DeveÌze, info, MethodDeclaration, logger.info("--> indexing on index_1 which is an alias for index with routing [1]");
276: Benjamin DeveÌze, info, MethodDeclaration, logger.info("--> indexing on index_2 which is a concrete index");
280: Benjamin DeveÌze, info, MethodDeclaration, logger.info("--> search all on index_* should find two");
299: Luca Cavanna, info, MethodDeclaration, logger.info("--> indexing on index_1 which is an alias for index with routing [1]");
301: Luca Cavanna, info, MethodDeclaration, logger.info("--> indexing on index_2 which is a concrete index");
306: Luca Cavanna, info, MethodDeclaration, logger.info("--> search all on index_* should find two");
316: Igor Motov, info, MethodDeclaration, logger.info("--> creating alias with routing [3]");
320: Igor Motov, info, MethodDeclaration, logger.info("--> indexing with id [0], and routing [3]");
322: Igor Motov, info, MethodDeclaration, logger.info("--> verifying get with no routing, should not find anything");
324: Igor Motov, info, MethodDeclaration, logger.info("--> verifying get and search with routing, should find");
331: Igor Motov, info, MethodDeclaration, logger.info("--> creating alias with routing [4]");
335: Igor Motov, info, MethodDeclaration, logger.info("--> verifying search with wrong routing should not find");
341: Igor Motov, info, MethodDeclaration, logger.info("--> creating alias with search routing [3,4] and index routing 4");
345: Igor Motov, info, MethodDeclaration, logger.info("--> indexing with id [1], and routing [4]");
347: Igor Motov, info, MethodDeclaration, logger.info("--> verifying get with no routing, should not find anything");
349: Igor Motov, info, MethodDeclaration, logger.info("--> verifying get and search with routing, should find");
109: Scott Somerville, info, WhileStmt, logger.info("--> shrinking index [" + previousIndex + "] to [" + index + "]");
131: Scott Somerville, info, ForeachStmt, logger.info("--> routed search on index [" + index + "] visited [" + response.getTotalShards() + "] shards for routing [" + routing + "] and got hits [" + response.getHits().getTotalHits() + "]");
81: Simon Willnauer, info, MethodDeclaration, logger.info("--> indexing with id [1], and routing [{}]", routingValue);
84: kimchy, info, MethodDeclaration, logger.info("--> verifying get with no routing, should not find anything");
88: kimchy, info, MethodDeclaration, logger.info("--> verifying get with routing, should find");
93: kimchy, info, MethodDeclaration, logger.info("--> deleting with no routing, should not delete anything");
100: kimchy, info, MethodDeclaration, logger.info("--> deleting with routing, should delete");
107: kimchy, info, MethodDeclaration, logger.info("--> indexing with id [1], and routing [0]");
110: kimchy, info, MethodDeclaration, logger.info("--> verifying get with no routing, should not find anything");
114: kimchy, info, MethodDeclaration, logger.info("--> verifying get with routing, should find");
125: Simon Willnauer, info, MethodDeclaration, logger.info("--> indexing with id [1], and routing [{}]", routingValue);
128: kimchy, info, MethodDeclaration, logger.info("--> verifying get with no routing, should not find anything");
132: kimchy, info, MethodDeclaration, logger.info("--> verifying get with routing, should find");
137: kimchy, info, MethodDeclaration, logger.info("--> search with no routing, should fine one");
142: kimchy, info, MethodDeclaration, logger.info("--> search with wrong routing, should not find");
148: kimchy, info, MethodDeclaration, logger.info("--> search with correct routing, should find");
155: Simon Willnauer, info, MethodDeclaration, logger.info("--> indexing with id [{}], and routing [{}]", routingValue, secondRoutingValue);
158: kimchy, info, MethodDeclaration, logger.info("--> search with no routing, should fine two");
164: Simon Willnauer, info, MethodDeclaration, logger.info("--> search with {} routing, should find one", routingValue);
170: Simon Willnauer, info, MethodDeclaration, logger.info("--> search with {} routing, should find one", secondRoutingValue);
176: Jim Ferenczi, info, MethodDeclaration, logger.info("--> search with {},{} indexRoutings , should find two", routingValue, "1");
182: Jim Ferenczi, info, MethodDeclaration, logger.info("--> search with {},{},{} indexRoutings , should find two", routingValue, secondRoutingValue, routingValue);
196: Simon Willnauer, info, MethodDeclaration, logger.info("--> indexing with id [1], and routing [{}]", routingValue);
199: Martijn van Groningen, info, MethodDeclaration, logger.info("--> verifying get with no routing, should fail");
201: kimchy, info, MethodDeclaration, logger.info("--> indexing with id [1], with no routing, should fail");
209: kimchy, info, MethodDeclaration, logger.info("--> verifying get with routing, should find");
214: javanna, info, MethodDeclaration, logger.info("--> deleting with no routing, should fail");
353: Simon Willnauer, info, MethodDeclaration, logger.info("--> indexing with id [1], and routing [{}]", routingValue);
355: Simon Willnauer, info, MethodDeclaration, logger.info("--> indexing with id [2], and routing [{}]", routingValue);
359: Martijn van Groningen, info, MethodDeclaration, logger.info("--> verifying get with id [1] with routing [0], should succeed");
362: Martijn van Groningen, info, MethodDeclaration, logger.info("--> verifying get with id [1], with no routing, should fail");
370: Martijn van Groningen, info, MethodDeclaration, logger.info("--> verifying explain with id [2], with routing [0], should succeed");
377: Martijn van Groningen, info, MethodDeclaration, logger.info("--> verifying explain with id [2], with no routing, should fail");
386: Martijn van Groningen, info, MethodDeclaration, logger.info("--> verifying term vector with id [1], with routing [0], should succeed");
410: Martijn van Groningen, info, MethodDeclaration, logger.info("--> verifying mget with ids [1,2], with routing [0], should succeed");
420: Martijn van Groningen, info, MethodDeclaration, logger.info("--> verifying mget with ids [1,2], with no routing, should fail");
76: Igor Motov, info, MethodDeclaration, logger.info("--> setup script service");
71: Igor Motov, info, MethodDeclaration, logger.info("Using lowLevelCancellation: {}", lowLevelCancellation);
105: Igor Motov, info, LambdaExpr, logger.info("The plugin blocked on {} out of {} shards", numberOfBlockedPlugins, numberOfShards);
121: Igor Motov, info, MethodDeclaration, logger.info("Cancelling search");
134: Igor Motov, info, CatchClause, logger.info("All shards failed with", ex);
130: Igor Motov, info, TryStmt, logger.info("Search response {}", response);
144: Igor Motov, info, MethodDeclaration, logger.info("Executing search");
153: Luca Cavanna, info, MethodDeclaration, logger.info("Segments {}", Strings.toString(client().admin().indices().prepareSegments("test").get()));
162: Igor Motov, info, MethodDeclaration, logger.info("Executing search");
171: Luca Cavanna, info, MethodDeclaration, logger.info("Segments {}", Strings.toString(client().admin().indices().prepareSegments("test").get()));
180: Igor Motov, info, MethodDeclaration, logger.info("Executing search");
195: Igor Motov, info, IfStmt, logger.info("Cleaning scroll with id {}", response.getScrollId());
209: Igor Motov, info, MethodDeclaration, logger.info("Executing search");
228: Igor Motov, info, MethodDeclaration, logger.info("Executing scroll with id {}", scrollId);
241: Igor Motov, info, MethodDeclaration, logger.info("Cleaning scroll with id {}", scrollId);
58: Britta Weber, info, MethodDeclaration, logger.info("search type is {}", searchType);
102: Christoph BÃ¼scher, info, MethodDeclaration, logger.info("Content string: {}", factoriesBuilder);
111: Christoph BÃ¼scher, info, MethodDeclaration, logger.info("Content string: {}", contentString);
437: Yannick Welsch, info, MethodDeclaration, logger.info("Indexing [{}] docs", numDocs);
88: Yannick Welsch, info, MethodDeclaration, logger.info("AGG COLLECTION MODE: {}", aggCollectionMode);
592: Martijn van Groningen, info, ForeachStmt, logger.info("Checking results for bucket {}", bucketName);
633: Martijn van Groningen, info, ForeachStmt, logger.info("Checking results for bucket {}", bucketName);
623: Martijn van Groningen, info, TryStmt, logger.info("bucket_order={} size={} execution_hint={}", bucketOrder, size, executionHint);
716: Martijn van Groningen, info, TryStmt, logger.info("bucket_order={} size={} execution_hint={}, collect_mode={}", bucketOrder, size, executionHint, collectionMode);
189: Lee Hinman, info, MethodDeclaration, logger.info("Full high_card_idx Response Content:\n{ {} }", Strings.toString(builder));
484: Nhat Nguyen, error, ForeachStmt, logger.error(new ParameterizedMessage("Shard Failure: {}", failure), failure.getCause());
487: Simon Willnauer, info, ForStmt, logger.info("{}: top_hits: [{}][{}] control: [{}][{}]", i, hits.getAt(i).getId(), hits.getAt(i).getSortValues()[0], controlHits.getAt(i).getId(), controlHits.getAt(i).getSortValues()[0]);
663: Yannick Welsch, info, ForeachStmt, logger.info("Track score={}", trackScore);
65: Jason Tedor, info, MethodDeclaration, logger.info("running iteration for id {}, preference {}", id, preference);
74: Jason Tedor, info, MethodDeclaration, logger.info("using preference {}", preference);
86: Jason Tedor, info, IfStmt, logger.info("hits count mismatch on any shard search failed, post explicit refresh hits are {}", searchResponseAfterRefresh.getHits().getTotalHits());
89: Jason Tedor, info, IfStmt, logger.info("hits count mismatch on any shard search failed, post explicit wait for green hits are {}", searchResponseAfterGreen.getHits().getTotalHits());
120: Yannick Welsch, info, IfStmt, logger.info("non-critical exceptions: {}", nonCriticalExceptions);
111: Simon Willnauer, info, MethodDeclaration, logger.info("creating index: [test] using settings: [{}]", settings.build());
129: Simon Willnauer, info, MethodDeclaration, logger.info("Start Refresh");
132: Simon Willnauer, info, MethodDeclaration, logger.info("Refresh failed [{}] numShardsFailed: [{}], shardFailuresLength: [{}], successfulShards: [{}], totalShards: [{}] ", refreshFailed, refreshResponse.getFailedShards(), refreshResponse.getShardFailures().length, refreshResponse.getSuccessfulShards(), refreshResponse.getTotalShards());
156: Simon Willnauer, info, CatchClause, logger.info("expected SearchPhaseException: [{}]", ex.getMessage());
141: Simon Willnauer, info, TryStmt, logger.info("Searching for [test:{}]", English.intToEnglish(docToQuery));
144: javanna, info, TryStmt, logger.info("Successful shards: [{}]  numShards: [{}]", searchResponse.getSuccessfulShards(), test.numPrimaries);
150: javanna, info, TryStmt, logger.info("Match all Successful shards: [{}]  numShards: [{}]", searchResponse.getSuccessfulShards(), test.numPrimaries);
116: Simon Willnauer, info, IfStmt, logger.info("creating index: [test] using settings: [{}]", settings.build());
94: Simon Willnauer, info, IfStmt, logger.info("creating index: [test] using settings: [{}]", settings.build());
130: Ryan Ernst, info, IfStmt, logger.info("ClusterHealth timed out - only index one doc and expect searches to fail");
152: Ryan Ernst, info, MethodDeclaration, logger.info("Start Refresh");
155: Ryan Ernst, info, MethodDeclaration, logger.info("Refresh failed [{}] numShardsFailed: [{}], shardFailuresLength: [{}], successfulShards: [{}], totalShards: [{}] ", refreshFailed, refreshResponse.getFailedShards(), refreshResponse.getShardFailures().length, refreshResponse.getSuccessfulShards(), refreshResponse.getTotalShards());
177: Ryan Ernst, info, CatchClause, logger.info("SearchPhaseException: [{}]", ex.getMessage());
162: Ryan Ernst, info, TryStmt, logger.info("Searching for [test:{}]", English.intToEnglish(docToQuery));
165: Ryan Ernst, info, TryStmt, logger.info("Successful shards: [{}]  numShards: [{}]", searchResponse.getSuccessfulShards(), numShards.numPrimaries);
172: Ryan Ernst, info, TryStmt, logger.info("Match all Successful shards: [{}]  numShards: [{}]", searchResponse.getSuccessfulShards(), numShards.numPrimaries);
54: Colin Goodheart-Smithe, info, MethodDeclaration, logger.info("Start Testing failed search with wrong query");
85: Colin Goodheart-Smithe, info, MethodDeclaration, logger.info("Running Cluster Health");
91: Yannick Welsch, info, MethodDeclaration, logger.info("Done Cluster Health, status {}", clusterHealth.getStatus());
116: Colin Goodheart-Smithe, info, MethodDeclaration, logger.info("Done Testing failed search");
305: Colin Goodheart-Smithe, info, MethodDeclaration, logger.info("Start Testing failed search with wrong query");
317: Colin Goodheart-Smithe, info, MethodDeclaration, logger.info("Done Testing failed search");
325: kimchy, info, MethodDeclaration, logger.info("Start Testing failed search with wrong from");
347: kimchy, info, MethodDeclaration, logger.info("Done Testing failed search");
353: Igor Motov, info, MethodDeclaration, logger.info("Start Testing failed multi search with a wrong query");
369: Igor Motov, info, MethodDeclaration, logger.info("Done Testing failed search");
375: Britta Weber, info, MethodDeclaration, logger.info("Start Testing failed multi search with a wrong query");
392: Britta Weber, info, MethodDeclaration, logger.info("Done Testing failed search");
457: Lukas Vlcek, info, MethodDeclaration, logger.info("--> highlighting and searching on field1 and field2 produces different tags");
487: Shay Banon, info, MethodDeclaration, logger.info("--> highlighting and searching on field*");
551: kimchy, info, MethodDeclaration, logger.info("--> highlighting and searching on field1");
569: kimchy, info, MethodDeclaration, logger.info("--> highlighting and searching on field1");
578: Nik Everett, info, MethodDeclaration, logger.info("--> searching with boundary characters");
587: Nik Everett, info, MethodDeclaration, logger.info("--> searching with boundary characters on the field");
605: Jim Ferenczi, info, ForeachStmt, logger.info("--> highlighting and searching on 'field' with sentence boundary_scanner");
635: Jim Ferenczi, info, ForeachStmt, logger.info("--> highlighting and searching on 'field' with sentence boundary_scanner");
666: Shai Erera, info, MethodDeclaration, logger.info("--> highlighting and searching on 'field' with word boundary_scanner");
726: Nik Everett, info, MethodDeclaration, logger.info("--> highlighting and searching on field1 with default phrase limit");
733: Nik Everett, info, MethodDeclaration, logger.info("--> highlighting and searching on field1 with large phrase limit");
923: Luca Cavanna, info, MethodDeclaration, logger.info("--> indexing docs");
926: kimchy, info, MethodDeclaration, logger.info("--> searching explicitly on field1 and highlighting on it");
1296: Jim Ferenczi, info, MethodDeclaration, logger.info("--> highlighting and searching on field1");
1314: Simon Willnauer, info, MethodDeclaration, logger.info("--> highlighting and searching on field1");
1333: Simon Willnauer, info, MethodDeclaration, logger.info("--> highlighting and searching on field1");
1350: Simon Willnauer, info, MethodDeclaration, logger.info("--> highlighting and searching on field1");
1377: Simon Willnauer, info, MethodDeclaration, logger.info("--> highlighting and searching on field0");
1394: Jim Ferenczi, info, MethodDeclaration, logger.info("--> highlighting and searching on field1");
1447: Jim Ferenczi, info, MethodDeclaration, logger.info("--> highlighting and searching on field4");
1459: Jim Ferenczi, info, MethodDeclaration, logger.info("--> highlighting and searching on field4");
1941: Jim Ferenczi, info, MethodDeclaration, logger.info("--> highlighting and searching on field1");
1949: Jim Ferenczi, info, MethodDeclaration, logger.info("--> searching on field1, highlighting on field1");
1958: Jim Ferenczi, info, MethodDeclaration, logger.info("--> searching on field2, highlighting on field2");
1968: Jim Ferenczi, info, MethodDeclaration, logger.info("--> searching on field2, highlighting on field2");
1979: Jim Ferenczi, info, MethodDeclaration, logger.info("--> searching on field2, highlighting on field2, falling back to the plain highlighter");
2022: Jim Ferenczi, info, MethodDeclaration, logger.info("--> highlighting and searching on field1");
2104: Yannick Welsch, info, ForStmt, logger.info("Running multi-match type: [{}] highlight with type: [{}]", matchQueryType, highlighterType);
2127: Jim Ferenczi, info, MethodDeclaration, logger.info("--> highlighting and searching on field1");
2279: Jim Ferenczi, info, MethodDeclaration, logger.info("--> highlighting and searching on field1");
2297: Jim Ferenczi, info, MethodDeclaration, logger.info("--> highlighting and searching on field1");
2323: Luca Cavanna, info, MethodDeclaration, logger.info("--> highlighting and searching on field2");
2340: Jim Ferenczi, info, MethodDeclaration, logger.info("--> highlighting and searching on field2");
2357: Jim Ferenczi, info, MethodDeclaration, logger.info("--> highlighting and searching on field2");
2374: Jim Ferenczi, info, MethodDeclaration, logger.info("--> highlighting and searching on field2");
2398: Jim Ferenczi, info, MethodDeclaration, logger.info("--> highlighting and searching on field2");
2414: Jim Ferenczi, info, MethodDeclaration, logger.info("--> highlighting and searching on field2");
2429: Jim Ferenczi, info, MethodDeclaration, logger.info("--> highlighting and searching on field1");
2443: Jim Ferenczi, info, MethodDeclaration, logger.info("--> highlighting and searching on field1");
2460: Jim Ferenczi, info, MethodDeclaration, logger.info("--> highlighting and searching on field1");
2475: Jim Ferenczi, info, MethodDeclaration, logger.info("--> highlighting and searching on field1");
2500: Luca Cavanna, info, MethodDeclaration, logger.info("--> indexing docs");
2503: Jim Ferenczi, info, MethodDeclaration, logger.info("--> searching explicitly on field1 and highlighting on it");
2822: Jim Ferenczi, info, ForeachStmt, logger.info("--> highlighting (type=" + highlighterType + ") and searching on field1");
287: Shay Banon, info, MethodDeclaration, logger.info("running doc['num1'].value");
322: Shay Banon, info, MethodDeclaration, logger.info("running doc['num1'].value * factor");
413: Simon Willnauer, info, MethodDeclaration, logger.info("--> Hit[0] {} Explanation:\n {}", sr.getHits().getAt(0).getId(), sr.getHits().getAt(0).getExplanation());
376: Yannick Welsch, info, MethodDeclaration, logger.info("max repeat: {}", maxRepeat);
377: Yannick Welsch, info, MethodDeclaration, logger.info("avg repeat: {}", sumRepeat / (double) filled);
378: Yannick Welsch, info, MethodDeclaration, logger.info("distribution: {}", filled / (double) count);
396: Yannick Welsch, info, IfStmt, logger.info("percentile_75: {}", i);
394: Yannick Welsch, info, IfStmt, logger.info("percentile_25: {}", i);
392: Yannick Welsch, info, IfStmt, logger.info("median: {}", i);
403: Yannick Welsch, info, MethodDeclaration, logger.info("mean: {}", sum / (double) count);
330: Yannick Welsch, info, MethodDeclaration, logger.info("Created Random GeometryCollection containing {} shapes", gcb.numShapes());
74: kimchy, info, MethodDeclaration, logger.info("Creating index test");
80: kimchy, info, MethodDeclaration, logger.info("Running Cluster Health");
83: kimchy, info, MethodDeclaration, logger.info("Indexing...");
88: kimchy, info, MethodDeclaration, logger.info("Running moreLikeThis");
95: Simon Willnauer, info, MethodDeclaration, logger.info("Creating index test");
98: Simon Willnauer, info, MethodDeclaration, logger.info("Running Cluster Health");
101: Simon Willnauer, info, MethodDeclaration, logger.info("Indexing...");
108: Simon Willnauer, info, MethodDeclaration, logger.info("Running moreLikeThis");
115: Igor Motov, info, MethodDeclaration, logger.info("Creating index test");
120: Igor Motov, info, MethodDeclaration, logger.info("Creating aliases alias release");
125: Igor Motov, info, MethodDeclaration, logger.info("Running Cluster Health");
128: Igor Motov, info, MethodDeclaration, logger.info("Indexing...");
135: Igor Motov, info, MethodDeclaration, logger.info("Running moreLikeThis on index");
140: Igor Motov, info, MethodDeclaration, logger.info("Running moreLikeThis on beta shard");
146: Igor Motov, info, MethodDeclaration, logger.info("Running moreLikeThis on release shard");
152: Leonardo Menezes, info, MethodDeclaration, logger.info("Running moreLikeThis on alias with node client");
312: Alex Ksikes, info, MethodDeclaration, logger.info("Creating index test");
318: Alex Ksikes, info, MethodDeclaration, logger.info("Running Cluster Health");
321: Alex Ksikes, info, MethodDeclaration, logger.info("Indexing...");
332: Alex Ksikes, info, MethodDeclaration, logger.info("Running More Like This with include true");
341: Alex Ksikes, info, MethodDeclaration, logger.info("Running More Like This with include false");
348: Alex Ksikes, info, MethodDeclaration, logger.info("Creating index test");
354: Alex Ksikes, info, MethodDeclaration, logger.info("Running Cluster Health");
357: Alex Ksikes, info, MethodDeclaration, logger.info("Indexing...");
364: Alex Ksikes, info, MethodDeclaration, logger.info("Running MoreLikeThis");
371: Alex Ksikes, info, MethodDeclaration, logger.info("Creating the index ...");
377: Alex Ksikes, info, MethodDeclaration, logger.info("Indexing ...");
391: Yannick Welsch, info, ForStmt, logger.info("Running More Like This with max_query_terms = {}", max_query_terms);
403: Alex Ksikes, info, MethodDeclaration, logger.info("Creating the index ...");
409: Alex Ksikes, info, MethodDeclaration, logger.info("Indexing with each doc having one less term ...");
420: Alex Ksikes, info, MethodDeclaration, logger.info("Testing each minimum_should_match from 0% - 100% with 10% increment ...");
427: Yannick Welsch, info, ForStmt, logger.info("Testing with minimum_should_match = {}", minimumShouldMatch);
445: Alex Ksikes, info, MethodDeclaration, logger.info("Indexing a single document ...");
453: Alex Ksikes, info, MethodDeclaration, logger.info("Checking the document matches ...");
466: Alex Ksikes, info, MethodDeclaration, logger.info("Creating the index ...");
471: Alex Ksikes, info, MethodDeclaration, logger.info("Creating an index with a single document ...");
478: Alex Ksikes, info, MethodDeclaration, logger.info("Checking with a malformed field value ...");
493: Alex Ksikes, info, MethodDeclaration, logger.info("Checking with an empty document ...");
504: Alex Ksikes, info, MethodDeclaration, logger.info("Checking the document matches otherwise ...");
525: Alex Ksikes, info, MethodDeclaration, logger.info("Create a document that has all the fields.");
532: Alex Ksikes, info, MethodDeclaration, logger.info("Indexing each field value of this document as a single document.");
539: Alex Ksikes, info, MethodDeclaration, logger.info("First check the document matches all indexed docs.");
550: Alex Ksikes, info, MethodDeclaration, logger.info("Now check like this doc, but ignore one doc in the index, then two and so on...");
71: Adrien Grand, info, ForeachStmt, logger.info("--> Testing out preference={}", pref);
76: Yannick Welsch, info, ForStmt, logger.info("Query: {}", q);
130: Yannick Welsch, info, ForStmt, logger.info("Query: {}", q);
311: Yannick Welsch, info, MethodDeclaration, logger.info("Query: {}", q);
363: Yannick Welsch, info, MethodDeclaration, logger.info("Query: {}", q);
410: Yannick Welsch, info, MethodDeclaration, logger.info("Query: {}", q);
457: Yannick Welsch, info, MethodDeclaration, logger.info("Query: {}", q);
503: Yannick Welsch, info, MethodDeclaration, logger.info("Query: {}", q.toString());
549: Yannick Welsch, info, MethodDeclaration, logger.info("Query: {}", q);
561: Yannick Welsch, error, ForeachStmt, logger.error("Shard search failure: {}", f);
605: Yannick Welsch, info, MethodDeclaration, logger.info("Query: {}", q);
138: Adrien Grand, info, ForeachStmt, logger.info("Explanation for [{}] / [{}] / [{}]: [{}]", fieldName, id, searchHit.getSourceAsString(), explanation.getExplanation());
372: Lee Hinman, info, LambdaExpr, logger.info("--> using {}", qb);
512: David Pilato, info, MethodDeclaration, logger.info(" --> Using time_zone [{}], now is [{}]", timeZone.getID(), now);
1239: Shay Banon, info, MethodDeclaration, logger.info("--> term query on 1");
1259: Shay Banon, info, MethodDeclaration, logger.info("--> terms query on 1");
1279: Shay Banon, info, MethodDeclaration, logger.info("--> term filter on 1");
1299: Shay Banon, info, MethodDeclaration, logger.info("--> terms filter on 1");
1515: Shay Banon, info, MethodDeclaration, logger.info("regular");
1518: Shay Banon, info, MethodDeclaration, logger.info("prefix");
1521: Shay Banon, info, MethodDeclaration, logger.info("wildcard");
1524: Shay Banon, info, MethodDeclaration, logger.info("fuzzy");
1527: Shay Banon, info, MethodDeclaration, logger.info("regexp");
137: Lee Hinman, info, MethodDeclaration, logger.info("--> query 1");
142: Lee Hinman, info, MethodDeclaration, logger.info("--> query 2");
149: Christoph BÃ¼scher, info, MethodDeclaration, logger.info("--> query 3");
155: Christoph BÃ¼scher, info, MethodDeclaration, logger.info("--> query 4");
167: Christoph BÃ¼scher, info, MethodDeclaration, logger.info("--> query 5");
173: Christoph BÃ¼scher, info, MethodDeclaration, logger.info("--> query 6");
178: Christoph BÃ¼scher, info, MethodDeclaration, logger.info("--> query 7");
571: Lee Hinman, info, LambdaExpr, logger.info("--> using {}", qb);
172: kimchy, info, MethodDeclaration, logger.info("running doc['num1'].value > 1");
190: Colin Goodheart-Smithe, info, MethodDeclaration, logger.info("running doc['num1'].value > param1");
205: Colin Goodheart-Smithe, info, MethodDeclaration, logger.info("running doc['num1'].value > param1");
174: Martijn van Groningen, info, MethodDeclaration, logger.info("numDocs={}, scrollRequestSize={}, sort={}, searchType={}", numDocs, scrollRequestSize, sort, searchType);
251: Yannick Welsch, info, CatchClause, logger.info("Control:\n{}", control);
252: Yannick Welsch, info, CatchClause, logger.info("Scroll size={}, from={}:\n{}", size, scrollDocs, scroll);
768: Isabel Drost-Fromm, info, MethodDeclaration, logger.info("--> sort with no missing (same as missing _last)");
780: Isabel Drost-Fromm, info, MethodDeclaration, logger.info("--> sort with missing _last");
792: Isabel Drost-Fromm, info, MethodDeclaration, logger.info("--> sort with missing _first");
842: Isabel Drost-Fromm, info, MethodDeclaration, logger.info("--> sort with no missing (same as missing _last)");
854: Isabel Drost-Fromm, info, MethodDeclaration, logger.info("--> sort with missing _last");
866: Isabel Drost-Fromm, info, MethodDeclaration, logger.info("--> sort with missing _first");
878: Isabel Drost-Fromm, info, MethodDeclaration, logger.info("--> sort with missing b");
900: Isabel Drost-Fromm, info, MethodDeclaration, logger.info("--> sort with an unmapped field, verify it fails");
84: Yannick Welsch, info, MethodDeclaration, logger.info("d1: {}", d1Builder);
85: Yannick Welsch, info, MethodDeclaration, logger.info("d2: {}", d2Builder);
150: Christoph BÃ¼scher, info, MethodDeclaration, logger.info("d1: {}", d1Builder);
151: Christoph BÃ¼scher, info, MethodDeclaration, logger.info("d2: {}", d2Builder);
422: Tanguy Leroux, warn, IfStmt, logger.warn("Failed shards:");
424: Tanguy Leroux, warn, ForeachStmt, logger.warn("-> {}", shardSearchFailure);
442: Tanguy Leroux, warn, IfStmt, logger.warn("Failed shards:");
444: Tanguy Leroux, warn, ForeachStmt, logger.warn("-> {}", shardSearchFailure);
133: Yannick Welsch, debug, MethodDeclaration, logger.debug("###### indices search stats: {}", indicesStats.getTotal().getSearch());
98: Simon Willnauer, info, MethodDeclaration, logger.info("--> run suggestions with one index");
112: Simon Willnauer, info, MethodDeclaration, logger.info("--> run suggestions with two indices");
138: Simon Willnauer, info, MethodDeclaration, logger.info("--> run suggestions with three indices");
157: Simon Willnauer, info, MethodDeclaration, logger.info("--> run suggestions with four indices");
165: Daniel Mitterdorfer, info, IfStmt, logger.info("Skipping test as it uses a custom duplicate check that is obsolete when strict duplicate checks are enabled.");
173: Igor Motov, info, MethodDeclaration, logger.info("--> start 2 nodes");
177: Igor Motov, info, MethodDeclaration, logger.info("--> wait for the second node to join the cluster");
180: Igor Motov, info, MethodDeclaration, logger.info("--> set test persistent setting");
189: Igor Motov, info, MethodDeclaration, logger.info("--> create repository");
194: Igor Motov, info, MethodDeclaration, logger.info("--> start snapshot");
200: Igor Motov, info, MethodDeclaration, logger.info("--> clean the test persistent setting");
211: Igor Motov, info, MethodDeclaration, logger.info("--> restore snapshot");
219: Igor Motov, info, MethodDeclaration, logger.info("--> ensure that zen discovery minimum master nodes wasn't restored");
227: Igor Motov, info, MethodDeclaration, logger.info("--> start node");
231: Igor Motov, info, MethodDeclaration, logger.info("--> add custom persistent metadata");
244: Igor Motov, info, MethodDeclaration, logger.info("--> create repository");
249: Igor Motov, info, MethodDeclaration, logger.info("--> start snapshot");
255: Igor Motov, info, MethodDeclaration, logger.info("--> change custom persistent metadata");
276: Igor Motov, info, MethodDeclaration, logger.info("--> delete repository");
279: Igor Motov, info, MethodDeclaration, logger.info("--> create repository");
284: Igor Motov, info, MethodDeclaration, logger.info("--> restore snapshot");
287: Igor Motov, info, MethodDeclaration, logger.info("--> make sure old repository wasn't restored");
291: Igor Motov, info, MethodDeclaration, logger.info("--> check that custom persistent metadata was restored");
293: Igor Motov, info, MethodDeclaration, logger.info("Cluster state: {}", clusterState);
300: Igor Motov, info, MethodDeclaration, logger.info("--> restart all nodes");
304: Igor Motov, info, MethodDeclaration, logger.info("--> check that gateway-persistent custom metadata survived full cluster restart");
306: Igor Motov, info, MethodDeclaration, logger.info("Cluster state: {}", clusterState);
346: Igor Motov, info, MethodDeclaration, logger.info("--> start 2 nodes");
352: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
359: Igor Motov, info, MethodDeclaration, logger.info("--> create repository");
360: Igor Motov, info, MethodDeclaration, logger.info("--> creating repository");
373: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
376: Igor Motov, info, MethodDeclaration, logger.info("--> waiting for block to kick in");
379: Igor Motov, info, MethodDeclaration, logger.info("--> execution was blocked on node [{}], shutting it down", blockedNode);
382: Yannick Welsch, info, MethodDeclaration, logger.info("--> stopping node [{}]", blockedNode);
384: Igor Motov, info, MethodDeclaration, logger.info("--> waiting for completion");
386: Igor Motov, info, MethodDeclaration, logger.info("Number of failed shards [{}]", snapshotInfo.shardFailures().size());
387: Igor Motov, info, MethodDeclaration, logger.info("--> done");
391: Igor Motov, info, MethodDeclaration, logger.info("--> start 2 nodes");
400: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
407: Igor Motov, info, MethodDeclaration, logger.info("--> creating repository");
424: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
427: Igor Motov, info, MethodDeclaration, logger.info("--> waiting for block to kick in");
430: Igor Motov, info, MethodDeclaration, logger.info("--> execution was blocked on node [{}], aborting snapshot", blockedNode);
436: Yannick Welsch, info, MethodDeclaration, logger.info("--> stopping node [{}]", blockedNode);
447: Igor Motov, info, MethodDeclaration, logger.info("--> making sure that snapshot no longer exists");
456: Igor Motov, info, MethodDeclaration, logger.info("--> done");
460: Igor Motov, info, MethodDeclaration, logger.info("--> start 2 nodes");
465: Igor Motov, info, MethodDeclaration, logger.info("--> create an index that will have some unallocated shards");
470: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data into test-idx-some");
477: Igor Motov, info, MethodDeclaration, logger.info("--> shutdown one of the nodes");
481: Igor Motov, info, MethodDeclaration, logger.info("--> create an index that will have all allocated shards");
486: Igor Motov, info, MethodDeclaration, logger.info("--> create an index that will be closed");
490: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data into test-idx-all");
499: Igor Motov, info, MethodDeclaration, logger.info("--> create an index that will have no allocated shards");
505: Igor Motov, info, MethodDeclaration, logger.info("--> creating repository");
510: Igor Motov, info, MethodDeclaration, logger.info("--> start snapshot with default settings and closed index - should be blocked");
516: Igor Motov, info, MethodDeclaration, logger.info("--> start snapshot with default settings without a closed index - should fail");
554: Igor Motov, info, IfStmt, logger.info("checking snapshot completion using wait_for_completion flag");
558: Igor Motov, info, IfStmt, logger.info("State: [{}], Reason: [{}]", createSnapshotResponse.getSnapshotInfo().state(), createSnapshotResponse.getSnapshotInfo().reason());
524: Igor Motov, info, IfStmt, logger.info("checking snapshot completion using status");
532: Boaz Leskes, trace, LambdaExpr, logger.trace("current snapshot status [{}]", snapshotStatuses.get(0));
539: Igor Motov, info, IfStmt, logger.info("State: [{}], Reason: [{}]", createSnapshotResponse.getSnapshotInfo().state(), createSnapshotResponse.getSnapshotInfo().reason());
567: Igor Motov, info, MethodDeclaration, logger.info("--> restore incomplete snapshot - should fail");
570: Igor Motov, info, MethodDeclaration, logger.info("--> restore snapshot for the index that was snapshotted completely");
579: Igor Motov, info, MethodDeclaration, logger.info("--> restore snapshot for the partial index");
590: Igor Motov, info, MethodDeclaration, logger.info("--> restore snapshot for the index that didn't have any shards snapshotted successfully");
603: Igor Motov, info, MethodDeclaration, logger.info("--> start 2 nodes");
612: Igor Motov, info, MethodDeclaration, logger.info("--> create repository");
617: Igor Motov, info, MethodDeclaration, logger.info("--> create an index that will have some unallocated shards");
622: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data into test-idx");
629: Igor Motov, info, MethodDeclaration, logger.info("--> start snapshot");
632: Igor Motov, info, MethodDeclaration, logger.info("--> close the index");
635: Igor Motov, info, MethodDeclaration, logger.info("--> shutdown one of the nodes that should make half of the shards unavailable");
645: Igor Motov, info, MethodDeclaration, logger.info("--> restore index snapshot");
657: Igor Motov, info, MethodDeclaration, logger.info("--> check that at least half of the shards had some reuse: [{}]", reusedShards);
662: Igor Motov, info, MethodDeclaration, logger.info("--> start first node");
664: Igor Motov, info, MethodDeclaration, logger.info("--> start second node");
673: Igor Motov, info, MethodDeclaration, logger.info("--> make sure that properly setup repository can be registered on all nodes");
682: Igor Motov, info, MethodDeclaration, logger.info("--> start two nodes");
740: Igor Motov, info, MethodDeclaration, logger.info("-->  starting two master nodes and two data nodes");
746: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
757: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
767: Igor Motov, info, MethodDeclaration, logger.info("number of shards: {}", numberOfShards);
771: Yannick Welsch, info, MethodDeclaration, logger.info("--> stopping master node");
774: Igor Motov, info, MethodDeclaration, logger.info("--> wait until the snapshot is done");
782: Igor Motov, info, MethodDeclaration, logger.info("--> verify that snapshot was succesful");
793: Igor Motov, info, MethodDeclaration, logger.info("-->  starting three master nodes and two data nodes");
799: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
810: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
820: Igor Motov, info, MethodDeclaration, logger.info("number of shards: {}", numberOfShards);
827: Igor Motov, info, MethodDeclaration, logger.info("--> stopping data node {}", dataNode);
829: Igor Motov, info, MethodDeclaration, logger.info("--> stopping master node {} ", masterNode);
832: Igor Motov, info, MethodDeclaration, logger.info("--> wait until the snapshot is done");
840: Igor Motov, info, MethodDeclaration, logger.info("--> verify that snapshot was partial");
854: Ali Beyad, info, MethodDeclaration, logger.info("-->  starting two master nodes and two data nodes");
858: Ali Beyad, info, MethodDeclaration, logger.info("-->  creating repository");
869: Ali Beyad, info, MethodDeclaration, logger.info("-->  indexing some data");
879: Ali Beyad, info, MethodDeclaration, logger.info("-->  stopping random data node, which should cause shards to go missing");
887: Ali Beyad, info, MethodDeclaration, logger.info("-->  snapshot");
891: Ali Beyad, info, MethodDeclaration, logger.info("--> waiting for block to kick in on " + masterNode);
894: Ali Beyad, info, MethodDeclaration, logger.info("-->  stopping master node");
897: Ali Beyad, info, MethodDeclaration, logger.info("-->  wait until the snapshot is done");
909: Ali Beyad, info, MethodDeclaration, logger.info("-->  verify that snapshot failed");
922: Ali Beyad, info, MethodDeclaration, logger.info("-->  starting a master node and a data node");
932: Ali Beyad, info, MethodDeclaration, logger.info("-->  creating repository");
941: Ali Beyad, info, MethodDeclaration, logger.info("--> indexing some data");
950: Ali Beyad, info, MethodDeclaration, logger.info("--> shrink the index");
955: Ali Beyad, info, MethodDeclaration, logger.info("--> snapshot the shrunk index");
961: Ali Beyad, info, MethodDeclaration, logger.info("--> delete index and stop the data node");
967: Ali Beyad, info, MethodDeclaration, logger.info("--> start a new data node");
975: Ali Beyad, info, MethodDeclaration, logger.info("--> restore the shrunk index and ensure all shards are allocated");
57: Ali Beyad, info, MethodDeclaration, logger.info("--> creating repository");
65: Ali Beyad, info, MethodDeclaration, logger.info("--> snapshot twice");
85: Ali Beyad, info, MethodDeclaration, logger.info("--> start deletion of first snapshot");
88: Ali Beyad, info, MethodDeclaration, logger.info("--> waiting for block to kick in on node [{}]", blockedNode);
91: Ali Beyad, info, MethodDeclaration, logger.info("--> try deleting the second snapshot, should fail because the first deletion is in progress");
99: Ali Beyad, info, MethodDeclaration, logger.info("--> unblocking blocked node [{}]", blockedNode);
102: Ali Beyad, info, MethodDeclaration, logger.info("--> wait until first snapshot is finished");
105: Ali Beyad, info, MethodDeclaration, logger.info("--> delete second snapshot, which should now work");
111: Ali Beyad, info, MethodDeclaration, logger.info("--> creating repository");
119: Ali Beyad, info, MethodDeclaration, logger.info("--> snapshot");
131: Ali Beyad, info, MethodDeclaration, logger.info("--> start deletion of snapshot");
133: Ali Beyad, info, MethodDeclaration, logger.info("--> waiting for block to kick in on node [{}]", blockedNode);
136: Ali Beyad, info, MethodDeclaration, logger.info("--> try creating a second snapshot, should fail because the deletion is in progress");
145: Ali Beyad, info, MethodDeclaration, logger.info("--> unblocking blocked node [{}]", blockedNode);
148: Ali Beyad, info, MethodDeclaration, logger.info("--> wait until snapshot deletion is finished");
151: Ali Beyad, info, MethodDeclaration, logger.info("--> creating second snapshot, which should now work");
157: Ali Beyad, info, MethodDeclaration, logger.info("--> creating repository");
165: Ali Beyad, info, MethodDeclaration, logger.info("--> snapshot");
186: Ali Beyad, info, MethodDeclaration, logger.info("--> start deletion of snapshot");
188: Ali Beyad, info, MethodDeclaration, logger.info("--> waiting for block to kick in on node [{}]", blockedNode);
191: Ali Beyad, info, MethodDeclaration, logger.info("--> try restoring the other snapshot, should fail because the deletion is in progress");
199: Ali Beyad, info, MethodDeclaration, logger.info("--> unblocking blocked node [{}]", blockedNode);
202: Ali Beyad, info, MethodDeclaration, logger.info("--> wait until snapshot deletion is finished");
205: Ali Beyad, info, MethodDeclaration, logger.info("--> restoring snapshot, which should now work");
54: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
61: Igor Motov, info, MethodDeclaration, logger.info("--> verify the repository");
66: Igor Motov, info, MethodDeclaration, logger.info("--> verify that we didn't leave any files as a result of verification");
69: Igor Motov, info, MethodDeclaration, logger.info("--> check that repository is really there");
77: Igor Motov, info, MethodDeclaration, logger.info("-->  creating another repository");
84: Igor Motov, info, MethodDeclaration, logger.info("--> check that both repositories are in cluster state");
95: Igor Motov, info, MethodDeclaration, logger.info("--> check that both repositories can be retrieved by getRepositories query");
102: Igor Motov, info, MethodDeclaration, logger.info("--> delete repository test-repo-1");
108: Igor Motov, info, MethodDeclaration, logger.info("--> delete repository test-repo-2");
126: Igor Motov, info, MethodDeclaration, logger.info("--> trying creating repository with incorrect settings");
134: Igor Motov, info, MethodDeclaration, logger.info("--> trying creating fs repository with location that is not registered in path.repo setting");
148: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository test-repo-1 with 0s timeout - shouldn't ack");
158: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository test-repo-2 with standard timeout - should ack");
167: Igor Motov, info, MethodDeclaration, logger.info("-->  deleting repository test-repo-2 with 0s timeout - shouldn't ack");
172: Igor Motov, info, MethodDeclaration, logger.info("-->  deleting repository test-repo-1 with standard timeout - should ack");
183: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository that cannot write any files - should fail");
188: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository that cannot write any files, but suppress verification - should be acked");
192: Igor Motov, info, MethodDeclaration, logger.info("-->  verifying repository");
197: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
178: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
184: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
205: Igor Motov, info, IfStmt, logger.info("--> starting asynchronous flush for indices {}", Arrays.toString(indices));
212: Boaz Leskes, info, MethodDeclaration, logger.info("--> capturing history UUIDs");
224: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
236: Igor Motov, info, MethodDeclaration, logger.info("--> delete some data");
251: Igor Motov, info, MethodDeclaration, logger.info("--> close indices");
254: Igor Motov, info, MethodDeclaration, logger.info("--> restore all indices from the snapshot");
273: Igor Motov, info, MethodDeclaration, logger.info("--> delete indices");
275: Igor Motov, info, MethodDeclaration, logger.info("--> restore one index after deletion");
305: Igor Motov, info, MethodDeclaration, logger.info("Path [{}]", absolutePath);
315: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
321: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
343: Simon Willnauer, info, MethodDeclaration, logger.info("-->  creating repository");
364: Simon Willnauer, info, MethodDeclaration, logger.info("--> close index");
367: Simon Willnauer, info, MethodDeclaration, logger.info("--> restore all indices from the snapshot");
375: Simon Willnauer, info, MethodDeclaration, logger.info("--> restore indices with different names");
387: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
390: Igor Motov, info, MethodDeclaration, logger.info("--> create index with foo type");
399: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot it");
404: Igor Motov, info, MethodDeclaration, logger.info("--> delete the index and recreate it with bar type");
411: Igor Motov, info, MethodDeclaration, logger.info("--> close index");
414: Igor Motov, info, MethodDeclaration, logger.info("--> restore all indices from the snapshot");
418: Igor Motov, info, MethodDeclaration, logger.info("--> assert that old mapping is restored");
423: Igor Motov, info, MethodDeclaration, logger.info("--> assert that old settings are restored");
431: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
436: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
447: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
451: Igor Motov, info, MethodDeclaration, logger.info("--> create test indices");
455: Igor Motov, info, MethodDeclaration, logger.info("--> create aliases");
464: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
467: Igor Motov, info, MethodDeclaration, logger.info("-->  delete all indices");
471: Igor Motov, info, MethodDeclaration, logger.info("--> restore snapshot with aliases");
476: Igor Motov, info, MethodDeclaration, logger.info("--> check that aliases are restored");
479: Igor Motov, info, MethodDeclaration, logger.info("-->  update aliases");
483: Igor Motov, info, MethodDeclaration, logger.info("-->  delete and close indices");
488: Igor Motov, info, MethodDeclaration, logger.info("--> restore snapshot without aliases");
493: Igor Motov, info, MethodDeclaration, logger.info("--> check that aliases are not restored and existing aliases still exist");
502: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
506: Igor Motov, info, MethodDeclaration, logger.info("-->  creating test template");
527: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
533: Igor Motov, info, MethodDeclaration, logger.info("-->  delete test template");
538: Igor Motov, info, MethodDeclaration, logger.info("--> restore cluster state");
543: Igor Motov, info, MethodDeclaration, logger.info("--> check that template is restored");
552: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
562: Igor Motov, info, IfStmt, logger.info("-->  creating test template");
585: Igor Motov, info, IfStmt, logger.info("-->  creating test pipeline");
599: Igor Motov, info, IfStmt, logger.info("-->  creating test script");
606: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot without global state");
616: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot with global state");
627: Igor Motov, info, IfStmt, logger.info("-->  delete test template");
634: Igor Motov, info, IfStmt, logger.info("-->  delete test pipeline");
639: Igor Motov, info, IfStmt, logger.info("-->  delete test script");
643: Igor Motov, info, MethodDeclaration, logger.info("--> try restoring cluster state from snapshot without global state");
647: Igor Motov, info, MethodDeclaration, logger.info("--> check that template wasn't restored");
651: Igor Motov, info, MethodDeclaration, logger.info("--> restore cluster state");
656: Igor Motov, info, IfStmt, logger.info("--> check that template is restored");
662: Igor Motov, info, IfStmt, logger.info("--> check that pipeline is restored");
668: Igor Motov, info, IfStmt, logger.info("--> check that script is restored");
676: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
683: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot without global state but with indices");
689: Igor Motov, info, MethodDeclaration, logger.info("-->  delete global state and index ");
705: Igor Motov, info, MethodDeclaration, logger.info("--> try restoring index and cluster state from snapshot without global state");
710: Igor Motov, info, MethodDeclaration, logger.info("--> check that global state wasn't restored but index was");
722: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
734: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
741: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
764: Boaz Leskes, info, CatchClause, logger.info("--> caught a top level exception, asserting what's expected", ex);
772: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
783: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
790: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
797: Igor Motov, info, IfStmt, logger.info("--> some failures");
793: Igor Motov, info, IfStmt, logger.info("--> no failures");
838: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
847: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
854: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
859: Igor Motov, info, MethodDeclaration, logger.info("-->  update repository with mock version");
868: Igor Motov, info, MethodDeclaration, logger.info("--> delete index");
870: Igor Motov, info, MethodDeclaration, logger.info("--> restore index after deletion");
875: Igor Motov, info, MethodDeclaration, logger.info("--> total number of simulated failures during restore: [{}]", getFailureCount("test-repo"));
899: Yannick Welsch, info, MethodDeclaration, logger.info("-->  creating repository");
906: Yannick Welsch, info, MethodDeclaration, logger.info("--> indexing some data");
913: Yannick Welsch, info, MethodDeclaration, logger.info("--> snapshot");
920: Yannick Welsch, info, MethodDeclaration, logger.info("-->  update repository with mock version");
931: Yannick Welsch, info, MethodDeclaration, logger.info("--> delete index");
933: Yannick Welsch, info, MethodDeclaration, logger.info("--> restore corrupt index");
1099: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
1106: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
1113: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
1118: Igor Motov, info, MethodDeclaration, logger.info("-->  update repository with mock version");
1128: Igor Motov, info, MethodDeclaration, logger.info("--> delete index");
1130: Igor Motov, info, MethodDeclaration, logger.info("--> restore index after deletion");
1134: Igor Motov, info, MethodDeclaration, logger.info("--> wait for the index to appear");
1138: Igor Motov, info, MethodDeclaration, logger.info("--> delete index");
1140: Igor Motov, info, MethodDeclaration, logger.info("--> get restore results");
1146: Igor Motov, info, MethodDeclaration, logger.info("--> restoring working repository");
1150: Igor Motov, info, MethodDeclaration, logger.info("--> trying to restore index again");
1162: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
1167: Igor Motov, info, MethodDeclaration, logger.info("-->  creating index that cannot be allocated");
1170: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
1183: Yannick Welsch, info, MethodDeclaration, logger.info("-->  creating repository at {}", repo.toAbsolutePath());
1194: Igor Motov, info, MethodDeclaration, logger.info("--> creating {} snapshots ", numberOfSnapshots);
1200: Igor Motov, info, ForStmt, logger.info("--> snapshot {}", i);
1210: Igor Motov, info, MethodDeclaration, logger.info("--> delete all snapshots except the first one and last one");
1219: Igor Motov, info, MethodDeclaration, logger.info("--> delete index");
1222: Igor Motov, info, MethodDeclaration, logger.info("--> restore index");
1229: Igor Motov, info, MethodDeclaration, logger.info("--> delete the last snapshot");
1231: Ali Beyad, info, MethodDeclaration, logger.info("--> make sure that number of files is back to what it was when the first snapshot was made, " + "plus two because one backup index-N file should remain and incompatible-snapshots");
1240: Yannick Welsch, info, MethodDeclaration, logger.info("-->  creating repository at {}", repo.toAbsolutePath());
1249: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
1254: Igor Motov, info, MethodDeclaration, logger.info("--> creating snapshot");
1267: Igor Motov, info, MethodDeclaration, logger.info("--> delete index metadata and shard metadata");
1276: Igor Motov, info, MethodDeclaration, logger.info("--> delete snapshot");
1279: Igor Motov, info, MethodDeclaration, logger.info("--> make sure snapshot doesn't exist");
1291: Yannick Welsch, info, MethodDeclaration, logger.info("-->  creating repository at {}", repo.toAbsolutePath());
1299: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
1304: Igor Motov, info, MethodDeclaration, logger.info("--> creating snapshot");
1309: Tanguy Leroux, info, MethodDeclaration, logger.info("--> delete global state metadata");
1313: Igor Motov, info, MethodDeclaration, logger.info("--> delete snapshot");
1316: Igor Motov, info, MethodDeclaration, logger.info("--> make sure snapshot doesn't exist");
1324: Yannick Welsch, info, MethodDeclaration, logger.info("-->  creating repository at {}", repo.toAbsolutePath());
1332: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
1337: Igor Motov, info, MethodDeclaration, logger.info("--> creating snapshot");
1342: Igor Motov, info, MethodDeclaration, logger.info("--> truncate snapshot file to make it unreadable");
1347: Igor Motov, info, MethodDeclaration, logger.info("--> delete snapshot");
1350: Igor Motov, info, MethodDeclaration, logger.info("--> make sure snapshot doesn't exist");
1353: Igor Motov, info, MethodDeclaration, logger.info("--> make sure that we can create the snapshot again");
1422: Ali Beyad, info, MethodDeclaration, logger.info("-->  creating repository at {}", repo.toAbsolutePath());
1427: Ali Beyad, info, MethodDeclaration, logger.info("--> indexing some data");
1432: Ali Beyad, info, MethodDeclaration, logger.info("--> creating snapshot");
1436: Ali Beyad, info, MethodDeclaration, logger.info("--> deleting shard level index file");
1447: Ali Beyad, info, MethodDeclaration, logger.info("--> creating another snapshot");
1454: Ali Beyad, info, MethodDeclaration, logger.info("--> restoring the first snapshot, the repository should not have lost any shard data despite deleting index-N, " + "because it should have iterated over the snap-*.data files as backup");
1465: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
1472: Igor Motov, info, MethodDeclaration, logger.info("-->  closing index test-idx-closed");
1478: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
1483: Igor Motov, info, MethodDeclaration, logger.info("-->  deleting snapshot");
1486: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot with closed index");
1493: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
1500: Igor Motov, info, MethodDeclaration, logger.info("-->  closing index test-idx");
1503: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
1511: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
1525: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
1534: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
1539: Igor Motov, info, MethodDeclaration, logger.info("--> restore indices with different names");
1547: Igor Motov, info, MethodDeclaration, logger.info("--> close just restored indices");
1550: Igor Motov, info, MethodDeclaration, logger.info("--> and try to restore these indices again");
1559: Igor Motov, info, MethodDeclaration, logger.info("--> close indices");
1562: Igor Motov, info, MethodDeclaration, logger.info("--> restore indices with different names");
1567: Igor Motov, info, MethodDeclaration, logger.info("--> delete indices");
1570: Igor Motov, info, MethodDeclaration, logger.info("--> try renaming indices using the same name");
1578: Igor Motov, info, MethodDeclaration, logger.info("--> try renaming indices using the same name");
1586: Igor Motov, info, MethodDeclaration, logger.info("--> try renaming indices using invalid index name");
1594: Igor Motov, info, MethodDeclaration, logger.info("--> try renaming indices into existing alias name");
1602: Igor Motov, info, MethodDeclaration, logger.info("--> try renaming indices into existing alias of itself");
1610: Igor Motov, info, MethodDeclaration, logger.info("--> try renaming indices into existing alias of another restored index");
1618: Igor Motov, info, MethodDeclaration, logger.info("--> try renaming indices into existing alias of itself, but don't restore aliases ");
1630: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
1641: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
1651: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
1654: Igor Motov, info, MethodDeclaration, logger.info("--> waiting for block to kick in");
1657: Igor Motov, info, MethodDeclaration, logger.info("--> execution was blocked on node [{}], moving shards away from this node", blockedNode);
1661: Igor Motov, info, MethodDeclaration, logger.info("--> unblocking blocked node");
1663: Igor Motov, info, MethodDeclaration, logger.info("--> waiting for completion");
1665: Igor Motov, info, MethodDeclaration, logger.info("Number of failed shards [{}]", snapshotInfo.shardFailures().size());
1666: Igor Motov, info, MethodDeclaration, logger.info("--> done");
1674: Igor Motov, info, MethodDeclaration, logger.info("--> delete index");
1677: Igor Motov, info, MethodDeclaration, logger.info("--> replace mock repository with real one at the same location");
1681: Igor Motov, info, MethodDeclaration, logger.info("--> restore index");
1691: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
1704: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
1714: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
1717: Igor Motov, info, MethodDeclaration, logger.info("--> waiting for block to kick in");
1720: Igor Motov, info, MethodDeclaration, logger.info("--> execution was blocked on node [{}], trying to delete repository", blockedNode);
1726: Igor Motov, info, CatchClause, logger.info("--> in-use repository deletion failed");
1729: Igor Motov, info, MethodDeclaration, logger.info("--> trying to move repository to another location");
1736: Igor Motov, info, CatchClause, logger.info("--> in-use repository replacement failed");
1739: Igor Motov, info, MethodDeclaration, logger.info("--> trying to create a repository with different name");
1743: Igor Motov, info, MethodDeclaration, logger.info("--> unblocking blocked node");
1745: Igor Motov, info, MethodDeclaration, logger.info("--> waiting for completion");
1747: Igor Motov, info, MethodDeclaration, logger.info("Number of failed shards [{}]", snapshotInfo.shardFailures().size());
1748: Igor Motov, info, MethodDeclaration, logger.info("--> done");
1756: Igor Motov, info, MethodDeclaration, logger.info("--> delete index");
1759: Igor Motov, info, MethodDeclaration, logger.info("--> replace mock repository with real one at the same location");
1763: Igor Motov, info, MethodDeclaration, logger.info("--> restore index");
1774: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
1785: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
1791: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
1798: Igor Motov, info, MethodDeclaration, logger.info("--> delete index");
1801: Igor Motov, info, MethodDeclaration, logger.info("--> create read-only URL repository");
1808: Igor Motov, info, MethodDeclaration, logger.info("--> restore index after deletion");
1814: Igor Motov, info, MethodDeclaration, logger.info("--> list available shapshots");
1819: Igor Motov, info, MethodDeclaration, logger.info("--> try deleting snapshot");
1822: Igor Motov, info, MethodDeclaration, logger.info("--> try making another snapshot");
1829: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
1844: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
1851: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
1856: Igor Motov, info, MethodDeclaration, logger.info("--> delete index");
1859: Igor Motov, info, MethodDeclaration, logger.info("--> restore index");
1887: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
1900: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
1910: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
1914: Igor Motov, info, MethodDeclaration, logger.info("--> waiting for block to kick in");
1917: Igor Motov, info, MethodDeclaration, logger.info("--> execution was blocked on node [{}], checking snapshot status with specified repository and snapshot", blockedNode);
1932: Yannick Welsch, info, MethodDeclaration, logger.info("--> checking snapshot status for all currently running and snapshot with empty repository");
1947: Yannick Welsch, info, MethodDeclaration, logger.info("--> checking that _current returns the currently running snapshot");
1953: Igor Motov, info, MethodDeclaration, logger.info("--> unblocking blocked node");
1957: Igor Motov, info, MethodDeclaration, logger.info("Number of failed shards [{}]", snapshotInfo.shardFailures().size());
1958: Igor Motov, info, MethodDeclaration, logger.info("--> done");
1961: Yannick Welsch, info, MethodDeclaration, logger.info("--> checking snapshot status again after snapshot is done");
1974: Yannick Welsch, info, MethodDeclaration, logger.info("--> checking snapshot status after it is done with empty repository");
1978: Yannick Welsch, info, MethodDeclaration, logger.info("--> checking that _current no longer returns the snapshot");
2003: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
2013: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
2020: Igor Motov, info, MethodDeclaration, logger.info("--> start relocations");
2023: Igor Motov, info, MethodDeclaration, logger.info("--> wait for relocations to start");
2027: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
2030: Igor Motov, info, MethodDeclaration, logger.info("--> wait for snapshot to complete");
2034: Igor Motov, info, MethodDeclaration, logger.info("--> done");
2040: Simon Willnauer, info, MethodDeclaration, logger.info("-->  creating repository");
2050: Simon Willnauer, info, MethodDeclaration, logger.info("-->  indexing");
2102: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
2109: Igor Motov, info, MethodDeclaration, logger.info("--> create test index with synonyms search analyzer");
2136: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot it");
2141: Igor Motov, info, MethodDeclaration, logger.info("--> delete the index and recreate it while changing refresh interval and analyzer");
2154: Igor Motov, info, MethodDeclaration, logger.info("--> try restoring while changing the number of shards - should fail");
2161: Jun Ohtani, info, MethodDeclaration, logger.info("--> try restoring while changing the number of replicas to a negative number - should fail");
2172: Igor Motov, info, MethodDeclaration, logger.info("--> restore index with correct settings from the snapshot");
2180: Igor Motov, info, MethodDeclaration, logger.info("--> assert that correct settings are restored");
2191: Igor Motov, info, MethodDeclaration, logger.info("--> delete the index and recreate it while deleting all index settings");
2194: Igor Motov, info, MethodDeclaration, logger.info("--> restore index with correct settings from the snapshot");
2202: Igor Motov, info, MethodDeclaration, logger.info("--> assert that correct settings are restored and index is still functional");
2216: Yannick Welsch, info, MethodDeclaration, logger.info("-->  creating repository");
2228: Yannick Welsch, info, MethodDeclaration, logger.info("--> create index");
2294: Yannick Welsch, info, TryStmt, logger.info("--> cleaning up blocks");
2239: Simon Willnauer, info, TryStmt, logger.info("--> using initial block settings {}", initialSettings);
2242: Yannick Welsch, info, IfStmt, logger.info("--> apply initial blocks to index");
2246: Yannick Welsch, info, TryStmt, logger.info("--> snapshot index");
2252: Yannick Welsch, info, TryStmt, logger.info("--> remove blocks and delete index");
2259: Yannick Welsch, info, TryStmt, logger.info("--> restore index with additional block changes");
2268: Simon Willnauer, info, TryStmt, logger.info("--> applying changed block settings {}", changedSettings);
2282: Simon Willnauer, info, TryStmt, logger.info("--> merged block settings {}", mergedSettings);
2284: Yannick Welsch, info, TryStmt, logger.info("--> checking consistency between settings and blocks");
2306: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
2331: Igor Motov, info, MethodDeclaration, logger.info("--> indexing some data");
2342: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot allow partial {}", allowPartial);
2345: Igor Motov, info, MethodDeclaration, logger.info("--> wait for block to kick in");
2386: Yannick Welsch, info, IfStmt, logger.info("--> unblock all data nodes");
2383: Yannick Welsch, info, IfStmt, logger.info("--> unblock running master node");
2373: Yannick Welsch, info, TryStmt, logger.info("--> close index while non-partial snapshot is running");
2365: Yannick Welsch, info, TryStmt, logger.info("--> delete index while non-partial snapshot is running");
2358: Yannick Welsch, info, IfStmt, logger.info("--> close index while partial snapshot is running");
2355: Yannick Welsch, info, IfStmt, logger.info("--> delete index while partial snapshot is running");
2390: Igor Motov, info, MethodDeclaration, logger.info("--> waiting for snapshot to finish");
2400: Yannick Welsch, info, IfStmt, logger.info("Snapshot successfully completed");
2394: Yannick Welsch, info, IfStmt, logger.info("Deleted/Closed index during snapshot, but allow partial");
2408: Yannick Welsch, info, MethodDeclaration, logger.info("-->  creating repository");
2419: Yannick Welsch, info, MethodDeclaration, logger.info("--> indexing some data");
2428: Yannick Welsch, info, MethodDeclaration, logger.info("--> snapshot");
2432: Yannick Welsch, info, MethodDeclaration, logger.info("--> deleting indices before restoring");
2436: Yannick Welsch, info, MethodDeclaration, logger.info("--> execution will be blocked on all data nodes");
2457: Yannick Welsch, info, TryStmt, logger.info("--> unblocking all data nodes");
2440: Yannick Welsch, info, TryStmt, logger.info("--> start restore");
2445: Yannick Welsch, info, TryStmt, logger.info("--> waiting for block to kick in");
2448: Yannick Welsch, info, TryStmt, logger.info("--> close index while restore is running");
2461: Yannick Welsch, info, MethodDeclaration, logger.info("--> wait for restore to finish");
2463: Yannick Welsch, info, MethodDeclaration, logger.info("--> check that all shards were recovered");
2472: Ali Beyad, info, MethodDeclaration, logger.info("-->  creating repository");
2478: Ali Beyad, info, MethodDeclaration, logger.info("--> creating index");
2482: Ali Beyad, info, MethodDeclaration, logger.info("--> indexing some data");
2489: Ali Beyad, info, MethodDeclaration, logger.info("--> take snapshots");
2497: Ali Beyad, info, MethodDeclaration, logger.info("--> delete index before restoring");
2500: Ali Beyad, info, MethodDeclaration, logger.info("--> execution will be blocked on all data nodes");
2528: Ali Beyad, info, TryStmt, logger.info("--> unblocking all data nodes");
2505: Ali Beyad, info, TryStmt, logger.info("--> start restore");
2510: Ali Beyad, info, TryStmt, logger.info("--> waiting for block to kick in");
2513: Ali Beyad, info, TryStmt, logger.info("--> try deleting the snapshot while the restore is in progress (should throw an error)");
2520: Ali Beyad, info, TryStmt, logger.info("-- try deleting another snapshot while the restore is in progress (should throw an error)");
2532: Ali Beyad, info, MethodDeclaration, logger.info("--> wait for restore to finish");
2539: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
2548: Ali Beyad, info, MethodDeclaration, logger.info("--> create the index");
2557: Igor Motov, info, MethodDeclaration, logger.info("--> snapshot");
2563: Igor Motov, info, MethodDeclaration, logger.info("--> emulate an orphan snapshot");
2602: Igor Motov, info, MethodDeclaration, logger.info("--> try deleting the orphan snapshot");
2618: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository");
2638: Yannick Welsch, info, MethodDeclaration, logger.info("-->  creating repository at {}", repo.toAbsolutePath());
2645: Xu Zhang, info, MethodDeclaration, logger.info("--> indexing some data");
2651: Xu Zhang, info, MethodDeclaration, logger.info("--> creating 2 snapshots");
2660: Xu Zhang, info, MethodDeclaration, logger.info("--> truncate snapshot file to make it unreadable");
2666: Xu Zhang, info, MethodDeclaration, logger.info("--> get snapshots request should return both snapshots");
2832: Ali Beyad, info, MethodDeclaration, logger.info("-->  creating repository at {}", repo.toAbsolutePath());
2838: Ali Beyad, info, MethodDeclaration, logger.info("--> creating an index and indexing documents");
2846: Ali Beyad, info, MethodDeclaration, logger.info("--> take first snapshot");
2857: Ali Beyad, info, MethodDeclaration, logger.info("--> index more documents");
2863: Ali Beyad, info, MethodDeclaration, logger.info("--> second snapshot of the same name should fail");
2877: Ali Beyad, info, MethodDeclaration, logger.info("--> delete the first snapshot");
2880: Ali Beyad, info, MethodDeclaration, logger.info("--> try creating a snapshot with the same name, now it should work because the first one was deleted");
2896: Ali Beyad, info, MethodDeclaration, logger.info("-->  creating repository at {}", repo.toAbsolutePath());
2904: Ali Beyad, info, MethodDeclaration, logger.info("--> get snapshots on an empty repository");
2919: Ali Beyad, info, MethodDeclaration, logger.info("--> creating an index and indexing documents");
2949: Ali Beyad, info, MethodDeclaration, logger.info("--> take {} snapshot(s)", numSnapshots - 1);
2962: Ali Beyad, info, MethodDeclaration, logger.info("--> take another snapshot to be in-progress");
2979: Ali Beyad, info, MethodDeclaration, logger.info("--> get all snapshots with a current in-progress");
3015: Ali Beyad, info, MethodDeclaration, logger.info("--> make sure duplicates are not returned in the response");
3053: Ali Beyad, info, MethodDeclaration, logger.info("--> indexing some data");
3059: Ali Beyad, info, MethodDeclaration, logger.info("--> creating repository");
3070: Ali Beyad, info, MethodDeclaration, logger.info("--> snapshot");
3075: Ali Beyad, info, MethodDeclaration, logger.info("--> waiting for block to kick in on node [{}]", blockedNode);
3078: Ali Beyad, info, MethodDeclaration, logger.info("--> removing primary shard that is being snapshotted");
3087: Ali Beyad, info, MethodDeclaration, logger.info("--> unblocking blocked node [{}]", blockedNode);
3090: Ali Beyad, info, MethodDeclaration, logger.info("--> ensuring snapshot is aborted and the aborted shard was marked as failed");
3098: Ali Beyad, info, MethodDeclaration, logger.info("--> creating repository");
3109: Ali Beyad, info, MethodDeclaration, logger.info("--> indexing some data");
3123: Ali Beyad, info, MethodDeclaration, logger.info("--> snapshot with potential I/O failures");
3142: Ali Beyad, info, MethodDeclaration, logger.info("--> snapshot with no I/O failures");
3157: Ali Beyad, info, MethodDeclaration, logger.info("--> creating repository");
3166: Ali Beyad, info, MethodDeclaration, logger.info("--> creating good index");
3178: Ali Beyad, info, MethodDeclaration, logger.info("--> creating bad index");
3189: Ali Beyad, info, MethodDeclaration, logger.info("--> snapshot bad index and get status");
3202: Ali Beyad, info, MethodDeclaration, logger.info("--> snapshot both good and bad index and get status");
3228: Ali Beyad, info, MethodDeclaration, logger.info("--> creating repository");
3237: Ali Beyad, info, MethodDeclaration, logger.info("--> creating random number of indices");
3244: Ali Beyad, info, MethodDeclaration, logger.info("--> creating random number of snapshots");
3276: Ali Beyad, info, MethodDeclaration, logger.info("--> verify _all returns snapshot info");
3285: Ali Beyad, info, MethodDeclaration, logger.info("--> verify wildcard returns snapshot info");
3294: Ali Beyad, info, MethodDeclaration, logger.info("--> verify individual requests return snapshot info");
3313: Boaz Leskes, info, MethodDeclaration, logger.info("-->  creating repository at {}", repo.toAbsolutePath());
3319: Boaz Leskes, info, MethodDeclaration, logger.info("--> creating an index and indexing documents");
3345: Boaz Leskes, info, MethodDeclaration, logger.info("--> snapshot");
3352: Boaz Leskes, info, MethodDeclaration, logger.info("--> delete indices");
3355: Boaz Leskes, info, MethodDeclaration, logger.info("--> restore all indices from the snapshot");
3365: Boaz Leskes, info, MethodDeclaration, logger.info("--> indexing some more");
56: Nhat Nguyen, info, MethodDeclaration, logger.info("-->  creating repository");
71: Nhat Nguyen, info, MethodDeclaration, logger.info("--> blocking repository");
82: Nhat Nguyen, info, MethodDeclaration, logger.info("--> start disrupting cluster");
88: Nhat Nguyen, info, MethodDeclaration, logger.info("--> unblocking repository");
101: Nhat Nguyen, info, MethodDeclaration, logger.info("--> stop disrupting cluster");
110: Nhat Nguyen, info, LambdaExpr, logger.info("Snapshot status [{}], successfulShards [{}]", snapshotInfo.state(), snapshotInfo.successfulShards());
128: Yannick Welsch, info, ConstructorDeclaration, logger.info("starting mock repository with random prefix {}", randomPrefix);
196: Igor Motov, debug, MethodDeclaration, logger.debug("Blocking execution");
208: Igor Motov, debug, MethodDeclaration, logger.debug("Unblocking execution");
242: Igor Motov, info, IfStmt, logger.info("checking [{}] [{}]", path, Math.abs(hashCode(path)) < Integer.MAX_VALUE * probability);
275: Igor Motov, info, IfStmt, logger.info("throwing random IOException for file [{}] at path [{}]", blobName, path());
264: Igor Motov, info, IfStmt, logger.info("throwing random IOException for file [{}] at path [{}]", blobName, path());
286: Ali Beyad, info, MethodDeclaration, logger.info("blocking I/O operation for file [{}] at path [{}]", blobName, path());
302: Igor Motov, info, MethodDeclaration, logger.info("blocking I/O operation for file [{}] at path [{}]", blobName, path());
144: jaymode, warn, IfStmt, logger.warn("this runnable ran after it was cancelled");
57: Shay Banon, info, MethodDeclaration, logger.info("pre node threads are {}", preNodeStartThreadNames);
59: Shay Banon, info, MethodDeclaration, logger.info("do some indexing, flushing, optimize, and searches");
86: Shay Banon, info, MethodDeclaration, logger.info("post node threads are {}", threadNames);
88: Shay Banon, info, MethodDeclaration, logger.info("post node *new* threads are {}", threadNames);
401: Simon Willnauer, info, BlockStmt, logger.info("closing all source nodes");
404: Simon Willnauer, info, BlockStmt, logger.info("all source nodes are closed");
435: Simon Willnauer, error, IfStmt, logger.error("expected TransportException but got a different one see #25301", ex.get());
143: Benjamin DeveÌze, info, MethodDeclaration, logger.info("--> creating index test");
542: Daniel Mitterdorfer, warn, CatchClause, logger.warn("Test was forcefully stopped. Client [{}] may still have outstanding requests.", Thread.currentThread().getName());
523: Daniel Mitterdorfer, debug, IfStmt, logger.debug("Client [{}] issued [{}] of [{}] requests", Thread.currentThread().getName(), i, numberOfUpdatesPerThread);
539: Daniel Mitterdorfer, info, TryStmt, logger.info("Client [{}] issued all [{}] requests.", Thread.currentThread().getName(), numberOfUpdatesPerThread);
560: Simon Willnauer, info, ForeachStmt, logger.info("Captured failure on concurrent update:", throwable);
691: Brian Murphy, error, CatchClause, logger.error("Something went wrong", e);
667: Brian Murphy, warn, CatchClause, logger.warn("Got NoNodeException waiting for 1 second for things to recover.");
684: Brian Murphy, warn, CatchClause, logger.warn("Got NoNodeException waiting for 1 second for things to recover.");
715: Veres Lajos, info, DoStmt, logger.info("[{}] going to try and acquire [{}] in [{}]ms [{}] available to acquire right now", name, maxRequests, msRemaining, requestsOutstanding.availablePermits());
744: Brian Murphy, info, ForeachStmt, logger.info("Captured failure on concurrent update:", throwable);
774: Brian Murphy, error, IfStmt, logger.error("Actual version [{}] Expected version [{}] Total failures [{}]", response.getVersion(), expectedVersion, totalFailures);
37: kimchy, info, MethodDeclaration, logger.info("--> create an index with 1 shard and max replicas based on nodes");
41: kimchy, info, MethodDeclaration, logger.info("execute concurrent updates on the same doc");
54: Yannick Welsch, error, MethodDeclaration, logger.error("Unexpected exception while indexing", e);
67: kimchy, info, MethodDeclaration, logger.info("done indexing, check all have the same field value");
326: Yannick Welsch, info, SwitchStmt, logger.info("--> use random simple ids");
336: Yannick Welsch, info, SwitchStmt, logger.info("--> use random realistic unicode ids");
346: Yannick Welsch, info, SwitchStmt, logger.info("--> use sequential ids");
358: Yannick Welsch, info, SwitchStmt, logger.info("--> use zero-padded sequential ids");
373: Yannick Welsch, info, SwitchStmt, logger.info("--> use random long ids");
386: Yannick Welsch, info, SwitchStmt, logger.info("--> use zero-padded random long ids");
499: Yannick Welsch, debug, IfStmt, logger.debug("--> use id prefix {}", idPrefix);
522: Yannick Welsch, debug, MethodDeclaration, logger.debug("--> use {} ids; {} operations", numIDs, idVersions.length);
553: Yannick Welsch, debug, ForeachStmt, logger.debug("--> id={} version={} delete?={} truth?={}", idVersion.id, idVersion.version, idVersion.delete, truth.get(idVersion.id) == idVersion);
579: Yannick Welsch, trace, IfStmt, logger.trace("{}: index={}", Thread.currentThread().getName(), index);
612: Yannick Welsch, trace, IfStmt, logger.trace("--> {}: TEST: now refresh at {}", threadID, System.nanoTime() - startTime);
614: Yannick Welsch, trace, IfStmt, logger.trace("--> {}: TEST: refresh done at {}", threadID, System.nanoTime() - startTime);
617: Yannick Welsch, trace, IfStmt, logger.trace("--> {}: TEST: now flush at {}", threadID, System.nanoTime() - startTime);
619: Yannick Welsch, trace, IfStmt, logger.trace("--> {}: TEST: flush done at {}", threadID, System.nanoTime() - startTime);
647: Yannick Welsch, error, IfStmt, logger.error("--> FAILED: idVersion={} actualVersion= {}", idVersion, actualVersion);
657: Yannick Welsch, error, IfStmt, logger.error("All versions: {}", sb);
151: Boaz Leskes, debug, DoStmt, logger.debug("ClusterState: {}", clusterState.getRoutingNodes());
513: Boaz Leskes, warn, CatchClause, logger.warn("failed read store, treating as empty", e);
54: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository {}", repoName);
60: Igor Motov, info, ForStmt, logger.info("-->  create random index {} with {} records", indexNames[i], docCounts[i]);
67: Igor Motov, info, MethodDeclaration, logger.info("-->  create snapshot {}:{}", repoName, snapshotName);
73: Igor Motov, info, IfStmt, logger.info("-->  delete indices {}", deleteIndices);
88: Igor Motov, info, IfStmt, logger.info("--> delete {} random documents from {}", deleteCount, index);
83: Igor Motov, info, IfStmt, logger.info("--> add random documents to {}", index);
97: Igor Motov, info, IfStmt, logger.info("-->  close indices {}", closeIndices);
101: Igor Motov, info, MethodDeclaration, logger.info("--> restore all indices from the snapshot");
110: Tanguy Leroux, info, MethodDeclaration, logger.info("-->  delete snapshot {}:{}", repoName, snapshotName);
116: Igor Motov, info, MethodDeclaration, logger.info("-->  creating repository {}", repoName);
137: Igor Motov, info, IfStmt, logger.info("--> add {} random documents to {}", docCount, indexName);
128: Igor Motov, info, IfStmt, logger.info("--> delete {} random documents from {}", deleteCount, indexName);
142: Igor Motov, info, ForStmt, logger.info("-->  create snapshot {}:{} with {} documents", repoName, snapshotName + "-" + i, docCounts[i]);
150: Igor Motov, info, ForStmt, logger.info("-->  performing restore of the iteration {}", iterationToRestore);
152: Igor Motov, info, ForStmt, logger.info("-->  close index");
155: Igor Motov, info, ForStmt, logger.info("--> restore index from the snapshot");
164: Tanguy Leroux, info, ForStmt, logger.info("-->  delete snapshot {}:{}", repoName, snapshotName + "-" + i);
172: Ali Beyad, info, MethodDeclaration, logger.info("-->  creating repository");
179: Ali Beyad, info, MethodDeclaration, logger.info("--> indexing some data");
187: Ali Beyad, info, MethodDeclaration, logger.info("--> take a snapshot");
192: Ali Beyad, info, MethodDeclaration, logger.info("--> indexing more data");
199: Ali Beyad, info, MethodDeclaration, logger.info("--> take another snapshot with only 2 of the 3 indices");
206: Ali Beyad, info, MethodDeclaration, logger.info("--> delete a snapshot");
209: Ali Beyad, info, MethodDeclaration, logger.info("--> verify index folder deleted from blob container");
129: Boaz Leskes, info, ConstructorDeclaration, logger.info("--> creating {} indexing threads (auto start: [{}], numOfDocs: [{}])", writerCount, autoStart, numOfDocs);
194: Jason Tedor, warn, CatchClause, logger.warn((Supplier<?>) () -> new ParameterizedMessage("**** failed indexing thread {} on doc id {}", indexerId, docId), e);
140: Boaz Leskes, info, TryStmt, logger.info("**** starting indexing thread {}", indexerId);
190: Simon Willnauer, info, TryStmt, logger.info("**** done indexing thread {}  stop: {} numDocsIndexed: {}", indexerId, stop.get(), ids.size());
227: Boaz Leskes, debug, MethodDeclaration, logger.debug("updating budget to [{}]", numOfDocs);
78: Simon Willnauer, info, TryStmt, logger.info("Corrupting file --  flipping at position {} from {} to {} file: {}", filePointer, Integer.toHexString(oldValue), Integer.toHexString(newValue), fileToCorrupt.getFileName());
95: Yannick Welsch, info, TryStmt, logger.info("Checksum {}", msg);
389: Britta Weber, info, IfStmt, logger.info("[{}#{}]: {} test", getTestClass().getSimpleName(), getTestName(), message);
387: Britta Weber, info, IfStmt, logger.info("[{}]: {} suite", getTestClass().getSimpleName(), message);
711: Lee Hinman, info, IfStmt, logger.info("using custom data_path for index: [{}]", dataPath);
871: Yannick Welsch, warn, IfStmt, logger.warn("{}", sb);
890: Boaz Leskes, debug, IfStmt, logger.debug("allowNodes: updating [{}]'s setting to [{}]", index, build.toDelimitedString(';'));
952: Yannick Welsch, info, IfStmt, logger.info("{} timed out, cluster state:\n{}\n{}", method, client().admin().cluster().prepareState().get().getState(), client().admin().cluster().preparePendingClusterTasks().get());
960: Yannick Welsch, debug, MethodDeclaration, logger.debug("indices {} are {}", indices.length == 0 ? "[_all]" : indices, color);
983: Boaz Leskes, info, IfStmt, logger.info("waitForRelocation timed out (status={}), cluster state:\n{}\n{}", status, client().admin().cluster().prepareState().get().getState(), client().admin().cluster().preparePendingClusterTasks().get());
1048: Jason Tedor, debug, IfStmt, logger.debug("[{}] docs indexed. waiting for [{}]", lastKnownCount.get(), numDocs);
1043: Jason Tedor, debug, CatchClause, logger.debug("failed to executed count", e);
1046: Jason Tedor, debug, IfStmt, logger.debug("[{}] docs visible for search. waiting for [{}]", lastKnownCount.get(), numDocs);
1078: Boaz Leskes, debug, MethodDeclaration, logger.debug("cluster state:\n{}\n{}", client().admin().cluster().prepareState().get().getState(), client().admin().cluster().preparePendingClusterTasks().get());
1087: Ryan Ernst, debug, MethodDeclaration, logger.debug("segments {} state: \n{}", indices.length == 0 ? "[_all]" : indices, Strings.toString(segsRsp.toXContent(JsonXContent.contentBuilder().prettyPrint(), ToXContent.EMPTY_PARAMS)));
1095: Luca Cavanna, info, MethodDeclaration, logger.info("memory: {}", Strings.toString(client().admin().cluster().prepareNodesStats().clear().setJvm(true).get(), true, true));
1100: Simon Willnauer, trace, IfStmt, logger.trace("Check consistency for [{}] nodes", cluster().size());
1136: Simon Willnauer, error, CatchClause, logger.error("Cluster state from master:\n{}\nLocal cluster state:\n{}", masterClusterState.toString(), localClusterState.toString());
1170: Martijn van Groningen, debug, MethodDeclaration, logger.debug("ensuring cluster is stable with [{}] nodes. access node: [{}]. timeout: [{}]", nodeCount, viaNode, timeValue);
1439: Simon Willnauer, info, IfStmt, logger.info("Index [{}] docs async: [{}] bulk: [{}] partitions [{}]", builders.size(), false, true, partition.size());
1430: Nik Everett, info, IfStmt, logger.info("Index [{}] docs async: [{}] bulk: [{}]", builders.size(), false, false);
1424: Nik Everett, info, IfStmt, logger.info("Index [{}] docs async: [{}] bulk: [{}]", builders.size(), true, false);
1616: Simon Willnauer, info, TryStmt, logger.info("Action Failed", t);
112: Britta Weber, info, MethodDeclaration, logger.info("[{}#{}]: cleaning up after test", getTestClass().getSimpleName(), getTestName());
312: Boaz Leskes, info, IfStmt, logger.info("ensureGreen timed out, cluster state:\n{}\n{}", client().admin().cluster().prepareState().get().getState(), client().admin().cluster().preparePendingClusterTasks().get());
317: Simon Willnauer, debug, MethodDeclaration, logger.debug("indices {} are green", indices.length == 0 ? "[_all]" : indices);
288: Boaz Leskes, info, MethodDeclaration, logger.info("[{}]: before test", getTestName());
317: Boaz Leskes, info, MethodDeclaration, logger.info("[{}]: after test", getTestName());
1099: Lee Hinman, info, MethodDeclaration, logger.info("--> checking that [{}] has been cleared", path);
1110: Lee Hinman, info, ForeachStmt, logger.info("--> found file: [{}]", file.toAbsolutePath().toString());
120: Simon Willnauer, info, TryStmt, logger.info("Setup ExternalTestCluster [{}] made of [{}] nodes", nodeInfos.getClusterName().value(), size());
279: Boaz Leskes, info, ConstructorDeclaration, logger.info("Setup InternalTestCluster [{}] with seed [{}] using [{}] dedicated masters, " + "[{}] (data) nodes and [{}] coord only nodes (min_master_nodes are [{}])", clusterName, SeedUtils.formatSeed(clusterSeed), numSharedDedicatedMasterNodes, numSharedDataNodes, numSharedCoordOnlyNodes, autoManageMinMasterNodes ? "auto-managed" : "manual");
485: Boaz Leskes, info, ForStmt, logger.info("increasing cluster size from {} to {}", size, n);
513: Boaz Leskes, info, MethodDeclaration, logger.info("changing cluster size from {} data nodes to {}", size, n);
806: Simon Willnauer, trace, IfStmt, logger.trace("Using transport client for node [{}] sniff: [{}]", node.settings().get("node.name"), false);
904: Yannick Welsch, debug, IfStmt, logger.debug("removing node data paths: [{}]", Arrays.toString(locations));
995: Boaz Leskes, debug, IfStmt, logger.debug("Cluster hasn't changed - moving out - nodes: [{}] nextNodeId: [{}] numSharedNodes: [{}]", nodes.keySet(), nextNodeId.get(), newSize);
998: Boaz Leskes, debug, MethodDeclaration, logger.debug("Cluster is NOT consistent - restarting shared nodes - nodes: [{}] nextNodeId: [{}] numSharedNodes: [{}]", nodes.keySet(), nextNodeId.get(), newSize);
1005: Boaz Leskes, debug, IfStmt, logger.debug("Close Node [{}] not shared", nodeAndClient.name);
1053: Boaz Leskes, debug, MethodDeclaration, logger.debug("Cluster is consistent again - nodes: [{}] nextNodeId: [{}] numSharedNodes: [{}]", nodes.keySet(), nextNodeId.get(), newSize);
1068: Yannick Welsch, trace, MethodDeclaration, logger.trace("validating cluster formed via [{}], expecting {}", viaNode, expectedNodes);
1191: Simon Willnauer, info, CatchClause, logger.info("Failed to wipe data directory for node location: {}", path);
1189: Simon Willnauer, info, TryStmt, logger.info("Successfully wiped data directory for node location: {}", path);
1314: Simon Willnauer, info, IfStmt, logger.info("Closing random node [{}] ", nodeAndClient.name);
1329: Simon Willnauer, info, IfStmt, logger.info("Closing filtered random node [{}] ", nodeAndClient.name);
1342: Simon Willnauer, info, MethodDeclaration, logger.info("Closing master node [{}] ", masterNodeName);
1352: Simon Willnauer, info, IfStmt, logger.info("Closing random non master node [{}] current master [{}] ", nodeAndClient.name, getMasterName());
1489: Boaz Leskes, info, MethodDeclaration, logger.info("Restarting node [{}] ", nodeAndClient.name);
1524: Boaz Leskes, info, ForeachStmt, logger.info("Stopping node [{}] ", nodeAndClient.name);
1558: Boaz Leskes, info, ForeachStmt, logger.info("resetting node [{}] ", nodeAndClient.name);
1588: Simon Willnauer, warn, CatchClause, logger.warn("Can't fetch cluster state", e);
1722: Boaz Leskes, debug, IfStmt, logger.debug("updating min_master_nodes to [{}]", minMasterNodes);
1800: Martijn van Groningen, info, IfStmt, logger.info("Clearing active scheme {}, expected healing time {}", activeDisruptionScheme, expectedHealingTime);
2079: Daniel Mitterdorfer, error, CatchClause, logger.error("Could not assert finished requests within timeout", e);
124: Britta Weber, trace, IfStmt, logger.trace("Skipping lock file: {}", file);
130: Britta Weber, trace, MethodDeclaration, logger.trace("--> Moving {} to {}", relativeFile, destFile);
69: Simon Willnauer, debug, MethodDeclaration, logger.debug("Reset test cluster with transport client ratio: [{}]", transportClientRatio);
64: Boaz Leskes, info, MethodDeclaration, logger.info("pinging using mock zen ping");
69: Boaz Leskes, trace, TryStmt, logger.trace("nothing has changed since the last ping. waiting for a change");
56: Boaz Leskes, info, MethodDeclaration, logger.info("delaying cluster state updates on node [{}]", disruptionNodeCopy);
71: Yannick Welsch, error, MethodCallExpr, logger.error("unexpected error during disruption", e);
66: Martijn van Groningen, info, MethodDeclaration, logger.info("stopping long GCs on [{}]", disruptedNode);
72: Martijn van Groningen, info, CatchClause, logger.info("background thread failed to stop");
78: Yannick Welsch, info, MethodDeclaration, logger.info("node [{}] goes into GC for for [{}]", disruptedNode, duration);
86: Yannick Welsch, info, TryStmt, logger.info("node [{}] resumes from GC", disruptedNode);
106: Martijn van Groningen, error, CatchClause, logger.error("error in background worker", e);
106: Jason Tedor, warn, IfStmt, logger.warn("failed to suspend node [{}]'s threads within [{}] millis. Suspending thread stack trace:\n {}", disruptedNode, getSuspendingTimeoutInMillis(), stackTrace(suspendingThread.getStackTrace()));
239: Jason Tedor, trace, IfStmt, logger.trace("suspending thread [{}]", threadName);
270: Jason Tedor, trace, IfStmt, logger.trace("resumed thread [{}] as it is in a critical section", threadName);
125: Yannick Welsch, info, MethodDeclaration, logger.info("stop disrupting node (disruption type: {}, disrupted links: {})", networkLinkDisruptionType, disruptedLinks);
137: Yannick Welsch, info, MethodDeclaration, logger.info("start disrupting (disruption type: {}, disrupted links: {})", networkLinkDisruptionType, disruptedLinks);
147: Yannick Welsch, info, MethodDeclaration, logger.info("stop disrupting (disruption scheme: {}, disrupted links: {})", networkLinkDisruptionType, disruptedLinks);
80: Boaz Leskes, info, MethodDeclaration, logger.info("stopping to slow down cluster state processing on [{}]", disruptedNode);
86: Boaz Leskes, info, CatchClause, logger.info("background thread failed to stop");
97: Boaz Leskes, info, MethodDeclaration, logger.info("delaying cluster state updates on node [{}] for [{}]", disruptionNodeCopy, duration);
160: Boaz Leskes, error, CatchClause, logger.error("error in background worker", e);
71: Simon Willnauer, debug, CatchClause, logger.debug("Failed to release searcher", ex);
106: Adrien Grand, trace, IfStmt, logger.trace("Using [{}] for shard [{}] seed: [{}] wrapReader: [{}]", this.getClass().getName(), shardId, seed, wrapReader);
53: Robert Muir, trace, MethodDeclaration, logger.trace("Test {} started", description.getDisplayName());
58: Robert Muir, trace, MethodDeclaration, logger.trace("Test {} finished", description.getDisplayName());
135: Luca Cavanna, info, IfStmt, logger.info("initializing REST clients against {}", clusterHosts);
270: Nik Everett, debug, ForeachStmt, logger.debug("wiping snapshot [{}/{}]", repoName, name);
275: Igor Motov, debug, IfStmt, logger.debug("wiping snapshot repository [{}]", repoName);
325: Nik Everett, info, MethodDeclaration, logger.info("There are still tasks running after this test that might break subsequent tests {}.", stillRunning);
125: javanna, debug, IfStmt, logger.debug("sending the request body as source param with GET method");
167: Alexander Reelsen, debug, ForeachStmt, logger.debug("Adding header {} with value {}", header.getKey(), header.getValue());
171: javanna, debug, MethodDeclaration, logger.debug("calling api [{}]", apiName);
172: javanna, debug, MethodDeclaration, logger.debug("resetting client, response and stash");
115: Luca Cavanna, warn, IfStmt, logger.warn("Fallback to simple info '/' request, _cat/nodes is not authorized");
117: Luca Cavanna, info, IfStmt, logger.info("initializing yaml client, minimum es version: [{}] hosts: {}", esVersion, hosts);
111: Luca Cavanna, info, TryStmt, logger.info("initializing yaml client, minimum es version: [{}] master version: [{}] hosts: {}", esVersion, masterVersion, hosts);
309: Nik Everett, debug, IfStmt, logger.debug("start setup test [{}]", testCandidate.getTestPath());
313: Nik Everett, debug, IfStmt, logger.debug("end setup test [{}]", testCandidate.getTestPath());
323: Nik Everett, debug, TryStmt, logger.debug("start teardown test [{}]", testCandidate.getTestPath());
327: Nik Everett, debug, TryStmt, logger.debug("end teardown test [{}]", testCandidate.getTestPath());
339: Martijn van Groningen, info, CatchClause, logger.info("Stash dump on test failure [{}]", Strings.toString(restTestExecutionContext.stash(), true, true).replace("\\n", "\n").replace("\\r", "\r").replace("\\t", "\t"));
56: Boaz Leskes, trace, MethodDeclaration, logger.trace("stashing [{}]=[{}]", key, value);
59: javanna, trace, IfStmt, logger.trace("replaced stashed value [{}] with same key [{}]", old, key);
59: Boaz Leskes, trace, MethodDeclaration, logger.trace("assert that [{}] is greater than [{}] (field: [{}])", actualValue, expectedValue, getField());
59: Boaz Leskes, trace, MethodDeclaration, logger.trace("assert that [{}] is greater than or equal to [{}] (field: [{}])", actualValue, expectedValue, getField());
52: Boaz Leskes, trace, MethodDeclaration, logger.trace("assert that [{}] doesn't have a true value (field: [{}])", actualValue, getField());
53: Boaz Leskes, trace, MethodDeclaration, logger.trace("assert that [{}] has a true value (field [{}])", actualValue, getField());
66: Boaz Leskes, trace, MethodDeclaration, logger.trace("assert that [{}] has length [{}] (field: [{}])", actualValue, expectedValue, getField());
59: Boaz Leskes, trace, MethodDeclaration, logger.trace("assert that [{}] is less than [{}] (field: [{}])", actualValue, expectedValue, getField());
59: Boaz Leskes, trace, MethodDeclaration, logger.trace("assert that [{}] is less than or equal to [{}] (field: [{}])", actualValue, expectedValue, getField());
66: javanna, trace, IfStmt, logger.trace("assert that [{}] matches [{}]", stringValue, regex);
74: Boaz Leskes, trace, MethodDeclaration, logger.trace("assert that [{}] matches [{}] (field [{}])", actualValue, expectedValue, getField());
97: Simon Willnauer, debug, IfStmt, logger.debug("Using MockDirWrapper with seed [{}] throttle: [{}] crashIndex: [{}]", SeedUtils.formatSeed(seed), throttle, crashIndex);
116: Michael McCandless, info, IfStmt, logger.info("start check index");
141: Robert Muir, warn, CatchClause, logger.warn("failed to check index", e);
143: Simon Willnauer, info, TryStmt, logger.info("end check index");
133: Simon Willnauer, debug, IfStmt, logger.debug("check index [success]\n{}", os.bytes().utf8ToString());
129: Nhat Nguyen, warn, IfStmt, logger.warn("check index [failure] index files={}\n{}", Arrays.toString(dir.listAll()), os.bytes().utf8ToString());
58: Jason Tedor, warn, CatchClause, logger.warn((Supplier<?>) () -> new ParameterizedMessage("failed to notify task manager listener about unregistering the task with id {}", task.getId()), e);
83: Igor Motov, warn, IfStmt, logger.warn("trying to remove the same with id {} twice", task.getId());
77: Jason Tedor, warn, CatchClause, logger.warn((Supplier<?>) () -> new ParameterizedMessage("failed to notify task manager listener about unregistering the task with id {}", task.getId()), e);
94: Jason Tedor, warn, CatchClause, logger.warn((Supplier<?>) () -> new ParameterizedMessage("failed to notify task manager listener about waitForTaskCompletion the task with id {}", task.getId()), e);
292: Lee Hinman, info, IfStmt, logger.info("--> preventing {} request", action);
441: Simon Willnauer, debug, MethodDeclaration, logger.debug("failed to send delayed request", e);
214: Simon Willnauer, error, CatchClause, logger.error("Unexpected failure", e);
238: Simon Willnauer, error, MethodDeclaration, logger.error("Unexpected failure", exp);
269: Simon Willnauer, error, MethodDeclaration, logger.error("Unexpected failure", exp);
292: Yannick Welsch, error, CatchClause, logger.error("Unexpected failure", e);
320: Yannick Welsch, error, MethodDeclaration, logger.error("Unexpected failure", exp);
389: Boaz Leskes, error, CatchClause, logger.error("Unexpected failure", e);
494: Simon Willnauer, error, CatchClause, logger.error("Unexpected failure", e);
518: Daniel Mitterdorfer, error, MethodDeclaration, logger.error("Unexpected failure", exp);
541: Daniel Mitterdorfer, error, CatchClause, logger.error("Unexpected failure", e);
567: Daniel Mitterdorfer, error, MethodDeclaration, logger.error("Unexpected failure", exp);
647: Boaz Leskes, info, CatchClause, logger.info("caught exception while responding", e);
656: Boaz Leskes, trace, CatchClause, logger.trace("caught exception while responding from node B", e);
670: Boaz Leskes, trace, MethodDeclaration, logger.trace("caught exception while sending from B", e);
685: Jason Tedor, trace, CatchClause, logger.trace((Supplier<?>) () -> new ParameterizedMessage("caught exception while sending to node {}", nodeA), e);
703: Boaz Leskes, error, MethodDeclaration, logger.error("unexpected error", e);
722: Simon Willnauer, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("caught exception while sending to node {}", node), e);
770: Daniel Mitterdorfer, info, TryStmt, logger.info("Stop ServiceB now");
853: Simon Willnauer, error, CatchClause, logger.error("Unexpected failure", e);
923: Daniel Mitterdorfer, error, MethodDeclaration, logger.error("Unexpected failure", exp);
1288: Daniel Mitterdorfer, error, MethodDeclaration, logger.error("Unexpected failure", exp);
1332: Daniel Mitterdorfer, error, MethodDeclaration, logger.error("Unexpected failure", exp);
1376: Daniel Mitterdorfer, error, MethodDeclaration, logger.error("Unexpected failure", exp);
1416: Daniel Mitterdorfer, error, MethodDeclaration, logger.error("Unexpected failure", exp);
1797: Simon Willnauer, debug, IfStmt, logger.debug("send response for {}", request.info);
1758: Simon Willnauer, debug, IfStmt, logger.debug("send secondary request from {} to {} - {}", toNodeMap.get(service), node, request.info);
1773: Simon Willnauer, debug, TryStmt, logger.debug("send secondary response {}", response.info);
1784: Simon Willnauer, debug, TryStmt, logger.debug("send secondary exception response for request {}", request.info);
1826: Simon Willnauer, debug, MethodDeclaration, logger.debug("---> received response: {}", response.info);
1832: Jason Tedor, debug, MethodDeclaration, logger.debug((Supplier<?>) () -> new ParameterizedMessage("---> received exception for id {}", id), exp);
1849: Simon Willnauer, debug, ForStmt, logger.debug("send from {} to {}", toNodeMap.get(service), node);
1853: Simon Willnauer, debug, MethodDeclaration, logger.debug("waiting for response");
1857: Simon Willnauer, debug, IfStmt, logger.debug("now failing forcefully");
1861: Simon Willnauer, debug, MethodDeclaration, logger.debug("DONE");
305: Simon Willnauer, warn, CatchClause, logger.warn("failed on handling exception", ex);
132: Tim Brooks, warn, CatchClause, logger.warn("unexpected exception while stopping nio group", e);
400: Nik Everett, info, ConstructorDeclaration, logger.info("Looked up versions [{}={}]", property, versions);
50: Jason Tedor, Warn, MethodDeclaration, final String testHeader = DeprecationLogger.formatWarning("test");
51: Jason Tedor, Warn, MethodDeclaration, final String anotherHeader = DeprecationLogger.formatWarning("another");
52: Jason Tedor, Warn, MethodDeclaration, final String someMoreHeader = DeprecationLogger.formatWarning("some more");
53: Jason Tedor, Warn, MethodDeclaration, final String catHeader = DeprecationLogger.formatWarning("cat");
76: Yannick Welsch, Error, LambdaExpr, System.err.println(wrongLoggerUsage.getErrorLines());
50: Yannick Welsch, info, IfStmt, logger.info("Checking logger usage for method {}", method.getName());
53: Yannick Welsch, error, IfStmt, ESLoggerUsageChecker.check(errors::add, classInputStream, m -> m.equals(method.getName()) || m.startsWith("lambda$" + method.getName()));
121: Yannick Welsch, info, MethodDeclaration, logger.info("Hello {}", "world");
125: Yannick Welsch, info, MethodDeclaration, logger.info("Hello {}");
130: Yannick Welsch, info, MethodDeclaration, logger.info("Hello {}");
134: Yannick Welsch, info, MethodDeclaration, logger.info("Hello {}, {}, {}", "world", 2, "third argument");
138: Yannick Welsch, info, MethodDeclaration, logger.info("Hello {}, {}", "world", 2, "third argument");
142: Yannick Welsch, info, MethodDeclaration, logger.info("Hello {}, {}, {}, {}, {}, {}, {}", "world", 2, "third argument", 4, 5, 6, new String("last arg"));
146: Yannick Welsch, info, MethodDeclaration, logger.info("Hello {}, {}, {}, {}, {}, {}, {}", "world", 2, "third argument", 4, 5, 6, 7, new String("last arg"));
150: Yannick Welsch, info, MethodDeclaration, logger.info(new ParameterizedMessage("Hello {}, {}, {}", "world", 2, "third argument"));
154: Yannick Welsch, info, MethodDeclaration, logger.info(new ParameterizedMessage("Hello {}, {}", "world", 2, "third argument"));
158: Yannick Welsch, info, MethodDeclaration, logger.info(new ParameterizedMessage("Hello {}, {}", "world", 2));
162: Yannick Welsch, info, MethodDeclaration, logger.info(new ParameterizedMessage("Hello {}, {}, {}", "world", 2));
166: Yannick Welsch, info, MethodDeclaration, logger.info((Supplier<?>) () -> new ParameterizedMessage("Hello {}, {}, {}", "world", 2, "third argument"));
170: Yannick Welsch, info, MethodDeclaration, logger.info((Supplier<?>) () -> new ParameterizedMessage("Hello {}, {}", "world", 2, "third argument"));
174: Yannick Welsch, info, MethodDeclaration, logger.info("Hello", new Exception());
178: Jason Tedor, info, MethodDeclaration, logger.info((Supplier<?>) () -> new ParameterizedMessage("Hello {}", "world"), new Exception());
182: Yannick Welsch, info, MethodDeclaration, logger.info("Hello {}", "world", new Exception());
186: Jason Tedor, info, MethodDeclaration, logger.info((Supplier<?>) () -> new ParameterizedMessage("Hello {}, {}", "world", 42), new Exception());
190: Yannick Welsch, info, MethodDeclaration, logger.info("Hello {}, {}", "world", 42, new Exception());
194: Yannick Welsch, info, MethodDeclaration, logger.info(Boolean.toString(b), new Exception());
198: Jason Tedor, info, MethodDeclaration, logger.info((Supplier<?>) () -> new ParameterizedMessage(Boolean.toString(b), 42), new Exception());
208: Yannick Welsch, info, MethodDeclaration, logger.info(message, args);
218: Yannick Welsch, info, MethodDeclaration, logger.info(message, args);
228: Yannick Welsch, info, MethodDeclaration, logger.info(message, args);
46: Zachary Tong, error, MethodDeclaration, logger.error("This failing test was generated by documentation starting at {}. It may include many snippets. " + "See Elasticsearch's docs/README.asciidoc for an explanation of test generation.", name);
139: Zachary Tong, warn, IfStmt, logger.warn("Deleting leftover user {}", user);
27: jaymode, error, MethodDeclaration, logger.error("project.basedir [{}]", System.getProperty("project.basedir"));
154: Ryan Ernst, warn, MethodDeclaration, logger.warn("{}", builder);
340: Ryan Ernst, debug, MethodDeclaration, logger.debug("initializing license state");
411: jaymode, debug, IfStmt, logger.debug("skipped license notifications reason: [{}]", GatewayService.STATE_NOT_RECOVERED_BLOCK);
380: jaymode, debug, IfStmt, logger.debug("previous [{}]", prevLicensesMetaData);
381: jaymode, debug, IfStmt, logger.debug("current [{}]", currentLicensesMetaData);
440: Ryan Ernst, warn, IfStmt, logger.warn("license [{}] - expired", license.uid());
437: Ryan Ernst, warn, IfStmt, logger.warn("license [{}] - grace", license.uid());
435: Ryan Ernst, debug, IfStmt, logger.debug("license [{}] - valid", license.uid());
470: Areek Zillur, info, IfStmt, logger.info("license [{}] mode [{}] - valid", license.uid(), license.operationMode().name().toLowerCase(Locale.ROOT));
60: Areek Zillur, error, CatchClause, logger.error("couldn't initialize watching license mode file", e);
103: Simon Willnauer, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("couldn't read operation mode from [{}]", licenseModePath.toAbsolutePath()), e);
113: Simon Willnauer, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("invalid operation mode in [{}]", licenseModePath.toAbsolutePath()), e);
47: Tim Brooks, debug, MethodDeclaration, logger.debug("license prior to starting basic license: {}", oldLicensesMetaData);
96: Tim Brooks, error, MethodDeclaration, logger.error(new ParameterizedMessage("unexpected failure during [{}]", source), e);
53: Tim Brooks, debug, MethodDeclaration, logger.debug("started self generated trial license: {}", oldLicensesMetaData);
94: Tim Brooks, error, MethodDeclaration, logger.error(new ParameterizedMessage("unexpected failure during [{}]", source), e);
46: Tim Brooks, debug, IfStmt, logger.debug("registered self generated license: {}", licensesMetaData);
72: Tim Brooks, error, MethodDeclaration, logger.error((Supplier<?>) () -> new ParameterizedMessage("unexpected failure during [{}]", source), e);
80: Tim Brooks, info, MethodDeclaration, logger.info("Existing basic license has an expiration. Basic licenses no longer expire." + "Regenerating license.\n\nOld license:\n {}\n\n New license:\n{}", license, newLicenseMetadata.getLicense());
60: Dimitris Athanasiou, error, IfStmt, LOGGER.error("[{}] Search request returned shard failures: {}", jobId, Arrays.toString(shardFailures));
152: Dimitris Athanasiou, error, CatchClause, LOGGER.error("[" + jobId + "] An error occurred while deleting interim results", e);
80: David Kyle, warn, IfStmt, logger.warn("[{}] DeleteByQuery for indices [{}, {}] timed out.", jobId, indexName, indexPattern);
83: David Kyle, warn, IfStmt, logger.warn("[{}] {} failures and {} conflicts encountered while running DeleteByQuery on indices [{}, {}].", jobId, bulkByScrollResponse.getBulkFailures().size(), bulkByScrollResponse.getVersionConflicts(), indexName, indexPattern);
87: David Kyle, warn, ForeachStmt, logger.warn("DBQ failure: " + failure);
97: David Kyle, info, LambdaExpr, logger.info("Running DBQ on [" + indexName + "," + indexPattern + "] for job [" + jobId + "]");
158: Martijn van Groningen, error, CatchClause, logger.error("Unable to apply field level security");
134: Jay Modi, warn, IfStmt, logger.warn("client did not trust this server's certificate, closing connection {}", channel);
132: Jay Modi, trace, IfStmt, logger.trace(new ParameterizedMessage("client did not trust server's certificate, closing connection {}", channel), e);
127: Jay Modi, warn, IfStmt, logger.warn("connection {} closed during handshake", channel);
125: Jay Modi, trace, IfStmt, logger.trace(new ParameterizedMessage("connection {} closed during ssl handshake", channel), e);
120: Jay Modi, warn, IfStmt, logger.warn("received plaintext traffic on an encrypted channel, closing connection {}", channel);
117: Jay Modi, trace, IfStmt, logger.trace(new ParameterizedMessage("received plaintext traffic on an encrypted channel, closing connection {}", channel), e);
53: Tim Vernum, debug, ConstructorDeclaration, logger.debug("Configured with trust restrictions: [{}]", restrictions);
107: Tim Vernum, info, IfStmt, logger.info("Rejecting certificate [{}] [{}] with common-names [{}]", certificate.getSubjectDN(), certificate.getSerialNumber().toString(16), names);
104: Tim Vernum, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("Trusting certificate [{}] [{}] with common-names [{}]", certificate.getSubjectDN(), certificate.getSerialNumber().toString(16), names));
119: Tim Vernum, debug, IfStmt, logger.debug("Name [{}] matches trusted pattern [{}]", match.get(), trust);
135: Tim Vernum, warn, IfStmt, logger.warn(message);
162: Tim Vernum, debug, IfStmt, logger.debug("Certificate [{}] has 'otherName' [{}] with unsupported object-id [{}]", certificate.getSubjectDN(), seq, id);
157: Tim Vernum, warn, IfStmt, logger.warn("Certificate [{}] has 'otherName' [{}] with unsupported name-value type [{}]", certificate.getSubjectDN(), seq, nameValue.getClass().getSimpleName());
154: Tim Vernum, trace, IfStmt, logger.trace("Read cn [{}] from ASN1Sequence [{}]", cn, seq);
174: Tim Vernum, trace, MethodDeclaration, logger.trace("Certificate [{}] has subject alternative names [{}]", certificate.getSubjectDN(), sans);
67: jaymode, error, CatchClause, logger.error("failed to start watching directory [{}] for ssl configuration [{}]", path, sslConfiguration);
79: jaymode, debug, MethodDeclaration, logger.debug("reloading ssl configuration [{}]", configuration);
126: Jay Modi, info, IfStmt, logger.info("reloaded [{}] and updated ssl contexts using this file", file);
389: jaymode, error, IfStmt, logger.error("unsupported ciphers [{}] were requested but cannot be used in this JVM, however there are supported ciphers " + "that will be used [{}]. If you are trying to use ciphers with a key length greater than 128 bits on an Oracle JVM, " + "you will need to install the unlimited strength JCE policy files.", unsupportedCiphers, supportedCiphersList);
404: jaymode, debug, IfStmt, logger.debug("using ssl settings [{}]", sslConfiguration);
54: Jay Modi, Error, CatchClause, logger.error("Error loading template [{}] as part of metadata upgrading", templateName);
172: Suyog Rao, error, CatchClause, logger.error(new ParameterizedMessage("Cannot parse the template [{}]", templateName), e);
117: Jason Tedor, error, CatchClause, action.logger().error((Supplier<?>) () -> new ParameterizedMessage("failed to execute action [{}/{}]. failed to execute condition", ctx.watch().id(), id), e);
137: Jason Tedor, error, CatchClause, action.logger().error((Supplier<?>) () -> new ParameterizedMessage("failed to execute action [{}/{}]. failed to transform payload.", ctx.watch().id(), id), e);
130: Alexander Reelsen, error, IfStmt, action.logger().error("failed to execute action [{}/{}]. failed to transform payload. {}", ctx.watch().id(), id, transformResult.reason());
147: Jason Tedor, error, CatchClause, action.logger().error((Supplier<?>) () -> new ParameterizedMessage("failed to execute action [{}/{}]", ctx.watch().id(), id), e);
161: Ryan Ernst, error, IfStmt, logger.error("received data for decryption with size [{}] that is less than IV length [{}]", bytes.length, ivLength);
48: Jason Tedor, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to execute [{}] transform for [{}]", TYPE, ctx.id()), e);
66: Jason Tedor, error, MethodDeclaration, logger.error("error on metaData cleanup after test", e);
94: Areek Zillur, error, MethodDeclaration, logger.error("error on metaData cleanup after test", e);
49: Yannick Welsch, info, MethodDeclaration, logger.info("--> start one master out of two [recovery state]");
51: Yannick Welsch, info, MethodDeclaration, logger.info("--> start second master out of two [recovered state]");
59: Yannick Welsch, info, MethodDeclaration, logger.info("--> starting {} node(s)", numNodes);
63: jaymode, info, MethodDeclaration, logger.info("--> put signed license");
70: jaymode, info, MethodDeclaration, logger.info("--> restart all nodes");
74: jaymode, info, MethodDeclaration, logger.info("--> get and check signed license");
76: jaymode, info, MethodDeclaration, logger.info("--> remove licenses");
80: jaymode, info, MethodDeclaration, logger.info("--> restart all nodes");
95: Areek Zillur, info, MethodDeclaration, logger.info("--> starting {} node(s)", numNodes);
99: Areek Zillur, info, MethodDeclaration, logger.info("--> put signed license");
117: jaymode, info, MethodDeclaration, logger.info("--> restart node");
120: jaymode, info, MethodDeclaration, logger.info("--> await node for enabled");
131: jaymode, info, MethodDeclaration, logger.info("--> restart node");
134: jaymode, info, MethodDeclaration, logger.info("--> await node for grace_period");
145: jaymode, info, MethodDeclaration, logger.info("--> restart node");
148: jaymode, info, MethodDeclaration, logger.info("--> await node for disabled");
129: Alexander Reelsen, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to respond to request [{} {}]", s.getRequestMethod(), s.getRequestURI()), e);
108: Alexander Reelsen, debug, IfStmt, logger.debug("[{}:{}] incoming HTTP request [{} {}], returning status [{}] body [{}]", getHostName(), getPort(), s.getRequestMethod(), s.getRequestURI(), response.getStatusCode(), getStartOfBody(response));
136: Alexander Reelsen, info, MethodDeclaration, logger.info("bound HTTP mock server to [{}:{}]", getHostName(), getPort());
211: Alexander Reelsen, trace, IfStmt, logger.trace("[{}:{}] Enqueueing response [{}], status [{}] body [{}]", getHostName(), getPort(), responses.size(), response.getStatusCode(), getStartOfBody(response));
246: Alexander Reelsen, debug, MethodDeclaration, logger.debug("[{}:{}] Counting down all latches before terminating executor", getHostName(), getPort());
26: Jay Modi, info, IfStmt, logger.info("AES 256 is not available");
23: Jay Modi, info, IfStmt, logger.info("AES 256 is available");
49: Jay Modi, error, LambdaExpr, logger.error("unexpected exception", e);
86: Jay Modi, error, LambdaExpr, logger.error("unexpected exception", e);
100: Jay Modi, error, LambdaExpr, logger.error("unexpected exception", e);
53: Hendrik Muhs, warn, CatchClause, logger.warn("failed to stop all datafeeds. Forcing stop", e1);
62: Hendrik Muhs, warn, CatchClause, logger.warn("Force-closing all data feeds failed", e2);
59: Hendrik Muhs, error, IfStmt, logger.error("Got status code " + statusCode + " when stopping datafeeds");
50: Hendrik Muhs, error, IfStmt, logger.error("Got status code " + statusCode + " when stopping datafeeds");
72: David Roberts, error, IfStmt, logger.error("Got status code " + statusCode + " when deleting datafeed " + datafeedId);
95: Hendrik Muhs, warn, CatchClause, logger.warn("failed to close all jobs. Forcing closed", e1);
100: Hendrik Muhs, warn, CatchClause, logger.warn("Force-closing all jobs failed", e2);
92: Hendrik Muhs, error, IfStmt, logger.error("Got status code " + statusCode + " when closing all jobs");
110: David Roberts, error, IfStmt, logger.error("Got status code " + statusCode + " when deleting job " + jobId);
89: Zachary Tong, debug, ForeachStmt, logger.debug(jobConfig);
91: Zachary Tong, debug, ForeachStmt, logger.debug("Deleting job " + jobId);
114: Alexander Reelsen, info, MethodDeclaration, logger.info("Going to index [{}] documents with [{}] unique values and commit after [{}] documents have been indexed", numDocs, numValues, commitAfter);
140: Martijn van Groningen, info, MethodDeclaration, logger.info("Value count matrix:\n{}", valueToHitCountOutput);
151: Martijn van Groningen, info, ForStmt, logger.info("Going to verify hit count with query [{}] with expected total hits [{}]", parsedQuery.query(), expectedHitCount);
193: Jay Modi, info, LambdaExpr, logger.info("index name [{}]", index);
210: Chris Earle, info, LambdaExpr, logger.info("index name [{}]", index);
247: Jay Modi, info, LambdaExpr, logger.info("index name [{}]", index);
63: Yannick Welsch, info, MethodDeclaration, logger.info("{}[{}]", passwd, passwd.length());
121: jaymode, info, MethodDeclaration, logger.info("resolve name [{}], address [{}], subject alt names [{}]", resolveName, NetworkAddress.format(address), generalNames);
91: Tim Vernum, info, MethodDeclaration, logger.info("Using [{}] key/truststore [{}]", testnodeStoreType, testnodeStore);
637: Chris Earle, error, MethodDeclaration, logger.error(ex);
315: markharwood, trace, MethodDeclaration, logger.trace("executing expansion graph search request");
728: Jason Tedor, error, CatchClause, logger.error("unable to execute the graph query", e);
662: markharwood, trace, TryStmt, logger.trace("executing initial graph search request");
38: Martijn van Groningen, warn, MethodDeclaration, logger.warn("cannot close all jobs", e);
607: Jay Modi, Error, CatchClause, logger.warn("Error loading the template for the notification message index", e);
624: Jay Modi, Error, CatchClause, logger.warn("Error loading the template for the " + MlMetaIndex.INDEX_NAME + " index", e);
643: Jay Modi, Error, CatchClause, logger.error("Error loading the template for the " + AnomalyDetectorsIndex.jobStateIndexName() + " index", e);
663: Jay Modi, Error, CatchClause, logger.error("Error loading the template for the " + AnomalyDetectorsIndex.jobResultsIndexPrefix() + " indices", e);
98: Martijn van Groningen, warn, IfStmt, logger.warn("[{}] {}", datafeedConfig.getJobId(), msg);
79: Dimitris Athanasiou, debug, MethodDeclaration, LOGGER.debug("Starting ML daily maintenance service");
84: Dimitris Athanasiou, debug, MethodDeclaration, LOGGER.debug("Stopping ML daily maintenance service");
104: Dimitris Athanasiou, debug, IfStmt, LOGGER.debug("failed to schedule next maintenance task; shutting down", e);
112: Dimitris Athanasiou, info, MethodDeclaration, LOGGER.info("triggering scheduled [ML] maintenance tasks");
115: Jay Modi, info, MethodCallExpr, LOGGER.info("Successfully completed [ML] maintenance tasks");
116: Jay Modi, error, MethodCallExpr, LOGGER.error("An error occurred during maintenance tasks execution", e);
113: Jay Modi, info, MethodDeclaration, executeAsyncWithOrigin(client, ML_ORIGIN, DeleteExpiredDataAction.INSTANCE, new DeleteExpiredDataAction.Request(), ActionListener.wrap(response -> LOGGER.info("Successfully completed [ML] maintenance tasks"), e -> LOGGER.error("An error occurred during maintenance tasks execution", e)));
80: David Kyle, error, MethodDeclaration, logger.error("unable to install ml metadata", e);
49: Michael Basnight, info, MethodDeclaration, logger.info("Deleting expired data");
72: Michael Basnight, info, IfStmt, logger.info("Completed deletion of expired data");
218: Michael Basnight, debug, MethodDeclaration, logger.debug("Job [" + jobId + "] is successfully marked as deleted");
60: Michael Basnight, warn, IfStmt, logger.warn("More than one model found for [job_id: " + request.getJobId() + ", snapshot_id: " + request.getSnapshotId() + "] tuple.");
87: Michael Basnight, debug, MethodDeclaration, logger.debug("[{}] {}", request.getJobId(), msg);
56: Michael Basnight, debug, MethodDeclaration, logger.debug("finalizing jobs [{}]", jobIdString);
83: Michael Basnight, debug, MethodDeclaration, logger.debug("finalized job [{}]", jobIdString);
53: Michael Basnight, debug, MethodDeclaration, logger.debug("Get datafeed '{}'", request.getDatafeedId());
57: Michael Basnight, debug, MethodDeclaration, logger.debug("Get stats for datafeed '{}'", request.getDatafeedId());
52: Michael Basnight, debug, MethodDeclaration, logger.debug("Get job '{}'", request.getJobId());
103: Michael Basnight, debug, MethodDeclaration, logger.debug("Get stats for job [{}]", jobId);
42: Michael Basnight, debug, MethodDeclaration, logger.debug("Get model snapshots for job {} snapshot ID {}. from = {}, size = {}" + " start = '{}', end='{}', sort={} descending={}", request.getJobId(), request.getSnapshotId(), request.getPageParams().getFrom(), request.getPageParams().getSize(), request.getStart(), request.getEnd(), request.getSort(), request.getDescOrder());
239: Michael Basnight, debug, MethodDeclaration, logger.debug("Search for buckets in: [{}, {})", curTime, curEnd);
50: Michael Basnight, info, MethodDeclaration, logger.info("[{}] Killing job", jobTask.getJobId());
67: Michael Basnight, debug, IfStmt, logger.debug("[{}] Cannot kill the process because job is not open", request.getJobId());
142: Martijn van Groningen, debug, IfStmt, logger.debug(reason);
161: Martijn van Groningen, trace, IfStmt, logger.trace(reason);
172: Dimitris Athanasiou, trace, IfStmt, logger.trace(reason);
180: Dimitris Athanasiou, trace, IfStmt, logger.trace(reason);
189: Dimitris Athanasiou, trace, IfStmt, logger.trace(reason);
227: Martijn van Groningen, trace, IfStmt, logger.trace(reason);
241: David Roberts, trace, CatchClause, logger.trace(reason);
251: Martijn van Groningen, trace, IfStmt, logger.trace(reason);
270: David Roberts, trace, CatchClause, logger.trace(reason);
299: David Roberts, debug, IfStmt, logger.debug("Falling back to allocating job [{}] by job counts because machine memory was not available for node [{}]", jobId, nodeNameAndMlAttributes(node));
286: David Roberts, trace, IfStmt, logger.trace(reason);
310: Martijn van Groningen, debug, IfStmt, logger.debug("no node selected for job [{}], reasons [{}]", jobId, explanation);
306: Martijn van Groningen, debug, IfStmt, logger.debug("selected node [{}] for job [{}]", minLoadedNode, jobId);
418: Hendrik Muhs, info, IfStmt, logger.info("No mappings found for [{}], recreating", index);
413: Hendrik Muhs, error, CatchClause, logger.error(new ParameterizedMessage("Failed to retrieve mapping version for [{}], recreating", index), e);
408: Hendrik Muhs, info, IfStmt, logger.info("Version of mappings for [{}] not found, recreating", index);
393: Hendrik Muhs, info, IfStmt, logger.info("Version of mappings for [{}] not found, recreating", index);
403: Hendrik Muhs, info, IfStmt, logger.info("Mappings for [{}] are outdated [{}], updating it[{}].", index, mappingVersion, Version.CURRENT);
566: David Roberts, error, MethodDeclaration, logger.error("[" + persistentTask.getParams().getJobId() + "] Failed to cancel persistent task that could " + "not be assigned due to [" + exception.getMessage() + "]", e);
611: Michael Basnight, trace, IfStmt, logger.trace("Mappings are uptodate.");
660: Michael Basnight, warn, IfStmt, logger.warn("[{}] {}", params.getJobId(), msg);
694: Michael Basnight, info, MethodDeclaration, logger.info("Changing [{}] from [{}] to [{}]", MachineLearning.CONCURRENT_JOB_ALLOCATIONS.getKey(), this.maxConcurrentJobAllocations, maxConcurrentJobAllocations);
700: Michael Basnight, info, MethodDeclaration, logger.info("Changing [{}] from [{}] to [{}]", MachineLearning.MAX_MACHINE_MEMORY_PERCENT.getKey(), this.maxMachineMemoryPercent, maxMachineMemoryPercent);
725: Dimitris Athanasiou, trace, MethodDeclaration, LOGGER.trace("[{}] Cancelling job task because: {}", jobId, reason);
69: David Kyle, debug, IfStmt, logger.debug("[{}] Cannot persist the job because the job is not open", request.getJobId());
131: Michael Basnight, info, IfStmt, logger.info("Created datafeed [{}]", request.getDatafeed().getId());
70: Michael Basnight, debug, MethodDeclaration, logger.debug("Received request to revert to snapshot id '{}' for job '{}', deleting intervening results: {}", request.getSnapshotId(), request.getJobId(), request.getDeleteInterveningResults());
91: Michael Basnight, info, MethodDeclaration, logger.info("Reverting to snapshot '" + request.getSnapshotId() + "'");
111: Luca Cavanna, debug, LambdaExpr, logger.debug("Removing intervening records: last record: " + deleteAfter + ", last result: " + modelSnapshot.getLatestResultTimeStamp());
114: Luca Cavanna, info, LambdaExpr, logger.info("Deleting results after '" + deleteAfter + "'");
124: Yannick Welsch, debug, IfStmt, logger.debug("datafeed already started", e);
198: David Roberts, error, MethodDeclaration, logger.error("[" + persistentTask.getParams().getDatafeedId() + "] Failed to cancel persistent task that could " + "not be assigned due to [" + exception.getMessage() + "]", e);
214: Michael Basnight, warn, IfStmt, logger.warn(msg);
60: Michael Basnight, info, IfStmt, logger.info("Updated datafeed [{}]", request.getUpdate().getId());
57: Michael Basnight, debug, MethodDeclaration, logger.debug("Received request to update model snapshot [{}] for job [{}]", request.getSnapshotId(), request.getJobId());
104: Dimitris Athanasiou, info, MethodDeclaration, LOGGER.info("[{}] {}", jobId, msg);
116: Dimitris Athanasiou, info, IfStmt, LOGGER.info("[{}] Lookback has finished", jobId);
125: David Kyle, debug, IfStmt, LOGGER.debug("[{}] Lookback finished after being stopped", jobId);
140: David Kyle, info, IfStmt, LOGGER.info("[{}] Skipped to time [{}]", jobId, flushResponse.getLastFinalizedBucketEnd().getTime());
180: Dimitris Athanasiou, trace, MethodDeclaration, LOGGER.trace("[{}] Searching data in: [{}, {})", jobId, start, end);
199: Martijn van Groningen, debug, CatchClause, LOGGER.debug("[" + jobId + "] error while extracting data", e);
230: Martijn van Groningen, debug, CatchClause, LOGGER.debug("[" + jobId + "] error while posting data", e);
222: Martijn van Groningen, trace, TryStmt, LOGGER.trace("[{}] Processed another {} records", jobId, counts.getProcessedRecordCount());
251: Martijn van Groningen, debug, MethodDeclaration, LOGGER.debug("[{}] Complete iterating data extractor [{}], [{}], [{}], [{}], [{}]", jobId, error, recordCount, lastEndTimeMs, isRunning(), dataExtractor.isCancelled());
311: Dimitris Athanasiou, debug, CatchClause, LOGGER.debug("[" + jobId + "] error while flushing job", e);
306: Martijn van Groningen, trace, TryStmt, LOGGER.trace("[" + jobId + "] Sending flush request");
336: David Kyle, debug, CatchClause, LOGGER.debug("[" + jobId + "] error while persisting job", e);
331: David Kyle, trace, TryStmt, LOGGER.trace("[" + jobId + "] Sending persist request");
113: Martijn van Groningen, info, MethodDeclaration, logger.info("[{}] attempt to stop datafeed [{}] [{}]", reason, task.getDatafeedId(), task.getAllocationId());
126: Martijn van Groningen, info, IfStmt, logger.info("Closing [{}] datafeeds, because [{}]", numDatafeeds, reason);
164: Martijn van Groningen, error, MethodDeclaration, logger.error("Failed lookback import for job [" + holder.datafeed.getJobId() + "]", e);
194: Martijn van Groningen, warn, IfStmt, logger.warn("[{}] {}", holder.datafeed.getJobId(), lookbackNoDataMsg);
198: Martijn van Groningen, error, CatchClause, logger.error("Failed lookback import for job [" + holder.datafeed.getJobId() + "]", e);
217: Martijn van Groningen, debug, IfStmt, logger.debug("Waiting [{}] before executing next realtime import for job [{}]", delay, jobId);
222: David Roberts, error, MethodDeclaration, logger.error("Unexpected datafeed failure for job [" + jobId + "] stopping...", e);
246: Martijn van Groningen, error, CatchClause, logger.error("Unexpected datafeed failure for job [" + jobId + "] stopping...", e);
320: Martijn van Groningen, info, MethodDeclaration, logger.info("[{}] attempt to stop datafeed [{}] for job [{}]", source, datafeed.getId(), datafeed.getJobId());
346: Martijn van Groningen, info, IfStmt, logger.info("[{}] datafeed [{}] for job [{}] was already stopped", source, datafeed.getId(), datafeed.getJobId());
330: Martijn van Groningen, info, TryStmt, logger.info("[{}] stopping datafeed [{}] for job [{}], acquired [{}]...", source, datafeed.getId(), datafeed.getJobId(), acquired);
336: Dimitris Athanasiou, info, TryStmt, logger.info("[{}] datafeed [{}] for job [{}] has been stopped{}", source, datafeed.getId(), datafeed.getJobId(), acquired ? "" : ", but there may be pending tasks as the timeout [" + timeout.getStringRep() + "] expired");
324: Martijn van Groningen, info, TryStmt, logger.info("[{}] try lock [{}] to stop datafeed [{}] for job [{}]...", source, timeout, datafeed.getId(), datafeed.getJobId());
394: Dimitris Athanasiou, debug, IfStmt, logger.debug("[{}] No need to auto-close job as job state is [{}]", getJobId(), jobState);
423: Jay Modi, error, IfStmt, logger.error("[{}] job close action was not acknowledged", getJobId());
436: David Roberts, error, IfStmt, logger.error("[" + getJobId() + "] failed to auto-close job", e);
434: David Roberts, debug, IfStmt, logger.debug("[{}] {}", getJobId(), e.getMessage());
444: David Roberts, error, MethodDeclaration, logger.error("Failed to remove datafeed persistent task - will not auto close job [" + getJobId() + "]", e);
460: Dimitris Athanasiou, info, IfStmt, logger.info("Datafeed [{}] is waiting for job [{}] to be opened", datafeedTask.getDatafeedId(), getJobId(datafeedTask));
501: Dimitris Athanasiou, warn, IfStmt, logger.warn("Datafeed [{}] is stopping because job [{}] state is [{}]", datafeedTask.getDatafeedId(), getJobId(datafeedTask), jobState);
49: Dimitris Athanasiou, debug, IfStmt, LOGGER.debug(msg);
59: Dimitris Athanasiou, debug, MethodDeclaration, LOGGER.debug(assignmentFailure.reason);
110: Dimitris Athanasiou, debug, CatchClause, LOGGER.debug(reason, e);
77: Dimitris Athanasiou, trace, MethodDeclaration, LOGGER.trace("[{}] Data extractor received cancel request", context.jobId);
101: Dimitris Athanasiou, debug, MethodDeclaration, LOGGER.debug("[{}] Executing aggregated search", context.jobId);
103: Dimitris Athanasiou, debug, MethodDeclaration, LOGGER.debug("[{}] Search response was obtained", context.jobId);
164: Dimitris Athanasiou, debug, IfStmt, LOGGER.debug("Skipping bucket at [{}], startTime is [{}]", bucketTime, startTime);
102: David Kyle, debug, IfStmt, LOGGER.debug("[{}]Chunked search configured:  totalHits = {}, dataTimeSpread = {} ms, chunk span = {} ms", context.jobId, dataSummary.totalHits, dataSummary.getDataTimeSpread(), chunkSpan);
120: Dimitris Athanasiou, debug, MethodDeclaration, LOGGER.debug("[{}] Data summary response was obtained", context.jobId);
169: David Kyle, trace, MethodDeclaration, LOGGER.trace("[{}] advances time to [{}, {})", context.jobId, currentStart, currentEnd);
78: Dimitris Athanasiou, trace, MethodDeclaration, LOGGER.trace("[{}] Data extractor received cancel request", context.jobId);
96: Dimitris Athanasiou, debug, MethodDeclaration, LOGGER.debug("[{}] Initializing scroll", context.jobId);
98: Dimitris Athanasiou, debug, MethodDeclaration, LOGGER.debug("[{}] Search response was obtained", context.jobId);
149: David Kyle, debug, IfStmt, LOGGER.debug("[{}] Resetting scroll search after shard failure", context.jobId);
186: Dimitris Athanasiou, debug, MethodDeclaration, LOGGER.debug("[{}] Continuing scroll with id [{}]", context.jobId, scrollId);
192: David Kyle, debug, IfStmt, LOGGER.debug("[{}] Reinitializing scroll due to SearchPhaseExecutionException", context.jobId);
199: Dimitris Athanasiou, debug, MethodDeclaration, LOGGER.debug("[{}] Search response was obtained", context.jobId);
168: Dimitris Athanasiou, debug, MethodDeclaration, logger.debug("Returning jobs matching [" + expression + "]");
447: Martijn van Groningen, debug, MethodDeclaration, logger.debug("Deleting job '" + jobId + "'");
453: Dimitris Athanasiou, info, IfStmt, logger.info("Job [" + jobId + "] deleted");
94: Dimitris Athanasiou, Error, CatchClause, logger.error("Error while processing next job update", e);
116: Dimitris Athanasiou, error, IfStmt, logger.error(msg);
112: Martijn van Groningen, info, IfStmt, logger.info("Successfully updated remote job [{}]", update.getJobId());
130: David Roberts, error, IfStmt, logger.error("Failed to update remote job [" + update.getJobId() + "]", e);
128: David Roberts, debug, IfStmt, logger.debug("Remote job [{}] not updated as it is no longer open", update.getJobId());
125: David Roberts, debug, IfStmt, logger.debug("Remote job [{}] not updated as it has been deleted", update.getJobId());
90: Dimitris Athanasiou, trace, MethodDeclaration, LOGGER.trace("ES API CALL: search index {}", index);
72: Martijn van Groningen, warn, CatchClause, logger.warn((Supplier<?>) () -> new ParameterizedMessage("[{}] Error serialising DataCounts stats", jobId), ioe);
222: David Kyle, warn, IfStmt, LOGGER.warn("{} result, {} quantile state and {} categorizer state documents exist for a prior job with Id [{}]", resultDocCount, quantileDocCount, categorizerStateDocCount, job.getId());
265: Dimitrios Athanasiou, trace, IfStmt, LOGGER.trace("ES API CALL: create index {}", indexName);
279: Dimitrios Athanasiou, info, IfStmt, LOGGER.info("Index already exists");
433: David Kyle, debug, IfStmt, LOGGER.debug("Found 0 hits for [{}]", new Object[] { searchRequest.indices() });
421: David Kyle, error, IfStmt, LOGGER.error("[{}] Search request returned shard failures: {}", jobId, Arrays.toString(shardFailures));
640: David Roberts, trace, MethodDeclaration, LOGGER.trace("ES API CALL: search all of category definitions from index {} sort ascending {} from {} size {}", indexName, CategoryDefinition.CATEGORY_ID.getPreferredName(), from, size);
691: Dimitris Athanasiou, trace, MethodDeclaration, LOGGER.trace("ES API CALL: search all of records from index {} with query {}", indexName, searchSourceBuilder);
726: David Roberts, trace, MethodDeclaration, LOGGER.trace("ES API CALL: search all of influencers from index {}{}  with filter from {} size {}", () -> indexName, () -> (query.getSortField() != null) ? " with sort " + (query.isSortDescending() ? "descending" : "ascending") + " on field " + query.getSortField() : "", query::getFrom, query::getSize);
850: David Roberts, trace, MethodDeclaration, LOGGER.trace("ES API CALL: search all model snapshots from index {} sort ascending {} with filter after sort from {} size {}", indexName, sortField, from, size);
877: David Roberts, trace, MethodDeclaration, LOGGER.trace("ES API CALL: search model plots from index {} from {} size {}", indexName, from, size);
908: Dimitris Athanasiou, trace, MethodDeclaration, LOGGER.trace("ES API CALL: search latest {} for job {}", ModelSizeStats.RESULT_TYPE_VALUE, jobId);
925: Jay Modi, trace, IfStmt, LOGGER.trace("No {} for job with id {}", resultDescription, jobId);
944: Hendrik Muhs, trace, IfStmt, LOGGER.trace("No {} for job with id {}", resultDescription, jobId);
1026: David Roberts, trace, IfStmt, LOGGER.trace("[{}] Insufficient history to calculate established memory use", jobId);
1009: Jay Modi, trace, IfStmt, LOGGER.trace("[{}] Coefficient of variation [{}] when calculating established memory use", jobId, coefficientOfVaration);
82: David Kyle, error, CatchClause, logger.error(new ParameterizedMessage("[{}] Error serialising result", jobId), e);
102: David Kyle, trace, MethodDeclaration, logger.trace("[{}] ES API CALL: bulk request with {} actions", jobId, bulkRequest.numberOfActions());
107: Jay Modi, error, IfStmt, logger.error("[{}] Bulk index of results has errors: {}", jobId, addRecordsResponse.buildFailureMessage());
108: David Kyle, trace, MethodDeclaration, logger.trace("[{}] ES API CALL: index bucket to index [{}] with ID [{}]", jobId, indexName, id);
120: David Kyle, trace, ForeachStmt, logger.trace("[{}] ES BULK ACTION: index bucket influencer to index [{}] with ID [{}]", jobId, indexName, id);
134: David Kyle, trace, ForeachStmt, logger.trace("[{}] ES BULK ACTION: index record to index [{}] with ID [{}]", jobId, indexName, record.getId());
150: David Kyle, trace, ForeachStmt, logger.trace("[{}] ES BULK ACTION: index influencer to index [{}] with ID [{}]", jobId, indexName, influencer.getId());
158: David Kyle, trace, MethodDeclaration, logger.trace("[{}] ES BULK ACTION: index model plot to index [{}] with ID [{}]", jobId, indexName, modelPlot.getId());
164: Hendrik Muhs, trace, MethodDeclaration, logger.trace("[{}] ES BULK ACTION: index forecast to index [{}] with ID [{}]", jobId, indexName, forecast.getId());
170: Hendrik Muhs, trace, MethodDeclaration, logger.trace("[{}] ES BULK ACTION: index forecast request stats to index [{}] with ID [{}]", jobId, indexName, forecastRequestStats.getId());
180: David Kyle, error, CatchClause, logger.error(new ParameterizedMessage("[{}] Error serialising {}", jobId, resultType), e);
195: David Kyle, trace, MethodDeclaration, logger.trace("[{}] ES API CALL: bulk request with {} actions", jobId, bulkRequest.numberOfActions());
200: Jay Modi, error, IfStmt, logger.error("[{}] Bulk index of results has errors: {}", jobId, addRecordsResponse.buildFailureMessage());
257: Martijn van Groningen, trace, MethodDeclaration, logger.trace("[{}] Persisting model size stats, for size {}", jobId, modelSizeStats.getModelBytes());
268: Dimitris Athanasiou, trace, MethodDeclaration, logger.trace("[{}] Persisting model size stats, for size {}", jobId, modelSizeStats.getModelBytes());
293: David Kyle, trace, MethodDeclaration, logger.trace("[{}] ES API CALL: refresh index {}", jobId, indexName);
310: Martijn van Groningen, trace, MethodDeclaration, logger.trace("[{}] ES API CALL: refresh index {}", jobId, indexName);
355: David Roberts, error, CatchClause, logger.error(new ParameterizedMessage("[{}] Error writing [{}]", jobId, (id == null) ? "auto-generated ID" : id), e);
366: David Roberts, trace, IfStmt, logger.trace("[{}] ES API CALL: to index {} with auto-generated ID", jobId, indexName);
364: David Roberts, trace, IfStmt, logger.trace("[{}] ES API CALL: to index {} with ID [{}]", jobId, indexName, id);
73: Dimitris Athanasiou, trace, ForeachStmt, LOGGER.trace("ES API CALL: get ID {} from index {}", stateDocId, indexName);
78: Jay Modi, error, IfStmt, LOGGER.error("Expected {} documents for model state for {} snapshot {} but failed to find {}", modelSnapshot.getSnapshotDocCount(), jobId, modelSnapshot.getSnapshotId(), stateDocId);
97: Dimitris Athanasiou, trace, WhileStmt, LOGGER.trace("ES API CALL: get ID {} from index {}", docId, indexName);
287: Colin Goodheart-Smithe, info, MethodDeclaration, logger.info(status);
142: Hendrik Muhs, debug, ForStmt, LOGGER.debug("Checking bucket {} compare sizes, this bucket: {} average: {}", pruneBucket, bucketSize, averageBucketSize);
165: Hendrik Muhs, debug, IfStmt, LOGGER.debug("Sparse bucket {}, this bucket: {} average: {}, sparsity score: {}", pruneBucket, bucketSize, averageBucketSize, sparsityScore);
69: Jason Tedor, Error, CatchClause, LOGGER.error("Error tailing C++ controller logs", e);
71: Jason Tedor, info, LambdaExpr, LOGGER.info("Native controller process has stopped - no new native processes can be started");
98: David Roberts, error, IfStmt, LOGGER.error(msg);
120: David Roberts, error, IfStmt, LOGGER.error(msg);
125: David Roberts, debug, SynchronizedStmt, LOGGER.debug("Starting process with command: " + command);
146: David Roberts, error, IfStmt, LOGGER.error(msg);
151: David Roberts, debug, SynchronizedStmt, LOGGER.debug("Killing process with PID: " + pid);
187: Colin Goodheart-Smithe, debug, MethodDeclaration, logger.debug("Periodic operations staggered by " + intervalStagger + " seconds for job '" + job.getId() + "'");
192: Colin Goodheart-Smithe, info, IfStmt, logger.info("Will not persist model state - " + DONT_PERSIST_MODEL_STATE_SETTING + " setting was set");
153: Colin Goodheart-Smithe, info, IfStmt, logger.info("Restoring quantiles for job '" + job.getId() + "'");
166: Martijn van Groningen, info, LambdaExpr, LOGGER.info("[{}] job closed", job.getId());
197: David Kyle, warn, CatchClause, LOGGER.warn(new ParameterizedMessage("[{}] Timed out waiting for killed job", job.getId()), e);
276: David Kyle, debug, MethodDeclaration, LOGGER.debug("[{}] waiting for flush", job.getId());
295: David Roberts, debug, IfStmt, LOGGER.debug("[{}] Flush completed", job.getId());
351: David Kyle, error, IfStmt, LOGGER.error(new ParameterizedMessage("[{}] Unexpected exception writing to process", job.getId()), e);
141: Martijn van Groningen, info, IfStmt, logger.info("Closing [{}] jobs, because [{}]", numJobs, reason);
150: Dimitris Athanasiou, trace, MethodDeclaration, logger.trace("[{}] Killing process: awaitCompletion = [{}]; reason = [{}]", jobTask.getJobId(), awaitCompletion, reason);
234: Martijn van Groningen, debug, MethodDeclaration, logger.debug("Flushing job {}", jobTask.getJobId());
238: David Kyle, debug, IfStmt, logger.debug(message);
246: David Kyle, error, IfStmt, logger.error(msg);
261: Hendrik Muhs, debug, MethodDeclaration, logger.debug("Forecasting job {}", jobTask.getJobId());
265: Hendrik Muhs, debug, IfStmt, logger.debug(message);
275: Hendrik Muhs, error, IfStmt, logger.error(msg, e);
286: Martijn van Groningen, debug, IfStmt, logger.debug(message);
323: Dimitris Athanasiou, info, MethodDeclaration, logger.info("Opening job [{}]", jobId);
337: Dimitris Athanasiou, debug, IfStmt, logger.debug("Aborted opening job [{}] as it has been closed", jobId);
341: Dimitris Athanasiou, debug, IfStmt, logger.debug("Cannot open job [{}] when its state is [{}]", jobId, processContext.getState().getClass().getName());
365: Martijn van Groningen, warn, LambdaExpr, logger.warn("Failed to gather information required to open job [" + jobId + "]", e1);
402: Dimitris Athanasiou, warn, IfStmt, logger.warn("[{}] {}", jobId, msg);
407: Dimitrios Athanasiou, warn, IfStmt, logger.warn("[{}] {}", jobId, msg);
438: David Kyle, error, CatchClause, logger.error("Can't close autodetect", ioe);
466: Dimitris Athanasiou, info, MethodDeclaration, logger.info("[{}] {}", jobId, msg);
493: David Roberts, debug, MethodDeclaration, logger.debug("Attempting to close job [{}], because [{}]", jobId, reason);
498: Dimitris Athanasiou, debug, IfStmt, logger.debug("Cannot close job [{}] as it has already been closed", jobId);
529: David Roberts, warn, CatchClause, logger.warn("[" + jobId + "] Exception closing autodetect process", e);
505: David Roberts, debug, IfStmt, logger.debug("Cannot close job [{}] as it has already been closed", jobId);
512: David Roberts, info, IfStmt, logger.info("Closing job [{}], because [{}]", jobId, reason);
510: David Roberts, info, IfStmt, logger.info("Closing job [{}]", jobId);
517: David Roberts, debug, IfStmt, logger.debug("Job [{}] is being closed before its process is started", jobId);
575: Martijn van Groningen, info, MethodDeclaration, logger.info("Successfully set job state to [{}] for job [{}]", state, jobTask.getJobId());
580: Martijn van Groningen, error, MethodDeclaration, logger.error("Could not set job state to [" + state + "] for job [" + jobTask.getJobId() + "]", e);
593: Igor Motov, Error, CatchClause, logger.warn("Error while delegating response", e1);
602: Igor Motov, Error, CatchClause, logger.warn("Error while delegating exception [" + e.getMessage() + "]", e1);
680: David Roberts, error, CatchClause, logger.error("error handling job operation", e);
95: David Roberts, error, IfStmt, LOGGER.error(new ParameterizedMessage("[{}] Error tailing autodetect process logs", jobId), e);
103: Hendrik Muhs, error, IfStmt, LOGGER.error("[{}] autodetect process stopped unexpectedly: {}", jobId, errors);
116: David Roberts, error, IfStmt, LOGGER.error(new ParameterizedMessage("[{}] Error reading autodetect state output", jobId), e);
112: David Roberts, info, IfStmt, LOGGER.info("[{}] State output finished", jobId);
130: Dimitris Athanasiou, Error, IfStmt, LOGGER.error("Error restoring model state for job " + jobId, e);
225: Martijn van Groningen, warn, CatchClause, LOGGER.warn(new ParameterizedMessage("[{}] Exception closing the running autodetect process", jobId), e);
227: Martijn van Groningen, warn, CatchClause, LOGGER.warn(new ParameterizedMessage("[{}] Exception closing the running autodetect process", jobId), e);
223: David Roberts, debug, TryStmt, LOGGER.debug("[{}] Autodetect process exited", jobId);
247: David Roberts, warn, CatchClause, LOGGER.warn("[{}] Failed to get PID of autodetect process to kill", jobId);
271: David Roberts, warn, IfStmt, LOGGER.warn("[{}] Failed to delete file {}", jobId, fileToDelete.toString());
269: David Roberts, debug, IfStmt, LOGGER.debug("[{}] Deleted file {}", jobId, fileToDelete.toString());
79: Martijn van Groningen, error, CatchClause, LOGGER.error("Can't close autodetect", ioe);
103: Colin Goodheart-Smithe, error, CatchClause, LOGGER.error(msg);
59: Dimitris Athanasiou, error, IfStmt, LOGGER.error("Failed to acquire process lock for job [{}]", jobTask.getJobId());
122: Dimitris Athanasiou, info, IfStmt, LOGGER.info("Killing job [{}]{}, because [{}]", jobId, extraInfo, reason);
120: Dimitris Athanasiou, info, IfStmt, LOGGER.info("Killing job [{}]{}", jobId, extraInfo);
128: Dimitris Athanasiou, error, CatchClause, LOGGER.error("[{}] Failed to kill autodetect process for job", jobId);
173: Dimitris Athanasiou, debug, MethodDeclaration, LOGGER.debug("Process set to [running] while it was already in that state");
193: Dimitris Athanasiou, debug, MethodDeclaration, LOGGER.debug("Process set to [running] while it was in [dying]");
199: Dimitris Athanasiou, debug, MethodDeclaration, LOGGER.debug("Process set to [dying] while it was already in that state");
162: Hendrik Muhs, warn, IfStmt, LOGGER.warn("[{}] some results not processed due to the termination of autodetect", jobId);
138: David Kyle, warn, CatchClause, LOGGER.warn(new ParameterizedMessage("[{}] Error processing autodetect result", jobId), e);
129: David Kyle, trace, IfStmt, LOGGER.trace("[{}] Bucket number {} parsed from output", jobId, bucketCount);
147: David Kyle, warn, CatchClause, LOGGER.warn(new ParameterizedMessage("[{}] Error persisting autodetect results", jobId), e);
150: David Kyle, info, TryStmt, LOGGER.info("[{}] {} buckets parsed from autodetect output", jobId, bucketCount);
231: Hendrik Muhs, trace, IfStmt, LOGGER.trace("Received Forecast Stats [{}]", forecastRequestStats.getId());
260: Dimitris Athanasiou, debug, IfStmt, LOGGER.debug("[{}] Parsed Quantiles with timestamp {}", context.jobId, quantiles.getTimestamp());
267: Dimitris Athanasiou, debug, IfStmt, LOGGER.debug("[{}] Quantiles queued for renormalization", context.jobId);
273: Martijn van Groningen, debug, IfStmt, LOGGER.debug("[{}] Flush acknowledgement parsed from output for ID {}", context.jobId, flushAcknowledgement.getId());
288: Dimitris Athanasiou, trace, MethodDeclaration, LOGGER.trace("[{}] Parsed ModelSizeStats: {} / {} / {} / {} / {} / {}", context.jobId, modelSizeStats.getModelBytes(), modelSizeStats.getTotalByFieldCount(), modelSizeStats.getTotalOverFieldCount(), modelSizeStats.getTotalPartitionFieldCount(), modelSizeStats.getBucketAllocationFailuresCount(), modelSizeStats.getMemoryStatus());
334: David Kyle, info, CatchClause, LOGGER.info("[{}] Interrupted acquiring update model snapshot semaphore", jobId);
342: Dimitris Athanasiou, debug, MethodDeclaration, LOGGER.debug("[{}] Updated job with model snapshot id [{}]", jobId, modelSnapshot.getSnapshotId());
348: Jay Modi, error, MethodDeclaration, LOGGER.error("[" + jobId + "] Failed to update job with new model snapshot id [" + modelSnapshot.getSnapshotId() + "]", e);
365: David Roberts, debug, MethodDeclaration, LOGGER.debug("[{}] Updated job with established model memory [{}]", jobId, establishedModelMemory);
370: David Roberts, error, MethodDeclaration, LOGGER.error("[" + jobId + "] Failed to update job with new established model memory [" + establishedModelMemory + "]", e);
374: David Roberts, error, MethodCallExpr, LOGGER.error("[" + jobId + "] Failed to calculate established model memory", e);
397: David Kyle, info, CatchClause, LOGGER.info("[{}] Interrupted waiting for results processor to complete", jobId);
84: Martijn van Groningen, debug, CatchClause, logger.debug("io error while parsing", e);
92: David Kyle, error, IfStmt, logger.error("Expecting Json Field name token after the Start Object token");
94: David Roberts, trace, MethodDeclaration, logger.trace("[{}] ES API CALL: bulk index", jobId);
174: Colin Goodheart-Smithe, error, CatchClause, logger.error(e.getMessage());
107: David Roberts, warn, IfStmt, LOGGER.warn("Not enough fields in csv record, expected at least " + maxIndex + ". " + line);
150: David Roberts, error, IfStmt, LOGGER.error(msg);
79: Colin Goodheart-Smithe, debug, MethodDeclaration, logger.debug("FieldConfig:\n" + contents.toString());
199: Colin Goodheart-Smithe, warn, CatchClause, logger.warn("Attempting to recover from malformed JSON data.", e);
222: Colin Goodheart-Smithe, error, IfStmt, logger.error("Failed to recover from malformed JSON data.", e);
293: Hendrik Muhs, warn, IfStmt, LOGGER.warn(new ParameterizedMessage("IO failure receiving C++ log message: {}", new Object[] { bytesRef.utf8ToString() }), e);
290: Hendrik Muhs, warn, IfStmt, LOGGER.warn(new ParameterizedMessage("[{}] IO failure receiving C++ log message: {}", new Object[] { jobId, bytesRef.utf8ToString() }), e);
47: David Roberts, error, CatchClause, LOGGER.error("Could not set up no-op pipe", e);
55: David Roberts, error, CatchClause, LOGGER.error(new ParameterizedMessage("[{}] Error tailing normalizer process logs", new Object[] { jobId }), e);
86: David Roberts, warn, CatchClause, LOGGER.warn(new ParameterizedMessage("[{}] Exception closing the running normalizer process", new Object[] { jobId }), e);
88: David Roberts, warn, CatchClause, LOGGER.warn("[{}] Exception closing the running normalizer process", jobId);
84: David Roberts, debug, TryStmt, LOGGER.debug("[{}] Normalizer process exited", jobId);
61: David Roberts, error, CatchClause, LOGGER.error(msg);
63: David Roberts, error, CatchClause, LOGGER.error(new ParameterizedMessage("[{}] Error reading normalizer results", new Object[] { jobId }), e);
83: David Roberts, error, CatchClause, LOGGER.error("[" + jobId + "] Error writing to the normalizer", e);
88: David Roberts, error, CatchClause, LOGGER.error("[" + jobId + "] Error closing normalizer", e);
97: David Roberts, error, CatchClause, LOGGER.error(new ParameterizedMessage("[{}] Error processing normalizer results", new Object[] { jobId }), e);
132: David Roberts, error, IfStmt, LOGGER.error("[{}] Unused normalized scores remain after updating all results: {} for {}", jobId, normalizedScores.size(), results.size());
152: David Roberts, error, IfStmt, LOGGER.error("[{}] {}", jobId, msg);
93: David Roberts, debug, MethodDeclaration, LOGGER.debug("[{}] Normalization resulted in: {} updates, {} no-ops", jobId, counts[0], counts[1]);
108: David Roberts, debug, IfStmt, LOGGER.debug("[{}] No buckets to renormalize for job", jobId);
155: David Roberts, debug, IfStmt, LOGGER.debug("[{}] No records to renormalize for job", jobId);
159: David Roberts, debug, WhileStmt, LOGGER.debug("[{}] Will renormalize a batch of {} records", jobId, records.size());
178: David Roberts, debug, IfStmt, LOGGER.debug("[{}] No influencers to renormalize for job", jobId);
182: David Roberts, debug, WhileStmt, LOGGER.debug("[{}] Will renormalize a batch of {} influencers", jobId, influencers.size());
173: David Roberts, error, CatchClause, LOGGER.error("[" + jobId + "] Normalization failed", e);
160: David Roberts, warn, IfStmt, LOGGER.warn("[{}] Quantiles not supplied in time order - {} after {}", jobId, latestBucketTimeMs, earliestBucketTimeMs);
65: Dimitris Athanasiou, debug, MethodDeclaration, LOGGER.debug("Removing forecasts that expire before [{}]", cutoffEpochMs);
96: Dimitris Athanasiou, info, IfStmt, LOGGER.info("Deleted [{}] documents corresponding to [{}] expired forecasts", bulkByScrollResponse.getDeleted(), forecastsToDelete.size());
117: Dimitris Athanasiou, info, IfStmt, LOGGER.info("More than [{}] forecasts were found. This run will only delete [{}] of them", MAX_FORECASTS, MAX_FORECASTS);
68: Dimitris Athanasiou, debug, MethodDeclaration, LOGGER.debug("Removing model snapshots of job [{}] that have a timestamp before [{}]", job.getId(), cutoffEpochMs);
65: Dimitris Athanasiou, debug, MethodDeclaration, LOGGER.debug("Removing results of job [{}] that have a timestamp before [{}]", job.getId(), cutoffEpochMs);
110: Dimitris Athanasiou, debug, MethodDeclaration, LOGGER.debug("[{}] {}", jobId, msg);
59: Jay Modi, trace, MethodDeclaration, LOGGER.trace("Successfully persisted {}", type);
64: Jay Modi, debug, MethodDeclaration, LOGGER.debug(new ParameterizedMessage("Error writing {}", new Object[] { type }, e));
219: Martijn van Groningen, info, MethodDeclaration, logger.info("stop the only running ml node");
228: Martijn van Groningen, info, MethodDeclaration, logger.info("start ml node");
241: Martijn van Groningen, info, MethodDeclaration, logger.info("Start non ml node:");
244: Martijn van Groningen, info, MethodDeclaration, logger.info("Starting ml nodes");
291: Martijn van Groningen, info, MethodDeclaration, logger.info("stopping ml nodes");
299: Martijn van Groningen, error, CatchClause, logger.error("error stopping node", e);
314: Martijn van Groningen, info, MethodDeclaration, logger.info("re-starting ml nodes");
329: Martijn van Groningen, info, MethodDeclaration, logger.info("Start non ml node:");
334: Martijn van Groningen, info, MethodDeclaration, logger.info("Starting ml node");
363: Martijn van Groningen, info, MethodDeclaration, logger.info("Stop data node");
374: Martijn van Groningen, info, MethodDeclaration, logger.info("Start data node");
65: Martijn van Groningen, info, MethodDeclaration, logger.info("Starting dedicated master node...");
71: Martijn van Groningen, info, MethodDeclaration, logger.info("Starting ml and data node...");
77: Martijn van Groningen, info, LambdaExpr, logger.info("Stopping dedicated master node");
84: Martijn van Groningen, info, LambdaExpr, logger.info("Restarting dedicated master node");
98: Martijn van Groningen, info, LambdaExpr, logger.info("Restarting all nodes");
100: Martijn van Groningen, info, LambdaExpr, logger.info("Restarted all nodes");
106: David Kyle, info, MethodDeclaration, logger.info("Starting dedicated master node...");
112: David Kyle, info, MethodDeclaration, logger.info("Starting ml and data node...");
108: Martijn van Groningen, info, CatchClause, logger.info("good news everybody --> reached maximum number of allowed opened jobs, after trying to open the {}th job", i);
93: Martijn van Groningen, info, TryStmt, logger.info("Opened {}th job", i);
132: David Roberts, info, MethodDeclaration, logger.info("[{}] is [{}]", AutodetectProcessManager.MAX_OPEN_JOBS_PER_NODE.getKey(), maxNumberOfJobsPerNode);
137: Martijn van Groningen, info, MethodDeclaration, logger.info("Started [{}] nodes", numNodes);
205: Martijn van Groningen, info, MethodDeclaration, logger.info("[{}#{}]: Cleaning up datafeeds and jobs after test", getTestClass().getSimpleName(), getTestName());
236: Martijn van Groningen, error, IfStmt, logger.error("Item response failure [{}]", itemResponse.getFailureMessage());
241: Martijn van Groningen, info, MethodDeclaration, logger.info("Indexed [{}] documents", numDocs);
290: Hendrik Muhs, warn, CatchClause, logger.warn("Force-stopping datafeed with _all failed.", e2);
277: Hendrik Muhs, info, TryStmt, logger.info("Closing all datafeeds (using _all)");
333: Hendrik Muhs, warn, CatchClause, logger.warn("Force-closing jobs failed.", e2);
320: Dimitris Athanasiou, info, TryStmt, logger.info("Closing jobs using [{}]", MetaData.ALL);
123: Tanguy Leroux, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to start monitoring service"), e);
119: Tanguy Leroux, debug, TryStmt, logger.debug("monitoring service is starting");
121: Tanguy Leroux, debug, TryStmt, logger.debug("monitoring service started");
133: Tanguy Leroux, debug, IfStmt, logger.debug("monitoring service is stopping");
135: Tanguy Leroux, debug, IfStmt, logger.debug("monitoring service stopped");
141: Tanguy Leroux, debug, MethodDeclaration, logger.debug("monitoring service is closing");
148: Tanguy Leroux, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to close exporter [{}]", exporter.name()), e);
151: Tanguy Leroux, debug, MethodDeclaration, logger.debug("monitoring service closed");
192: Tanguy Leroux, debug, IfStmt, logger.debug("monitoring execution is skipped");
197: Tanguy Leroux, debug, IfStmt, logger.debug("monitoring execution is skipped until previous execution terminated");
222: Tanguy Leroux, warn, CatchClause, logger.warn((Supplier<?>) () -> new ParameterizedMessage("monitoring collector [{}] failed to collect data", collector.name()), e);
235: Tanguy Leroux, warn, MethodDeclaration, logger.warn("monitoring execution failed", e);
241: Tanguy Leroux, warn, MethodDeclaration, logger.warn("monitoring execution has been rejected", e);
249: Tanguy Leroux, warn, MethodDeclaration, logger.warn("monitoring execution failed", e);
258: Jay Modi, warn, IfStmt, logger.warn("monitoring execution did not complete after waiting for 10s");
57: Tanguy Leroux, debug, MethodDeclaration, logger.debug("starting cleaning service");
59: Tanguy Leroux, debug, MethodDeclaration, logger.debug("cleaning service started");
64: Tanguy Leroux, debug, MethodDeclaration, logger.debug("stopping cleaning service");
66: Tanguy Leroux, debug, MethodDeclaration, logger.debug("cleaning service stopped");
71: Tanguy Leroux, debug, MethodDeclaration, logger.debug("closing cleaning service");
73: Tanguy Leroux, debug, MethodDeclaration, logger.debug("cleaning service closed");
109: Michael Basnight, warn, IfStmt, logger.warn("[{}] setting will be ignored until an appropriate license is applied", MonitoringField.HISTORY_DURATION.getKey());
166: Tanguy Leroux, debug, IfStmt, logger.debug("cleaning service is disabled due to invalid license");
173: Chris Earle, trace, MethodDeclaration, logger.trace("cleaning up indices with retention [{}]", retention);
180: Jason Tedor, error, CatchClause, logger.error("listener failed to clean indices", e);
184: Chris Earle, trace, MethodDeclaration, logger.trace("done cleaning up indices");
195: Chris Earle, debug, MethodDeclaration, logger.debug("scheduling next execution in [{}] seconds", delay.seconds());
201: Tanguy Leroux, debug, IfStmt, logger.debug("couldn't schedule new execution of the cleaner, executor is shutting down", e);
210: Jason Tedor, error, MethodDeclaration, logger.error("failed to clean indices", e);
76: Tanguy Leroux, trace, IfStmt, logger.trace("collector [{}] can not collect data due to invalid license", name());
90: Tanguy Leroux, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("collector [{}] timed out when collecting data", name()));
92: Tanguy Leroux, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("collector [{}] failed to collect data", name()), e);
86: Tanguy Leroux, trace, IfStmt, logger.trace("collector [{}] - collecting data...", name());
135: Tanguy Leroux, trace, IfStmt, logger.trace((Supplier<?>) () -> new ParameterizedMessage("collector [{}] - " + "unable to collect data because of expired license", name()), e);
99: Jason Tedor, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to close exporter [{}]", exporter.name()), e);
108: Chris Earle, trace, IfStmt, logger.trace("skipping exporters because the cluster state is not loaded");
122: Jason Tedor, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("exporter [{}] failed to open exporting bulk", exporter.name()), e);
117: Chris Earle, debug, IfStmt, logger.debug("skipping exporter [{}] as it is not ready yet", exporter.name());
148: uboness, debug, IfStmt, logger.debug("exporter [{}/{}] is disabled", type, name);
165: Chris Earle, warn, CatchClause, logger.warn((Supplier<?>) () -> new ParameterizedMessage("failed to render document [{}], skipping it [{}]", doc, name), e);
161: Tanguy Leroux, trace, TryStmt, logger.trace("added index request [index={}, type={}, id={}]", index, doc.getType(), id);
119: Chris Earle, warn, MethodDeclaration, logger.warn(msg, cause);
123: Chris Earle, warn, MethodDeclaration, logger.warn("unexpected error while indexing monitoring document: [{}]", text);
317: Alexander Reelsen, debug, IfStmt, logger.debug("exporter [{}] using host sniffing", config.name());
390: Alexander Reelsen, debug, MethodDeclaration, logger.debug("exporter [{}] using hosts {}", config.name(), hosts);
454: Alexander Reelsen, warn, IfStmt, logger.warn("exporter [{}] is not using https, but using user authentication with plaintext " + "username/password!", config.name());
662: Chris Earle, error, CatchClause, logger.error("an error occurred while closing the internal client sniffer", e);
667: Chris Earle, error, CatchClause, logger.error("an error occurred while closing the internal client", e);
58: Chris Earle, trace, MethodDeclaration, logger.trace("checking sub-resources existence and publishing on the [{}]", resourceOwnerName);
70: Chris Earle, trace, MethodDeclaration, logger.trace("all sub-resources exist [{}] on the [{}]", exists, resourceOwnerName);
80: Chris Earle, warn, MethodDeclaration, logger.warn("connection failed to node at [{}://{}:{}]", host.getSchemeName(), host.getHostName(), host.getPort());
279: Chris Earle, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to parse [{}/{}] on the [{}]", resourceBasePath, resourceName, resourceOwnerName), e);
312: Chris Earle, trace, MethodDeclaration, logger.trace("checking if {} [{}] exists on the [{}] {}", resourceType, resourceName, resourceOwnerName, resourceOwnerType);
339: Chris Earle, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to verify {} [{}] on the [{}] {} with status code [{}]", resourceType, resourceName, resourceOwnerName, resourceOwnerType, statusCode), e);
347: Chris Earle, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to verify {} [{}] on the [{}] {}", resourceType, resourceName, resourceOwnerName, resourceOwnerType), e);
329: Chris Earle, debug, IfStmt, logger.debug("{} [{}] does not exist on the [{}] {}", resourceType, resourceName, resourceOwnerName, resourceOwnerType);
325: Chris Earle, debug, IfStmt, logger.debug("{} [{}] found on the [{}] {}", resourceType, resourceName, resourceOwnerName, resourceOwnerType);
384: Chris Earle, trace, MethodDeclaration, logger.trace("uploading {} [{}] to the [{}] {}", resourceType, resourceName, resourceOwnerName, resourceOwnerType);
401: Chris Earle, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to upload {} [{}] on the [{}] {}", resourceType, resourceName, resourceOwnerName, resourceOwnerType), e);
394: Chris Earle, debug, IfStmt, logger.debug("{} [{}] uploaded to the [{}] {}", resourceType, resourceName, resourceOwnerName, resourceOwnerType);
430: Chris Earle, trace, MethodDeclaration, logger.trace("deleting {} [{}] from the [{}] {}", resourceType, resourceName, resourceOwnerName, resourceOwnerType);
451: Chris Earle, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to delete {} [{}] on the [{}] {}", resourceType, resourceName, resourceOwnerName, resourceOwnerType), e);
444: Chris Earle, debug, IfStmt, logger.debug("{} [{}] deleted from the [{}] {}", resourceType, resourceName, resourceOwnerName, resourceOwnerType);
59: Chris Earle, trace, MethodDeclaration, logger.trace("checking [{}] to ensure that it supports the minimum version [{}]", resourceOwnerName, minimumVersion);
64: Chris Earle, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to verify minimum version [{}] on the [{}] monitoring cluster", minimumVersion, resourceOwnerName), e);
95: Nik Everett, error, IfStmt, logger.error("version [{}] < [{}] and NOT supported for [{}]", version, minimumVersion, resourceOwnerName);
92: Nik Everett, debug, IfStmt, logger.debug("version [{}] >= [{}] and supported for [{}]", version, minimumVersion, resourceOwnerName);
118: Chris Earle, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to parse [_xpack] on the [{}]", resourceOwnerName), e);
85: Chris Earle, trace, IfStmt, logger.trace("local exporter [{}] - added index request [index={}, type={}, id={}, pipeline={}]", name, request.index(), request.type(), request.id(), request.getPipeline());
107: Jay Modi, trace, TryStmt, logger.trace("exporter [{}] - exporting {} documents", name, requestBuilder.numberOfActions());
133: Tanguy Leroux, warn, ForeachStmt, logger.warn("unexpected error while indexing monitoring document", e);
154: Chris Earle, trace, IfStmt, logger.trace("stopped");
186: Chris Earle, info, IfStmt, logger.info("waiting for elected master node [{}] to setup local exporter [{}] (does it have x-pack installed?)", clusterService.state().nodes().getMasterNode(), config.name());
199: Chris Earle, debug, IfStmt, logger.debug("started");
221: Chris Earle, debug, IfStmt, logger.debug("monitoring index template [{}] does not exist, so service cannot start (waiting on master)", template);
231: Chris Earle, debug, IfStmt, logger.debug("monitoring ingest pipeline [{}] does not exist, so service cannot start (waiting on master)", pipelineName(pipelineId));
238: Chris Earle, trace, MethodDeclaration, logger.trace("monitoring index templates and pipelines are installed, service can start");
258: Chris Earle, debug, IfStmt, logger.debug("waiting until metadata writes are unblocked");
263: Chris Earle, trace, IfStmt, logger.trace("already installing something, waiting for install to complete");
278: Chris Earle, debug, IfStmt, logger.debug((Supplier<?>) () -> new ParameterizedMessage("template {} not found", missingTemplates.stream().map(Map.Entry::getKey).collect(Collectors.toList())));
302: Chris Earle, trace, IfStmt, logger.trace("all pipelines found");
295: Chris Earle, debug, ForeachStmt, logger.debug("pipeline [{}] not found", pipelineName);
314: Chris Earle, trace, IfStmt, logger.trace("cannot manage cluster alerts because [.watches] index is not allocated");
331: Chris Earle, debug, IfStmt, logger.debug("monitoring index templates and pipelines are installed on master node, service can start");
344: Chris Earle, trace, IfStmt, logger.trace("all installation requests returned a response");
393: Chris Earle, debug, MethodDeclaration, logger.debug("installing ingest pipeline [{}]", pipelineName);
407: Chris Earle, debug, MethodDeclaration, logger.debug("installing template [{}]", template);
452: Chris Earle, trace, IfStmt, logger.trace("pruning monitoring watch [{}]", uniqueWatchId);
446: Chris Earle, trace, IfStmt, logger.trace("checking monitoring watch [{}]", uniqueWatchId);
467: Chris Earle, trace, MethodDeclaration, logger.trace("adding monitoring watch [{}]", uniqueWatchId);
488: Tanguy Leroux, debug, IfStmt, logger.debug("exporter not ready");
496: Tanguy Leroux, debug, IfStmt, logger.debug("cleaning indices [expiration={}, retention={}]", expiration, retention);
529: Tanguy Leroux, debug, IfStmt, logger.debug("detected expired index [name={}, created={}, expired={}]", indexName, new DateTime(creationDate, DateTimeZone.UTC), expiration);
541: Tanguy Leroux, debug, IfStmt, logger.debug("no old indices found for clean up");
538: Tanguy Leroux, info, IfStmt, logger.info("cleaning up [{}] old indices", indices.size());
548: Tanguy Leroux, trace, MethodDeclaration, logger.trace("deleting {} indices: [{}]", indices.size(), collectionToCommaDelimitedString(indices));
555: Jay Modi, debug, IfStmt, logger.debug("{} indices deleted", indices.size());
565: Jay Modi, error, MethodDeclaration, logger.error("failed to delete indices", e);
607: Chris Earle, trace, IfStmt, logger.trace("successfully handled monitoring {} [{}]", type, name);
604: Chris Earle, error, IfStmt, logger.error("failed to set monitoring {} [{}]", type, name);
602: Chris Earle, trace, IfStmt, logger.trace("successfully set monitoring {} [{}]", type, name);
614: Chris Earle, error, MethodDeclaration, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to set monitoring {} [{}]", type, name), e);
638: Chris Earle, trace, IfStmt, logger.trace("found monitoring watch [{}]", uniqueWatchId);
651: Chris Earle, error, IfStmt, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to get monitoring watch [{}]", uniqueWatchId), e);
153: Tanguy Leroux, debug, MethodDeclaration, logger.debug("--> creates a cleaner service that cleans every second");
159: Tanguy Leroux, debug, MethodDeclaration, logger.debug("--> registers cleaning listener");
164: Tanguy Leroux, debug, TryStmt, logger.debug("--> starts cleaning service");
167: Tanguy Leroux, debug, TryStmt, logger.debug("--> waits for listener to be executed");
205: Alexander Reelsen, info, MethodDeclaration, logger.info(settings);
277: Jay Modi, debug, MethodCallExpr, logger.debug("--> thread [{}] successfully exported {} documents", threadNum, threadDocs);
278: Jay Modi, debug, MethodCallExpr, logger.debug("--> thread [{}] failed to export {} documents", threadNum, threadDocs);
276: Jay Modi, debug, MethodDeclaration, exporters.export(docs, ActionListener.wrap(r -> logger.debug("--> thread [{}] successfully exported {} documents", threadNum, threadDocs), e -> logger.debug("--> thread [{}] failed to export {} documents", threadNum, threadDocs)));
69: Chris Earle, trace, MethodDeclaration, verify(logger).trace("checking if {} [{}] exists on the [{}] {}", resourceType, resourceName, owner, ownerType);
71: Chris Earle, error, MethodDeclaration, verify(logger).error(any(org.apache.logging.log4j.util.Supplier.class), any(ResponseException.class));
106: Chris Earle, trace, MethodDeclaration, verify(logger).trace("checking if {} [{}] exists on the [{}] {}", resourceType, resourceName, owner, ownerType);
108: Chris Earle, error, MethodDeclaration, verify(logger).error(any(org.apache.logging.log4j.util.Supplier.class), any(ResponseException.class));
128: Chris Earle, trace, MethodDeclaration, verify(logger).trace("checking if {} [{}] exists on the [{}] {}", resourceType, resourceName, owner, ownerType);
129: Chris Earle, debug, MethodDeclaration, verify(logger).debug("{} [{}] found on the [{}] {}", resourceType, resourceName, owner, ownerType);
131: Chris Earle, error, MethodDeclaration, verify(logger).error(any(org.apache.logging.log4j.util.Supplier.class), any(ResponseException.class));
147: Chris Earle, trace, MethodDeclaration, verify(logger).trace("checking if {} [{}] exists on the [{}] {}", resourceType, resourceName, owner, ownerType);
149: Chris Earle, error, MethodDeclaration, verify(logger).error(any(org.apache.logging.log4j.util.Supplier.class), eq(e));
170: Chris Earle, trace, MethodDeclaration, verify(logger).trace("uploading {} [{}] to the [{}] {}", resourceType, resourceName, owner, ownerType);
172: Chris Earle, error, MethodDeclaration, verify(logger).error(any(org.apache.logging.log4j.util.Supplier.class), eq(e));
198: Chris Earle, trace, MethodDeclaration, verify(logger).trace("deleting {} [{}] from the [{}] {}", resourceType, resourceName, owner, ownerType);
200: Chris Earle, error, MethodDeclaration, verify(logger).error(any(org.apache.logging.log4j.util.Supplier.class), eq(e));
285: Chris Earle, trace, MethodDeclaration, verify(logger).trace("checking if {} [{}] exists on the [{}] {}", resourceType, resourceName, owner, ownerType);
297: Chris Earle, debug, MethodDeclaration, verify(logger).debug(debugLogMessage, resourceType, resourceName, owner, ownerType);
321: Chris Earle, trace, MethodDeclaration, verify(logger).trace("checking if {} [{}] exists on the [{}] {}", resourceType, resourceName, owner, ownerType);
336: Chris Earle, debug, MethodDeclaration, verify(logger).debug(debugLogMessage, resourceType, resourceName, owner, ownerType);
353: Chris Earle, trace, MethodDeclaration, verify(logger).trace("uploading {} [{}] to the [{}] {}", resourceType, resourceName, owner, ownerType);
360: Chris Earle, error, IfStmt, verify(logger).error(any(org.apache.logging.log4j.util.Supplier.class), e.capture());
356: Chris Earle, debug, IfStmt, verify(logger).debug("{} [{}] uploaded to the [{}] {}", resourceType, resourceName, owner, ownerType);
399: Chris Earle, trace, MethodDeclaration, verify(logger).trace("deleting {} [{}] from the [{}] {}", resourceType, resourceName, owner, ownerType);
406: Chris Earle, error, IfStmt, verify(logger).error(any(org.apache.logging.log4j.util.Supplier.class), e.capture());
402: Chris Earle, debug, IfStmt, verify(logger).debug("{} [{}] deleted from the [{}] {}", resourceType, resourceName, owner, ownerType);
210: uboness, trace, MethodDeclaration, logger.trace("checking if index exists [{}]", Strings.arrayToCommaDelimitedString(indices));
204: Zachary Tong, warn, IfStmt, logger.warn("\"Live\" index not found during rollup search.", e);
218: Zachary Tong, warn, IfStmt, logger.warn("Rollup index not found during rollup search.", e);
65: Zachary Tong, debug, MethodDeclaration, logger.debug("Request to cancel Task for Rollup job [" + jobId + "] successful.");
72: Zachary Tong, debug, MethodDeclaration, logger.debug("Task for Rollup job [" + jobId + "] successfully canceled.");
78: Zachary Tong, Error, MethodDeclaration, logger.error("Error while cancelling task for Rollup job [" + jobId + "]." + e);
86: Zachary Tong, warn, MethodDeclaration, logger.warn(msg);
94: Zachary Tong, Error, MethodDeclaration, logger.error("Error while requesting to cancel task for Rollup job [" + jobId + "]" + e);
144: Zachary Tong, error, IfStmt, logger.error(msg);
140: Zachary Tong, debug, IfStmt, logger.debug("Rolled index already exists for rollup job [" + job.getConfig().getId() + "], updating metadata.");
161: Zachary Tong, error, IfStmt, logger.error(msg);
170: Zachary Tong, error, IfStmt, logger.error(msg);
179: Zachary Tong, error, IfStmt, logger.error(msg);
200: Zachary Tong, error, LambdaExpr, logger.error(msg);
136: Zachary Tong, debug, IfStmt, logger.debug("Creating msearch with only normal request");
393: Zachary Tong, warn, CatchClause, logger.warn((org.apache.logging.log4j.util.Supplier<?>) () -> new ParameterizedMessage("Failed to send error response for action [{}] and request [{}]", actionName, request), e1);
53: Zachary Tong, debug, MethodDeclaration, logger.debug("Buckets: [" + agg.getBuckets().size() + "][" + jobId + "]");
196: Zachary Tong, warn, SwitchStmt, logger.warn("Schedule was triggered for rollup job [" + job.getConfig().getId() + "], but prior indexer is still running.");
200: Zachary Tong, debug, SwitchStmt, logger.debug("Schedule was triggered for rollup job [" + job.getConfig().getId() + "] but job is stopped.  Ignoring trigger.");
205: Zachary Tong, debug, SwitchStmt, logger.debug("Schedule was triggered for rollup job [" + job.getConfig().getId() + "], state: [" + currentState + "]");
227: Zachary Tong, debug, IfStmt, logger.debug("Could not move from STARTED to INDEXING state because current state is [" + state.get() + "]");
224: Zachary Tong, debug, IfStmt, logger.debug("Beginning to rollup [" + job.getConfig().getId() + "], state: [" + currentState + "]");
232: Zachary Tong, warn, SwitchStmt, logger.warn("Encountered unexpected state [" + currentState + "] while indexing");
248: Zachary Tong, info, SwitchStmt, logger.info("Rollup job encountered [" + IndexerState.STOPPING + "] state, halting indexer.");
256: Zachary Tong, info, SwitchStmt, logger.info("Requested shutdown of indexer for job [" + job.getConfig().getId() + "]");
262: Zachary Tong, warn, SwitchStmt, logger.warn("Encountered unexpected state [" + currentState + "] while indexing");
271: Zachary Tong, Error, IfStmt, logger.warn("Error while attempting to bulk index rollup documents: " + response.buildFailureMessage());
306: Zachary Tong, debug, IfStmt, logger.debug("Finished indexing for job [" + job.getConfig().getId() + "], saving state and shutting down.");
74: Zachary Tong, info, MethodDeclaration, logger.info("Rollup job [" + params.getConfig().getId() + "] created.");
122: Zachary Tong, debug, IfStmt, logger.debug("Updating persistent status of job [" + job.getConfig().getId() + "] to [" + state.toString() + "]");
129: Zachary Tong, debug, MethodDeclaration, logger.debug("Finished indexing for job [" + job.getConfig().getId() + "]");
134: Zachary Tong, warn, MethodDeclaration, logger.warn("Rollup job [" + job.getConfig().getId() + "] failed with an exception: ", exc);
159: Zachary Tong, debug, IfStmt, logger.debug("We have existing status, setting state to [" + status.getState() + "] " + "and current position to [" + status.getPosition() + "] for job [" + job.getConfig().getId() + "]");
228: Zachary Tong, debug, MethodDeclaration, logger.debug("Updating status for rollup job [" + job.getConfig().getId() + "] to [" + status.getState() + "][" + status.getPosition() + "]");
233: Zachary Tong, debug, LambdaExpr, logger.debug("Succesfully updated status for rollup job [" + job.getConfig().getId() + "] to [" + status.getState() + "][" + status.getPosition() + "]");
272: Zachary Tong, debug, LambdaExpr, logger.debug("Succesfully updated status for rollup job [" + job.getConfig().getId() + "] to [" + status.getState() + "]");
297: Zachary Tong, info, TryStmt, logger.info("Rollup indexer [" + job.getConfig().getId() + "] received abort request, stopping indexer.");
314: Zachary Tong, info, MethodDeclaration, logger.info("Received cancellation request for Rollup job [" + job.getConfig().getId() + "], state: [" + indexer.getState() + "]");
331: Zachary Tong, debug, IfStmt, logger.debug("Rollup indexer [" + event.getJobName() + "] schedule has triggered, state: [" + indexer.getState() + "]");
370: Zachary Tong, info, ForStmt, logger.info("Day: [" + i + "]: " + ts.toString() + " [" + ts.getMillis() + "]");
414: Zachary Tong, error, LambdaExpr, logger.error("state: [" + state + "]");
445: Ryan Ernst, debug, IfStmt, logger.debug("Using authentication failure handler from extension [" + extensionName + "]");
442: Ryan Ernst, debug, IfStmt, logger.debug("Using default authentication failure handler");
805: jaymode, warn, IfStmt, logger.warn("the [action.auto_create_index] setting is configured to be restrictive [{}]. " + " for the next 6 months audit indices are allowed to be created, but please make sure" + " that any future history indices after 6 months with the pattern " + "[.security_audit_log*] are allowed to be created", value);
900: Jay Modi, Error, CatchClause, logger.error("Error loading template [{}] as part of metadata upgrading", IndexAuditTrail.INDEX_TEMPLATE_NAME);
109: Lee Hinman, error, CatchClause, logger.error("failed to start index audit trail", e);
97: Lee Hinman, error, MethodDeclaration, logger.error("failed to start index audit trail services", throwable);
182: Tim Vernum, error, CatchClause, logger.error("failed to stop audit trail module", e);
81: uboness, error, IfStmt, logger.error("blocking [{}] operation due to expired license. Cluster health, cluster stats and indices stats \n" + "operations are blocked on license expiration. All data operations (read and write) continue to work. \n" + "If you have a new license, please update it. Otherwise, please reach out to your support contact.", action);
57: javanna, trace, ForeachStmt, logger.trace("intercepted bulk request for index [{}] without any update requests, continuing execution", bulkItemRequest.index());
48: javanna, trace, IfStmt, logger.trace("intercepted request for index [{}] with field level access controls [{}] document level access " + "controls [{}]. disabling conflicting features", index, fieldLevelSecurityEnabled, documentLevelSecurityEnabled);
56: javanna, trace, ForeachStmt, logger.trace("intercepted request for index [{}] without field or document level access controls", index);
57: Jason Tedor, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to delete role [{}]", request.name()), e);
48: Lee Hinman, info, IfStmt, logger.info("updated role [{}]", request.name());
46: Lee Hinman, info, IfStmt, logger.info("added role [{}]", request.name());
52: Tim Vernum, trace, MethodDeclaration, logger.trace("Attempting to authenticate SamlToken [{}]", saml);
66: Tim Vernum, debug, LambdaExpr, logger.debug(() -> new ParameterizedMessage("SamlToken [{}] could not be authenticated", saml), e);
81: Tim Vernum, info, CatchClause, logger.info("Failed to invalidate SAML session", e);
95: Tim Vernum, debug, IfStmt, logger.debug("Logout request [{}] has no NameID value, so cannot invalidate any sessions", result);
102: Tim Vernum, debug, LambdaExpr, logger.debug("Found [{}] token pairs to invalidate for SAML metadata [{}]", sessionTokens.size(), tokenMetadata);
121: Tim Vernum, info, LambdaExpr, logger.info("Failed to invalidate SAML access_token [{}] - {}", tokenPair.v1().getId(), e.toString());
81: Tim Vernum, debug, CatchClause, logger.debug("Internal exception during SAML logout", e);
68: Tim Vernum, trace, IfStmt, logger.trace("SAML Logout User [{}], Token [{}...{}]", authentication.getUser().principal(), token.substring(0, 8), token.substring(token.length() - 8));
75: Albert Zaharovits, debug, MethodDeclaration, logger.debug(() -> new ParameterizedMessage("Check whether role [{}] has privileges cluster=[{}] index=[{}]", Strings.arrayToCommaDelimitedString(userRole.names()), Strings.arrayToCommaDelimitedString(request.clusterPrivileges()), Strings.arrayToCommaDelimitedString(request.indexPrivileges())));
103: Albert Zaharovits, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("Role [{}] does not have [{}] on [{}]", Strings.arrayToCommaDelimitedString(userRole.names()), privilege, index));
99: Albert Zaharovits, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("Role [{}] has [{}] on [{}]", Strings.arrayToCommaDelimitedString(userRole.names()), privilege, index));
62: Lee Hinman, info, IfStmt, logger.info("updated user [{}]", request.username());
60: Lee Hinman, info, IfStmt, logger.info("added user [{}]", request.username());
69: Jason Tedor, error, MethodDeclaration, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to put user [{}]", request.username()), e);
246: Jay Modi, debug, IfStmt, logger.debug("security audit index template [{}] is not up to date", INDEX_TEMPLATE_NAME);
253: jaymode, debug, IfStmt, logger.debug("security audit index [{}] does not exist, so service can start", index);
258: jaymode, debug, IfStmt, logger.debug("security audit index [{}] all primary shards started, so service can start", index);
261: jaymode, debug, MethodDeclaration, logger.debug("security audit index [{}] does not have all primary shards started, so service cannot start", index);
290: Tim Vernum, trace, MethodDeclaration, logger.trace("remote cluster state is [{}] [{}]", clusterStateResponse.getClusterName(), clusterStateResponse.getState());
311: Tim Vernum, debug, LambdaExpr, logger.debug("have yellow status on remote index [{}] ", indexName);
316: Tim Vernum, error, LambdaExpr, logger.error("failed to get wait for yellow status on remote index [" + indexName + "]", e);
299: Jay Modi, error, LambdaExpr, logger.error("failed to put audit trail template", e);
325: jaymode, error, MethodDeclaration, logger.error("failed to get remote cluster state", e);
359: Jay Modi, info, IfStmt, logger.info("Missing _meta field in mapping [{}] of index [{}]", docMapping.type(), index);
373: Jay Modi, trace, IfStmt, logger.trace("audit index [{}] has the incorrect version [{}]", index, versionString);
370: Jay Modi, trace, IfStmt, logger.trace("audit index [{}] mapping is missing meta field [{}]", index, SECURITY_VERSION_STRING);
352: Jay Modi, trace, IfStmt, logger.trace("audit index [{}] is missing mapping for type [{}]", index, DOC_TYPE);
386: Jay Modi, trace, LambdaExpr, logger.trace("updated mappings on audit index [{}]", index);
389: Jay Modi, error, LambdaExpr, logger.error(new ParameterizedMessage("failed to update mappings on audit index [{}]", index), e);
398: Jay Modi, error, IfStmt, logger.error(message);
410: Tim Vernum, trace, IfStmt, logger.trace("successful state transition from starting to started, current value: [{}]", state.get());
408: Jay Modi, error, IfStmt, logger.error(message);
423: Jay Modi, warn, IfStmt, logger.warn("index audit trail failed to store all pending events after waiting for 10s");
443: Colin Goodheart-Smithe, warn, CatchClause, logger.warn("failed to index audit event: [authentication_success]", e);
455: Colin Goodheart-Smithe, warn, CatchClause, logger.warn("failed to index audit event: [authentication_success]", e);
467: aleph-zero, warn, CatchClause, logger.warn("failed to index audit event: [anonymous_access_denied]", e);
478: aleph-zero, warn, CatchClause, logger.warn("failed to index audit event: [anonymous_access_denied]", e);
490: jaymode, warn, CatchClause, logger.warn("failed to index audit event: [authentication_failed]", e);
501: jaymode, warn, CatchClause, logger.warn("failed to index audit event: [authentication_failed]", e);
513: aleph-zero, warn, CatchClause, logger.warn("failed to index audit event: [authentication_failed]", e);
526: aleph-zero, warn, CatchClause, logger.warn("failed to index audit event: [authentication_failed]", e);
540: aleph-zero, warn, CatchClause, logger.warn("failed to index audit event: [authentication_failed]", e);
553: aleph-zero, warn, CatchClause, logger.warn("failed to index audit event: [authentication_failed]", e);
573: jaymode, warn, CatchClause, logger.warn("failed to index audit event: [access_granted]", e);
588: jaymode, warn, CatchClause, logger.warn("failed to index audit event: [access_denied]", e);
599: jaymode, warn, CatchClause, logger.warn("failed to index audit event: [tampered_request]", e);
610: jaymode, warn, CatchClause, logger.warn("failed to index audit event: [tampered_request]", e);
621: jaymode, warn, CatchClause, logger.warn("failed to index audit event: [tampered_request]", e);
632: aleph-zero, warn, CatchClause, logger.warn("failed to index audit event: [connection_granted]", e);
643: aleph-zero, warn, CatchClause, logger.warn("failed to index audit event: [connection_denied]", e);
658: jaymode, warn, CatchClause, logger.warn("failed to index audit event: [run_as_granted]", e);
673: jaymode, warn, CatchClause, logger.warn("failed to index audit event: [run_as_denied]", e);
688: jaymode, warn, CatchClause, logger.warn("failed to index audit event: [run_as_denied]", e);
889: jaymode, warn, IfStmt, logger.warn("failed to index audit event: [{}]. internal queue is full, which may be caused by a high indexing rate or " + "issue with the destination", type);
931: Ryan Ernst, warn, IfStmt, logger.warn("invalid host:port specified: [{}] for setting [{}.hosts]", REMOTE_CLIENT_SETTINGS.getKey(), host);
956: Ryan Ernst, info, MethodDeclaration, logger.info("forwarding audit events to remote cluster [{}] using hosts [{}]", clientSettings.get("cluster.name", ""), hostPortPairs.toString());
974: jaymode, warn, IfStmt, logger.warn("overriding the default [{}} setting is forbidden. ignoring...", name);
997: jaymode, debug, CatchClause, logger.debug("unexpected exception while putting index template", e);
1047: jaymode, info, IfStmt, logger.info("failed to bulk index audit events: [{}]", response.buildFailureMessage());
1053: Jay Modi, error, MethodDeclaration, logger.error(new ParameterizedMessage("failed to bulk index audit events: [{}]", failure.getMessage()), failure);
1117: jaymode, debug, CatchClause, logger.debug("index audit queue consumer interrupted", e);
1122: jaymode, warn, CatchClause, logger.warn("failed to index audit message from queue", e);
187: Albert Zaharovits, info, IfStmt, logger.info("{}[rest] [authentication_success]\t{}, realm=[{}], uri=[{}], params=[{}]", localNodeInfo.prefix, principal(user), realm, request.uri(), request.params());
184: Albert Zaharovits, info, IfStmt, logger.info("{}[rest] [authentication_success]\t{}, realm=[{}], uri=[{}], params=[{}], request_body=[{}]", localNodeInfo.prefix, principal(user), realm, request.uri(), request.params(), restRequestContent(request));
205: Albert Zaharovits, info, IfStmt, logger.info("{}[transport] [authentication_success]\t{}, {}, realm=[{}], action=[{}], request=[{}]", localNodeInfo.prefix, originAttributes(threadContext, message, localNodeInfo), principal(user), realm, action, message.getClass().getSimpleName());
201: Albert Zaharovits, info, IfStmt, logger.info("{}[transport] [authentication_success]\t{}, {}, realm=[{}], action=[{}], indices=[{}], request=[{}]", localNodeInfo.prefix, originAttributes(threadContext, message, localNodeInfo), principal(user), realm, action, arrayToCommaDelimitedString(indices.get()), message.getClass().getSimpleName());
225: Albert Zaharovits, info, IfStmt, logger.info("{}[transport] [anonymous_access_denied]\t{}, action=[{}], request=[{}]", localNodeInfo.prefix, originAttributes(threadContext, message, localNodeInfo), action, message.getClass().getSimpleName());
221: Albert Zaharovits, info, IfStmt, logger.info("{}[transport] [anonymous_access_denied]\t{}, action=[{}], indices=[{}], request=[{}]", localNodeInfo.prefix, originAttributes(threadContext, message, localNodeInfo), action, arrayToCommaDelimitedString(indices.get()), message.getClass().getSimpleName());
240: Albert Zaharovits, info, IfStmt, logger.info("{}[rest] [anonymous_access_denied]\t{}, uri=[{}]", localNodeInfo.prefix, hostAttributes(request), request.uri());
237: Albert Zaharovits, info, IfStmt, logger.info("{}[rest] [anonymous_access_denied]\t{}, uri=[{}], request_body=[{}]", localNodeInfo.prefix, hostAttributes(request), request.uri(), restRequestContent(request));
258: Albert Zaharovits, info, IfStmt, logger.info("{}[transport] [authentication_failed]\t{}, principal=[{}], action=[{}], request=[{}]", localNodeInfo.prefix, originAttributes(threadContext, message, localNodeInfo), token.principal(), action, message.getClass().getSimpleName());
254: Albert Zaharovits, info, IfStmt, logger.info("{}[transport] [authentication_failed]\t{}, principal=[{}], action=[{}], indices=[{}], request=[{}]", localNodeInfo.prefix, originAttributes(threadContext, message, localNodeInfo), token.principal(), action, arrayToCommaDelimitedString(indices.get()), message.getClass().getSimpleName());
274: Albert Zaharovits, info, IfStmt, logger.info("{}[rest] [authentication_failed]\t{}, uri=[{}]", localNodeInfo.prefix, hostAttributes(request), request.uri());
271: Albert Zaharovits, info, IfStmt, logger.info("{}[rest] [authentication_failed]\t{}, uri=[{}], request_body=[{}]", localNodeInfo.prefix, hostAttributes(request), request.uri(), restRequestContent(request));
291: Albert Zaharovits, info, IfStmt, logger.info("{}[transport] [authentication_failed]\t{}, action=[{}], request=[{}]", localNodeInfo.prefix, originAttributes(threadContext, message, localNodeInfo), action, message.getClass().getSimpleName());
287: Albert Zaharovits, info, IfStmt, logger.info("{}[transport] [authentication_failed]\t{}, action=[{}], indices=[{}], request=[{}]", localNodeInfo.prefix, originAttributes(threadContext, message, localNodeInfo), action, arrayToCommaDelimitedString(indices.get()), message.getClass().getSimpleName());
307: Albert Zaharovits, info, IfStmt, logger.info("{}[rest] [authentication_failed]\t{}, principal=[{}], uri=[{}]", localNodeInfo.prefix, hostAttributes(request), token.principal(), request.uri());
304: Albert Zaharovits, info, IfStmt, logger.info("{}[rest] [authentication_failed]\t{}, principal=[{}], uri=[{}], request_body=[{}]", localNodeInfo.prefix, hostAttributes(request), token.principal(), request.uri(), restRequestContent(request));
327: Albert Zaharovits, info, IfStmt, logger.info("{}[transport] [realm_authentication_failed]\trealm=[{}], {}, principal=[{}], action=[{}], request=[{}]", localNodeInfo.prefix, realm, originAttributes(threadContext, message, localNodeInfo), token.principal(), action, message.getClass().getSimpleName());
321: Albert Zaharovits, info, IfStmt, logger.info("{}[transport] [realm_authentication_failed]\trealm=[{}], {}, principal=[{}], action=[{}], indices=[{}], " + "request=[{}]", localNodeInfo.prefix, realm, originAttributes(threadContext, message, localNodeInfo), token.principal(), action, arrayToCommaDelimitedString(indices.get()), message.getClass().getSimpleName());
345: Albert Zaharovits, info, IfStmt, logger.info("{}[rest] [realm_authentication_failed]\trealm=[{}], {}, principal=[{}], uri=[{}]", localNodeInfo.prefix, realm, hostAttributes(request), token.principal(), request.uri());
341: jaymode, info, IfStmt, logger.info("{}[rest] [realm_authentication_failed]\trealm=[{}], {}, principal=[{}], uri=[{}], request_body=[{}]", localNodeInfo.prefix, realm, hostAttributes(request), token.principal(), request.uri(), restRequestContent(request));
366: Albert Zaharovits, info, IfStmt, logger.info("{}[transport] [access_granted]\t{}, {}, roles=[{}], action=[{}], request=[{}]", localNodeInfo.prefix, originAttributes(threadContext, message, localNodeInfo), subject(authentication), arrayToCommaDelimitedString(roleNames), action, message.getClass().getSimpleName());
361: Albert Zaharovits, info, IfStmt, logger.info("{}[transport] [access_granted]\t{}, {}, roles=[{}], action=[{}], indices=[{}], request=[{}]", localNodeInfo.prefix, originAttributes(threadContext, message, localNodeInfo), subject(authentication), arrayToCommaDelimitedString(roleNames), action, arrayToCommaDelimitedString(indices.get()), message.getClass().getSimpleName());
387: Albert Zaharovits, info, IfStmt, logger.info("{}[transport] [access_denied]\t{}, {}, roles=[{}], action=[{}], request=[{}]", localNodeInfo.prefix, originAttributes(threadContext, message, localNodeInfo), subject(authentication), arrayToCommaDelimitedString(roleNames), action, message.getClass().getSimpleName());
382: Albert Zaharovits, info, IfStmt, logger.info("{}[transport] [access_denied]\t{}, {}, roles=[{}], action=[{}], indices=[{}], request=[{}]", localNodeInfo.prefix, originAttributes(threadContext, message, localNodeInfo), subject(authentication), arrayToCommaDelimitedString(roleNames), action, arrayToCommaDelimitedString(indices.get()), message.getClass().getSimpleName());
402: Albert Zaharovits, info, IfStmt, logger.info("{}[rest] [tampered_request]\t{}, uri=[{}]", localNodeInfo.prefix, hostAttributes(request), request.uri());
399: Albert Zaharovits, info, IfStmt, logger.info("{}[rest] [tampered_request]\t{}, uri=[{}], request_body=[{}]", localNodeInfo.prefix, hostAttributes(request), request.uri(), restRequestContent(request));
419: Albert Zaharovits, info, IfStmt, logger.info("{}[transport] [tampered_request]\t{}, action=[{}], request=[{}]", localNodeInfo.prefix, originAttributes(threadContext, message, localNodeInfo), action, message.getClass().getSimpleName());
415: Albert Zaharovits, info, IfStmt, logger.info("{}[transport] [tampered_request]\t{}, action=[{}], indices=[{}], request=[{}]", localNodeInfo.prefix, originAttributes(threadContext, message, localNodeInfo), action, arrayToCommaDelimitedString(indices.get()), message.getClass().getSimpleName());
438: Albert Zaharovits, info, IfStmt, logger.info("{}[transport] [tampered_request]\t{}, {}, action=[{}], request=[{}]", localNodeInfo.prefix, originAttributes(threadContext, request, localNodeInfo), principal(user), action, request.getClass().getSimpleName());
434: Albert Zaharovits, info, IfStmt, logger.info("{}[transport] [tampered_request]\t{}, {}, action=[{}], indices=[{}], request=[{}]", localNodeInfo.prefix, originAttributes(threadContext, request, localNodeInfo), principal(user), action, arrayToCommaDelimitedString(indices.get()), request.getClass().getSimpleName());
449: Albert Zaharovits, info, IfStmt, logger.info("{}[ip_filter] [connection_granted]\torigin_address=[{}], transport_profile=[{}], rule=[{}]", localNodeInfo.prefix, NetworkAddress.format(inetAddress), profile, rule);
457: Albert Zaharovits, info, IfStmt, logger.info("{}[ip_filter] [connection_denied]\torigin_address=[{}], transport_profile=[{}], rule=[{}]", localNodeInfo.prefix, NetworkAddress.format(inetAddress), profile, rule);
475: Albert Zaharovits, info, IfStmt, logger.info("{}[transport] [run_as_granted]\t{}, {}, roles=[{}], action=[{}], request=[{}]", localNodeInfo.prefix, originAttributes(threadContext, message, localNodeInfo), runAsSubject(authentication), arrayToCommaDelimitedString(roleNames), action, message.getClass().getSimpleName());
470: Albert Zaharovits, info, IfStmt, logger.info("{}[transport] [run_as_granted]\t{}, {}, roles=[{}], action=[{}], indices=[{}], request=[{}]", localNodeInfo.prefix, originAttributes(threadContext, message, localNodeInfo), runAsSubject(authentication), arrayToCommaDelimitedString(roleNames), action, arrayToCommaDelimitedString(indices.get()), message.getClass().getSimpleName());
497: Albert Zaharovits, info, IfStmt, logger.info("{}[transport] [run_as_denied]\t{}, {}, roles=[{}], action=[{}], request=[{}]", localNodeInfo.prefix, originAttributes(threadContext, message, localNodeInfo), runAsSubject(authentication), arrayToCommaDelimitedString(roleNames), action, message.getClass().getSimpleName());
492: Albert Zaharovits, info, IfStmt, logger.info("{}[transport] [run_as_denied]\t{}, {}, roles=[{}], action=[{}], indices=[{}], request=[{}]", localNodeInfo.prefix, originAttributes(threadContext, message, localNodeInfo), runAsSubject(authentication), arrayToCommaDelimitedString(roleNames), action, arrayToCommaDelimitedString(indices.get()), message.getClass().getSimpleName());
515: Albert Zaharovits, info, IfStmt, logger.info("{}[rest] [run_as_denied]\t{}, {}, roles=[{}], uri=[{}]", localNodeInfo.prefix, hostAttributes(request), runAsSubject(authentication), arrayToCommaDelimitedString(roleNames), request.uri());
511: Albert Zaharovits, info, IfStmt, logger.info("{}[rest] [run_as_denied]\t{}, {}, roles=[{}], uri=[{}], request_body=[{}]", localNodeInfo.prefix, hostAttributes(request), runAsSubject(authentication), arrayToCommaDelimitedString(roleNames), request.uri(), restRequestContent(request));
208: Jay Modi, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("caught exception while trying to read authentication from request [{}]", request), e);
240: Tim Vernum, warn, CatchClause, logger.warn("An exception occurred while attempting to find authentication credentials", e);
272: Tim Vernum, info, IfStmt, logger.info("Authentication of [{}] was terminated by realm [{}] - {}", authenticationToken.principal(), realm.name(), result.getMessage());
283: Tim Vernum, warn, LambdaExpr, logger.warn(new ParameterizedMessage("An error occurred while attempting to authenticate [{}] against realm [{}]", authenticationToken.principal(), realm.name()), ex);
366: Jay Modi, debug, IfStmt, logger.debug("user [{}] attempted to runAs with an empty username", user.principal());
354: Tim Vernum, warn, LambdaExpr, logger.warn("Authentication to realm {} failed - {}{}", realm.name(), message, cause);
418: Jay Modi, debug, IfStmt, logger.debug("user [{}] is disabled. failing authentication", finalUser);
81: jaymode, debug, IfStmt, logger.debug("delete by query of tokens finished with [{}] deletions, [{}] bulk failures, [{}] search failures", response.getDeleted(), response.getBulkFailures().size(), response.getSearchFailures().size());
84: jaymode, debug, ForeachStmt, logger.debug(new ParameterizedMessage("deletion failed for index [{}], type [{}], id [{}]", failure.getIndex(), failure.getType(), failure.getId()), failure.getCause());
88: jaymode, debug, ForeachStmt, logger.debug(new ParameterizedMessage("search failed for index [{}], shard [{}] on node [{}]", failure.getIndex(), failure.getShardId(), failure.getNodeId()), failure.getReason());
103: Jay Modi, error, IfStmt, logger.error("failed to delete expired tokens", e);
101: Jay Modi, debug, IfStmt, logger.debug("failed to delete expired tokens", e);
164: uboness, debug, IfStmt, logger.debug("realm [{}/{}] is disabled", type, name);
285: Jay Modi, debug, CatchClause, logger.debug("invalid token", e);
277: Jay Modi, debug, IfStmt, logger.debug("invalid token", e);
409: Simon Willnauer, debug, IfStmt, logger.debug("invalid key {} key: {}", passphraseHash, keyCache.cache.keySet());
398: Simon Willnauer, warn, CatchClause, logger.warn("invalid token", e);
388: Tim Vernum, error, IfStmt, logger.error(new ParameterizedMessage("failed to get token [{}]", tokenId), e);
385: Tim Vernum, warn, IfStmt, logger.warn("failed to get token [{}] since index is not available", tokenId);
340: Jay Modi, debug, IfStmt, logger.debug("invalid token");
469: Jay Modi, error, CatchClause, logger.error("received a malformed token as part of a invalidation request", e);
618: Jay Modi, warn, IfStmt, logger.warn("could not find token document [{}] but there should " + "be one as token has version [{}]", tokenDocId, version);
675: Tim Vernum, info, IfStmt, logger.info("could not find token document with refresh_token [{}]", refreshToken);
684: Tim Vernum, debug, IfStmt, logger.debug("failed to search for token document, retrying", e);
748: Jay Modi, info, IfStmt, logger.info("could not find token document [{}] for refresh", tokenDocId);
969: Jay Modi, error, IfStmt, logger.error(new ParameterizedMessage("failed to get token [{}]", userToken.getId()), e);
966: Jay Modi, warn, IfStmt, logger.warn("failed to get token [{}] since index is not available", userToken.getId());
1223: Simon Willnauer, debug, IfStmt, logger.debug("prune key {} ", value.getKeyHash());
1220: Simon Willnauer, debug, IfStmt, logger.debug("keeping key {} ", value.getKeyHash());
1270: Simon Willnauer, debug, MethodDeclaration, logger.debug("refreshed keys current: {}, keys: {}", currentUsedKeyHash, keyCache.cache.keySet());
1295: Simon Willnauer, info, MethodDeclaration, logger.info("rotate keys on master");
1353: Simon Willnauer, info, IfStmt, logger.info("refresh keys");
1357: Yannick Welsch, warn, CatchClause, logger.warn("refreshing metadata failed", e);
1359: Simon Willnauer, info, IfStmt, logger.info("refreshed keys");
109: Simon Willnauer, trace, IfStmt, logger.trace("could not retrieve users because security index does not exist");
178: Jay Modi, error, IfStmt, logger.error(new ParameterizedMessage("failed to retrieve user [{}]", user), t);
174: Jay Modi, trace, IfStmt, logger.trace((org.apache.logging.log4j.util.Supplier<?>) () -> new ParameterizedMessage("could not retrieve user [{}] because security index does not exist", user), t);
221: Simon Willnauer, debug, IfStmt, logger.debug((org.apache.logging.log4j.util.Supplier<?>) () -> new ParameterizedMessage("failed to change password for user [{}]", request.username()), e);
506: Jay Modi, trace, IfStmt, logger.trace((org.apache.logging.log4j.util.Supplier<?>) () -> new ParameterizedMessage("could not retrieve built in user [{}] info since security index unavailable", username), e);
555: jaymode, error, IfStmt, logger.error("failed to retrieve built in users", e);
552: jaymode, trace, IfStmt, logger.trace("could not retrieve built in users since security index does not exist", e);
575: Jay Modi, error, MethodDeclaration, logger.error(new ParameterizedMessage("unable to clear realm cache for user [{}]", username), e);
603: Jay Modi, error, CatchClause, logger.error(new ParameterizedMessage("error in the format of data for user [{}]", username), e);
183: Simon Willnauer, error, LambdaExpr, logger.error("failed to retrieve reserved users", e);
204: Jay Modi, error, LambdaExpr, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to retrieve password hash for reserved user [{}]", username), e);
192: Tim Vernum, debug, IfStmt, logger.debug("Marking user [{}] as disabled because the security mapping is not at the required version", username);
110: Jason Tedor, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to parse users file [{}]. skipping/removing all users...", path.toAbsolutePath()), e);
126: uboness, trace, MethodDeclaration, logger.trace("reading users file [{}]...", path.toAbsolutePath());
154: uboness, error, IfStmt, logger.error("invalid entry in users file [{}], line [{}]. skipping...", path.toAbsolutePath(), lineNr);
160: Alexander Reelsen, error, IfStmt, logger.error("invalid username [{}] in users file [{}], skipping... ({})", username, path.toAbsolutePath(), validationError);
168: jaymode, debug, MethodDeclaration, logger.debug("parsed [{}] users from file [{}]", users.size(), path.toAbsolutePath());
197: jaymode, info, IfStmt, logger.info("users file [{}] changed. updating users... )", file.toAbsolutePath());
98: Jason Tedor, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to parse users_roles file [{}]. skipping/removing all entries...", path.toAbsolutePath()), e);
116: uboness, trace, MethodDeclaration, logger.trace("reading users_roles file [{}]...", path.toAbsolutePath());
139: uboness, error, IfStmt, logger.error("invalid entry in users_roles file [{}], line [{}]. skipping...", path.toAbsolutePath(), lineNr);
145: Alexander Reelsen, error, IfStmt, logger.error("invalid role entry in users_roles file [{}], line [{}] - {}. skipping...", path.toAbsolutePath(), lineNr, validationError);
151: Alexander Reelsen, error, IfStmt, logger.error("invalid entry for role [{}] in users_roles file [{}], line [{}]. no users found. skipping...", role, path.toAbsolutePath(), lineNr);
157: Alexander Reelsen, error, IfStmt, logger.error("invalid entry for role [{}] in users_roles file [{}], line [{}]. no users found. skipping...", role, path.toAbsolutePath(), lineNr);
177: jaymode, debug, MethodDeclaration, logger.debug("parsed [{}] user to role mappings from file [{}]", usersRoles.size(), path.toAbsolutePath());
221: jaymode, info, IfStmt, logger.info("users roles file [{}] changed. updating users roles...", file.toAbsolutePath());
56: Jay Modi, debug, IfStmt, logger.debug("group SID to DN [{}] search filter: [{}]", userDn, filter);
244: Tim Vernum, debug, IfStmt, logger.debug(new ParameterizedMessage("Exception occurred during {} for {}", action, LdapRealm.this), e);
273: Jay Modi, error, MethodDeclaration, logger.error("execution of ldap runnable failed", e);
283: Jay Modi, trace, IfStmt, logger.trace("skipping execution of ldap runnable as the current state is [{}]", state.get());
298: Jay Modi, warn, IfStmt, logger.warn("skipping execution of ldap runnable as it has been waiting for " + "execution too long");
55: Tim Vernum, info, ConstructorDeclaration, logger.info("Realm [{}] is in user-dn-template mode: [{}]", config.name(), userDnTemplates);
65: Jay Modi, info, ConstructorDeclaration, logger.info("Realm [{}] is in user-search mode - base_dn=[{}], search filter=[{}]", config.name(), userSearchBaseDn, searchFilter);
166: Jay Modi, warn, IfStmt, logger.warn(new ParameterizedMessage("[{}] and [{}} have not been specified or are not valid distinguished names," + "so connection health checking is disabled", RealmSettings.getFullSettingKey(config, PoolingSessionFactorySettings.BIND_DN), RealmSettings.getFullSettingKey(config, PoolingSessionFactorySettings.HEALTH_CHECK_DN)));
100: Tim Vernum, debug, MethodDeclaration, logger.debug("Resolving LDAP groups + meta-data for user [{}]", userDn);
103: Tim Vernum, debug, LambdaExpr, logger.debug("Resolved {} LDAP groups [{}] for user [{}]", groups.size(), groups, userDn);
106: Tim Vernum, debug, LambdaExpr, logger.debug("Resolved {} meta-data fields [{}] for user [{}]", meta.size(), meta, userDn);
525: Tim Vernum, trace, IfStmt, LOGGER.trace("LDAP referred elsewhere {} => {}", request, Arrays.toString(referralUrls));
569: Tim Vernum, warn, CatchClause, LOGGER.warn((Supplier<?>) () -> new ParameterizedMessage("caught exception while trying to follow referral [{}]", referralUrl), e);
646: Tim Vernum, debug, IfStmt, LOGGER.debug(new ParameterizedMessage("Failed to retrieve results from referral URL [{}]." + " Treating as 'no results'", referralURL), e);
70: Tim Vernum, warn, IfStmt, logger.warn("ldap_search timeout [{}] is less than the minimum supported search " + "timeout of 1s. using 1s", searchTimeout.millis());
187: jaymode, debug, IfStmt, logger.debug("using encryption for LDAP connections without hostname verification");
185: jaymode, debug, IfStmt, logger.debug("using encryption for LDAP connections with hostname verification");
153: jaymode, debug, IfStmt, logger.debug("certificate authentication succeeded for [{}] but could not extract principal from DN", dn);
161: jaymode, debug, IfStmt, logger.debug("certificate authentication succeeded for [{}] but extracted principal was empty", dn);
178: jaymode, debug, IfStmt, logger.debug("failed certificate validation for principal [{}]", token.principal());
175: jaymode, trace, IfStmt, logger.trace((Supplier<?>) () -> new ParameterizedMessage("failed certificate validation for principal [{}]", token.principal()), e);
73: Tim Vernum, trace, CatchClause, logger.trace("Rejecting SAML response {} because {}", SamlUtils.toString(root), e.getMessage());
88: Tim Vernum, trace, IfStmt, logger.trace(SamlUtils.describeSamlObject(response));
91: Tim Vernum, debug, IfStmt, logger.debug("The SAML Response with ID {} is unsolicited. A user might have used a stale URL or the Identity Provider " + "incorrectly populates the InResponseTo attribute", response.getID());
121: Tim Vernum, trace, IfStmt, logger.trace(sb.toString());
124: Tim Vernum, debug, IfStmt, logger.debug("The Attribute Statements of SAML Response with ID {} contained no attributes and the SAML Assertion Subject did" + "not contain a SAML NameID. Please verify that the Identity Provider configuration with regards to attribute " + "release is correct. ", response.getID());
200: Tim Vernum, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("Failed to decrypt SAML assertion [{}] with [{}]", text(encrypted, 512), describe(getSpConfiguration().getEncryptionCredentials())), e);
208: Tim Vernum, trace, IfStmt, logger.trace("(Possibly decrypted) Assertion: {}", SamlUtils.samlObjectToString(assertion));
209: Tim Vernum, trace, IfStmt, logger.trace(SamlUtils.describeSamlObject(assertion));
224: Tim Vernum, trace, ForeachStmt, logger.trace("SAML AttributeStatement has [{}] attributes and [{}] encrypted attributes", statement.getAttributes().size(), statement.getEncryptedAttributes().size());
230: Tim Vernum, trace, IfStmt, logger.trace("Successfully decrypted attribute: {}" + SamlUtils.samlObjectToString(attribute));
240: Tim Vernum, info, IfStmt, logger.info("SAML message has encrypted attribute [" + text(encrypted, 32) + "], but no encryption key has been configured");
246: Tim Vernum, info, CatchClause, logger.info("Failed to decrypt SAML attribute " + text(encrypted, 32), e);
254: Tim Vernum, trace, IfStmt, logger.trace("SAML Assertion was intended for the following Service providers: {}", conditions.getAudienceRestrictions().stream().map(r -> text(r, 32)).collect(Collectors.joining(" | ")));
257: Tim Vernum, trace, IfStmt, logger.trace("SAML Assertion is only valid between: " + conditions.getNotBefore() + " and " + conditions.getNotOnOrAfter());
277: Tim Vernum, trace, IfStmt, logger.trace("SAML Assertion Subject Confirmation intended recipient is: " + confirmationData.get(0).getRecipient());
278: Tim Vernum, trace, IfStmt, logger.trace("SAML Assertion Subject Confirmation is only valid before: " + confirmationData.get(0).getNotOnOrAfter());
279: Tim Vernum, trace, IfStmt, logger.trace("SAML Assertion Subject Confirmation is in response to: " + confirmationData.get(0).getInResponseTo());
69: Tim Vernum, trace, CatchClause, logger.trace("Rejecting SAML logout request {} because {}", SamlUtils.toString(root), e.getMessage());
125: Tim Vernum, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("SAML Signature [{}] failed against credentials [{}] [{}]", signatureText, credential.getEntityId(), credential.getPublicKey()));
121: Tim Vernum, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("SAML Signature [{}] matches credentials [{}] [{}]", signatureText, credential.getEntityId(), credential.getPublicKey()));
136: Tim Vernum, info, CatchClause, logger.info("Failed to decode base64 string [{}] - {}", content, e.toString());
174: Tim Vernum, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("Failed to decrypt SAML EncryptedID [{}] with [{}]", text(encrypted, 512), describe(getSpConfiguration().getEncryptionCredentials())), e);
36: Tim Vernum, debug, IfStmt, logger.debug("Cannot perform logout because the IDP {} does not provide a logout service", identityProvider.getEntityID());
387: Tim Vernum, debug, TryStmt, logger.debug("Parsed token [{}] to attributes [{}]", token, attributes);
465: Tim Vernum, info, SwitchStmt, logger.info("SAML assertion contains multiple values for attribute [{}] returning first one", name);
551: Tim Vernum, info, IfStmt, logger.info("Ignoring setting [{}] because the IdP metadata is being loaded from a file", RealmSettings.getFullSettingKey(config, IDP_METADATA_HTTP_REFRESH));
620: Tim Vernum, trace, IfStmt, logger.trace("Constructed SAML Authentication Request: {}", SamlUtils.samlObjectToString(authnRequest));
636: Tim Vernum, trace, IfStmt, logger.trace("Constructed SAML Logout Request: {}", SamlUtils.samlObjectToString(logoutRequest));
652: Tim Vernum, trace, IfStmt, logger.trace("Constructed SAML Logout Response: {}", SamlUtils.samlObjectToString(logoutResponse));
690: Tim Vernum, warn, CatchClause, logger.warn(new ParameterizedMessage("An error occurred while reloading file {}", file), e);
725: Tim Vernum, debug, IfStmt, logger.debug("Attribute [{}] is [{}], which does not match [{}]", attributeName, s, regex.pattern());
730: Tim Vernum, debug, IfStmt, logger.debug("Attribute [{}] is [{}], which does match [{}] but group(1) is empty", attributeName, s, regex.pattern());
154: Tim Vernum, warn, CatchClause, logger.warn("SecurityException while attempting to validate SAML signature", e);
150: Tim Vernum, debug, TryStmt, logger.debug(() -> new ParameterizedMessage("SAML Signature [{}] matches credentials [{}] [{}]", signatureText, credential.getEntityId(), credential.getPublicKey()));
169: Tim Vernum, debug, CatchClause, logger.debug(() -> new ParameterizedMessage("SAML Signature [{}] does not match credentials [{}] [{}] -- {}", signatureText, credential.getEntityId(), credential.getPublicKey(), e));
171: Tim Vernum, trace, CatchClause, logger.trace("SAML Signature failure caused by", e);
174: Tim Vernum, warn, CatchClause, logger.warn("Exception while attempting to validate SAML Signature", e);
188: Tim Vernum, warn, MethodDeclaration, logger.warn("The XML Signature of this SAML message cannot be validated. Please verify that the saml realm uses the correct SAML" + "metadata file/URL for this Identity Provider");
195: Tim Vernum, warn, MethodDeclaration, logger.warn("The XML Signature of this SAML message cannot be validated. Please verify that the saml realm uses the correct SAML" + "metadata file/URL for this Identity Provider");
290: Tim Vernum, trace, IfStmt, logger.trace("Received SAML Message: {} \n", SamlUtils.toString(root, true));
88: Tim Vernum, debug, LambdaExpr, logger.debug("Initializing OpenSAML");
92: Tim Vernum, debug, LambdaExpr, logger.debug("Initialized OpenSAML");
169: Tim Vernum, Error, CatchClause, LOGGER.info("Error marshalling SAMLObject ", e);
319: Tim Vernum, Error, CatchClause, LOGGER.warn("Error resolving schema file path", e);
329: Tim Vernum, debug, MethodDeclaration, LOGGER.debug("XML transformation error", e);
335: Tim Vernum, debug, MethodDeclaration, LOGGER.debug("XML transformation error", e);
341: Tim Vernum, debug, MethodDeclaration, LOGGER.debug("XML transformation error", e);
356: Tim Vernum, debug, MethodDeclaration, LOGGER.debug("XML Parser error ", e);
362: Tim Vernum, debug, MethodDeclaration, LOGGER.debug("XML Parser error ", e);
368: Tim Vernum, debug, MethodDeclaration, LOGGER.debug("XML Parser error ", e);
46: Lee Hinman, trace, IfStmt, logger.trace("invalidating cache for user [{}] in realm [{}]", username, name());
53: Lee Hinman, trace, IfStmt, logger.trace("invalidating cache for all users in realm [{}]", name());
129: Tim Vernum, debug, IfStmt, logger.debug("cached user came from a lookup and could not be used for authentication. " + "realm [{}] authenticated user [{}] with roles [{}]", name(), token.principal(), user.roles());
118: Tim Vernum, debug, IfStmt, logger.debug("cached user's password changed. realm [{}] authenticated user [{}], with roles [{}]", name(), token.principal(), user.roles());
107: Tim Vernum, debug, IfStmt, logger.debug("realm [{}] authenticated user [{}] (enabled:{}), with roles [{}]", name(), token.principal(), user.enabled(), user.roles());
98: Tim Vernum, debug, IfStmt, logger.debug("realm [{}] authenticated user [{}], with roles [{}]", name(), token.principal(), user.roles());
84: Tim Vernum, debug, IfStmt, logger.debug("user [{}] not found in cache for realm [{}], proceeding with normal authentication", token.principal(), name());
90: Tim Vernum, debug, IfStmt, logger.debug("realm [{}] authenticated user [{}], with roles [{}]", name(), token.principal(), user.roles());
94: Jason Tedor, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to parse role mappings file [{}]. skipping/removing all mappings...", path.toAbsolutePath()), e);
103: uboness, trace, MethodDeclaration, logger.trace("reading realm [{}/{}] role mappings file [{}]...", realmType, realmName, path.toAbsolutePath());
112: Tim Vernum, warn, IfStmt, logger.warn(message.getFormattedMessage() + " Role mapping will be skipped.");
143: Tim Vernum, error, IfStmt, logger.error(message.getFormattedMessage() + " skipping...", e);
150: jaymode, debug, TryStmt, logger.debug("[{}] role mappings found in file [{}] for realm [{}/{}]", dnToRoles.size(), path.toAbsolutePath(), realmType, realmName);
186: Tim Vernum, debug, IfStmt, logger.debug("the roles [{}], are mapped from these [{}] groups [{}] using file [{}] for realm [{}/{}]", roles, config.type(), groupDns, file.getFileName(), config.type(), config.name());
196: Tim Vernum, debug, IfStmt, logger.debug("the roles [{}], are mapped from the user [{}] using file [{}] for realm [{}/{}]", (rolesMappedToUserDn == null) ? Collections.emptySet() : rolesMappedToUserDn, userDnString, file.getFileName(), config.type(), config.name());
221: Alexander Reelsen, info, IfStmt, logger.info("role mappings file [{}] changed for realm [{}/{}]. updating mappings...", file.toAbsolutePath(), config.type(), config.name());
180: Jay Modi, trace, IfStmt, LOGGER.trace(new ParameterizedMessage("failed to parse [{}] as a DN", string), e);
144: Jay Modi, error, LambdaExpr, logger.error(new ParameterizedMessage("failed to load role mappings from index [{}] skipping all mappings.", SECURITY_INDEX_NAME), ex);
158: Tim Vernum, warn, CatchClause, logger.warn(new ParameterizedMessage("Role mapping [{}] cannot be parsed and will be skipped", id), e);
187: Tim Vernum, error, CatchClause, logger.error(new ParameterizedMessage("failed to modify role-mapping [{}]", name), e);
217: Jay Modi, error, MethodDeclaration, logger.error(new ParameterizedMessage("failed to put role-mapping [{}]", mapping.getName()), e);
245: Tim Vernum, error, MethodDeclaration, logger.error(new ParameterizedMessage("failed to delete role-mapping [{}]", request.getName()), e);
282: Tim Vernum, info, IfStmt, logger.info("The security index is not yet available - no role mappings can be loaded");
284: Jay Modi, debug, IfStmt, logger.debug("Security Index [{}] [exists: {}] [available: {}] [mapping up to date: {}]", SECURITY_INDEX_NAME, securityLifecycleService.isSecurityIndexExisting(), securityLifecycleService.isSecurityIndexAvailable(), securityLifecycleService.isSecurityIndexMappingUpToDate());
337: Jay Modi, debug, LambdaExpr, logger.debug((org.apache.logging.log4j.util.Supplier<?>) () -> new ParameterizedMessage("Cleared cached in realms [{}] due to role mapping change", Arrays.toString(realmNames)));
342: Jay Modi, warn, LambdaExpr, logger.warn("Failed to clear cache for realms [{}]", Arrays.toString(realmNames));
358: Tim Vernum, trace, LambdaExpr, logger.trace("User [{}] matches role-mapping [{}] with roles [{}]", user.getUsername(), m.getName(), m.getRoles());
364: Tim Vernum, debug, LambdaExpr, logger.debug("Mapping user [{}] to roles [{}]", user, roles);
47: Martijn van Groningen, debug, MethodDeclaration, logger.debug("full cache clear, reason [{}]", reason);
56: Martijn van Groningen, debug, IfStmt, logger.debug("opting out of the query cache. current request doesn't hold indices permissions");
70: Boaz Leskes, trace, IfStmt, logger.trace("not opting out of the query cache. request for index [{}] has field level security disabled", indexName);
66: Robert Muir, trace, IfStmt, logger.trace("opting out of the query cache. request for index [{}] is unsafe to cache", indexName);
63: Robert Muir, trace, IfStmt, logger.trace("not opting out of the query cache. request for index [{}] is safe to cache", indexName);
154: Tim Vernum, debug, IfStmt, logger.debug("Requested role [{}] does not exist (cached)", s);
166: Tim Vernum, debug, LambdaExpr, logger.debug(() -> new ParameterizedMessage("Roles [{}] were resolved from the native index store", names(descriptors)));
170: Jay Modi, warn, LambdaExpr, logger.warn("role retrieval failed from the native roles store", e);
205: Tim Vernum, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("Requested roles [{}] do not exist", Strings.collectionToCommaDelimitedString(missing)));
185: Tim Vernum, debug, LambdaExpr, logger.debug(() -> new ParameterizedMessage("Roles [{}] were resolved by [{}]", names(resolvedDescriptors), rolesProvider));
220: Tim Vernum, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("Roles [{}] are builtin roles", names(descriptors)));
225: Tim Vernum, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("Roles [{}] were resolved from [{}]", names(fileRoles), fileRolesStore.getFile()));
140: jaymode, debug, MethodDeclaration, logger.debug("attempting to read roles file located at [{}]", path.toAbsolutePath());
170: jaymode, debug, IfStmt, logger.debug("roles file does not exist");
162: Jason Tedor, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to read roles file [{}]. skipping all roles...", path.toAbsolutePath()), ioe);
152: Jay Modi, warn, IfStmt, logger.warn("role [{}] uses document and/or field level security, which is not enabled by the current license" + ". this role will be ignored", descriptor.getName());
149: Alexander Reelsen, warn, IfStmt, logger.warn("role [{}] is reserved. the relevant role definition in the mapping file will be ignored", descriptor.getName());
174: Tim Vernum, info, MethodDeclaration, logger.info("parsed [{}] roles from file [{}]", roles.size(), path.toAbsolutePath());
184: jaymode, trace, MethodDeclaration, logger.trace("attempting to read roles file located at [{}]", path.toAbsolutePath());
195: Jason Tedor, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to read roles file [{}]. skipping all roles...", path.toAbsolutePath()), ioe);
248: jaymode, error, IfStmt, logger.error(e.getMessage() + ". skipping role...");
246: Jason Tedor, debug, IfStmt, logger.debug((Supplier<?>) () -> new ParameterizedMessage("parsing exception for role [{}]", finalRoleName), e);
260: Jason Tedor, error, IfStmt, logger.error((Supplier<?>) () -> new ParameterizedMessage("invalid role definition in roles file [{}]. skipping role...", path), e);
253: Jason Tedor, error, IfStmt, logger.error((Supplier<?>) () -> new ParameterizedMessage("invalid role definition [{}] in roles file [{}]. skipping role...", finalRoleName, path), e);
220: Alexander Reelsen, error, IfStmt, logger.error("invalid role definition [{}] in roles file [{}]. invalid role name - {}. skipping role... ", roleName, path.toAbsolutePath(), validationError);
236: jaymode, error, IfStmt, logger.error("invalid role definition [{}] in roles file [{}]. skipping role...", roleName, path.toAbsolutePath());
241: jaymode, error, TryStmt, logger.error("invalid role definition [{}] in roles file [{}]. skipping role...", roleName, path.toAbsolutePath());
277: Jay Modi, error, IfStmt, logger.error("invalid role definition [{}] in roles file [{}]. document and field level security is not " + "enabled. set [{}] to [true] in the configuration file. skipping role...", roleName, path.toAbsolutePath(), XPackSettings.DLS_FLS_ENABLED.getKey());
328: Jason Tedor, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("could not reload roles file [{}]. Current roles remain unmodified", file.toAbsolutePath()), e);
326: Tim Vernum, info, TryStmt, logger.info("updated roles (roles file [{}] {})", file.toAbsolutePath(), Files.exists(file) ? "changed" : "removed");
150: Simon Willnauer, error, MethodDeclaration, logger.error("failed to delete role from the index", e);
191: Jay Modi, error, MethodDeclaration, logger.error(new ParameterizedMessage("failed to put role [{}]", request.name()), e);
282: Jay Modi, error, IfStmt, logger.error(new ParameterizedMessage("failed to load role [{}]", roleId), e);
278: Jay Modi, warn, IfStmt, logger.warn((org.apache.logging.log4j.util.Supplier<?>) () -> new ParameterizedMessage("failed to load role [{}] index not available", roleId), e);
310: Jay Modi, error, MethodDeclaration, logger.error(new ParameterizedMessage("unable to clear cache for role [{}]", role), e);
361: Jay Modi, error, CatchClause, logger.error(new ParameterizedMessage("error in the format of data for role [{}]", name), e);
67: Ryan Ernst, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to send failure response for uri [{}]", request.uri()), inner);
146: Jay Modi, error, CatchClause, logger.error("failed to send failure response", inner);
74: Tim Vernum, trace, TryStmt, logger.trace("SAML Authenticate: [{}...] [{}]", Strings.cleanTruncate(input.content, 128), input.ids);
99: Tim Vernum, info, CatchClause, logger.info("Failed to decode base64 string [{}] - {}", content, e.toString());
35: Tim Vernum, info, IfStmt, logger.info("The '{}' realm is not available under the current license", SAML_REALM_TYPE);
174: Jay Modi, warn, CatchClause, logger.warn(new ParameterizedMessage("failed to notify listener [{}] of index health change", consumer), e);
184: Jay Modi, warn, CatchClause, logger.warn(new ParameterizedMessage("failed to notify listener [{}] of index out of date change", consumer), e);
194: Tim Vernum, debug, MethodDeclaration, logger.debug("Security index [{}] is not yet active", indexName);
283: Tim Vernum, error, CatchClause, logger.error(new ParameterizedMessage("Cannot parse the mapping for index [{}]", indexName), e);
278: Tim Vernum, info, IfStmt, logger.info("Missing _meta field in mapping [{}] of index [{}]", mappingMetaData.type(), indexName);
240: Simon Willnauer, warn, CatchClause, logger.warn("failed to send exception response for action [" + action + "]", e1);
191: Simon Willnauer, debug, IfStmt, logger.debug("SSL Peer did not present a certificate on channel [{}]", channel);
187: Simon Willnauer, trace, IfStmt, logger.trace((Supplier<?>) () -> new ParameterizedMessage("SSL Peer did not present a certificate on channel [{}]", channel), e);
245: Simon Willnauer, warn, IfStmt, logger.warn("skipping ip filter rules for profile [{}] since the profile is not bound to any addresses", profile);
254: Simon Willnauer, debug, IfStmt, logger.debug("loaded ip filtering profiles: {}", profileRules.keySet());
86: Jay Modi, warn, IfStmt, logger.warn("http client did not trust this server's certificate, closing connection {}", ctx.channel());
83: Jay Modi, trace, IfStmt, logger.trace(new ParameterizedMessage("http client did not trust server's certificate, closing connection {}", ctx.channel()), cause);
78: Jay Modi, warn, IfStmt, logger.warn("connection {} closed during ssl handshake", ctx.channel());
76: Jay Modi, trace, IfStmt, logger.trace(new ParameterizedMessage("connection {} closed during ssl handshake", ctx.channel()), cause);
71: Jason Tedor, warn, IfStmt, logger.warn("received plaintext http traffic on a https channel, closing connection {}", ctx.channel());
68: Jay Modi, trace, IfStmt, logger.trace(new ParameterizedMessage("received plaintext http traffic on a https channel, closing connection {}", ctx.channel()), cause);
57: jaymode, debug, ForeachStmt, logger.debug("--> created role [{}]", role);
84: jaymode, debug, MethodDeclaration, logger.debug("--> modifying roles {} to have run_as", toModify);
93: jaymode, debug, ForeachStmt, logger.debug("--> updated role [{}] with run_as", role);
114: jaymode, debug, ForeachStmt, logger.debug("--> getting role [{}]", role);
1021: Martijn van Groningen, info, MethodDeclaration, logger.info("queryProfileShardResult=" + Strings.toString(queryProfileShardResult));
148: Martijn van Groningen, info, ForeachStmt, logger.info("Checking allowed field [{}]", allowedField);
157: Martijn van Groningen, info, ForeachStmt, logger.info("Checking disallowed field [{}]", disallowedField);
88: Tim Brooks, info, MethodDeclaration, logger.info("setting up reserved passwords for test");
108: Tim Brooks, info, MethodDeclaration, logger.info("setting up reserved passwords finished");
37: javanna, info, TryStmt, logger.info("executing unauthorized request to /_xpack info");
44: javanna, info, MethodDeclaration, logger.info("executing authorized request to /_xpack infos");
166: jaymode, error, MethodDeclaration, logger.error("names {}", names);
180: Tim Vernum, warn, MethodDeclaration, logger.warn("Request failed", e);
154: jaymode, info, IfStmt, logger.info("--> remote indexing disabled.");
169: Jay Modi, info, MethodDeclaration, logger.info("--> remote indexing enabled. security enabled: [{}], SSL enabled: [{}], nodes: [{}]", useSecurity, useSSL, numNodes);
334: Simon Willnauer, info, MethodDeclaration, logger.info("--> settings: [{}]", settings);
920: jaymode, debug, CatchClause, logger.debug("caught exception while executing search", e);
946: jaymode, info, IfStmt, logger.info("ensureYellow timed out, cluster state:\n{}\n{}", getClient().admin().cluster().prepareState().get().getState(), getClient().admin().cluster().preparePendingClusterTasks().get());
952: jaymode, debug, MethodDeclaration, logger.debug("indices {} are yellow", indices.length == 0 ? "[_all]" : indices);
149: Tim Vernum, info, MethodDeclaration, logger.info("Test configuration: ssl=[{}] localAudit=[{}][{}]", sslEnabled, localAudit, outputs);
119: Albert Zaharovits, Info, MethodDeclaration, assertTrue(Pattern.matches("\\[127\\.0\\.0\\.1\\] \\[127\\.0\\.0\\.1\\] \\[node_.*\\] ", loggingAuditTrail.localNodeInfo.prefix));
122: Albert Zaharovits, Info, MethodDeclaration, assertTrue(Pattern.matches("\\[127\\.0\\.0\\.1\\] \\[node_.*\\] ", loggingAuditTrail.localNodeInfo.prefix));
126: Albert Zaharovits, Info, MethodDeclaration, assertTrue(Pattern.matches("\\[127\\.0\\.0\\.1\\] \\[node_.*\\] ", loggingAuditTrail.localNodeInfo.prefix));
130: Albert Zaharovits, Info, MethodDeclaration, assertTrue(Pattern.matches("\\[127\\.0\\.0\\.1\\] \\[127\\.0\\.0\\.1\\] ", loggingAuditTrail.localNodeInfo.prefix));
87: Albert Zaharovits, INFO, MethodDeclaration, logger = CapturingLogger.newCapturingLogger(Level.INFO);
146: Albert Zaharovits, Info, MethodDeclaration, prefix = LoggingAuditTrail.LocalNodeInfo.resolvePrefix(settings, localNode);
151: Albert Zaharovits, INFO, MethodDeclaration, final Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
177: Albert Zaharovits, INFO, MethodDeclaration, final Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
197: Albert Zaharovits, INFO, MethodDeclaration, final Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
220: Albert Zaharovits, INFO, MethodDeclaration, final Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
246: Albert Zaharovits, INFO, MethodDeclaration, final Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
271: Albert Zaharovits, INFO, MethodDeclaration, final Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
291: Albert Zaharovits, INFO, MethodDeclaration, final Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
318: Albert Zaharovits, INFO, MethodDeclaration, final Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
339: Albert Zaharovits, INFO, MethodDeclaration, final Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
371: Albert Zaharovits, INFO, MethodDeclaration, final Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
396: Albert Zaharovits, INFO, MethodDeclaration, final Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
428: Albert Zaharovits, INFO, MethodDeclaration, final Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
464: Albert Zaharovits, INFO, MethodDeclaration, final Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
486: Albert Zaharovits, INFO, MethodDeclaration, final Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
513: Albert Zaharovits, INFO, MethodDeclaration, final Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
534: Albert Zaharovits, INFO, MethodDeclaration, final Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
552: Albert Zaharovits, INFO, MethodDeclaration, final Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
569: Albert Zaharovits, INFO, MethodDeclaration, final Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
597: Albert Zaharovits, INFO, MethodDeclaration, final Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
664: Albert Zaharovits, INFO, MethodDeclaration, final Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
688: Albert Zaharovits, INFO, MethodDeclaration, final Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
722: Albert Zaharovits, INFO, MethodDeclaration, final Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
905: Jay Modi, error, IfStmt, logger.error("unexpected exception", e);
1031: Jay Modi, error, MethodDeclaration, logger.error("unexpected exception", e);
397: jaymode, error, IfStmt, logger.error("put [{}] -> [{}]", orders.get(i), i);
116: Simon Willnauer, info, MethodDeclaration, logger.info("rotate on master: {}", masterName);
44: Lee Hinman, info, MethodDeclaration, logger.info("--> use SSL? {}", useSSL);
72: Lee Hinman, error, MethodDeclaration, logger.error("--> creating users");
80: Lee Hinman, error, MethodDeclaration, logger.error("--> waiting for .security index");
95: Lee Hinman, error, MethodDeclaration, logger.error("--> retrieving users using URL: {}, home: {}", url, home);
99: Lee Hinman, info, MethodDeclaration, logger.info("--> options: {}", options.asMap());
101: Ali Beyad, info, MethodDeclaration, logger.info("--> output: \n{}", t.getOutput());
112: Lee Hinman, error, MethodDeclaration, logger.error("--> creating roles");
125: Lee Hinman, error, MethodDeclaration, logger.error("--> waiting for .security index");
137: Lee Hinman, error, MethodDeclaration, logger.error("--> retrieving roles using URL: {}, home: {}", url, home);
142: Lee Hinman, info, MethodDeclaration, logger.info("--> output: \n{}", t.getOutput());
96: Jay Modi, ERROR, MethodDeclaration, terminalLogger.log(Level.ERROR, "logging an error");
101: Jay Modi, FATAL, MethodDeclaration, terminalLogger.log(Level.FATAL, "logging a fatal message");
101: Jay Modi, info, IfStmt, logger.info("anonymous is enabled, but configured with a missing role");
93: Jay Modi, info, IfStmt, logger.info("anonymous is enabled. creating [native_anonymous] role");
128: Lee Hinman, error, MethodDeclaration, logger.error("--> creating user");
130: jaymode, error, MethodDeclaration, logger.error("--> waiting for .security index");
132: Lee Hinman, info, MethodDeclaration, logger.info("--> retrieving user");
139: Lee Hinman, info, MethodDeclaration, logger.info("--> adding two more users");
164: Lee Hinman, info, MethodDeclaration, logger.info("--> deleting user");
167: Lee Hinman, info, MethodDeclaration, logger.info("--> retrieving user");
177: Lee Hinman, error, MethodDeclaration, logger.error("--> creating role");
185: jaymode, error, MethodDeclaration, logger.error("--> waiting for .security index");
187: Lee Hinman, info, MethodDeclaration, logger.info("--> retrieving role");
208: Lee Hinman, info, MethodDeclaration, logger.info("--> retrieving all roles");
213: jaymode, info, MethodDeclaration, logger.info("--> retrieving test_role and test_role3");
218: Lee Hinman, info, MethodDeclaration, logger.info("--> deleting role");
221: Lee Hinman, info, MethodDeclaration, logger.info("--> retrieving role");
228: Lee Hinman, error, MethodDeclaration, logger.error("--> creating role");
234: Lee Hinman, error, MethodDeclaration, logger.error("--> creating user");
236: jaymode, error, MethodDeclaration, logger.error("--> waiting for .security index");
238: Lee Hinman, info, MethodDeclaration, logger.info("--> retrieving user");
255: Lee Hinman, error, MethodDeclaration, logger.error("--> creating user");
257: jaymode, error, MethodDeclaration, logger.error("--> waiting for .security index");
259: Lee Hinman, info, MethodDeclaration, logger.info("--> retrieving user");
290: Lee Hinman, error, MethodDeclaration, logger.error("--> creating user");
292: jaymode, error, MethodDeclaration, logger.error("--> waiting for .security index");
294: Lee Hinman, info, MethodDeclaration, logger.info("--> retrieving user");
322: Lee Hinman, error, MethodDeclaration, logger.error("--> creating role");
328: Lee Hinman, error, MethodDeclaration, logger.error("--> creating user");
330: jaymode, error, MethodDeclaration, logger.error("--> waiting for .security index");
372: Lee Hinman, error, MethodDeclaration, logger.error("--> creating role");
379: jaymode, error, MethodDeclaration, logger.error("--> waiting for .security index");
608: Ali Beyad, info, MethodDeclaration, logger.info("--> running testRolesUsageStats with anonymousEnabled=[{}], roleExists=[{}]", anonymousEnabled, roleExists);
175: Jason Tedor, DEBUG, MethodDeclaration, Logger logger = CapturingLogger.newCapturingLogger(Level.DEBUG);
185: Jason Tedor, INFO, MethodDeclaration, Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
197: Jason Tedor, INFO, MethodDeclaration, Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
202: uboness, info, CatchClause, this.logger.info("expected", se);
218: Jason Tedor, INFO, MethodDeclaration, Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
179: Jason Tedor, DEBUG, MethodDeclaration, Logger log = CapturingLogger.newCapturingLogger(Level.DEBUG);
188: Jason Tedor, INFO, MethodDeclaration, Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
203: Jason Tedor, DEBUG, MethodDeclaration, Logger logger = CapturingLogger.newCapturingLogger(Level.DEBUG);
208: Jason Tedor, info, CatchClause, this.logger.info("expected", e);
260: Jason Tedor, DEBUG, MethodDeclaration, Logger logger = CapturingLogger.newCapturingLogger(Level.DEBUG);
77: jaymode, debug, MethodDeclaration, logger.debug("using [{}] ldap servers, urls {}", ldapServers.length, ldapUrls());
85: jaymode, debug, MethodDeclaration, logger.debug("list of all ports {}", ports);
88: jaymode, debug, MethodDeclaration, logger.debug("killing [{}] servers", numberToKill);
103: jaymode, debug, ForeachStmt, logger.debug("shutting down server index [{}] listening on [{}]", index, port);
121: jaymode, debug, CatchClause, logger.debug("caught exception", e);
116: jaymode, debug, TryStmt, logger.debug("opened socket [{}]", socket);
119: jaymode, debug, TryStmt, logger.debug("closing socket [{}]", socket);
135: jaymode, debug, ForStmt, logger.debug("iteration [{}]", iteration);
137: jaymode, debug, ForeachStmt, logger.debug("attempting connection with expected port [{}]", port);
154: jaymode, debug, MethodDeclaration, logger.debug("using [{}] ldap servers, urls {}", ldapServers.length, ldapUrls());
171: jaymode, debug, MethodDeclaration, logger.debug("shutting down server index [0] listening on [{}]", ldapServers[0].getListenPort());
189: jaymode, debug, ForeachStmt, logger.debug("shutting down server index [{}] listening on [{}]", index, port);
203: jaymode, debug, MethodDeclaration, logger.debug("first non stopped port [{}]", firstNonStoppedPort);
210: jaymode, debug, TryStmt, logger.debug("attempting connection with expected port [{}] iteration [{}]", firstNonStoppedPort, iteration);
49: Albert Zaharovits, warn, IfStmt, logger.warn("Attempting to run SAML test on turkish-like locale, but that breaks OpenSAML. Switching to English.");
381: Jay Modi, error, LambdaExpr, logger.error("caught exception", e);
435: Jay Modi, error, LambdaExpr, logger.error("caught exception", e);
202: Jason Tedor, INFO, MethodDeclaration, Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
232: Jason Tedor, DEBUG, MethodDeclaration, Logger logger = CapturingLogger.newCapturingLogger(Level.DEBUG);
243: Jason Tedor, INFO, MethodDeclaration, Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
260: Jason Tedor, INFO, MethodDeclaration, Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
265: uboness, info, CatchClause, this.logger.info("expected", e);
273: Jason Tedor, INFO, MethodDeclaration, Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
84: Tim Vernum, info, MethodDeclaration, logger.info("Role mappings are: [{}]", mappings);
100: Tim Vernum, info, MethodDeclaration, logger.info("UserData is [{}]", user);
969: Lee Hinman, info, MethodDeclaration, logger.info("--> action: {}", action);
240: Jason Tedor, ERROR, MethodDeclaration, Logger logger = CapturingLogger.newCapturingLogger(Level.ERROR);
266: Jay Modi, WARN, MethodDeclaration, Logger logger = CapturingLogger.newCapturingLogger(Level.WARN);
371: Jason Tedor, ERROR, MethodDeclaration, Logger logger = CapturingLogger.newCapturingLogger(Level.ERROR);
397: Jason Tedor, ERROR, MethodDeclaration, Logger logger = CapturingLogger.newCapturingLogger(Level.ERROR);
411: Jason Tedor, INFO, MethodDeclaration, Logger logger = CapturingLogger.newCapturingLogger(Level.INFO);
76: uboness, info, MethodDeclaration, logger.info("connecting to {}", address);
75: jaymode, info, MethodDeclaration, logger.info("node {} settings:\n{}", nodeOrdinal, settings);
93: jaymode, info, MethodDeclaration, logger.info("transport client settings:\n{}", settings);
126: jaymode, trace, CatchClause, logger.trace("expected exception", expected);
147: jaymode, info, TryStmt, logger.info("opened socket for reloading [{}]", socket);
151: jaymode, info, TryStmt, logger.info("ssl handshake completed on port [{}]", event.getSocket().getLocalPort());
150: Tim Vernum, warn, CatchClause, logger.warn(new ParameterizedMessage("unexpected handshake failure with certificate [{}] [{}]", trustedCert.certificate.getSubjectDN(), trustedCert.certificate.getSubjectAlternativeNames()), ex);
86: Lee Hinman, info, MethodDeclaration, logger.info(Strings.toString(builder));
343: Costin Leau, trace, IfStmt, log.trace("Attempting to resolve {}", plan.nodeString());
372: Costin Leau, trace, IfStmt, log.trace("Resolved {} to {}", u, named);
460: Nik Everett, trace, IfStmt, log.trace("Trying to resolve conflicts " + conflicting + " between left " + left.nodeString() + " and right " + right.nodeString());
111: Costin Leau, trace, IfStmt, log.trace("About to execute composite query {} on {}", StringUtils.toString(query), indices);
92: Costin Leau, trace, IfStmt, log.trace("About to execute query {} on {}", StringUtils.toString(sourceBuilder), index);
78: Costin Leau, trace, MethodDeclaration, log.trace("About to execute scroll query {}", scrollId);
60: Costin Leau, debug, IfStmt, log.debug("Parsing as statement: {}", sql);
77: Costin Leau, debug, IfStmt, log.debug("Parsing as expression: {}", expression);
167: Costin Leau, trace, IfStmt, log.trace("Rule {} applied w/o changes", rule);
162: Costin Leau, trace, IfStmt, log.trace("Rule {} applied\n{}", rule, NodeUtils.diffString(tf.before, tf.after));
183: Nik Everett, trace, IfStmt, log.trace("Batch {} applied took {}\n{}", batch.name, TimeValue.timeValueMillis(batchDuration), NodeUtils.diffString(before, after));
189: Nik Everett, debug, IfStmt, log.debug("Tree transformation took {}\n{}", TimeValue.timeValueMillis(totalDuration), NodeUtils.diffString(plan, currentPlan));
29: Costin Leau, info, MethodDeclaration, logger.info("Indexing {} records", indexSize);
39: Costin Leau, info, MethodDeclaration, logger.info("Fetching {} records at a time", fetchSize);
59: Costin Leau, info, MethodDeclaration, logger.info("Indexing {} records", indexSize);
69: Costin Leau, info, MethodDeclaration, logger.info("Fetching {} records at a time", fetchSize);
33: Igor Motov, info, MethodDeclaration, logger.info(expression);
63: Igor Motov, trace, ForeachStmt, logger.trace("[{}] check [{}] returned [{}]", index, check.getName(), upgradeActionRequired);
161: Igor Motov, info, MethodDeclaration, logger.info("before getInstance");
165: Igor Motov, info, MethodDeclaration, logger.info("after getInstance");
587: Alexander Reelsen, warn, MethodDeclaration, logger.warn("the [action.auto_create_index] setting is configured to be restrictive [{}]. " + " for the next 6 months daily history indices are allowed to be created, but please make sure" + " that any future history indices after 6 months with the pattern " + "[.watcher-history-YYYY.MM.dd] are allowed to be created", value);
108: Alexander Reelsen, debug, IfStmt, logger.debug("no distributed watch execution info found for watch [{}] on shard [{}], got configuration for {}", watch.id(), shardId, configuration.localShards.keySet());
119: Martijn van Groningen, debug, IfStmt, logger.debug("not updating trigger for watch [{}], watch has been updated as part of an execution", watch.id());
133: Martijn van Groningen, debug, IfStmt, logger.debug("watch [{}] should not be triggered", watch.id());
129: Martijn van Groningen, debug, IfStmt, logger.debug("removing watch [{}] to trigger", watch.id());
126: Martijn van Groningen, debug, IfStmt, logger.debug("adding watch [{}] to trigger", watch.id());
161: Martijn van Groningen, debug, IfStmt, logger.debug(() -> new ParameterizedMessage("removing watch [{}] from trigger", index.id()), ex);
220: Alexander Reelsen, error, CatchClause, logger.error("error loading watches index: [{}]", e.getMessage());
114: Alexander Reelsen, debug, IfStmt, logger.debug("not starting watcher. watcher can only start if its current state is [{}], but its current state now is [{}]", WatcherState.STOPPED, watcherState);
123: Martijn van Groningen, debug, IfStmt, logger.debug("not starting watcher. watcher was stopped manually and therefore cannot be auto-started");
130: Alexander Reelsen, debug, IfStmt, logger.debug("not starting watcher, watcher templates are missing in the cluster state");
144: Martijn van Groningen, debug, IfStmt, logger.debug("not starting watcher. because the cluster isn't ready yet to run watcher");
135: Alexander Reelsen, trace, IfStmt, logger.trace("starting... (based on cluster state version [{}])", state.getVersion());
141: Martijn van Groningen, warn, CatchClause, logger.warn("failed to start watcher. please wait for the cluster to become ready or try to start Watcher manually", e);
202: Alexander Reelsen, warn, IfStmt, logger.warn("not starting watcher, upgrade API run required: .watches[{}], .triggered_watches[{}]", isIndexInternalFormatWatchIndex, isIndexInternalFormatTriggeredWatchIndex);
229: Alexander Reelsen, error, MethodCallExpr, logger.error("error pausing watch execution", e);
228: Alexander Reelsen, error, IfStmt, executor.execute(wrapWatcherService(() -> watcherService.pauseExecution("no watcher index found"), e -> logger.error("error pausing watch execution", e)));
241: Alexander Reelsen, error, MethodCallExpr, logger.error("error pausing watch execution", e);
239: Alexander Reelsen, error, IfStmt, executor.execute(wrapWatcherService(() -> watcherService.pauseExecution("no routing node for local node found, network issue?"), e -> logger.error("error pausing watch execution", e)));
252: Alexander Reelsen, error, MethodCallExpr, logger.error("error pausing watch execution", e);
251: Alexander Reelsen, error, IfStmt, executor.execute(wrapWatcherService(() -> watcherService.pauseExecution("no local watcher shards found"), e -> logger.error("error pausing watch execution", e)));
267: Alexander Reelsen, error, MethodCallExpr, logger.error("error reloading watcher", e);
266: Alexander Reelsen, error, IfStmt, executor.execute(wrapWatcherService(() -> watcherService.reload(state, "new local watcher shard allocation ids"), e -> logger.error("error reloading watcher", e)));
110: Alexander Reelsen, trace, CatchClause, logger.trace((Supplier<?>) () -> new ParameterizedMessage("error getting index meta data [{}]: ", Watch.INDEX), e);
103: Alexander Reelsen, debug, IfStmt, logger.debug("watch index [{}] is marked as closed, watcher cannot be started", indexMetaData.getIndex().getName());
143: Jay Modi, debug, IfStmt, logger.debug("could not transition state from stopped to starting, current state [{}]", state.get());
127: Tanguy Leroux, debug, TryStmt, logger.debug("starting watch service...");
137: Tanguy Leroux, debug, TryStmt, logger.debug("watch service has started");
167: Alexander Reelsen, Error, CatchClause, logger.error("Error stopping watcher", e);
163: Jay Modi, debug, IfStmt, logger.debug("could not transition state from started to stopping, current state [{}]", state.get());
157: Alexander Reelsen, info, IfStmt, logger.info("stopping watch service, reason [{}]", reason);
161: Alexander Reelsen, debug, IfStmt, logger.debug("watch service has stopped");
153: Alexander Reelsen, trace, IfStmt, logger.trace("watcher is already in state [{}] not stopping", currentState);
197: Alexander Reelsen, info, MethodDeclaration, logger.info("paused watch execution, reason [{}], cancelled [{}] queued tasks", reason, cancelledTaskCount);
287: Alexander Reelsen, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("couldn't load watch [{}], ignoring it...", id), e);
304: Alexander Reelsen, debug, MethodDeclaration, logger.debug("Loaded [{}] watches for execution", watches.size());
29: uboness, INFO, ConstructorDeclaration, this.level = level != null ? level : LoggingLevel.INFO;
19: uboness, error, MethodDeclaration, logger.error(text);
26: uboness, warn, MethodDeclaration, logger.warn(text);
33: uboness, info, MethodDeclaration, logger.info(text);
40: uboness, debug, MethodDeclaration, logger.debug(text);
47: uboness, trace, MethodDeclaration, logger.trace(text);
225: Alexander Reelsen, info, IfStmt, logger.info("Using default proxy for http input and slack/hipchat/pagerduty/webhook actions [{}:{}]", proxyHost, proxyPort);
34: Jason Tedor, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to process triggered events [{}]", (Object) stream(events.spliterator(), false).toArray(size -> new TriggerEvent[size])), e);
120: Martijn van Groningen, debug, TryStmt, logger.debug("starting execution service");
124: Martijn van Groningen, debug, TryStmt, logger.debug("started execution service");
138: Brian Murphy, debug, IfStmt, logger.debug("stopping execution service");
146: Alexander Reelsen, debug, IfStmt, logger.debug("stopped execution service, cancelled [{}] queued tasks", cancelledTaskCount);
218: Alexander Reelsen, warn, IfStmt, logger.warn("failed to store watch records", e);
216: Alexander Reelsen, debug, IfStmt, logger.debug("failed to store watch records due to filled up watcher threadpool");
229: Alexander Reelsen, debug, MethodDeclaration, logger.debug("saving watch records [{}]", triggeredWatches.size());
248: Alexander Reelsen, warn, IfStmt, logger.warn("unable to find watch [{}] in watch index, perhaps it has been deleted", event.jobName());
270: Alexander Reelsen, error, IfStmt, logger.error("could not store triggered watch with id [{}]: [{}]", itemResponse.getId(), itemResponse.getFailureMessage());
329: Alexander Reelsen, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to update watch record [{}]", ctx.id()), e);
336: Alexander Reelsen, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to delete triggered watch [{}]", ctx.id()), e);
340: Alexander Reelsen, debug, TryStmt, logger.debug("finished [{}]/[{}]", watchId, ctx.id());
311: Alexander Reelsen, debug, IfStmt, logger.debug("not executing watch [{}]", watchId);
304: Alexander Reelsen, debug, IfStmt, logger.debug("executing watch [{}]", watchId);
284: Alexander Reelsen, trace, IfStmt, logger.trace("not executing watch [{}] because it is already queued", watchId);
395: Alexander Reelsen, warn, IfStmt, logger.warn("failed to execute watch [{}]", ctx.id().watchId());
393: Alexander Reelsen, debug, IfStmt, logger.debug((Supplier<?>) () -> new ParameterizedMessage("failed to execute watch [{}]", ctx.id().watchId()), e);
421: Alexander Reelsen, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("Error storing watch history record for watch [{}] after thread pool rejection", triggeredWatch.id()), exc);
429: Alexander Reelsen, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("Error deleting triggered watch store record for watch [{}] after thread pool " + "rejection", triggeredWatch.id()), exc);
510: Alexander Reelsen, debug, MethodDeclaration, logger.debug("triggered execution of [{}] watches", counter);
34: Jason Tedor, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to process triggered events [{}]", (Object) stream(events.spliterator(), false).toArray(size -> new TriggerEvent[size])), e);
98: Michael Basnight, trace, CatchClause, logger.trace((Supplier<?>) () -> new ParameterizedMessage("error getting index meta data [{}]: ", TriggeredWatchStoreField.INDEX_NAME), e);
90: Alexander Reelsen, debug, IfStmt, logger.debug("triggered watch index [{}] is marked as closed, watcher cannot be started", indexMetaData.getIndex().getName());
152: Alexander Reelsen, trace, MethodDeclaration, logger.trace("successfully deleted triggered watch with id [{}]", wid);
202: Jay Modi, debug, TryStmt, logger.debug("trying to find triggered watches for ids {}: found [{}] docs", ids, response.getHits().getTotalHits());
88: Alexander Reelsen, debug, TryStmt, logger.debug("indexed watch history record [{}]", watchRecord.id().value());
129: Alexander Reelsen, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to persist watch record [{}]", wr), ioe);
125: Alexander Reelsen, debug, CatchClause, logger.debug("overwrote watch history record [{}]", watchRecord.id().value());
115: Alexander Reelsen, debug, TryStmt, logger.debug("indexed watch history record [{}]", watchRecord.id().value());
45: Alexander Reelsen, error, CatchClause, logger.error("failed to execute [{}] input for watch [{}], reason [{}]", TYPE, ctx.watch().id(), e.getMessage());
51: Alexander Reelsen, error, CatchClause, logger.error("failed to execute [{}] input for watch [{}], reason [{}]", TYPE, ctx.watch().id(), e.getMessage());
77: Alexander Reelsen, warn, IfStmt, logger.warn("[{}] [{}] input expected content type [{}] but read [{}] from headers, using expected one", type(), ctx.id(), input.getExpectedResponseXContentType(), responseContentType);
63: Alexander Reelsen, error, CatchClause, logger.error("failed to execute [{}] input for watch [{}], reason [{}]", TYPE, ctx.watch().id(), e.getMessage());
70: Martijn van Groningen, trace, IfStmt, logger.trace("[{}] running query for [{}] [{}]", ctx.id(), ctx.watch().id(), request.getSearchSource().utf8ToString());
78: uboness, debug, IfStmt, logger.debug("[{}] found [{}] hits", ctx.id(), response.getHits().getTotalHits());
80: Alexander Reelsen, debug, ForeachStmt, logger.debug("[{}] hit [{}]", ctx.id(), hit.getSourceAsMap());
140: Yannick Welsch, error, CatchClause, logger.error("failed to close email transport for account [{}]", config.name);
138: Alexander Reelsen, trace, IfStmt, logger.trace("Watch[{}] reporting[{}] pdf is not ready, polling in [{}] again", context.watch().id(), attachment.id(), TimeValue.timeValueMillis(sleepMillis));
178: Alexander Reelsen, trace, IfStmt, logger.trace("Watch[{}] reporting[{}] invalid interval configuration [{}], using configured default [{}]", context.watch().id(), attachment.id(), attachment.interval(), this.interval);
91: uboness, error, CatchClause, logger.error("failed to execute hipchat api http request", e);
91: uboness, error, CatchClause, logger.error("failed to execute hipchat api http request", e);
104: uboness, error, CatchClause, logger.error("failed to execute hipchat api http request", e);
86: uboness, error, CatchClause, logger.error("failed to execute hipchat api http request", e);
67: Alexander Reelsen, error, ConstructorDeclaration, ESLoggerFactory.getLogger(getClass()).error("THE URL WAS [{}]", url);
118: uboness, error, CatchClause, logger.error("failed to execute slack api http request", e);
97: David Roberts, trace, IfStmt, logger.trace("not adding index template [{}], because it already exists", templateName);
93: David Roberts, debug, IfStmt, logger.debug("adding index template [{}], because it doesn't exist", templateName);
116: Jay Modi, Error, IfStmt, logger.error("Error adding watcher template [{}], request was not acknowledged", templateName);
123: Jay Modi, error, MethodDeclaration, logger.error(new ParameterizedMessage("Error adding watcher template [{}]", templateName), e);
43: Jason Tedor, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to execute [{}] transform for [{}]", TYPE, ctx.id()), e);
55: Jason Tedor, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("failed to execute [{}] transform for [{}]", TYPE, ctx.id()), e);
106: Jay Modi, error, CatchClause, logger.error(new ParameterizedMessage("failed to parse [{}]", request.getId()), e);
105: Alexander Reelsen, error, MethodDeclaration, logger.error(new ParameterizedMessage("could not update watcher stopped status to [{}], source [{}]", manuallyStopped, source), e);
95: Alexander Reelsen, debug, IfStmt, logger.debug("triggered job [{}] at [{}] (scheduled time was [{}])", schedule.name, new DateTime(triggeredTime, UTC), new DateTime(scheduledTime, UTC));
158: Alexander Reelsen, trace, WhileStmt, logger.trace("checking jobs [{}]", new DateTime(clock.millis(), UTC));
170: Brian Murphy, trace, MethodDeclaration, logger.trace("stopping ticker thread");
175: Brian Murphy, warn, CatchClause, logger.warn("caught an interrupted exception when waiting while closing ticker thread", e);
178: Brian Murphy, trace, MethodDeclaration, logger.trace("ticker thread stopped");
109: Michael Basnight, trace, IfStmt, logger.trace("parsing watch [{}] ", source.utf8ToString());
434: Alexander Reelsen, info, MethodDeclaration, logger.info("Testing [{}] documents with [{}] shards", numberOfDocuments, numberOfShards);
283: Simon Willnauer, info, MethodDeclaration, logger.info("email action json [{}]", bytes.utf8ToString());
378: Simon Willnauer, info, MethodDeclaration, logger.info("{}", bytes.utf8ToString());
445: Lee Hinman, info, MethodDeclaration, logger.info("JSON: {}", Strings.toString(builder));
480: Lee Hinman, info, MethodDeclaration, logger.info("JSON: {}", Strings.toString(builder));
186: Simon Willnauer, info, MethodDeclaration, logger.info("hipchat action json [{}]", bytes.utf8ToString());
259: Simon Willnauer, info, MethodDeclaration, logger.info("{}", bytes.utf8ToString());
67: Tanguy Leroux, info, MethodDeclaration, logger.info("jira action json [{}]", bytes.utf8ToString());
86: Tanguy Leroux, info, MethodDeclaration, logger.info("{}", bytes.utf8ToString());
122: uboness, INFO, MethodDeclaration, assertThat(executable.action().level, level == null ? is(LoggingLevel.INFO) : is(level));
186: Simon Willnauer, info, MethodDeclaration, logger.info("pagerduty action json [{}]", bytes.utf8ToString());
157: Simon Willnauer, info, MethodDeclaration, logger.info("slack action json [{}]", bytes.utf8ToString());
182: Simon Willnauer, info, MethodDeclaration, logger.info("{}", bytes.utf8ToString());
510: Alexander Reelsen, error, CatchClause, logger.error((Supplier<?>) () -> new ParameterizedMessage("Error in writing non HTTP response"), e);
43: Lee Hinman, info, CatchClause, logger.info("http connection timed out after {}", timeout);
69: Lee Hinman, info, CatchClause, logger.info("http connection timed out after {}", timeout);
96: Lee Hinman, info, CatchClause, logger.info("http connection timed out after {}", timeout);
54: Lee Hinman, info, MethodDeclaration, logger.info("http connection timed out after {}", timeout);
76: Lee Hinman, info, MethodDeclaration, logger.info("http connection timed out after {}", timeout);
99: Lee Hinman, info, MethodDeclaration, logger.info("http connection timed out after {}", timeout);
105: Jason Tedor, debug, MethodDeclaration, logger.debug("op [{}]", op);
106: Jason Tedor, debug, MethodDeclaration, logger.debug("value [{}]", value);
107: Jason Tedor, debug, MethodDeclaration, logger.debug("numberOfValues [{}]", numberOfValues);
108: Jason Tedor, debug, MethodDeclaration, logger.debug("values [{}]", values);
109: Jason Tedor, debug, MethodDeclaration, logger.debug("quantifier [{}]", quantifier);
110: Jason Tedor, debug, MethodDeclaration, logger.debug("met [{}]", met);
135: Jason Tedor, debug, MethodDeclaration, logger.debug("op [{}]", op);
136: Jason Tedor, debug, MethodDeclaration, logger.debug("value [{}]", value);
137: Jason Tedor, debug, MethodDeclaration, logger.debug("numberOfValues [{}]", numberOfValues);
138: Jason Tedor, debug, MethodDeclaration, logger.debug("values [{}]", values);
139: Jason Tedor, debug, MethodDeclaration, logger.debug("quantifier [{}]", quantifier);
140: Jason Tedor, debug, MethodDeclaration, logger.debug("met [{}]", met);
1002: Alexander Reelsen, info, ForStmt, tasks.add(new ExecutionService.WatchExecutionTask(ctx, () -> logger.info("this will never be called")));
59: Alexander Reelsen, info, TryStmt, logger.info("checking index [{}] with metadata:\n[{}]", metadatas.key, metadata.source().toString());
37: Lee Hinman, info, MethodDeclaration, logger.info("JSON: {}", Strings.toString(builder));
61: Lee Hinman, info, MethodDeclaration, logger.info("JSON: {}", Strings.toString(builder));
107: Lee Hinman, info, MethodDeclaration, logger.info("JSON is: {}", Strings.toString(builder));
134: Lee Hinman, info, MethodDeclaration, logger.info("JSON is: " + Strings.toString(builder));
56: Yannick Welsch, error, CatchClause, logger.error("Unexpected failure", e);
153: Lee Hinman, info, MethodDeclaration, logger.info("expected (r1): {}", BytesReference.bytes(jsonBuilder().value(reqR1)).utf8ToString());
180: Lee Hinman, info, MethodDeclaration, logger.info("expected (r2): {}", BytesReference.bytes(jsonBuilder().value(reqR1)).utf8ToString());
204: Lee Hinman, info, MethodDeclaration, logger.info("expected (u1): {}", BytesReference.bytes(jsonBuilder().value(reqU1)).utf8ToString());
228: Lee Hinman, info, MethodDeclaration, logger.info("expected (u2): {}", BytesReference.bytes(jsonBuilder().value(reqU2)).utf8ToString());
134: Lee Hinman, info, MethodDeclaration, logger.info("expected (r1): {}", BytesReference.bytes(jsonBuilder().value(req1)).utf8ToString());
157: Lee Hinman, info, MethodDeclaration, logger.info("expected (r2): {}", BytesReference.bytes(jsonBuilder().value(req2)).utf8ToString());
188: Boaz Leskes, info, IfStmt, logger.info("[{}#{}]: freezing time on nodes", getTestClass().getSimpleName(), getTestName());
202: Alexander Reelsen, info, MethodDeclaration, logger.info("[#{}]: clearing watcher state", getTestName());
227: Alexander Reelsen, info, IfStmt, logger.info("set alias for .watches index to [{}]", watchIndexName);
245: Alexander Reelsen, info, IfStmt, logger.info("set alias for .triggered-watches index to [{}]", triggeredWatchIndexName);
253: Alexander Reelsen, info, IfStmt, logger.info("creating watch history index [{}]", historyIndex);
348: Simon Willnauer, info, CatchClause, logger.info("Found [{}] records for watch [{}]", searchResponse.getHits().getTotalHits(), watchName);
351: Martijn van Groningen, info, ForeachStmt, logger.info("hit [{}]=\n {}", counter++, XContentHelper.convertToJson(hit.getSourceRef(), true, true));
400: Simon Willnauer, info, CatchClause, logger.info("Found [{}] records for watch [{}]", searchResponse.getHits().getTotalHits(), watchName);
403: Martijn van Groningen, info, ForeachStmt, logger.info("hit [{}]=\n {}", counter++, XContentHelper.convertToJson(hit.getSourceRef(), true, true));
453: Alexander Reelsen, info, LambdaExpr, logger.info("waiting to start watcher, current states {}", currentStatesFromStatsRequest);
498: Alexander Reelsen, info, LambdaExpr, logger.info("waiting to stop watcher, current states {}", currentStatesFromStatsRequest);
40: Michael Basnight, info, ConstructorDeclaration, logger.info("using time warped watchers plugin");
111: Alexander Reelsen, TRACE, ForStmt, client.prepareIndex(Watch.INDEX, Watch.DOC_TYPE, id).setSource(new WatchSourceBuilder().trigger(schedule(interval(interval + "s"))).input(searchInput(templateRequest(new SearchSourceBuilder(), "test"))).condition(new ScriptCondition(new Script(ScriptType.INLINE, Script.DEFAULT_SCRIPT_LANG, "ctx.payload.hits.total > 0", emptyMap()))).addAction("logging", ActionBuilders.loggingAction("test").setLevel(LoggingLevel.TRACE)).buildAsBytes(XContentType.JSON), XContentType.JSON).get();
351: Alexander Reelsen, info, MethodDeclaration, logger.info("created watch [{}] at [{}]", watchName, new DateTime(Clock.systemUTC().millis()));
224: Alexander Reelsen, info, MethodDeclaration, logger.info("Added [{}] triggered watches for [{}] different watches, starting watcher again", numRecords, numWatches);
292: Alexander Reelsen, info, LambdaExpr, logger.info("Watches not executed: [{}]: expected watch history count [{}] - [{}] successful watch exections", notExecutedCount, expectedWatchHistoryCount, successfulWatchExecutions);
320: Alexander Reelsen, info, MethodDeclaration, logger.info("Stopping watcher");
343: Alexander Reelsen, info, MethodDeclaration, logger.info("Starting watcher");
91: Alexander Reelsen, info, MethodDeclaration, logger.info("###3");
93: Alexander Reelsen, info, MethodDeclaration, logger.info("###4");
110: Alexander Reelsen, info, MethodDeclaration, logger.info("###5");
112: Alexander Reelsen, info, MethodDeclaration, logger.info("###6");
73: Martijn van Groningen, DEBUG, MethodDeclaration, LoggingAction.Builder loggingAction = loggingAction(new TextTemplate("_logging")).setLevel(LoggingLevel.DEBUG).setCategory("test");
91: Martijn van Groningen, info, MethodDeclaration, logger.info("result=\n{}", result);
108: Martijn van Groningen, info, IfStmt, logger.info("testing script transform with an indexed script");
105: Martijn van Groningen, info, IfStmt, logger.info("testing script transform with an inline script");
68: Alexander Reelsen, info, MethodDeclaration, logger.info("Waiting for watch to be executed at least once");
87: Alexander Reelsen, info, MethodDeclaration, logger.info("Ensured no more watches are being executed");
91: Alexander Reelsen, info, MethodDeclaration, logger.info("Sleeping for 5 seconds, watch history count [{}]", count1);
100: Alexander Reelsen, info, MethodDeclaration, logger.info("Activating watch again");
110: Alexander Reelsen, info, MethodDeclaration, logger.info("Sleeping for another five seconds, ensuring that watch is executed");
65: Alexander Reelsen, debug, MethodDeclaration, logger.debug("adding watch [{}]", watch.id());
94: Alexander Reelsen, trace, IfStmt, logger.trace("not executing job [{}], not found", jobName);
100: Alexander Reelsen, debug, ForStmt, logger.debug("firing watch [{}] at [{}]", jobName, now);
46: Yannick Welsch, info, ForeachStmt, logger.info("expression: {}", expression);
86: Alexander Reelsen, info, IfStmt, logger.info("job [{}] second fire", index);
82: Alexander Reelsen, info, IfStmt, logger.info("job [{}] first fire", index);
116: Alexander Reelsen, info, ForeachStmt, logger.info("triggered job on [{}]", clock);
126: Alexander Reelsen, info, MethodDeclaration, logger.info("Setting current time to [{}], job execution time [{}]", testNowTime, scheduledTime);
149: Alexander Reelsen, info, ForeachStmt, logger.info("triggered job on [{}]", new DateTime(clock.millis(), UTC));
161: Alexander Reelsen, info, MethodDeclaration, logger.info("Setting current time to [{}], job execution time [{}]", testNowTime, scheduledTime);
183: Alexander Reelsen, info, ForeachStmt, logger.info("triggered job");
197: Alexander Reelsen, info, MethodDeclaration, logger.info("Setting current time to [{}], job execution time [{}]", testNowTime, scheduledTime);
218: Simon Willnauer, info, MethodDeclaration, logger.info("{}", bytes.utf8ToString());
122: jaymode, info, IfStmt, logger.info("found audit index [{}]", cursor.value);
134: Jay Modi, info, LambdaExpr, logger.info("security audit log index is yellow");
138: Jay Modi, info, LambdaExpr, logger.info("refreshing audit indices");
140: Jay Modi, info, LambdaExpr, logger.info("refreshed audit indices");
127: Jay Modi, info, IfStmt, logger.info("settings response map {}", settingsResponseMap);
138: Jay Modi, info, IfStmt, logger.info("settings map {}", settingsMap);
148: Jay Modi, info, IfStmt, logger.info("upgrading security index {}", concreteSecurityIndex);
159: Jay Modi, info, IfStmt, logger.info("upgrade response:\n{}", toStr(upgradeResponse));
195: Igor Motov, info, IfStmt, logger.info("testing against {}", oldClusterVersion);
198: Jay Modi, info, IfStmt, logger.info("checking if the upgrade procedure on the new cluster is required");
200: Alexander Reelsen, info, IfStmt, logger.info(response);
223: Jay Modi, info, IfStmt, logger.info("upgrade procedure is not required for watcher");
204: Jay Modi, info, IfStmt, logger.info("upgrade procedure is required for watcher");
210: Jay Modi, info, IfStmt, logger.info("starting upgrade procedure on the new cluster");
218: Jay Modi, info, IfStmt, logger.info("checking that upgrade procedure on the new cluster is no longer required");
177: Tanguy Leroux, info, IfStmt, logger.info("Adding a watch on old cluster {}", oldClusterVersion);
181: Igor Motov, info, IfStmt, logger.info("Adding a watch with \"fun\" throttle periods on old cluster");
185: Igor Motov, info, IfStmt, logger.info("Adding a watch with \"fun\" read timeout on old cluster");
189: Igor Motov, info, IfStmt, logger.info("Waiting for watch results index to fill up...");
193: Igor Motov, info, IfStmt, logger.info("Done creating watcher-related indices");
291: Igor Motov, error, MethodDeclaration, logger.error("-----> {}", bwcWatch);
346: Igor Motov, info, MethodDeclaration, logger.info(put);
117: David Kyle, info, ForeachStmt, logger.info(i++ + ":\n" + nodeHotThreads.getHotThreads());
321: Dimitrios Athanasiou, debug, MethodDeclaration, logger.debug("Posting data to job [{}]:\n{}", jobId, data);
489: Dimitrios Athanasiou, error, CatchClause, logger.error("Cluster state from master:\n{}\nLocal cluster state:\n{}", masterClusterState.toString(), localClusterState.toString());
199: Martijn van Groningen, info, ForeachStmt, logger.info("params={}", mapAsJson);
356: Zachary Tong, error, CatchClause, logger.error(e.getMessage());
351: Zachary Tong, error, IfStmt, logger.error(responseBody);
123: Jay Modi, info, ForeachStmt, logger.info("testing connect as user [{}]", user);
84: Jay Modi, error, CatchClause, logger.warn("error calling template api", e);
82: Jay Modi, debug, TryStmt, logger.debug("template [{}] exists [{}]", template, exists);
67: Jay Modi, debug, MethodDeclaration, logger.debug("aggResponse {}", aggResponseMap);
149: Tim Vernum, warn, CatchClause, logger.warn(new ParameterizedMessage("Failure while handling {}", http.getRequestURI()), e);
447: Tim Vernum, info, MethodDeclaration, logger.info("Execute HTTP " + request.getMethod() + ' ' + request.getURI());
451: Tim Vernum, warn, CatchClause, logger.warn(new ParameterizedMessage("HTTP Request [{}] failed", request.getURI()), e);
470: Tim Vernum, info, MethodDeclaration, logger.info("Created SAML authentication request {}", body);
55: Jason Tedor, info, MethodDeclaration, logger.info("--> CONF: {}", testConfigDir);
60: Lee Hinman, info, MethodDeclaration, logger.info("--> using URL: {}", url);
68: Lee Hinman, info, MethodDeclaration, logger.info("--> output:\n{}", t.getOutput());
69: Lee Hinman, info, MethodDeclaration, logger.info("--> Starting Elasticsearch Java TransportClient {}, {}", transportAddresses, tempDir);
81: jaymode, info, TryStmt, logger.info("--> Elasticsearch Java TransportClient started");
83: Lee Hinman, info, TryStmt, logger.info("--> connected to [{}] cluster which is running [{}] node(s).", health.getClusterName(), health.getNumberOfNodes());
119: Lee Hinman, error, CatchClause, logger.error("could not start the client", e);
51: Jay Modi, info, MethodDeclaration, logger.info("--> CONF: {}", testConfigDir);
87: Jay Modi, info, MethodDeclaration, logger.info("CLI TOOL OUTPUT:\n{}", output);
95: Jay Modi, info, IfStmt, logger.info("user [{}] password [{}]", user, password);
149: Tim Vernum, info, ForStmt, logger.info("instance [{}] name [{}] [{}]", i, name, instanceInfo);
168: Tim Vernum, info, MethodDeclaration, logger.info("certificate tool output:\n{}", terminal.getOutput());
160: jaymode, info, ForStmt, logger.info("instance [{}] name [{}] [{}]", i, name, instanceInfo);
179: jaymode, info, MethodDeclaration, logger.info("certificate tool output:\n{}", terminal.getOutput());
97: Martijn van Groningen, error, IfStmt, logger.error("at [{}] expected [{}] but got [{}]", l, renderedTemplate.charAt(l), escapedString.charAt(l));
628: Costin Leau, warn, CatchClause, logger.warn("Failed to find an audit log. Skipping remaining tests in this class after this the missing audit" + "logs could turn up later.");
114: Nik Everett, info, TryStmt, logger.info("cli exited with code [{}]", exitCode);
129: Nik Everett, info, IfStmt, logger.info("out: {}", security.keystorePassword);
148: Nik Everett, info, IfStmt, logger.info("out: {}", security.password);
243: Costin Leau, info, MethodDeclaration, logger.info("out: {};", command);
280: Costin Leau, info, MethodDeclaration, logger.info("in : {}", line);
306: Costin Leau, info, MethodDeclaration, logger.info("in : {}", result);
152: Costin Leau, info, IfStmt, logger.info("^^^ Assertion failure ^^^");
153: Costin Leau, info, IfStmt, logger.info(JdbcTestUtils.resultSetCurrentData(actual));
117: Costin Leau, info, IfStmt, logger.info(JdbcTestUtils.resultSetCurrentData(actual));
39: Costin Leau, info, MethodDeclaration, logger.info(sb.toString());
45: Costin Leau, info, MethodDeclaration, logger.info(sb.toString());
66: Costin Leau, info, WhileStmt, log.info(sb);
113: Jay Modi, info, MethodDeclaration, ESLoggerFactory.getLogger("test").info("running test with realm configuration [{}], with direct group to role mapping [{}]. " + "Settings [{}]", realmConfig, realmConfig.mapGroupsAsRoles, realmConfig.settings);
189: Tim Vernum, info, ForeachStmt, logger.info("Created native role-mapping {} : {}", mappingName, response.isCreated());
425: Jay Modi, info, IfStmt, logger.info("using bind user [{}] with pooling enabled [{}]", user, poolingEnabled);
35: Tim Vernum, info, MethodDeclaration, ESLoggerFactory.getLogger("test").info("running test with secondary realm configuration [{}], with direct group to role mapping [{}]. Settings [{}]", secondaryRealmConfig, secondaryRealmConfig.mapGroupsAsRoles, secondaryRealmConfig.settings);
74: Colin Goodheart-Smithe, info, MethodDeclaration, logger.info("--> Elasticsearch Java TransportClient started");
82: Colin Goodheart-Smithe, Error, CatchClause, logger.error("Error getting cluster health", e);
79: Colin Goodheart-Smithe, info, TryStmt, logger.info("--> connected to [{}] cluster which is running [{}] node(s).", health.getClusterName(), health.getNumberOfNodes());
110: Colin Goodheart-Smithe, error, CatchClause, logger.error("can not start the client", e);
